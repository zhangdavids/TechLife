<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[EFK使用]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F05%2F02%2FEFK%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[EFK不是一个软件，而是一套解决方案，并且都是开源软件，之间互相配合使用，完美衔接，高效的满足了很多场合的应用，是目前主流的一种日志系统。EFK是三个开源软件的缩写，分别表示：Elasticsearch , FileBeat, Kibana , 其中ELasticsearch负责日志保存和搜索，FileBeat负责收集日志，Kibana 负责界面,当然EFK和大名鼎鼎的ELK只有一个区别，那就是EFK把ELK的Logstash替换成了FileBeat，因为Filebeat相对于Logstash来说有2个好处：1、侵入低，无需修改程序目前任何代码和配置2、相对于Logstash来说性能高，Logstash对于IO占用很大当然FileBeat也并不是完全好过Logstash，毕竟Logstash对于日志的格式化这些相对FileBeat好很多，FileBeat只是将日志从日志文件中读取出来，当然如果你日志本身是有一定格式的，FileBeat也可以格式化，但是相对于Logstash来说，还是差一点 Filebeat隶属于Beats。目前Beats包含六种工具：Packetbeat（搜集网络流量数据）Metricbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）Filebeat（搜集文件数据）Winlogbeat（搜集 Windows 事件日志数据）Auditbeat（ 轻量型审计日志采集器）Heartbeat（轻量级服务器健康采集器） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283wget http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz?AuthParam=1536892035_945cb24c750d0971b8c5b1925cc723a9mv jdk-8u181-linux-x64.tar.gz\?AuthParam\=1536892035_945cb24c750d0971b8c5b1925cc723a9 jdk-8u181-linux-x64.tar.gztar -zxvf jdk-8u181-linux-x64.tar.gz# 编辑环境变量 vi /etc/profileJAVA_HOME=/usr/local/jdk1.8.0_181/JRE_HOME=$JAVA_HOME/jreCLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATHsource /etc/profilejava -versionwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.4.tar.gztar -zxvf elasticsearch-6.2.4.tar.gzvi config/elasticsearch.ymlnetwork.host: 0.0.0.0 http.port: 9200$ adduser elastic#设置密码$ passwd elastic#需要输入2次密码#授权$ chmod -R 777 /usr/local/elasticsearch-6.2.4#切换用户$ su elastic./bin/elasticsearchvi /etc/security/limits.conf vi /etc/sysctl.confsysctl -pwget https://artifacts.elastic.co/downloads/kibana/kibana-6.2.4-linux-x86_64.tar.gztar -zxvf kibana-6.2.4-linux-x86_64.tar.gzvi config/kibana.ymlelasticsearch.url: &quot;http://localhost:9200&quot;server.host: &quot;0.0.0.0&quot;kibana.index: &quot;.kibana&quot;./bin/kibanawget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.4-linux-x86_64.tar.gztar -zxvf filebeat-6.2.4-linux-x86_64.tar.gzvi filebeat.ymlfilebeat.prospectors:- type: log enabled: true paths: - /var/xxx/*.log - /var/xxx/*.out multiline.pattern: ^\[ multiline.negate: true multiline.match: aftersetup.kibana: host: &quot;localhost:5601&quot;output.elasticsearch: hosts: [&quot;localhost:9200&quot;]./filebeat -c /usr/local/filebeat/filebeat.yml端口 9200/5601/]]></content>
  </entry>
  <entry>
    <title><![CDATA[异步编程（python3）]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F05%2F02%2F%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%EF%BC%88python3%EF%BC%89%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python装饰器总结]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F05%2F02%2Fpython%E8%A3%85%E9%A5%B0%E5%99%A8%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[写一个记录函数运行时间的装饰器123456789101112131415161718192021222324252627from functools import wrapsimport time# 使用直接装饰器 @listener(Monitor)class Monitor(object): @staticmethod def start_monitor(): return time.clock() @staticmethod def end_monitor(): return time.clock()def listener(listen): def log(func): @wraps(func) def wrapper(*args, **kw): startime = listen.start_monitor() f = func(*args, **kw) endtime = listen.end_monitor() print(&quot;total time is &#123;0&#125;&quot;.format(startime-endtime)) return f return wrapper return log 一个函数 挂多个装饰器的执行顺序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# -*- coding: utf-8 -*-import functools# 采用functools.wraps的目的是为了使装饰器返回的类型始终是func的类型，否则将返回嵌套高阶函数的中的类型，例如返回的是wraper# 采用参数*args ,**kw是解决函数多参数的问题def log(func): @functools.wraps(func) def wrapper(*args, **kw): print(&apos;call %s():&apos; % func.__name__) return func(*args, **kw) return wrapper# 修饰器参数的情况def logger(pram): def log(func): @functools.wraps(func) def wrapper(*args, **kw): print(&apos;call %s(): and parsms is %s&apos; %(func.__name__,pram)) return func(*args, **kw) return wrapper return log@logdef showMesage(name,age): print(&quot;my name is &#123;0&#125; and my age is &#123;1&#125;&quot;.format(name,age))@logger(&quot;hello&quot;)def getMessage(name,age): print(&quot;my name is &#123;0&#125; and my age is &#123;1&#125;&quot;.format(name,age))# 添加多个修饰器来拓展所需的功能@log@logger(&quot;hello15466&quot;)def recieveMessage(name,age): print(&quot;my name is &#123;0&#125; and my age is &#123;1&#125;&quot;.format(name,age))if __name__==&apos;__main__&apos;: # showMesage(&quot;ddd&quot;,21) # getMessage(&quot;aaa&quot;,43) recieveMessage(&quot;ccc&quot;,34) 类装饰器带参数的装饰器]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-web的未来]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F05%2F01%2Fpython-web%E7%9A%84%E6%9C%AA%E6%9D%A5%2F</url>
    <content type="text"><![CDATA[没有人愿意从事即将过时的技术 学习过气的技术 Django 主要是为web开发服务的 基于MVC的MTV模型 非常适合开发基于PC的传统网站，因为它同时包括了后端的开发(逻辑层，数据库层) 和前端的开发(如模板语言，样式)。基于PC的网站和自适应(responsive)的手机网站不会消失，不过其重要性会随着手机APP和小程序等的普及而逐渐降低。即使对于开发传统网站，Django也只有在后台开发上有些优势，在前端仍需要借助流行的JS框架如Vue.js才能开发出互动性强且符合未来审美趋势的优秀网站来。 最近几年及未来几年更流行的开发模式肯定是前后端分离。现代网络应用Web APP或大型网站一般是一个后台，然后对应各种客户端(iOS, android, 浏览器)。由于客户端的开发语言与后台的开发语言经常不一样，这时需要后台能够提供可以跨平台跨语言的一种标准的资源或数据(如Json格式)供前后端沟通，这就是Web API(网络应用程序结口)的作用了。Django本身开发不了符合REST规范的Web API, 不过借助django-rest-framework (DRF)可以快速开发出优秀规范的Web API来。所以我们这里要感谢DRF，因为它，Django的应用前景更广了，减少了被淘汰的风险。 web开发 一定会有 网络爬虫 计算与数据分析 人工智能 自动化运维 云计算 Python的最强大之处在于模块化和灵活性，而构建云计算的平台的IasS服务的OpenStack就是采用Python的，云计算的其他服务也都是在IasS服务之上的。 网络编程 Python提供了丰富的模块支持sockets编程，能方便快速地开发分布式应用程序。很多大规模软件开发计划例如Zope，Mnet, BitTorrent和Google都在广泛地使用它。 游戏开发 对比flask]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python爬虫要点]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F05%2F01%2Fpython%E7%88%AC%E8%99%AB%E8%A6%81%E7%82%B9%2F</url>
    <content type="text"><![CDATA[分块 抓取 解析 存储 反爬 加速 抓取爬虫的目标绝大多数是网页 少部分是app 网页分为两种 服务端渲染和客户端渲染 app 分为四种 普通接口 加密参数接口 加密内容接口 非常规协议接口 服务端有效的信息在HTML页面里 真实的数据 一般通过ajax接口形式进行获取的 服务端渲染 一般基本的http库 就可以爬取 客户端寻找 Ajax 接口，此种情形可以直接使用 Chrome/Firefox 的开发者工具直接查看 Ajax 具体的请求方式、参数等内容，然后用 HTTP 请求库模拟即可，另外还可以通过设置代理抓包来查看接口，如 Fiddler/Charles。 模拟浏览器执行，此种情形适用于网页接口和逻辑较为复杂的情况，可以直接以可见即可爬的方式进行爬取，如可以使用 Selenium、Splinter、Spynner、pyppeteer、PhantomJS、Splash、requests-html 等来实现。 直接提取 JavaScript 数据，此种情形适用于真实数据没有经过 Ajax 接口获取，而是直接包含在 HTML 结果的某个变量中，直接使用正则表达式将其提取即可。 模拟执行 JavaScript，某些情况下直接模拟浏览器执行效率会偏低，如果我们把 JavaScript 的某些执行和加密逻辑摸清楚了，可以直接执行相关的 JavaScript 来完成逻辑处理和接口请求，比如使用 Selenium、PyExecJS、PyV8、js2py 等库来完成即可。 对于普通无加密接口，这种直接抓包拿到接口的具体请求形式就好了，可用的抓包工具有 Charles、Fiddler、mitmproxy。 对于加密参数的接口，一种方法可以实时处理，例如 Fiddler、mitmdump、Xposed 等，另一种方法是将加密逻辑破解，直接模拟构造即可，可能需要一些反编译的技巧。 对于加密内容的接口，即接口返回结果完全看不懂是什么东西，可以使用可见即可爬的工具 Appium，也可以使用 Xposed 来 hook 获取渲染结果，也可以通过反编译和改写手机底层来实现破解。 对于非常规协议，可以使用 Wireshark 来抓取所有协议的包，或者使用 Tcpdump 来进行 TCP 数据包截获。 解析基本上两种 css xpath 一些其他接口 json xml 使用对应的库即可处理 智能解析意思就是说，如果能提供一个页面，算法可以自动来提取页面的标题、正文、日期等内容，同时把无用的信息给刨除。对于智能解析，分为四个方法进行了划分： readability 算法，这个算法定义了不同区块的不同标注集合，通过权重计算来得到最可能的区块位置。 疏密度判断，计算单位个数区块内的平均文本内容长度，根据疏密程度来大致区分。 Scrapyly 自学习，是 Scrapy 开发的组件，指定⻚页⾯面和提取结果样例例，其可⾃自学习提取规则，提取其他同类⻚页⾯面。 深度学习，使⽤用深度学习来对解析位置进⾏行行有监督学习，需要⼤大量量标注数据。如果能够容忍一定的错误率，可以使用智能解析来大大节省时间。 存储即选用合适的存储媒介来存储爬取到的结果，这里还是分为四种存储方式来进行介绍。 文件，如 JSON、CSV、TXT、图⽚、视频、⾳频等，常用的一些库有 csv、xlwt、json、pandas、pickle、python-docx 等。 数据库，分为关系型数据库、非关系型数据库，如 MySQL、MongoDB、HBase 等，常用的库有 pymysql、pymssql、redis-py、pymongo、py2neo、thrift。 搜索引擎，如 Solr、ElasticSearch 等，便于检索和实现⽂本匹配，常用的库有 elasticsearch、pysolr 等。 云存储，某些媒体文件可以存到如七⽜牛云、又拍云、阿里云、腾讯云、Amazon S3 等，常用的库有 qiniu、upyun、boto、azure-storage、google-cloud-storage 等。 反爬现在爬虫已经越来越难了 非浏览器检测 封IP 验证码 封账户 字体反爬等 对于封 IP 的情况，可以分为几种情况来处理：首先寻找手机站点、App 站点，如果存在此类站点，反爬会相对较弱。使用代理，如抓取免费代理、购买付费代理、使用 Tor 代理、Socks 代理等。在代理的基础上维护自己的代理池，防止代理浪费，保证实时可用。搭建 ADSL 拨号代理，稳定高效。 验证码分为非常多种，如普通图形验证码、算术题验证码、滑动验证码、点触验证码、手机验证码、扫二维码等。对于普通图形验证码，如果非常规整且没有变形或干扰，可以使用 OCR 识别，也可以使用机器学习、深度学习来进行模型训练，当然打码平台是最方便的方式。对于算术题验证码，推荐直接使用打码平台。对于滑动验证码，可以使用破解算法，也可以模拟滑动。后者的关键在于缺口的找寻，可以使用图片比对，也可以写基本的图形识别算法，也可以对接打码平台，也可以使用深度学习训练识别接口。对于点触验证码，推荐使用打码平台。对于手机验证码，可以使用验证码分发平台，也可以购买专门的收码设备，也可以人工验证。对于扫二维码，可以人工扫码，也可以对接打码平台。 某些网站需要登录才能爬取，但是一个账号登录之后请求过于频繁会被封号，为了避免封号，可以采取如下措施：寻找手机站点或 App 站点，此种类别通常是接口形式，校验较弱。寻找无登录接口，尽可能寻找⽆无需登录即可爬取的接口。维护 Cookies 池，使⽤用批量账号模拟登录，使⽤时随机挑选可用 Cookies 使⽤即可，实现：https://github.com/Python3WebSpider/CookiesPool。 加速常见的措施 多线程 多进程 异步 分布式 细节优化 爬虫是网络请求密集型任务，所以使用多进程和多线程可以大大提高抓取效率，如使用 threading、multiprocessing 等。 将爬取过程改成非阻塞形式，当有响应式再进行处理，否则在等待时间内可以运行其他任务，如使用 asyncio、aiohttp、Tornado、Twisted、gevent、grequests、pyppeteer、pyspider、Scrapy 等。 分布式的关键在于共享爬取队列，可以使用 celery、huey、rq、rabbitmq、kafka 等来实现任务队列的对接，也可以使用现成的框架 pyspider、Scrapy-Redis、Scrapy-Cluster 等。 可以采取某些优化措施来实现爬取的加速，如： DNS 缓存 使用更快的解析方法 使用更高效的去重方法 模块分离化管控 如果搭建了分布式，要实现高效的爬取和管理调度、监控等操作，我们可以使用两种架构来维护我们的爬虫项目。 将 Scrapy 项目打包为 Docker 镜像，使用 K8S 控制调度过程。 将 Scrapy 项目部署到 Scrapyd，使用专用的管理工具如 SpiderKeeper、Gerapy 等管理。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python2-3迁移问题]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F30%2Fpython2-3%E8%BF%81%E7%A7%BB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[使用pathlib 处理更好的路径 类型现在是语言的一部分 运行时类型提示类型检查 使用@表示矩阵的乘法 **通配符的使用 print函数 数字文字的下划线（千位分隔符） 简单可看的字符串格式化f-string / 和 // 在数学运算当中有着明显的区别 严格的顺序 检查对象为None的合理方案 NLP unicode问题 保留了字典和**kwargs的顺序 可迭代对象拆包 提供了更高性能的pickle 更安全的列表推导 更简单的super（） IDE能够给出更好的提示 合并多个字典 1z = &#123;**x, **y&#125; 3.7加入data class类 存储数据对象 自定义对模块属性的访问 内置的断点 12breakout() # 3.7 加入 math 当中的常数 整数类型只有 int 代码变得更短 更易读 更安全]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提升工作效率的方法论006]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F29%2F%E6%8F%90%E5%8D%87%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA006%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[提升工作效率的方法论005]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F29%2F%E6%8F%90%E5%8D%87%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA005%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[提升工作效率的方法论004]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F29%2F%E6%8F%90%E5%8D%87%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA004%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[提升工作效率的方法论003]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F29%2F%E6%8F%90%E5%8D%87%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA003%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[提升工作效率的方法论002]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F29%2F%E6%8F%90%E5%8D%87%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA002%2F</url>
    <content type="text"><![CDATA[人月神话 优秀的程序员的开发效率是普通程序员的10倍 一个思考框架 我现在是一个什么水平 想达到一个什么水平 将怎样达到那个目标 通过资料搜集 对自己的未来有一个打算 未来有一个定位 往指定的方向努力 现状 目标 实现路径 四个思考原则 以始为终 任务分解 沟通反馈 自动化 设计验证码 找回密码 第三方登录 redis做缓存 手机号码接收验证码进行登录 做事情之前 先想想结果是怎样的 得到工作的要求 职业技能 知道如何使用 跑起来 深入研究源码 底层 如何改进？？？ 头脑中的创造 实际中的创造]]></content>
  </entry>
  <entry>
    <title><![CDATA[提升工作效率的方法论001]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F29%2F%E6%8F%90%E5%8D%87%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%E7%9A%84%E6%96%B9%E6%B3%95%E8%AE%BA001%2F</url>
    <content type="text"><![CDATA[人月神话 提到两个重要的概念 本质复杂度 偶然复杂度 选用的做事方法不当 导致要多做的事 忙碌解决的问题 都不是程序问题 而是由偶然复杂度导致的问题 选择了正确的做事方法 减少偶然复杂度带来的工作量 软件开发是可以有条不紊进行的 以始为终 任务分解 沟通反馈 自动化]]></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路000]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F27%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF000%2F</url>
    <content type="text"><![CDATA[始终是一名程序员 把信息世界看成一座大厦 程序员看成这个世界的建筑师 你在负责什么样的工作呢？ 搬砖师编程能力和业务基本上停留在堆叠代码 按照需求去实现功能需求的层面 只要能够让程序跑起来 能正确实现业务逻辑 可以被称为“会编程”的人 但是 只是让程序跑起来是不够的 更多的时间是维护代码 增加新的需求 对已有的功能进行调整 修改之前代码遗留下来的问题 优化性能等等 工程师代码的质量 可阅读性 可扩展性/可维护性 可测试性 可复用性 不会简单把写代码看做一门工作 把任务交代过去就完事 有代码洁癖 代码是一种艺术 是自己生命的一部分 会把写出来的代码改了又改 直到让自己满意为止 阅读和维护工程师的代码会有一种赏心悦目的感觉 架构师光靠把控软件工程师的水平 依赖他们自觉保障工程质量 是远远不够的 软件工程是一项非常复杂的系统工程 需要依赖一个能够掌控整个工程全局的团队 来规划和引导整个系统的演变过程 不单单是对软件系统进行边界划分和模块规格的定义 按时按质进行软件的迭代和发布 敏捷响应需求变更 防范软件质量风险 降低迭代维护成本 核心在四个字 掌控全局 架构思维类设计模式类分布式系统架构设计类重构类]]></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路010]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F27%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF010%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路009]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F27%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF009%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路008]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F27%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF008%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路007]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F27%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF007%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路006]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F27%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF006%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[操作系统之进程线程协程]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F24%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%8D%8F%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[两个线程操作同一临界区时，通过互斥锁保护，若A线程已经加锁，B线程再加锁时候会被阻塞，直到A释放锁，B再获得锁运行，进程B必须不停的主动获得锁、检查条件、释放锁、再获得锁、再检查、再释放，一直到满足运行的条件的时候才可以（而此过程中其他线程一直在等待该线程的结束），这种方式是比较消耗系统的资源的。而条件变量同样是阻塞，还需要通知才能唤醒，线程被唤醒后，它将重新检查判断条件是否满足，如果还不满足，该线程就休眠了，应该仍阻塞在这里，等待条件满足后被唤醒，节省了线程不断运行浪费的资源。这个过程一般用while语句实现。当线程B发现被锁定的变量不满足条件时会自动的释放锁并把自身置于等待状态，让出CPU的控制权给其它线程。其它线程 此时就有机会去进行操作，当修改完成后再通知那些由于条件不满足而陷入等待状态的线程。这是一种通知模型的同步方式，大大的节省了CPU的计算资源，减少了线程之间的竞争，而且提高了线程之间的系统工作的效率。这种同步方式就是条件变量。 如果学过java的话，其实就是线程之间的互斥和协作，条件变量就是用来协作的，对应java里wait()和notify()函数。]]></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路005]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F24%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF005%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路004]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F24%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF004%2F</url>
    <content type="text"><![CDATA[编程语言的出现，诞生了软件工程师（也叫做程序员）这样一个职业，而汇编语言则可以看做是软件工程师这个分工出现的标志。 通过编程语言，软件工程师和计算机可以进行交互，表达自己的思想。但是，如果我们把掌握编程语言看做是软件工程师的专业技能，其实又低估了编程语言带来的革命性变化。 编程语言在信息科技发展中的位置，如同人类文明中语言所在的位置。而编程语言写出来的软件（及其源代码），如同人类文明中不断被传承下来的图书典籍。 软件是活的书籍，有两个方面的理解 表达方式的多样性 对技术的现场还原 编程范式的进化 过程式 过程式就是以一条条命令的方式，让计算机按我们的意愿来执行 过程式编程最核心的两个概念是结构体和过程。通过结构体对数据进行组合，可以构建出任意复杂的自定义数据结构。通过过程可以抽象出任意复杂的自定义指令，复用以前的成果，简化意图的表达 函数式编程 本质上是过程式编程的一种约束，核心主张是变量不可变，函数尽可能没有副作用。在过程式编程中 数组是一个最常规的数据结构，但是在函数式编程中变量不可变，对某个下标的数组元素的修改，就需要复制整个数组，非常低效。在FP当中，需要通过一种复杂的平衡二叉树来实现一个使用界面（接口）上和过程式语言数组一致的“数组” 面向对象编程 引入了对象（类）和对象方法（类成员函数） 主张尽可能把方式（其实就是过程） 归纳到合适的对象（类）上 不主张全局函数（过程） 面向对象的核心思想是引入契约 基于对象这样一个概念对代码的使用界面进行抽象和封装 两个优点 清晰的使用界面 信息的封装 面向对象还有一个至关重要的概念是接口 通过接口 优雅实现过程式编程当中很费劲才能做到的一个能力： 多态 引入继承的概念 虽然带来了编码上的便捷性 但是带来了不必要的心智负担 本来复合对象的唯一构造方法是组合 现在多了一个选择 继承 GO语言的设计 是放弃了继承 全面强化组合 官方宣称是面向连接的语言 面向连接就是朴素的组合思想 研究连接 就是研究人与人如何组合 研究代码之间怎么组合 消息传递是多核背景下流行起来的一种编程思想 尽可能用消息传递来取代共享内存 从而尽可能避免显式的锁 降低编程负担 不只是提供了语言内建的消息传递机制 还因为消息传递是类型安全的 大大降低了犯错的机会 包 版本 文档生成 单元测试 语言对架构的影响是什么？？ 选择某种语言无关的接口表示 选择团队开发时采用的语言来描述接口 决策之一是开发效率 其二是后期的维护]]></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路003]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F23%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF003%2F</url>
    <content type="text"><![CDATA[CPU指令是一个有限的指令集 CPU执行的指令序列不是固定的 依赖于保存在存储中的数据 由软件工程师编写的软件决定 程序是计算机的灵魂 指令序列的可能性是无穷的 程序的可能性是无穷的 今天计算机创造的世界如此多姿多彩 正是得益于程序无穷的可能性 史前时代 为了解决编程效率的问题 汇编语言出现了 编译器将汇编语言写的程序编译为CPU指令序列 并将其保存到外置的存储设备（如硬盘）上 汇编语言解放的生产力是惊人的 有选择的话 没有人愿意用0101这样的东西来表达自己的思想 键盘和显示器的驱动程序 主流的外置存储设备 汇编程序编辑器 汇编编译器 可以执行一段保存在外置存储设备中的机器代码程序 不变的是 存储 编辑器 和 鼠标键盘磁盘的驱动程序和这些程序存储的位置 变化的是 用户输入的指令序列和位置 因为用户的输入的内容 可以由计算机来指定位置自动存储。]]></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路002]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F19%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF002%2F</url>
    <content type="text"><![CDATA[地基 冯 诺依曼 体系架构 需求 规格 为了解决一起的问题而生 引入了三类基础零部件 中央处理器 存储 输入输出设备 存储是负责存放计算涉及的相关数据 作为计算的输入参数和输出结果 以前就是指中央处理器内置支持的存储 输入输出设备 输入 键盘 鼠标输出 显示器 中央处理器 负责程序（指令序列）的执行 指令序列存放在存储里面 计算类 I/O类 指令跳转类 12func F(x []byte) (y []byte) x,y 物理上在存储 输入输出设备从根本上解决的问题是什么？ 是电脑无线可能的扩展能力 最重要的一点 输入输出设备和电脑是完全异构的 输入输出设备对电脑来说 就只是实现了某项能力的黑盒子]]></content>
  </entry>
  <entry>
    <title><![CDATA[openstack之keystone]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F18%2Fopenstack%E4%B9%8Bkeystone%2F</url>
    <content type="text"><![CDATA[一 基本概念 User 代表可以通过keystone进行访问的人或程序 通过认证信息进行验证 Tenant 是各个服务中的一些可以访问的资源集合 例如，在Nova中一个tenant可以是一些机器，在Swift和Glance中一个tenant可以是一些镜像存储，在Quantum中一个tenant可以是一些网络资源。Users默认的总是绑定到某些tenant上。 Role 即角色，Roles代表一组用户可以访问的资源权限，例如Nova中的虚拟机、Glance中的镜像。Users可以被添加到任意一个全局的 或 租户内的角色中。在全局的role中，用户的role权限作用于所有的租户，即可以对所有的租户执行role规定的权限；在租户内的role中，用户仅能在当前租户内执行role规定的权限。 Service 即服务，如Nova、Glance、Swift。根据前三个概念（User，Tenant和Role）一个服务可以确认当前用户是否具有访问其资源的权限。但是当一个user尝试着访问其租户内的service时，他必须知道这个service是否存在以及如何访问这个service，这里通常使用一些不同的名称表示不同的服务。在上文中谈到的Role，实际上也是可以绑定到某个service的。例如，当swift需要一个管理员权限的访问进行对象创建时，对于相同的role我们并不一定也需要对nova进行管理员权限的访问。为了实现这个目标，我们应该创建两个独立的管理员role，一个绑定到swift，另一个绑定到nova，从而实现对swift进行管理员权限访问不会影响到Nova或其他服务。 Endpoint 翻译为“端点”，我们可以理解它是一个服务暴露出来的访问点，如果需要访问一个服务，则必须知道他的endpoint。因此，在keystone中包含一个endpoint模板（endpoint template，在安装keystone的时候我们可以在conf文件夹下看到这个文件），这个模板提供了所有存在的服务endpoints信息。一个endpoint template包含一个URLs列表，列表中的每个URL都对应一个服务实例的访问地址，并且具有public、private和admin这三种权限。public url可以被全局访问（如http://compute.example.com），private url只能被局域网访问（如http://compute.example.local），admin url被从常规的访问中分离。 二 访问流程 用户Alice通过自己的户名和密码向keystone申请token，keystone认证用户名和密码后，返回token1 Alice通过token1发送keystone查询他所拥有的租户，keystone验证token1成功后，返回Alice的所有Tenant Alice选择一个租户，通过用户名和密码申请token，keystone认证用户名、密码、tenant后，返回token2。（其实1、2步仅仅是为了查询tenant，如果已经知道tenant，可以忽略1、2步） Alice通过token2发送创建server的请求，keystone验证token2(包括该token是否有效，是否有权限创建虚拟机等)成功后，然后再把请求下发到nova，最终创建虚拟机。 集群运行较长时间之后 访问其API会变得奇慢无比 keystone数据库存储了大量的token导致性能太差 解决的办法是经常清理token 为了避免上述问题，社区提出了 Fernet token ，它采用 cryptography 对称加密库(symmetric cryptography，加密密钥和解密密钥相同) 加密 token，具体由 AES-CBC 加密和散列函数 SHA256 签名。 Fernet 是专为 API token 设计的一种轻量级安全消息格式，不需要存储于数据库，减少了磁盘的 IO，带来了一定的 性能提升 。为了提高安全性，需要采用 Key Rotation 更换密钥。 Token 类型的选择涉及多个因素，包括 Keystone server 的负载、region 数量、安全因素、维护成本以及 token 本身的成熟度。region 的数量影响 PKI/PKIZ token 的大小，从安全的角度上看，UUID 无需维护密钥，PKI 需要妥善保管 Keystone server 上的私钥，Fernet 需要周期性的更换密钥，因此从安全、维护成本和成熟度上看，UUID &gt; PKI/PKIZ &gt; Fernet 如果： Keystone server 负载低，region 少于 3 个，采用 UUID token。 Keystone server 负载高，region 少于 3 个，采用 PKI/PKIZ token。 Keystone server 负载低，region 大与或等于 3 个，采用 UUID token。 Keystone server 负载高，region 大于或等于 3 个，K 版本及以上可考虑采用 Fernet token。 性能优化 openstack采用了token认证的机制，各api的调用都会涉及到token的验证问题，使得keystone成为一个性能的瓶颈。 token的验证环节包括：验证请求中包含的token是否有效、过期，该token对应的用户组和用户id，对应的授权服务访问地址等。 性能瓶颈的解决-1：memcache缓存 性能瓶颈的解决-2：keystone并行化 当前的keystone实现中并没有采用并行化的机制，keystone-all运行时分别发起两个进程、绑定到两个socket上，分别处理5000和35357端口上的请求。 大概的修改如下： 引入了多线程下共享的socket 根据配置选项works的大小，发起多个进程处理api的请求 代码修改之后，还需对keystone的配置做适当更新： keystone默认的token存储后端为基于内存的k-v，范围在一个进程的空间内。并行化之后，多个进程需共享访问token的存储后端，这里采用memcache。修改keystone.conf，并安装memcache服务。]]></content>
  </entry>
  <entry>
    <title><![CDATA[架构师之路001]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F17%2F%E6%9E%B6%E6%9E%84%E5%B8%88%E4%B9%8B%E8%B7%AF001%2F</url>
    <content type="text"><![CDATA[架构设计的宏观角度程序的基础架构 弄清楚电脑的工作原理 以及程序的运行原理 中央处理器+存储+一系列的输入输出设备 可编程性 开放设计的外部设备支持 CPU是一个非常简洁的模型 只读入和写出数据 对数据进行计算 第一个想消除客户端的多样性 并且跨平台提供统一编程接口的 是浏览器 管道化 随着浏览器成为事实意义上应用的使用平台，操作系统的功能变得单一，单一到只为浏览器提供服务，从逻辑概念上可以理解为服务器于浏览器之间数据传输的管道。]]></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之线性代数文本检索]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F16%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%96%87%E6%9C%AC%E6%A3%80%E7%B4%A2%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之线性代数向量空间模型]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F16%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之线性代数]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F16%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之概率统计小结02]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F16%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1%E5%B0%8F%E7%BB%9302%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之统计意义下]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F16%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BB%9F%E8%AE%A1%E6%84%8F%E4%B9%89%E4%B8%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之统计意义上]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F16%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BB%9F%E8%AE%A1%E6%84%8F%E4%B9%89%E4%B8%8A%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之动态规划下]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E4%B8%8B%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import copydef min_coins_recruit(target_money, coins): &quot;&quot;&quot; 对于总金额固定，使用函数的递归(嵌套调用)，找出最少钱币数 :param target_money: 总金额大小 :param coins: 可选面额的钱币列表，如 [2, 3, 7] :return: &quot;&quot;&quot; if target_money == 0: return 0 elif target_money &lt; min(coins): return None # 不存在或无解 elif target_money in coins: return 1 result = list() for j in coins: count = min_coins_recruit(target_money - j, coins) if count is None: continue else: result.append(count) if len(result) &gt; 0: return min(result) + 1 else: return None # 不存在或无解def min_coins_dyna_pro(target_money, coins): &quot;&quot;&quot; 对于总金额固定，使用动态规划算法，找出最少钱币数 :param target_money: 总金额大小 :param coins: 可选面额的钱币列表 :return: &quot;&quot;&quot; if min(coins) &gt; target_money: return None # 每个额度的钱币数，初始化值为 None，假设不存在或无解 count = list([None]*(target_money+1)) # 一些确定额度的钱币数 count[0] = 0 for j in coins: if j &lt;= target_money: count[j] = 1 # 动态规划求解钱币数 for i in range(min(coins) + 1, target_money+1): tmp_count = list() # 临时保存钱币数 tmp_coins = [j for j in coins if j &lt;= i] # 求解 count[i-j] 时，i-j 大于 0 for j in tmp_coins: if count[i-j] is not None: tmp_count.append(count[i-j]) if len(tmp_count) &gt; 0: count[i] = min(tmp_count) + 1 return count[target_money]# 如何获取钱币组合？if __name__ == &quot;__main__&quot;: print(&quot;动态规划，最少钱币数：&quot;, min_coins_dyna_pro(50, [2, 3, 7])) print(&quot;递归方法，最少钱币数：&quot;, min_coins_recruit(50, [2, 3, 7]))]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之归一化和标准化]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E5%BD%92%E4%B8%80%E5%8C%96%E5%92%8C%E6%A0%87%E5%87%86%E5%8C%96%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之信息增益和卡方]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E5%92%8C%E5%8D%A1%E6%96%B9%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之决策树]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E5%86%B3%E7%AD%96%E6%A0%91%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之信息熵]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E4%BF%A1%E6%81%AF%E7%86%B5%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之马尔科夫模型]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之语言模型]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之文本分类]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之朴素贝叶斯]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之递归归并排序]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E9%80%92%E5%BD%92%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[分治问题 适合于使用递归实现 帮助设计分布式系统和并行计算，细分后的问题交给不同的机器来处理 某些机器专门负责收集来自不同机器的处理结果 完成结果的合并 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566# coding=utf-8import copydef merge_sort(to_sort=None): &quot;&quot;&quot; 使用函数的递归（嵌套）调用，实现归并排序（从小到大） :param to_sort: 等待排序的数组 :return: 排序后的数组 &quot;&quot;&quot; if to_sort is None: return [] # 如果分解到只剩一个数，返回该数 if len(to_sort) == 1: return to_sort # 将数组分解成左右两半 mid = len(to_sort) // 2 # python3 // 表示整除，不带小数 left = copy.copy(to_sort[0:mid]) right = copy.copy(to_sort[mid:len(to_sort)]) # 嵌套调用 对两半数组分别进行排序 left = merge_sort(left) right = merge_sort(right) # 合并排序后的两半 merged = merge(left, right) return mergeddef merge(left=None, right=None): &quot;&quot;&quot; 合并两个已经排序完毕的数组（从小到大） :param left: 左半边数组 :param right: 右半边数组 :return: 合并后的数组 &quot;&quot;&quot; if left is None: left = [] if right is None: right = [] merged_one = list() ai = 0 bi = 0 # 轮流从两个数组中取出较小的值 放入合并后的数组中 while ai &lt; len(left) and bi &lt; len(right): if left[ai] &lt;= right[bi]: merged_one.append(left[ai]) ai = ai + 1 else: merged_one.append(right[bi]) bi = bi + 1 # 将某个数组内剩余的数字放入合并后的数组中 if ai &lt; len(left): for i in range(ai, len(left)): merged_one.append(left[i]) else: for i in range(bi, len(right)): merged_one.append(right[i]) return merged_oneif __name__ == &apos;__main__&apos;: to_sort_ = [7,6,2,4,1,9,3,8,0,5] sorted_ = merge_sort(to_sort_) print(sorted_)]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之递归下]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E9%80%92%E5%BD%92%E4%B8%8B%2F</url>
    <content type="text"><![CDATA[假设有四种面额的钱币，1 元、2 元、5 元和 10 元，而您一共给我 10 元，那您可以奖赏我 1 张 10 元，或者 10 张 1 元，或者 5 张 1 元外加 1 张 5 元等等。 如果考虑每次奖赏的金额和先后顺序，那么最终一共有多少种不同的奖赏方式呢？ 12345678910111213141516171819202122232425262728293031323334 # coding=utf-8import copyrewards = [1, 2, 5, 10] # 四种面额的纸币def get_all_components(total_rewards, result=None): &quot;&quot;&quot; 使用函数的递归（嵌套调用），找出所有可能的奖赏组合 :param total_rewards 奖赏总金额 result 保存当前的解 :return: None &quot;&quot;&quot; # 当 total_rewards=0 时，证明它是满足条件的解，结束嵌套调用，输出解 if result is None: result = [] if total_rewards == 0: print(result) return # 当 total_rewards&lt;0 时，证明它不是满足条件的解，不输出 elif total_rewards &lt; 0: return else: for i, _ in enumerate(rewards): new_result = copy.copy(result) # 由于有4种情况，需要 clone 当前的解并传入被调用的函数 new_result.append(rewards[i]) # 记录但当前但选择，解决一点问题 get_all_components(total_rewards-rewards[i], new_result) # 剩下但问题，留给嵌套调用去解决if __name__ == &apos;__main__&apos;: total_reward = 10 get_all_components(total_reward)]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之概率基础下]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80%E4%B8%8B%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之概率基础上]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80%E4%B8%8A%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之概率统计]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%A6%82%E7%8E%87%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之阶段小结01]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E9%98%B6%E6%AE%B5%E5%B0%8F%E7%BB%9301%2F</url>
    <content type="text"><![CDATA[数据结构是一个个解决问题的“模型” 数组和链表通过下表直接定位数据 特别适合快速随机访问 循环 迭代 二分查找 斐波那契数列 适用稠密的数列 稀疏的话 改用链表来处理 C C++ 当中使用指针来实现的 java是对象引用来实现的 哈希表链地址哈希表 哈希冲突的解决 栈 堆（求top K）深度优先搜索 先进后出 队列广度优先搜索 先进先出 消息队列等比较常用 内连接 外连接 基础算法分治思想 mapreduce的数据切分 如何确定请求被分配到哪台机器上？这就引入了负载均衡算法 轮询和源地址哈希算法 回溯八皇后和0-1背包问题]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之空间复杂度]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%A9%BA%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之时间复杂度]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之从树到图]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E4%BB%8E%E6%A0%91%E5%88%B0%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[如何根据两点 入规划从一个地铁站到另外一个地铁站的小汽车出现路线？ 也就是地图提供的寻路？ 这个是预期准备做的项目题干 dijkstra 算法 找最短路径 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131import randomclass Node(object): def __init__(self, user_id): self.user_id = user_id # 用户节点 id self.friends = list() # 用户指向的节点，元素表示节点 id self.weights = list() # 用户指向的节点，其边的权重值def set_user_relation(user_num, relation_num): &quot;&quot;&quot; 随机生成用户间的关系 :param user_num: 用户数量 即节点的数量 :param relation_num: 好友关系的数量 即边的数量 :return: &quot;&quot;&quot; # 生成所有表示用户的节点 use_nodes = list() for u in range(user_num): use_nodes.append(Node(u)) # 生成所有表示好友关系的边 for r in range(relation_num): friend_a_id = random.randrange(user_num) friend_b_id = random.randrange(user_num) # 自己不能是自己的好友 如果生成的两个好友 id 相同，跳过 if friend_a_id == friend_b_id or friend_b_id in use_nodes[friend_a_id].friends: continue friend_a = use_nodes[friend_a_id] friend_a.friends.append(friend_b_id) # 用户 friend_a 的好友 friend_a.weights.append(round(random.random(), 2)) # 权重值 return use_nodesdef dijkstra(graph, source): &quot;&quot;&quot; Dijkstra 单源最短路径算法简单实现 :param graph: 图 :param source: 源点（起始点） :return: pre_node 前驱节点 &quot;&quot;&quot; nodes_list = list() # 图 graph 中的节点id的集合 for node in range(len(graph)): nodes_list.append(graph[node].user_id) # 保存了从起始点 source 到任意节点到最小权重值（最短路径大小） min_weights_list = list([float(&quot;Inf&quot;)] * len(graph)) # 无穷大 Inf , 下标与节点对应 # 从源点 source 出发，已经找到 最小权重值（最短路径值大小）的节点集合 found_nodes = list() # 元素表示节点 id # 前驱节点 pre_node = list([None] * len(graph)) # 下标与节点对应，其元素为下标对应的前驱节点 # 初始的时候 if len(graph[source].friends) == 0: return pre_node for node in range(len(graph[source].friends)): min_weights_list[graph[source].friends[node]] = graph[source].weights[node] # 初始，与源点 source 直连的节点，其前驱节点为 source pre_node[graph[source].friends[node]] = source # min_weights_list[source] = 0 # 去掉这一步，便于查找最小权重值 found_nodes.append(source) while len(set(nodes_list) - set(found_nodes)) != 0: # 图可能是不连通，min_weights_list 中, 源点 source 到某些节点的权重值无穷大 if min(min_weights_list) == float(&quot;Inf&quot;): break # 第一步 查找最小权重值的节点 min_weight_index = min_weights_list.index(min(min_weights_list)) # 下标对应节点的id found_nodes.append(min_weight_index) # 第二步 更新权重值 for node in range(len(graph[min_weight_index].friends)): # 已经找到最短路径的节点，不再更新 if graph[min_weight_index].friends[node] in found_nodes: continue if min_weights_list[min_weight_index] + graph[min_weight_index].weights[node] &lt; \ min_weights_list[graph[min_weight_index].friends[node]]: # 更新 min_weights_list 中节点的权重值 min_weights_list[graph[min_weight_index].friends[node]] = min_weights_list[min_weight_index] + \ graph[min_weight_index].weights[node] # 更新前驱节点 pre_node[graph[min_weight_index].friends[node]] = min_weight_index # 该点权重值置为无穷大，为下一次循环准备 min_weights_list[min_weight_index] = float(&quot;Inf&quot;) return pre_nodedef shortest_path(graph, source, pre_node): &quot;&quot;&quot; 打印源点 source 到其它节点到最短路径 :param graph: 图 :param source: 源点 :param pre_node: 前驱节点列表 :return: &quot;&quot;&quot; print(&quot;------------- 源点 %s 到其它各节点的最短路径 ----------&quot; % source) for k, _ in enumerate(graph): pre = pre_node[k] if pre is None: print(&quot;源点 %s 到 %s 的最短路径：不存在&quot; % (source, k)) continue path = [str(k)] while pre != source and pre is not None: path.append(&quot; -&gt; &quot;) path.append(str(pre)) pre = pre_node[pre] if pre == source: path.append(&quot; -&gt; &quot;) path.append(str(pre)) print(&quot;源点 %s 到 %s 的最短路径：%s&quot; % (source, k, &apos;&apos;.join(path[::-1])))if __name__ == &quot;__main__&quot;: user_nodes_list = set_user_relation(10, 20) for i in range(len(user_nodes_list)): if len(user_nodes_list[i].friends): print(&quot;用户 &#123;&#125; 的好友: &#123;&#125;, \t权重值 &#123;&#125;&quot;.format(user_nodes_list[i].user_id, user_nodes_list[i].friends, user_nodes_list[i].weights)) else: print(&quot;用户 &#123;&#125; 的好友: 不存在&quot;.format(user_nodes_list[i].user_id)) print(&quot;\n------------- Dijkstra 单源最短路径算法 --------------\n&quot;) s = 1 # 源点 pre_node_list = dijkstra(user_nodes_list, s) print(&quot;各下标节点对应的前驱节点：&quot;, pre_node_list, &quot;\n&quot;) # 打印路径 shortest_path(user_nodes_list, s, pre_node_list)]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之BFS]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8BBFS%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之DFS]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F15%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8BDFS%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[从语言的角度来看看python]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F13%2F%E4%BB%8E%E8%AF%AD%E8%A8%80%E7%9A%84%E8%A7%92%E5%BA%A6%E6%9D%A5%E7%9C%8B%E7%9C%8Bpython%2F</url>
    <content type="text"><![CDATA[python的优点 简单 语法优雅 易学 入手非常快 免费/开源 自动内存管理 C C++内存管理会带来很大的麻烦 程序非常容易出现内存方面的漏洞 但是python中内存管理是自动完成的 可以专注于程序本身 可以移植 解释性 大多数的计算机语言是编译型的 运行之前需要将源码编译为操作系统可以执行的二进制格式 这样大型项目编译过程非常消耗时间 python解释器把源代码转换成字节码的中间形式 然后再把它翻译成计算机使用的机器语言并运行 面向对象 混合型 可扩展 丰富的第三方库 缺点 速度慢 强制缩进？？ 习惯很正常 单行语句 如果没有对性能上的高要求 python在大部分领域都可以胜任 有些需要Cython甚至C这些工具 golang项目 设计一塌糊涂 但是多核支持好 轻松跑出需要的性能 python的服务往往一个小问题就很致命 10qps以下 学艺不精找不到问题 往往以为python本身这么慢 动态类型如果代码写得烂 下限更低对解释器的依赖容易出现各种问题 部署的时候还要专门的一块代码去帮客户配置环境 文件过多 导致部署不方便 golang的话 是一个binary完事 不那么容易暴露内部实现 因为给的是可执行文件 解决性能不够好的问题 golang相对来说 菜鸟也能写出性能远高于python的程序 语法简单 总体上也比较安全 不用瞻前顾后]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式学习010]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0010%2F</url>
    <content type="text"></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习009]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0009%2F</url>
    <content type="text"></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习008]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0008%2F</url>
    <content type="text"></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习007]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0007%2F</url>
    <content type="text"></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习006]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0006%2F</url>
    <content type="text"></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习005]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0005%2F</url>
    <content type="text"><![CDATA[亚马逊的实践 程序模块通过service interface 开放 信息接口 通过接口 除此之外 没有其他通信方式 任何技术都可以使用 对外界开放的设计 不这样做的人 会被炒鱿鱼 配额和限流 分布式团队架构 分布式服务查错不易 没有专职的测试人员 也没有专职的运维人员 运维优先 崇尚简化和自动化 内部服务和外部服务一致 需要注意的问题 异构系统的不标准问题 软件和应用不标准 通讯协议不标准 数据格式不标准 开发和运维的过程和方法不标准 系统架构中的服务依赖性问题木桶短板效应 整个SLA由最差的那个服务所决定 故障发生的概率更大 出现故障不可怕 故障恢复时间过长才可怕 出现故障不可怕 故障影响面过大才可怕 多层架构的运维复杂度更大]]></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习004]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0004%2F</url>
    <content type="text"><![CDATA[go语言的体会 语言简单 上手快 并行和异步编程几乎无痛点 goroutine channel lib库 麻雀虽小 五脏俱全 c语言的理念和python的姿态 存在诸多的问题 垃圾回收 异常处理 泛型编程等 有没有一个好的社区 有没有工业化的标准 有没有一个或者多个杀手级应用 学习难度是否低 上手是否快 提高开发效率的开发框架 技术公司作为后盾 解决软件开发中的痛点（java解决内存管理问题） PaaS是承上启下的关键技术 软件生产线的问题 分布式服务化的问题 提高服务的可用性SLA 软件能力的复用 挤出时间来干这些“逆人性”的事情 渴望程度 使用语言开发 可维护的程序 如何进行后续的优化 前后端分离 计算机提升社会运作效率并不是靠前端来完成的 而是靠自动化来完成的 所以后端的业务逻辑和计算 才是业务的核心 所以我从技术支持 测试这种支持性的工作中脱离出来 想做一些产出性的工作 开发测试工具 运维系统和工具 开发项目管理软件 只有到开发上 你才有更好的发展]]></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习003]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0003%2F</url>
    <content type="text"><![CDATA[中心化的设计思想 中心化的设计思想很简单，按照角色分工 大体上两种 一种是中心节点 另外就是普通节点 如果中心节点出现问题 则集群会崩溃 去中心化的设计 不存在单点故障 完全意义的真正去中心化的分布式系统并不多见。相反，外部开来去中心化单工作机制采用了中心化设计思想的分布式系统正在不断涌出。在这种架构下，集群中的领导是被动态选择出来的，而不是认为预先置顶的，而且集群发声故障的情况下，集群的成员会自发的举行“会议”选举新的“领导”主持工作。最典型的案例就是ZooKeeper及Go语言实现的Etcd 分布式环境的问题有： 通信异常：从集中式向分布式演变过程中，必然会引入网络因素，而由于网络本身的不可靠性，因此也引入了额外的问题。分布式系统需要在各个节点之间进行网络通信，因此当网络通信设备故障就会导致无法顺利完成一次网络通信，就算各节点的网络通信正常，但是消息丢失和消息延时也是非常普遍的事情。 网络分区（脑裂）：网络发生异常情况导致分布式系统中部分节点之间的网络延时不断增大，最终导致组成分布式系统的所有节点，只有部分节点能够正常通行，而另一些节点则不能。我们称这种情况叫做网络分区（脑裂），当网络分区出现时，分布式系统会出现多个局部小集群（多个小集群可能又会产生多个master节点），所以分布式系统要求这些小集群要能独立完成原本需要整个分布式系统才能完成的功能，这就对分布式一致性提出了非常大的挑战。 节点故障：节点宕机是分布式环境中的常态，每个节点都有可能会出现宕机或僵死的情况，并且每天都在发生。 三态：由于网络不可靠的原因，因此分布式系统的每一次请求，都存在特有的“三态”概念，即：成功，失败与超时。在集中式单机部署中，由于没有网络因素，所以程序的每一次调用都能得到“成功”或者“失败”的响应，但是在分布式系统中，网络不可靠，可能就会出现超时的情况。可能在消息发送时丢失或者在响应过程中丢失，当出现超时情况时，网络通信的发起方是无法确定当前请求是否被成功处理的，所以这也是分布式事务的难点。 基本可用(basically available)：基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性——但请注意，这绝不等价于系统不可用。以下两个就是“基本可用”的典型例子。 响应时间上的损失：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1～2秒。 功能上的损失：正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利地完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面。 弱状态(soft state)弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。 最终一致性(eventual consistency)最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。 注意：最终一致性是一种特殊的弱一致性：系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态，因此所有客户端对系统的数据访问都能够获取到最新的值。同时，在没有发生故障的前提下，数据达到一致状态的时间延迟，取决于网络延迟、系统负载和数据复制方案设计等因素。 在实际工程实践中，最终一致性存在以下五类主要变种。 1 因果一致性（Causal consistency） 因果一致性是指，如果进程A在更新完某个数据项后通知了进程B，那么进程B之后对该数据项的访问都应该能够获取到进程A更新后的最新值，并且如果进程B要对该数据项进行更新操作的话，务必基于进程A更新后的最新值，即不能发生丢失更新情况。与此同时，与进程A无因果关系的进程C的数据访问则没有这样的限制。 2 读己之所写（Read your writes） 读己之所写是指，进程A更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者来说，其读取到的数据，一定不会比自己上次写入的值旧。因此，读己之所写也可以看作是一种特殊的因果一致性。 3 会话一致性（Session consistency） 会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读己之所写”的一致性，也就是说，执行更能操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。 4 单调读一致性（Monotonic read consistency） 单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对于该进程后续的任何数据访问都不应该返回更旧的值。 5 单调写一致性（Monotonic write consistency） 单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。 事实上，最终一致性并不是只有那些大型分布式系统才涉及的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多都会采用同步和异步方式来实现主备数据复制技术。1 .在同步方式中，数据的复制过程通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致（强一致性）。2. 而在异步方式中，备库的更新往往会存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果传输时间过长或者甚至在日志传输过程中出现异常导致无法及时将事务应用到备库上，那么很显然，从备库中读取的数据将是旧的，因此就出现了数据不一致的情况。当然，无论是采用多次重试还是人为数据订正，关系型数据库还是能够保证最终数据达到一致——这就是系统提供最终一致性保证的经典案例。 总的来说，BASE理论面向的是大型高可用可扩展的分布式系统，和传统事务的ACID特性是相反的，它完全不同于ACID的强一致性模型，而是提出通过牺牲强一致性来获得可用性，并允许数据在一段时间内是不一致的，但最终达到一致状态。但同时，在实际的分布式场景中，不同业务单元和组件对数据一致性的要求是不同的，因此在具体的分布式系统架构设计过程中，ACID特性与BASE理论往往又会结合在一起使用。]]></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式学习002]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0002%2F</url>
    <content type="text"><![CDATA[分布式学习的理论基础 Consistency 一致性:这里的一致性是针对于分布式读写的。对于一个分布式系统，当一条数据写成功，那么无论我怎么使用这个系统，我都应当能马上读取到这条最新的数据。不一致性的例子:我更新了一条微博，而我的关注者还不能看到。 Avalilability 可用性:是指系统应当随时可用，在reasonable的时间内返回reasonable的结果。一个反例:我更新了一条微博，我的关注者在刷我微博的时候显示对方正在更新微博，请稍后再试，或者显示一直在读取中。 Partition Toleranc 分区容忍性:分布式环境中数据必然会被划分成多个区分到不同的机器上，不同的机器之间会有数据交换。而机器一多某台机器发生发生故障的概率就会比较高，而且机器间数据的交换依赖于网络，网络也很有可能会有延时、丢包之类的问题。分区容忍性就要求在分布式系统要考虑到分布式环境的复杂性的前提下能正常提供服务。 分布式的挑战来自不确定性，不确定计算机什么时候crash、断电，不确定磁盘什么时候损坏，不确定每次网络通信要延迟多久，也不确定通信对端是否处理了发送的消息。而分布式的规模放大了这个不确定性，不确定性是令人讨厌的，所以有诸多的分布式理论、协议来保证在这种不确定性的情况下，系统还能继续正常工作。 负载均衡： Nginx：高性能、高并发的web服务器；功能包括负载均衡、反向代理、静态内容缓存、访问控制；工作在应用层 LVS： Linux virtual server，基于集群技术和Linux操作系统实现一个高性能、高可用的服务器；工作在网络层 webserver： Java：Tomcat，Apache，Jboss Python：gunicorn、uwsgi、twisted、webpy、tornado service： SOA、微服务、spring boot，django 容器： docker，kubernetes cache： memcache、redis等 协调中心： zookeeper、etcd等 zookeeper使用了Paxos协议Paxos是强一致性，高可用的去中心化分布式。zookeeper的使用场景非常广泛，之后细讲。 rpc框架： grpc、dubbo、brpc dubbo是阿里开源的Java语言开发的高性能RPC框架，在阿里系的诸多架构中，都使用了dubbo + spring boot 消息队列： kafka、rabbitMQ、rocketMQ、QSP 消息队列的应用场景：异步处理、应用解耦、流量削锋和消息通讯 实时数据平台： storm、akka 离线数据平台： hadoop、spark PS: apark、akka、kafka都是scala语言写的，看到这个语言还是很牛逼的 dbproxy： cobar也是阿里开源的，在阿里系中使用也非常广泛，是关系型数据库的sharding + replica 代理 db： mysql、oracle、MongoDB、HBase、pg 搜索： elasticsearch、solr 日志： rsyslog、elk、flume 通用的关系型数据库设计理论，需要满足四种指标: Atomicity 原子性: Consistency 一致性: Isolation 独立性: Durability 持久性: 一般情况下 cap只能保证其中的两个 没法全部兼得]]></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[技术领导力]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F12%2F%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[做技术有没有前途？ 目前中国的基础技术还在发展当中 技术能力不足 西方“精耕细作” 比拼技术 技术人员跟从和被驱动 野蛮开采 资源整合 精耕细作 发明创造 发展自己的核心技术 提高技术领导力 技术不是问题 技术领导力才是问题！！！ 能够发现问题 解决问题 比较优缺点 技术决定 更优雅、更简单、更容易的方式来解决问题 提高扩展性、重用性、可维护性 正确管理团队 创新能力 追求核心基础技术 追逐自动化的工具和技术 解放生产力 开发高效可重用组件 坚持高于社会主流的技术标准和要求 严于律己]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>team</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3合并多个字典]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F11%2Fpython3%E5%90%88%E5%B9%B6%E5%A4%9A%E4%B8%AA%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[123456789from collections import Countera = &#123;&apos;x&apos;: 1, &apos;z&apos;: 3&#125;b = &#123;&apos;y&apos;: 2, &apos;z&apos;: 4&#125;d = &#123;&apos;x&apos;: 1, &apos;z&apos;: 5&#125;c = sum(map(Counter, [a, b, d]), Counter())print(dict(c))]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python2合并多个字典]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F11%2Fpython2%E5%90%88%E5%B9%B6%E5%A4%9A%E4%B8%AA%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[1234567891011def union_dict(*objs): _keys = set(sum([obj.keys() for obj in objs],[])) _total = &#123;&#125; for _key in _keys: _total[_key] = sum([obj.get(_key,0) for obj in objs]) return _totalobj1 = &#123;&apos;a&apos;:1,&apos;b&apos;:2,&apos;c&apos;:3&#125;obj2 = &#123;&apos;a&apos;:1,&apos;b&apos;:3,&apos;d&apos;:4&#125;print union_dict(obj1,obj2)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lfu-cache]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F10%2Flfu-cache%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import collectionsimport functoolsfrom itertools import filterfalsefrom heapq import nsmallestfrom operator import itemgetterclass Counter(dict): def __missing__(self, key): return 0def lfu_cache(maxsize=100): def decorating_function(user_function): cache = &#123;&#125; # mapping of args to results use_count = Counter() # times each key has been accessed kwd_mark = object() # separate positional and keyword args @functools.wraps(user_function) def wrapper(*args, **kwds): key = args if kwds: key += (kwd_mark,) + tuple(sorted(kwds.items())) use_count[key] += 1 # get cache entry or compute if not found try: result = cache[key] wrapper.hits += 1 except KeyError: result = user_function(*args, **kwds) cache[key] = result wrapper.misses += 1 # purge least frequently used cache entry if len(cache) &gt; maxsize: for key, _ in nsmallest(maxsize // 10, use_count.items(), key=itemgetter(1)): del cache[key], use_count[key] return result def clear(): cache.clear() use_count.clear() wrapper.hits = wrapper.misses = 0 wrapper.hits = wrapper.misses = 0 wrapper.clear = clear return wrapper return decorating_functionif __name__ == &apos;__main__&apos;: @lfu_cache(maxsize=20) def f(x, y): return 3 * x + y domain = range(5) from random import choice for i in range(1000): r = f(choice(domain), choice(domain)) print(f.hits, f.misses)]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[web监控]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F10%2Fweb%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[Web 应用程序在执行时，监控工具收集分析并显示其相关信息，每个有问题的应用程序都有网络堆栈。通过监控工具提供的堆栈信息，开发和运营团队能够响应并解决问题。 收集和分析生产环境的数据在保持稳定性，维持高性能方面是十分重要的，尤其对错误的 Web 应用程序进行优化很有必要。 监控和​​日志的区别监控和日志都旨在帮助应用程序诊断问题，在调试过程中他们的目的非常相似。唯一的差别是，日志数据只会根据明确的事件而进行记录，而监控数据则集合数据背景进行分析。 例如，当错误发生时，该事件被记录在日志中。同时，监控应用的代码还要收集数据，不仅是异常 log，还包括函数的性能数据。 其实，俩两者之间的区别也不是那么明显，毕竟解决问题不是只有一条路径。只要对 Web 生产应用程序有用都是可以用的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[分布式学习001]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F09%2F%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%A6%E4%B9%A0001%2F</url>
    <content type="text"><![CDATA[分布式 目的 增大系统容量 提高系统的可用性 大流量处理 关键业务保护 提高架构的吞吐量 服务更多的并发和流量 提高系统的稳定性 让系统的可用性更高 加缓存 负载均衡 异步调用 数据镜像 数据分区 服务拆分 服务冗余 限流降级 高可用架构 高可用运维 服务治理 架构软件管理 devops 自动化运维 资源调度管理 整体架构监控 流量控制 全栈系统监控； 服务 / 资源调度； 流量调度； 状态 /数据调度 开发和运维的自动化 分布式的优势 模块化 系统模块重用度更高 开发和发布速度更快 系统协作性更高 团队协作改善 任何技术方案 都是 “按下葫芦浮起瓢” trade-off]]></content>
      <categories>
        <category>distribute</category>
      </categories>
      <tags>
        <tag>distribute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode之合并K个链表]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F09%2Fleetcode%E4%B9%8B%E5%90%88%E5%B9%B6K%E4%B8%AA%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[先进行划分 划分到两个或者一个 再两两合并 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123; public ListNode mergeKLists(ListNode[] lists)&#123; if(lists.length == 0) return null; if(lists.length == 1) return lists[0]; if(lists.length == 2)&#123; return mergeTwoLists(lists[0],lists[1]); &#125; int mid = lists.length/2; ListNode[] l1 = new ListNode[mid]; for(int i = 0; i &lt; mid; i++)&#123; l1[i] = lists[i]; &#125; ListNode[] l2 = new ListNode[lists.length-mid]; for(int i = mid,j=0; i &lt; lists.length; i++,j++)&#123; l2[j] = lists[i]; &#125; return mergeTwoLists(mergeKLists(l1),mergeKLists(l2)); &#125; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; if (l1 == null) return l2; if (l2 == null) return l1; ListNode head = null; if (l1.val &lt;= l2.val)&#123; head = l1; head.next = mergeTwoLists(l1.next, l2); &#125; else &#123; head = l2; head.next = mergeTwoLists(l1, l2.next); &#125; return head; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[lru-cache]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F08%2Flru-cache%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import collectionsimport functoolsfrom itertools import ifilterfalsedef lru_cache(maxsize=100, on_purge=None): &quot;&quot;&quot;Least-recently-used cache decorator. Arguments to the cached function must be hashable. Clear the cache with f.clear(). &quot;&quot;&quot; maxqueue = maxsize * 10 def decorating_function(user_function): cache = &#123;&#125; queue = collections.deque() refcount = collections.defaultdict(int) sentinel = object() kwd_mark = object() # lookup optimizations (ugly but fast) queue_append, queue_popleft = queue.append, queue.popleft queue_appendleft, queue_pop = queue.appendleft, queue.pop @functools.wraps(user_function) def wrapper(*args, **kwargs): # cache key records both positional and keyword args key = args if kwargs: key += (kwd_mark,) + tuple(sorted(kwargs.items())) # record recent use of this key queue_append(key) refcount[key] += 1 # get cache entry or compute if not found try: result = cache[key] except KeyError: result = user_function(*args, **kwargs) cache[key] = result # purge least recently used cache entry if len(cache) &gt; maxsize: key = queue_popleft() refcount[key] -= 1 while refcount[key]: key = queue_popleft() refcount[key] -= 1 if on_purge: on_purge(cache[key]) del cache[key], refcount[key] # periodically compact the queue by eliminating duplicate keys # while preserving order of most recent access if len(queue) &gt; maxqueue: refcount.clear() queue_appendleft(sentinel) for key in ifilterfalse(refcount.__contains__, iter(queue_pop, sentinel)): queue_appendleft(key) refcount[key] = 1 return result def clear(): if on_purge: for value in cache.itervalues(): on_purge(value) cache.clear() queue.clear() refcount.clear() wrapper._cache = cache wrapper.clear = clear return wrapper return decorating_function]]></content>
  </entry>
  <entry>
    <title><![CDATA[编程范式01]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F08%2F%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F01%2F</url>
    <content type="text"><![CDATA[编程范式函数式编程 就是把一些功能或者逻辑代码通过函数拼接方式来组织的玩法 代码当中还是需要处理状态的 函数式编程一般写出的 都是无状态的代码 对于状态和数据的处理 oop编程的三大特性： 封装、继承、多态 包含数据、属性、代码与方法 对象指的是类的实例 面向对象 设计模式：可复用面向对象软件的基础 23种设计模式 使用者不需要知道数据类型、结构、算法的细节不需要知道实现细节 只需要知道提供的接口利于抽象、封装、动态绑定、多态符合面向对象的特质和理念 继承需要給子类暴漏一些父类的设计和实现细节父类实现的改变会造成子类也需要改变继承主要是为了代码重用 但是实际上在子类中需要重新实现很多父类的方法继承更多的是为了多态 拼装对象拼装功能资源管理 oop的优缺点 能和真实的世界交相辉映 符合人的直觉面向对象和数据库模型设计类型 更多地关注对象间的模型设计强调于名词而不是动词 更多地关注对象和接口间的接口根据业务的特征 形成了一个高内聚的对象 有效地分离了抽象和具体实现 增强可重用性和可扩展性拥有大量非常优秀的设计原则和设计模式 SOLID单一功能开闭原则里氏替换接口隔离以及依赖反转 缺点： 代码需要附着在一个类上 鼓励了类型代码需要提供对象达到抽象的效果 导致了相当厚重的“代码粘合层”太多的封装以及对状态的鼓励 导致了大量不透明并在并发下出现很多问题 基于原型的编程范式 主流的就是javascript __proto__ 主要是安放在一个实际的对象中 用来产生一个链接 一个原型链 用于寻找方法名或者属性 prototype 是用new来创建一个对象时构造 __proto__ 用的它是构造函数的一个属性 go语言的委托模式 声明一个struct 和C语言的很像 然后直接把这个struct类型放到另一个struct里面 编程的本质 任何算法 都有两部分 一个是logic部分 用来解决实际问题的 另一个是control部分 用什么策略来解决问题（影响解决这个问题的效率） 程序=算法+数据结构算法=逻辑+控制 函数式编程 都是一种控制undo是想要解决的问题 undo的流程是控制接口是对逻辑的抽象 真正的逻辑放在不同的具体类中 通过依赖或者是依赖注入这样的控制来完成对数据在不同情况下的不同处理 control 是可以被标准化的 遍历数据、查找数据、多线程、并发、异步等 都是可以标准化的 需要处理数据 泛型编程 处理用户的逻辑 标准化接口/协议来实现 适配于任何的logic 有效分离logic control data 是写好程序的关键所在！ 有效分离logic control data 是写好程序的关键所在！ 有效分离logic control data 是写好程序的关键所在！ prolog 逻辑编程范式]]></content>
  </entry>
  <entry>
    <title><![CDATA[编程范式00]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F08%2F%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F00%2F</url>
    <content type="text"><![CDATA[编程范式游记 C语言是静态弱类型语言 使用变量的时候需要声明变量类型 但是类型间可以有隐式转换 不同的变量类型 可以用结构体组合起来 以此来声明新的数据类型 typedef 关键字定义类型的别名 以此达到变量类型的抽象 变量作用域 递归功能的过程式语言 传递参数一般是传值 也可以传递指针 通过指针 对内存进行了低级控制 然而引入了非常大的时间复杂度 编译预处理让编译更具有弹性 比如跨平台 面向过程的C语言无法满足更高层次的编程需求 C++就出现了 用引用来解决指针出现的问题用namespace解决名字空间冲突的问题用try-catch解决返回值编程的问题用class来解决对象的创建、复制 销毁的问题用重载操作符来达到操作上的泛型用模板template和虚函数的多态以及运行时识别来达到更高层次的泛型和多态用RALL 智能指针的方式 解决需要释放资源而出现的一些问题用STL解决算法和数据结构当中的坑 C++的泛型 从swap函数开始 编程语言中的类型问题 对真实世界中业务代码的抽象、重用和拼装 类型系统用于定义将编程语言当中的数值和表达式归类为许多不同的类型 如何操作这些类型 类型如何互相作用 内建的类型 抽象的类型 程序语言的安全性 利于编译器的优化 代码的可读性 抽象化 静态语言的代表 C C++ java动态语言 python php javascript 静态类型检查是在编译器进行语义分析时进行的动态类型检查系统更多的则是在运行时期做动态标记和相关检查 泛型的本质是什么 类型是对内存的一种抽象 不同的类型 会有不同的内存布局和内存分配的策略不同的类型 有不同的操作 特定的类型 会有特定的一组操作 标准化类型的内存分配、释放和访问标准化类型的操作标准化数据容器的操作 比如查找算法、过滤、聚合标准化类型上特有的操作 编程语言本质上帮助程序员屏蔽底层机器代码的实现 让我们更好的关注于业务代码逻辑 是一件很难trade-off的事 函数式编程fp 编程工作是解决业务上的问题 而不是计算机的问题 因此需要更贴近业务 更为抽象的语言 如oop的C++、java 函数式编程的特点 stateless 不维护任何状态 immutale 输入数据是不能动的 优势： 没有状态就没有伤害 并行执行没有伤害 copy-paste重构代码没有伤害 函数的执行没有并行上的问题 还带来了一些好处 惰性求值 确定性 劣势： 数据复制比较严重完全纯函数式haskell容易写纯函数纯函数需要花点精力 头等函数尾递归优化map&amp;reducepipeline管道递归柯里化 多个参数分解成多个函数高阶函数 把函数当成变量来用 关注描述问题而不是怎么实现 这样可以让代码更易读因为函数返回里面的这个函数 所以函数关注的是表达式 关注的是描述这个问题 而不是怎么实现这个事情 函数式编程LISP语言 修饰器模式（装饰器） Java Annotation 一种纯粹的函数式编程的技巧 用一个函数来构造另一个函数 关注带参数的装饰器 类装饰器 一个 __init \call__ 调用 python的语法糖 写出的代码比较酷 但是对于没有修饰器语法糖这类语言 看看go的代码 12 反射机制 获取函数名 Go的修饰器模式 好像无法做到泛型 无法做到通用 最大的泛型是interface{} 还有比较简单的reflection机制 表面上看 装饰器模式就是扩展现有的一个函数的功能 干一些其他的事情 或者是附加一些别的功能除了体验到函数式编程的代码扩展能力 还能感受到代码互相和随意拼装带来的好处Decorator这个函数其实是可以修饰几乎所有的函数的 可以将一些非业务功能 属于控制类型的代码抽象出来 像是for-loop 或者是打印日志 函数路由 或者是求函数运行时间这种非业务功能性的代码]]></content>
  </entry>
  <entry>
    <title><![CDATA[布隆过滤器]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F05%2F%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%2F</url>
    <content type="text"><![CDATA[100 亿是一个很大的数量级，这里每条 url 平均 64 字节，全部存储的话需要 640G 的内存空间。又因为使用了散列表这种数据结构，而散列表是会出现散列冲突的。为了让散列表维持较小的装载因子，避免出现过多的散列冲突，需要使用链表法来处理，这里就要存储链表指针。因此最后的内存空间可能超过 1000G 了。 判断一个数 是否存在 两种状态 存在true 或者不存在false 用每一位来存放某种状态，适用于大规模数据，但数据状态又不是很多的情况。 另外，位图法有一个优势就是空间不随集合内元素个数的增加而增加。它的存储空间计算方式是找到所有元素里面最大的元素（假设为 N ），所占空间为 N/8 bytes 出于对性能和内存占用的考虑 使用布隆过滤器 才是最好的 对于布隆过滤器而言，它的本质是一个位数组：位数组就是数组的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1。 布隆过滤器除了一个位数组，还有 K 个哈希函数。当一个元素加入布隆过滤器中的时候，会进行如下操作： 使用 K 个哈希函数对元素值进行 K 次计算，得到 K 个哈希值。根据得到的哈希值，在位数组中把对应下标的值置为 1。举个例子，假设布隆过滤器有 3 个哈希函数：f1, f2, f3 和一个位数组 arr。现在要把 2333 插入布隆过滤器中： 对值进行三次哈希计算，得到三个值 n1, n2, n3。把位数组中三个元素 arr[n1], arr[n2], arr[3] 都置为 1。当要判断一个值是否在布隆过滤器中，对元素进行三次哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。 不存在 一定是真的 存在 可能是误判！！！ 布隆过滤器的最大的用处就是，能够迅速判断一个元素是否在一个集合中。因此它有如下三个使用场景: 网页爬虫对 URL 的去重，避免爬取相同的 URL 地址进行垃圾邮件过滤：反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）有的黑客为了让服务宕机，他们会构建大量不存在于缓存中的 key 向服务器发起请求，在数据量足够大的情况下，频繁的数据库查询可能导致 DB 挂掉。布隆过滤器很好的解决了缓存击穿的问题。]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红黑树详细]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F05%2F%E7%BA%A2%E9%BB%91%E6%A0%91%E8%AF%A6%E7%BB%86%2F</url>
    <content type="text"><![CDATA[红黑树是一种含有红黑结点并能自平衡的二叉查找树。它必须满足下面性质： 性质1：每个节点要么是黑色，要么是红色。 性质2：根节点是黑色。 性质3：每个叶子节点（NIL）是黑色。 性质4：每个红色结点的两个子结点一定都是黑色。 性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。 从性质5又可以推出： 性质5.1：如果一个结点存在黑子结点，那么该结点肯定有两个子结点 红黑树能自平衡，它靠的是什么？三种操作：左旋、右旋和变色。 左旋：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。 右旋：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。 变色：结点的颜色由红变黑或由黑变红。]]></content>
  </entry>
  <entry>
    <title><![CDATA[图的两种遍历]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F05%2F%E5%9B%BE%E7%9A%84%E4%B8%A4%E7%A7%8D%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[深度优先搜索使用递归的方式需要栈结构辅助实现 广度优先搜索需要使用队列辅助实现 连通图 任意顶点出发可以访问图中的所有顶点 图的深度搜索]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串题]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F05%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%A2%98%2F</url>
    <content type="text"><![CDATA[125 验证回文串 左指针 右指针 12345678910111213141516171819202122class Solution &#123; public boolean isPalindrome(String s) &#123; if(s.length() == 0) return true; int l = 0, r = s.length() - 1; while(l &lt; r)&#123; //确定指定的字符是否为字母或数字 if(!Character.isLetterOrDigit(s.charAt(l)))&#123; l++; &#125;else if(!Character.isLetterOrDigit(s.charAt(r)))&#123; r--; &#125;else&#123; if(Character.toLowerCase(s.charAt(l)) != Character.toLowerCase(s.charAt(r))) return false; l++; r--; &#125; &#125; return true; &#125;&#125; 131 分割回文串 1234567891011121314151617181920212223242526272829303132333435class Solution &#123; List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;(); public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; if(s==null||s.length()==0) return res; dfs(s,new ArrayList&lt;String&gt;(),0); return res; &#125; public void dfs(String s,List&lt;String&gt; remain,int left)&#123; if(left==s.length())&#123; //判断终止条件 res.add(new ArrayList&lt;String&gt;(remain)); //添加到结果中 return; &#125; for(int right=left;right&lt;s.length();right++)&#123; //从left开始，依次判断left-&gt;right是不是回文串 if(isPalindroom(s,left,right))&#123; //判断是否是回文串 remain.add(s.substring(left,right+1)); //添加到当前回文串到list中 dfs(s,remain,right+1); //从right+1开始继续递归，寻找回文串 remain.remove(remain.size()-1); //回溯，从而寻找更长的回文串 &#125; &#125; &#125; /** * 判断是否是回文串 */ public boolean isPalindroom(String s,int left,int right)&#123; while(left&lt;right&amp;&amp;s.charAt(left)==s.charAt(right))&#123; left++; right--; &#125; return left&gt;=right; &#125;&#125; 139 单词拆分 动态规划 12345678910111213141516171819202122class Solution &#123; public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; int n = s.length(); int max_length=0; for(String temp:wordDict)&#123; max_length = temp.length() &gt; max_length ? temp.length() : max_length; &#125; // memo[i] 表示 s 中以 i - 1 结尾的字符串是否可被 wordDict 拆分 boolean[] memo = new boolean[n + 1]; memo[0] = true; for (int i = 1; i &lt;= n; i++) &#123; for (int j = i-1; j &gt;= 0 &amp;&amp; max_length &gt;= i - j; j--) &#123; if (memo[j] &amp;&amp; wordDict.contains(s.substring(j, i))) &#123; memo[i] = true; break; &#125; &#125; &#125; return memo[n]; &#125;&#125; 344 反转字符串 从两头往中间走 1234567891011121314class Solution &#123;public: string reverseString(string s) &#123; int i = 0, j = s.size() - 1; while (i &lt; j)&#123; swap(s[i],s[j]); i++; j--; &#125; return s; &#125;&#125;; 字符串转换为整数 12345678910111213141516171819public class Solution &#123; public int StrToInt(String str) &#123; if (str == null || str.length() == 0) return 0; boolean isNegative = str.charAt(0) == &apos;-&apos;; int ret = 0; for (int i = 0; i &lt; str.length(); i++) &#123; char c = str.charAt(i); if (i == 0 &amp;&amp; (c == &apos;+&apos; || c == &apos;-&apos;)) /* 符号判定 */ continue; if (c &lt; &apos;0&apos; || c &gt; &apos;9&apos;) /* 非法输入 */ return 0; ret = ret * 10 + (c - &apos;0&apos;); &#125; return isNegative ? -ret : ret; &#125;&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之责任链]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F03%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E8%B4%A3%E4%BB%BB%E9%93%BE%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384# encoding: utf-8&quot;&quot;&quot;责任链模式使多个对象都以机会处理请求, 从而避免请求的发送者和接受者之间的耦合关系将这个对象连成一条链, 沿着这条链传递请求, 直到有一个对象处理它为止- 可以随意增加或修改处理一个请求的链式结构&quot;&quot;&quot;from abc import ABCMeta, abstractmethodclass Handler(object): &quot;&quot;&quot; 定义一个处理请求的接口 &quot;&quot;&quot; __metaclass__ = ABCMeta def __init__(self): self.__successor = None @property def successor(self): return self.__successor @successor.setter def successor(self, value): self.__successor = value @abstractmethod def handle_request(self, request): passclass ConcreteHandlerA(Handler): &quot;&quot;&quot; 具体处理类, 处理它所负责的请求 如果可以处理该请求, 处理之, 否则转给后继者 &quot;&quot;&quot; def handle_request(self, request): if 0 &lt;= request &lt; 10: print &quot;%s process %s&quot; % (self.__class__.__name__, request) else: self.successor.handle_request(request)class ConcreteHandlerB(Handler): &quot;&quot;&quot; 具体处理类, 处理它所负责的请求 如果可以处理该请求, 处理之, 否则转给后继者 &quot;&quot;&quot; def handle_request(self, request): if 10 &lt;= request &lt; 20: print &quot;%s process %s&quot; % (self.__class__.__name__, request) else: self.successor.handle_request(request)class ConcreteHandlerC(Handler): &quot;&quot;&quot; 具体处理类, 处理它所负责的请求 如果可以处理该请求, 处理之, 否则转给后继者 &quot;&quot;&quot; def handle_request(self, request): if 20 &lt;= request &lt; 30: print &quot;%s process %s&quot; % (self.__class__.__name__, request) else: self.successor.handle_request(request)if __name__ == &apos;__main__&apos;: h1 = ConcreteHandlerA() h2 = ConcreteHandlerB() h3 = ConcreteHandlerC() h1.successor = h2 h2.successor = h3 for req in [2, 14, 22]: print req h1.handle_request(req)]]></content>
  </entry>
  <entry>
    <title><![CDATA[sanic源码阅读]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F02%2Fsanic%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233## Sanic源码阅读：基于0.1.2`Sanic`是一个可以使用`async/await`语法编写项目的异步非阻塞框架，它写法类似于`Flask`，但使用了异步特性，而且还使用`uvloop`作为事件循环，其底层使用的是`libuv`，从而使 `Sanic`的速度优势更加明显。本章，我将和大家一起看看`Sanic`里面的运行机制是怎样的，它的`Router Blueprint`等是如何实现的。如果你有以下的需求：- 想深入了解Sanic，迫切想知道它的运行机制- 直接阅读源码，做一些定制- 学习将Sanic-0.1.2阅读完后的一些建议，我觉得你应该有以下基础再阅读源码才会理解地比较好：- 理解[装饰器](https://github.com/howie6879/Sanic-For-Pythoneer/blob/master/docs/part2/%E9%99%84%E5%BD%95%EF%BC%9A%E5%85%B3%E4%BA%8E%E8%A3%85%E9%A5%B0%E5%99%A8.md)，见附录- 理解协程Sanic-0.1.2 的核心文件如下：``` shell.├── __init__.py├── blueprints.py├── config.py├── exceptions.py├── log.py├── request.py├── response.py├── router.py├── sanic.py├── server.py└── utils.py 通过运行下面的示例，这些文件都会被我们看到它的作用，拭目以待吧，为了方便诸位的理解，我已将我注解的一份Sanic代码上传到了github，见sanic_annotation。 simple_server.py让我们从simple_server开始吧，代码如下： 12345678910111213from sanic_0_1_2.src import Sanicfrom sanic_0_1_2.src.response import jsonapp = Sanic(__name__)@app.route("/")async def test(request): return json(&#123;"test": True&#125;)app.run(host="0.0.0.0", port=8000) 或许你直接把sanic_annotation项目直接clone到本地比较方便调试+理解： 12git clone https://github.com/howie6879/sanic_annotationcd sanic_annotation/sanic_0_1_2/examples/ 那么，现在一切准备就绪，开始阅读吧。 前两行代码导入包： Sanic：构建一个 Sanic 服务必须要实例化的类 json：以json格式返回结果，实际上是HTTPResponse类，根据实例化参数content_type的不同，构建不同的实例，如： text：content_type=&quot;text/plain; charset=utf-8&quot; html：content_type=&quot;text/html; charset=utf-8&quot; 实例化一个Sanic对象，app = Sanic(__name__)，可见sanic.py，我已经在这个文件里面做了一些注释，这里也详细说下Sanic类： route()：装饰器，构建uri和视图函数的映射关系，调用Router().add()方法 exception()：装饰器，和上面差不多，不过针对的是错误处理类Handler middleware()：装饰器，针对中间件 register_blueprint()：注册视图的函数，接受第一个参数是视图类blueprint，再调用该类下的register方法实现将此蓝图下的route、exception、middleware统一注册到app.route、app.exception、app.exception handle_request()：这是一个很重要的异步函数，当服务启动后，如果客户端发来一个有效的请求，会自动执行 on_message_complete函数，该函数的目的是异步调用 handle_request函数，handle_request函数会回调write_response函数，write_response接受的参数是此uri请求对应的视图函数，比如上面demo中，如果客户端请求’/‘，那么这里write_response就会接受json({&quot;test&quot;: True})，然后进一步处理，再返回给客户端 run()：Sanic服务的启动函数，必须执行，实际上会继续调用server.serve函数，详情下面会详细讲 stop()：终止服务 其实上面这部分介绍已经讲了Sanic基本的运行逻辑，如果你理解了，那下面的讲解对你来说是轻轻松松，如果不怎么明白，也不要紧，这是只是一个大体的介绍，跟着步骤来，也很容易理解，继续看代码： 1234# 此处将路由 / 与视图函数 test 关联起来@app.route("/")async def test(request): return json(&#123;"test": True&#125;) app.route，上面介绍过，随着Sanic服务的启动而启动，可定义参数uri, methods 目的是为url的path和视图函数对应起来，构建一对映射关系，本例中Sanic.router类下的Router.routes = [] 会增加一个名为Route的namedtuple，如下： 1[Route(handler=&lt;function test at 0x10a0f6488&gt;, methods=None, pattern=re.compile('^/$'), parameters=[])] 看到没，uri &#39;/&#39; 和视图函数test对应起来了，如果客户端请求&#39;/&#39;，当服务器监听到这个请求的时候,handle_request可以通过参数中的request.url来找到视图函数test并且执行，随即生成视图返回 那么这里write_response就会接受视图函数test返回的json({&quot;test&quot;: True}) 说下Router类，这个类的目的就是添加和获取路由对应的视图函数，把它想象成dict或许更容易理解： add(self, uri, methods, handler)：添加一个映射关系到self.routes get(self, request)：获取request.url对应的视图函数 最后一行，app.run(host=&quot;0.0.0.0&quot;, port=8000)，Sanic 下的run函数，启动一个http server，主要是启动run里面的serve函数，参数如下：123456789101112131415161718try: serve( host=host, port=port, debug=debug, # 服务开始后启动的函数 after_start=after_start, # 在服务关闭前启动的函数 before_stop=before_stop, # Sanic(__name__).handle_request() request_handler=self.handle_request, # 默认读取Config request_timeout=self.config.REQUEST_TIMEOUT, request_max_size=self.config.REQUEST_MAX_SIZE, )except: pass 让我们将目光投向server.py，这也是Sanic框架的核心代码： serve()：里面会创建一个TCP服务的协程，然后通过loop.run_forever()运行这个事件循环，以便接收客户端请求以及处理相关事件，每当一个新的客户端建立连接服务就会创建一个新的Protocol实例，接受请求与返回响应离不开其中的HttpProtocol，里面的函数支持接受数据、处理数据、执行视图函数、构建响应数据并返回给客户端 HttpProtocol：asyncio.Protocol的子类，用来处理与客户端的通信，我在server.py里写了对应的注释 至此，Sanic 服务启动了 不要小看这一个小小的demo，执行一下，竟然涉及到下面这么多个文件，让我们总结一下： sanic.py server.py router.py request.py response.py exceptions.py config.py log.py 除去__init__.py，Sanic项目一共就10个文件，这个小demo不显山不露水地竟然用到了8个，虽然其中几个没有怎么用到，但也足够说明，你如果理解了这个demo，Sanic的运行逻辑以及框架代码你已经了解地很深入了 blueprints.py这个例子看完，我们就能轻易地明白什么是blueprints，以及blueprints的运行方式，代码如下： 12345678910111213141516171819202122232425from sanic_0_1_2.src import Sanic# 引入Blueprintfrom sanic_0_1_2.src import Blueprintfrom sanic_0_1_2.src.response import json, textapp = Sanic(__name__)blueprint = Blueprint('name', url_prefix='/my_blueprint')blueprint2 = Blueprint('name2', url_prefix='/my_blueprint2')@blueprint.route('/foo')async def foo(request): return json(&#123;'msg': 'hi from blueprint'&#125;)@blueprint2.route('/foo')async def foo2(request): return json(&#123;'msg': 'hi from blueprint2'&#125;)app.register_blueprint(blueprint)app.register_blueprint(blueprint2)app.run(host="0.0.0.0", port=8000, debug=True) 让我们从这两行开始： 123blueprint = Blueprint('name', url_prefix='/my_blueprint')blueprint2 = Blueprint('name2', url_prefix='/my_blueprint2') 显然，blueprint以及blueprint2是Blueprint根据不同的参数生成的不同的实例对象，接下来要干嘛？没错，分析blueprints.py: BlueprintSetup：蓝图注册类 add_route：添加路由到app add_exception：添加对应抛出的错误到app add_middleware：添加中间件到app Blueprint：蓝图类，接收两个参数：name(蓝图名称) url_prefix 该蓝图的url前缀 route：路由装饰器，将会生成一个匿名函数到self.deferred_functions列表里稍后一起处理注册到app里 middleware：同上 exception：同上 record：注册一个回调函数到self.deferred_functions列表里面， make_setup_state：实例化BlueprintSetup register：注册视图，实际就是注册route、middleware、exception到app，此时会利用make_setupstate返回的BlueprintSetup示例进行对于的add*一系列操作，相当于Sanic().route()效果 请看下route和register函数，然后再看下面的代码： 12345678910111213# 生成一个匿名函数到self.deferred_functions列表里 包含三个参数 handler(foo), uri, methods@blueprint.route('/foo')async def foo(request): return json(&#123;'msg': 'hi from blueprint'&#125;)@blueprint2.route('/foo')async def foo2(request): return json(&#123;'msg': 'hi from blueprint2'&#125;)# 上一个例子说过这个函数，Sanic().register_blueprint() 注册蓝图app.register_blueprint(blueprint)app.register_blueprint(blueprint2) 怎么样，现在来看，是不是很轻松，这一行app.run(host=&quot;0.0.0.0&quot;, port=8000, debug=True)服务启动代码不用多说吧？ 总结看到这里，相信你已经完全理解了Sanic的运行机制，虽然还有middleware&amp;exception的注册以及调用机制没讲，但这和route的运行机制一样，如果你懂了route那么这两个也很简单。 如果诸位一遍没怎么看明白，这里我建议可以多看几遍，多结合编辑器Debug下源码，坚持下来，会发下Sanic真的很简单，当然，这只是第一个小版本的Sanic，和目前的版本相比，不论是代码结构的复杂程度以及功能对比，都有很大差距，毕竟，Sanic一直在开源工作者的努力下，慢慢成长。 ```]]></content>
  </entry>
  <entry>
    <title><![CDATA[关注最后一步-部署]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F04%2F01%2F%E5%85%B3%E6%B3%A8%E6%9C%80%E5%90%8E%E4%B8%80%E6%AD%A5-%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[gunicorn Gunicorn设计 Gunicorn 是一个 master 进程，spawn 出数个工作进程的 web 服务器。master 进程控制工作进程的产生与消亡，工作进程只需要接受请求并且处理。这样分离的方式使得 reload 代码非常方便，也很容易增加或减少工作进程。 工作进程这块作者给了很大的扩展余地，它可以支持不同的IO方式，如 Gevent,Sync 同步进程，Asyc 异步进程，Eventlet 等等。master 跟 worker 进程完全分离，使得 Gunicorn 实质上就是一个控制进程的服务。 Gunicorn源码结构 从 Application.run() 开始，首先初始化配置，从文件读取，终端读取等等方式完成 configurate。然后启动 Arbiter，Arbiter 是实质上的 master 进程的核心，它首先从配置类中读取并设置，然后初始化信号处理函数，建立 socket。然后就是开始 spawn 工作进程，根据配置的工作进程数进行 spawn。然后就进入了轮询状态，收到信号，处理信号然后继续。这里唤醒进程的方式是建立一个 PIPE，通过信号处理函数往 pipe 里 write，然后 master 从 select.select() 中唤醒。 工作进程在 spawn 后，开始初始化，然后同样对信号进行处理，并且开始轮询，处理 HTTP 请求，调用 WSGI 的应用端，得到 resopnse 返回。然后继续。 Sync 同步进程的好处在于每个 request 都是分离的，每个 request 失败都不会影响其他 request，但这样导致了性能上的瓶颈。 没有对错，找个框架入门好了~ flask 上手快，插件多，但是随着项目的深入，慢慢就是变成一个 django，绝对的django 一上来就是大而全，但胜在什么都有，什么都不用自己折腾 tornado 这货从一出生就开始用到现在，没有啥好也没啥不好，就是用习惯了。flask 的上手快是以各种插件为代价的，模板你要去找 jinja 吧？ orm 要找 sqlachemy 吧？这些都需要你自己去熟悉一下 而且，各种用 flask 和 django 的同学可能忽略了一个基本是事实就是，如果你有工作需要深入到源代码的话，那么 tornado 是一个极好的参考。django 的代码体系复杂而且庞大我就不说了，看 flask 的代码底层还要考虑 Werkzeug，其基于全局变量的 context 处理起来其实也不容易的。 顺便的，部署 tornado 的项目可以少拖一个 gunicorn 或者 uwsgi 之如此类，少很多坑 上面那些提及到性能的同学，完全没有必要进行对比。在 pypy/aiohttp/uvloop 的加持下，不是我非要针对谁，你们说的性能都是垃圾。]]></content>
  </entry>
  <entry>
    <title><![CDATA[完美数]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F31%2F%E5%AE%8C%E7%BE%8E%E6%95%B0%2F</url>
    <content type="text"><![CDATA[完美数12345678910111213class Solution &#123;public: bool checkPerfectNumber(int num) &#123; int sum = 1; for (int i = 2; i * i &lt;= num; ++i) &#123; if (num % i == 0) &#123; sum += i + (num / i == i ? 0 : num / i); &#125; &#125; return num != 1 &amp;&amp; sum == num; &#125;&#125;; 1234567class Solution &#123;public: bool checkPerfectNumber(int num) &#123; return num == 6 || num == 28 || num == 496 || num == 8128 || num == 33550336; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[2019-go-28]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F28%2F2019-go-28%2F</url>
    <content type="text"><![CDATA[go的 协程和线程都可以实现程序的并发执行 通过channel来进行协程之间的通信 一个包中可以包含多个init函数 程序编译的时候 先执行导入包init的函数 再执行本包内的init函数 几个缺陷 不支持函数式编程 go的泛型会給项目带来不必要的复杂性 通道/并行切片处理 垃圾回收器 以低延迟为最高优先级 错误处理 如果完成一个api 或者完成一个需要大量磁盘/网络调用的任务 go是首选！！！]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-27]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F28%2F2019-go-27%2F</url>
    <content type="text"><![CDATA[beego 模块化设计之 config解析文件的库，它的设计思路来自于 database/sql，目前支持解析的文件格式有 ini、json、xml、yaml 初始化解析器 iniconf, err := NewConfig(&quot;ini&quot;, &quot;testini.conf&quot;) if err != nil { t.Fatal(err) } iniconf.String(&quot;appname&quot;) 解析器对象支持的函数有如下： Set(key, val string) error String(key string) string Int(key string) (int, error) Int64(key string) (int64, error) Bool(key string) (bool, error) Float(key string) (float64, error) DIY(key string) (interface{}, error)]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-26]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F28%2F2019-go-26%2F</url>
    <content type="text"><![CDATA[beego 模块化设计之 toolbox健康检查 监控检查是用于当你应用于产品环境中进程，检查当前的状态是否正常， 12345678910type DatabaseCheck struct &#123;&#125;func (dc *DatabaseCheck) Check() error &#123; if dc.isConnected() &#123; return nil &#125; else &#123; return errors.New(&quot;can&apos;t connect database&quot;) &#125;&#125; toolbox.AddHealthCheck(&quot;database&quot;,&amp;DatabaseCheck{}) curl http://beego.me:8088/healthcheck 性能调试、访问统计、计划任务。 对于运行中的进程的性能监控是我们进行程序调优和查找问题的最佳方法，例如 GC、goroutine 等基础信息。profile 提供了方便的入口方便用户来调试程序，他主要是通过入口函数 ProcessInput 来进行处理各类请求，主要包括以下几种调试： lookup goroutine/heap/threadcreate/block/ start cpuprof 开始记录 cpuprof 信息，生产一个文件 cpu-pid.pprof，开始记录当前进程的 CPU 处理信息 stop cpuprof 关闭记录信息 get memprof 开启记录 memprof，生产一个文件 mem-pid.memprof gc summary 查看 GC 信息 toolbox.StatisticsMap.AddStatistics(&quot;POST&quot;, &quot;/api/user&quot;, &quot;&amp;admin.user&quot;, time.Duration(2000)) toolbox.StatisticsMap.AddStatistics(&quot;POST&quot;, &quot;/api/user&quot;, &quot;&amp;admin.user&quot;, time.Duration(120000)) toolbox.StatisticsMap.AddStatistics(&quot;GET&quot;, &quot;/api/user&quot;, &quot;&amp;admin.user&quot;, time.Duration(13000)) toolbox.StatisticsMap.AddStatistics(&quot;POST&quot;, &quot;/api/admin&quot;, &quot;&amp;admin.user&quot;, time.Duration(14000)) toolbox.StatisticsMap.AddStatistics(&quot;POST&quot;, &quot;/api/user/astaxie&quot;, &quot;&amp;admin.user&quot;, time.Duration(12000)) toolbox.StatisticsMap.AddStatistics(&quot;POST&quot;, &quot;/api/user/xiemengjun&quot;, &quot;&amp;admin.user&quot;, time.Duration(13000)) toolbox.StatisticsMap.AddStatistics(&quot;DELETE&quot;, &quot;/api/user&quot;, &quot;&amp;admin.user&quot;, time.Duration(1400)) toolbox.StatisticsMap.GetMap(os.Stdout) 玩过 linux 的用户都知道有一个计划任务的工具 crontab，我们经常利用该工具来定时的做一些任务，但是有些时候我们的进程内也希望定时的来处理一些事情，例如定时的汇报当前进程的内存信息，goroutine 信息等。或者定时的进行手工触发 GC，或者定时的清理一些日志数据等，所以实现了秒级别的定时任务，首先让我们看看如何使用： tk1 := toolbox.NewTask(&quot;tk1&quot;, &quot;0 12 * * * *&quot;, func() error { fmt.Println(&quot;tk1&quot;); return nil }) err := tk.Run() if err != nil { t.Fatal(err) } toolbox.AddTask(&quot;tk1&quot;, tk1) toolbox.StartTask() defer toolbox.StopTask() 字段的详细说明 //前6个字段分别表示： // 秒钟：0-59 // 分钟：0-59 // 小时：1-23 // 日期：1-31 // 月份：1-12 // 星期：0-6（0 表示周日） //还可以用一些特殊符号： // *： 表示任何时刻 // ,： 表示分割，如第三段里：2,4，表示 2 点和 4 点执行 // －：表示一个段，如第三端里： 1-5，就表示 1 到 5 点 // /n : 表示每个n的单位执行一次，如第三段里，*/1, 就表示每隔 1 个小时执行一次命令。也可以写成1-23/1. ///////////////////////////////////////////////////////// // 0/30 * * * * * 每 30 秒 执行 // 0 43 21 * * * 21:43 执行 // 0 15 05 * * * 05:15 执行 // 0 0 17 * * * 17:00 执行 // 0 0 17 * * 1 每周一的 17:00 执行 // 0 0,10 17 * * 0,2,3 每周日,周二,周三的 17:00和 17:10 执行 // 0 0-10 17 1 * * 毎月1日从 17:00 到 7:10 毎隔 1 分钟 执行 // 0 0 0 1,15 * 1 毎月1日和 15 日和 一日的 0:00 执行 // 0 42 4 1 * * 毎月1日的 4:42 分 执行 // 0 0 21 * * 1-6 周一到周六 21:00 执行 // 0 0,10,20,30,40,50 * * * * 每隔 10 分 执行 // 0 */10 * * * * 每隔 10 分 执行 // 0 * 1 * * * 从 1:0 到 1:59 每隔 1 分钟 执行 // 0 0 1 * * * 1:00 执行 // 0 0 */1 * * * 毎时 0 分 每隔 1 小时 执行 // 0 0 * * * * 毎时 0 分 每隔 1 小时 执行 // 0 2 8-20/3 * * * 8:02,11:02,14:02,17:02,20:02 执行 // 0 30 5 1,15 * * 1 日 和 15 日的 5:30 执行]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1024-2-poisonous-40]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F28%2F1024-2-poisonous-40%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374from random import randrangedef to_b4(n): return [n/4**k%4 for k in range(5)]def fr_b4(li): return sum([li[k]*4**k for k in range(5)])def drink(p1,p2): li1,li2 = to_b4(p1),to_b4(p2) g0 = [li1[k]==0 or li2[k]==0 for k in range(5)] g1 = [li1[k]==1 or li2[k]==1 for k in range(5)] g2 = [li1[k]==2 or li2[k]==2 for k in range(5)] g3 = [li1[k]==3 or li2[k]==3 for k in range(5)] gc,gf = &#123;&#125;,&#123;&#125; for i in range(4): for j in range(i+1,5): diff1 = abs(li1[i]-li1[j]) diff2 = abs(li2[i]-li2[j]) gc[i,j] = diff1 == 1 or diff2 == 1 gf[i,j] = diff1 &gt; 1 or diff2 &gt; 1 return g0,g1,g2,g3,gc,gfdef check(u,v,d1,d2,c,f): a = [[0,1,2,2],[1,0,1,2],[2,1,0,1],[2,2,1,0]] a11 = a[u][d1] a22 = a[v][d2] c1 = a11 == 1 or a22 == 1 f1 = a11 == 2 or a22 == 2 if c == c1 and f == f1: return u,v else: return v,udef test(g0,g1,g2,g3,gc,gf): diff = 5 t1,t2 = range(5),range(5) for k in range(4,-1,-1): li = [g0[k],g1[k],g2[k],g3[k]] u = li.index(True) if (li.count(True) == 1): t1[k],t2[k] = u,u else: li[u] = False v = li.index(True) if diff == 5: diff = k t1[k],t2[k] = u,v else: t1[k],t2[k] = check(u,v,t1[diff],t2[diff],gc[k,diff],gf[k,diff]) return fr_b4(t1),fr_b4(t2)poison1 = randrange(1024)poison2 = (poison1 + randrange(1,1024)) % 1024g0,g1,g2,g3,gc,gf = drink(poison1,poison2)target1,target2 = test(g0,g1,g2,g3,gc,gf)print poison1,poison2print to_b4(poison1)print to_b4(poison2)print &quot;0:&quot;,g0print &quot;1:&quot;,g1print &quot;2:&quot;,g2print &quot;3:&quot;,g3print &quot;c:&quot;,gcprint &quot;f:&quot;,gfprint target1,target2]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[1024-2-poisonous-65]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F28%2F1024-2-poisonous-65%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354from random import randrangedef to_b2(n): return [n / 2**k % 2 for k in range(10)]def fr_b2(li): return sum([li[k] * 2**k for k in range(10)])def drink(p1, p2): li1, li2 = to_b2(p1), to_b2(p2) g0 = [li1[k] == 0 or li2[k] == 0 for k in range(10)] g1 = [li1[k] == 1 or li2[k] == 1 for k in range(10)] gd = &#123;&#125; for i in range(9): for j in range(i + 1, 10): gd[i, j] = li1[i] != li1[j] or li2[i] != li2[j] return g0, g1, gddef test(g0, g1, gd): diff = 10 t1, t2 = range(10), range(10) for k in range(9, -1, -1): if not g0[k]: t1[k], t2[k] = 1, 1 elif not g1[k]: t1[k], t2[k] = 0, 0 elif diff == 10: diff = k t1[k], t2[k] = 0, 1 elif gd[k, diff]: t1[k], t2[k] = 1, 0 else: t1[k], t2[k] = 0, 1 return fr_b2(t1), fr_b2(t2)if __name__ == &quot;__main__&quot;: poison1 = randrange(1024) poison2 = (poison1 + randrange(1, 1024)) % 1024 g0, g1, gd = drink(poison1, poison2) target1, target2 = test(g0, g1, gd) print(poison1, poison2) print(to_b2(poison1)) print(to_b2(poison2)) print(&quot;0:&quot;, g0) print(&quot;1:&quot;, g1) print(&quot;d:&quot;, gd) print(target1, target2)]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[problem-oj4]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F26%2Fproblem-oj4%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#!/usr/bin/env python# -*- coding: utf-8 -*-&quot;&quot;&quot;给定一个仅包含整数，且按照大小顺序排好序的列表，列表内不存在重复的整数。实现一个函数，将列表格式化为由`,`(逗号)分隔的字符串；如果相邻的整数(至少3个)是连续的(值相差1为连续)，则将这几个相邻的整数格式化为由`-`(减号)分隔、左右分别为起始和终止位整数的字符串。示例：func([-6,-3,-2,-1,0,1,3,4,5,7,8,9,10,11,14,15,17,18,19,20]) --&gt; &apos;-6,-3-1,3-5,7-11,14,15,17-20&apos;func([-3,-2,-1,2,10,15,16,18,19,20]) --&gt; &apos;-3--1,2,10,15,16,18-20&apos;特殊情况示例：func([]) --&gt; &apos;&apos;&quot;&quot;&quot;import unittestfrom itertools import groupbydef func(lst): # your code sum = sub_arr(lst) return &apos;,&apos;.join(sum)def sub_arr(lst): fun = lambda x: x[1] - x[0] sum = [] for k, g in groupby(enumerate(lst), fun): s = [v for i, v in g]# print(s) if len(s) &lt;= 1: sum.append(str(s[0])) elif len(s) == 2: sum.append(str(s[0])) sum.append(str(s[1])) else: target = [str(s[0]), str(s[-1])] n = &apos;-&apos;.join(target) sum.append(n) return sumclass DefaultTestCase(unittest.TestCase): def test_func(self): self.assertEqual(func([-6,-3,-2,-1,0,1,3,4,5,7,8,9,10,11,14,15,17,18,19,20]), &apos;-6,-3-1,3-5,7-11,14,15,17-20&apos;) self.assertEqual(func([-3,-2,-1,2,10,15,16,18,19,20]), &apos;-3--1,2,10,15,16,18-20&apos;) self.assertEqual(func([]), &apos;&apos;) self.assertEqual(func([-6,-4,-2,0,2,4,6]), &apos;-6,-4,-2,0,2,4,6&apos;) self.assertEqual(func([-6,-5,-3,-2,0,1,3,4,6]), &apos;-6,-5,-3,-2,0,1,3,4,6&apos;)if __name__ == &apos;__main__&apos;: unittest.main()]]></content>
  </entry>
  <entry>
    <title><![CDATA[problem-oj5]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F26%2Fproblem-oj5%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#!/usr/bin/env python# -*- coding: utf-8 -*-&quot;&quot;&quot; 你需要实现一个转换器，将一个正整数在不同的进制(通用的/自定义的)之间转换。 后面有一些预定义的进制及其字符集。 示例： func(&quot;15&quot;, dec_chr, bin_chr) --&gt; &quot;1111&quot; func(&quot;15&quot;, dec_chr, oct_chr) --&gt; &quot;17&quot; func(&quot;1010&quot;, bin_chr, dec_chr) --&gt; &quot;10&quot; func(&quot;1010&quot;, bin_chr, hex_chr) --&gt; &quot;a&quot; func(&quot;0&quot;, dec_chr, alpha_chr) --&gt; &quot;a&quot; func(&quot;27&quot;, dec_chr, allow_chr) --&gt; &quot;bb&quot; func(&quot;hello&quot;, allow_chr, hex_chr) --&gt; &quot;320048&quot;&quot;&quot;&quot;import unittestbin_chr = &apos;01&apos;oct_chr = &apos;01234567&apos;dec_chr = &apos;0123456789&apos;hex_chr = &apos;0123456789abcdef&apos;allow_chr = &apos;abcdefghijklmnopqrstuvwxyz&apos;allup_chr = &apos;ABCDEFGHIJKLMNOPQRSTUVWXYZ&apos;alpha_chr = &apos;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&apos;alphanum_chr = &apos;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&apos;def func(input, source, target): &quot;&quot;&quot; 二进制 八进制 十进制 十六进制 小写（26） 大写（26） 字母（52） 字母和数字（62） 辗转相除 &quot;&quot;&quot; # your code # oct() # hex() # bin() if len(target) != len(source): transfer = input2dec(input, source) # print(transfer) get_re = dec2target(transfer, target) print(get_re) else: if target.startswith(&quot;A&quot;): get_re = input.upper() if target.startswith(&quot;a&quot;): get_re = input.lower() return get_redef input2dec(input, source): get_power = len(source) get_sum = 0 s = [i for i in input] s.reverse() for index, i in enumerate(s): num = source.find(i) get_value = num * (get_power**index) get_sum += get_value return get_sumdef dec2target(n, target): b=[] x = len(target) while True: s=n//x #商 y=n%x #余数 b=b+[y] if s==0: break n=s b.reverse() s = &apos;&apos; a = [i for i in target] for i in b:# print(a[i], end=&apos;&apos;) s += a[i] return sclass DefaultTestCase(unittest.TestCase): def test_func(self): self.assertEqual(func(&quot;15&quot;, dec_chr, bin_chr), &quot;1111&quot;) self.assertEqual(func(&quot;15&quot;, dec_chr, oct_chr), &quot;17&quot;) self.assertEqual(func(&quot;1010&quot;, bin_chr, dec_chr), &quot;10&quot;) self.assertEqual(func(&quot;1010&quot;, bin_chr, hex_chr), &quot;a&quot;) self.assertEqual(func(&quot;0&quot;, dec_chr, alpha_chr), &quot;a&quot;) self.assertEqual(func(&quot;27&quot;, dec_chr, allow_chr), &quot;bb&quot;) self.assertEqual(func(&quot;hello&quot;, allow_chr, hex_chr), &quot;320048&quot;) self.assertEqual(func(&quot;SAME&quot;, allup_chr, allup_chr), &quot;SAME&quot;) self.assertEqual(func(&quot;WORLD&quot;, allup_chr, alphanum_chr), &apos;Hgrz&apos;)if __name__ == &apos;__main__&apos;: unittest.main()]]></content>
  </entry>
  <entry>
    <title><![CDATA[shortest_path]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F25%2Fshortest-path%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758from dataclasses import dataclassfrom queue import PriorityQueue@dataclassclass Edge: start_id: int end_id: int weight: int@dataclass(order=True)class Vertex: distance_to_start = float(&quot;inf&quot;) vertex_id: intclass Graph: def __init__(self, num_vertices: int): self._num_vertices = num_vertices self._adjacency = [[] for _ in range(num_vertices)] def add_edge(self, from_vertex: int, to_vertex: int, weight: int) -&gt; None: self._adjacency[from_vertex].append(Edge(from_vertex, to_vertex, weight)) def dijkstra(self, from_vertex: int, to_vertex: int) -&gt; None: vertices = [Vertex(i) for i in range(self._num_vertices)] vertices[from_vertex].distance_to_start = 0 visited = [False] * self._num_vertices predecessor = [-1] * self._num_vertices q = PriorityQueue() q.put(vertices[from_vertex]) visited[from_vertex] = True while not q.empty(): min_vertex = q.get() if min_vertex.vertex_id == to_vertex: break for edge in self._adjacency[min_vertex.vertex_id]: next_vertex = vertices[edge.end_id] if min_vertex.distance_to_start + edge.weight &lt; next_vertex.distance_to_start: next_vertex.distance_to_start = min_vertex.distance_to_start + edge.weight predecessor[next_vertex.vertex_id] = min_vertex.vertex_id if not visited[next_vertex.vertex_id]: q.put(next_vertex) visited[next_vertex.vertex_id] = True path = lambda x: path(predecessor[x]) + [str(x)] if from_vertex != x else [str(from_vertex)] print(&quot;-&gt;&quot;.join(path(to_vertex)))if __name__ == &quot;__main__&quot;: graph = Graph(6) graph.add_edge(0, 1, 10) graph.add_edge(0, 4, 15) graph.add_edge(1, 2, 15) graph.add_edge(1, 3, 2) graph.add_edge(2, 5, 5) graph.add_edge(3, 2, 1) graph.add_edge(3, 5, 12) graph.add_edge(4, 5, 10) graph.dijkstra(0, 5)]]></content>
  </entry>
  <entry>
    <title><![CDATA[dijkstra]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F25%2Fdijkstra%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127#!/usr/bin/python# -*- coding: UTF-8 -*-from typing import List, Generatorimport heapqclass Graph: def __init__(self, vertex_count: int) -&gt; None: self.adj = [[] for _ in range(vertex_count)] def add_edge(self, s: int, t: int, w: int) -&gt; None: edge = Edge(s, t, w) self.adj[s].append(edge) def __len__(self) -&gt; int: return len(self.adj)class Vertex: def __init__(self, v: int, dist: int) -&gt; None: self.id = v self.dist = dist def __gt__(self, other) -&gt; bool: return self.dist &gt; other.dist def __repr__(self) -&gt; str: return str((self.id, self.dist))class Edge: def __init__(self, source: int, target: int, weight: int) -&gt; None: self.s = source self.t = target self.w = weightclass VertexPriorityQueue: def __init__(self) -&gt; None: self.vertices = [] def get(self) -&gt; Vertex: return heapq.heappop(self.vertices) def put(self, v: Vertex) -&gt; None: self.vertices.append(v) self.update_priority() def empty(self) -&gt; bool: return len(self.vertices) == 0 def update_priority(self) -&gt; None: heapq.heapify(self.vertices) def __repr__(self) -&gt; str: return str(self.vertices)def dijkstra(g: Graph, s: int, t: int) -&gt; int: size = len(g) pq = VertexPriorityQueue() # 节点队列 in_queue = [False] * size # 已入队标记 vertices = [ # 需要随时更新离s的最短距离的节点列表 Vertex(v, float(&apos;inf&apos;)) for v in range(size) ] predecessor = [-1] * size # 先驱 vertices[s].dist = 0 pq.put(vertices[s]) in_queue[s] = True while not pq.empty(): v = pq.get() if v.id == t: break for edge in g.adj[v.id]: if v.dist + edge.w &lt; vertices[edge.t].dist: # 当修改了pq中的元素的优先级后： # 1. 有入队操作：触发了pq的堆化，此后出队可以取到优先级最高的顶点 # 2. 无入队操作：此后出队取到的顶点可能不是优先级最高的，会有bug # 为确保正确，需要手动更新一次 vertices[edge.t].dist = v.dist + edge.w predecessor[edge.t] = v.id pq.update_priority() # 更新堆结构 if not in_queue[edge.t]: pq.put(vertices[edge.t]) in_queue[edge.t] = True for n in print_path(s, t, predecessor): if n == t: print(t) else: print(n, end=&apos; -&gt; &apos;) return vertices[t].distdef print_path(s: int, t: int, p: List[int]) -&gt; Generator[int, None, None]: if t == s: yield s else: yield from print_path(s, p[t], p) yield tif __name__ == &apos;__main__&apos;: g = Graph(6) g.add_edge(0, 1, 10) g.add_edge(0, 4, 15) g.add_edge(1, 2, 15) g.add_edge(1, 3, 2) g.add_edge(2, 5, 5) g.add_edge(3, 2, 1) g.add_edge(3, 5, 12) g.add_edge(4, 5, 10) print(dijkstra(g, 0, 5)) # 下面这个用例可以暴露更新队列元素优先级的问题 # g = Graph(4) # g.add_edge(0, 1, 18) # g.add_edge(0, 2, 3) # g.add_edge(2, 1, 1) # g.add_edge(1, 3, 5) # g.add_edge(2, 3, 8) # g.add_edge(0, 3, 15) # print(dijkstra(g, 0, 3))]]></content>
  </entry>
  <entry>
    <title><![CDATA[tg_sort]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F25%2Ftg-sort%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960from collections import dequefrom itertools import filterfalseclass Graph: def __init__(self, num_vertices: int): self._num_vertices = num_vertices self._adjacency = [[] for _ in range(num_vertices)] def add_edge(self, s: int, t: int) -&gt; None: self._adjacency[s].append(t) def tsort_by_kahn(self) -&gt; None: in_degree = [0] * self._num_vertices for v in range(self._num_vertices): if len(self._adjacency[v]): for neighbour in self._adjacency[v]: in_degree[neighbour] += 1 q = deque(filterfalse(lambda x: in_degree[x], range(self._num_vertices))) while q: v = q.popleft() print(f&quot;&#123;v&#125; -&gt; &quot;, end=&quot;&quot;) for neighbour in self._adjacency[v]: in_degree[neighbour] -= 1 if not in_degree[neighbour]: q.append(neighbour) print(&quot;\b\b\b &quot;) def tsort_by_dfs(self) -&gt; None: inverse_adjacency = [[] for _ in range(self._num_vertices)] for v in range(self._num_vertices): if len(self._adjacency[v]): for neighbour in self._adjacency[v]: inverse_adjacency[neighbour].append(v) visited = [False] * self._num_vertices def dfs(vertex: int) -&gt; None: if len(inverse_adjacency[vertex]): for v in inverse_adjacency[vertex]: if not visited[v]: visited[v] = True dfs(v) print(f&quot;&#123;vertex&#125; -&gt; &quot;, end=&quot;&quot;) for v in range(self._num_vertices): if not visited[v]: visited[v] = True dfs(v) print(&quot;\b\b\b &quot;)if __name__ == &quot;__main__&quot;: dag = Graph(4) dag.add_edge(1, 0) dag.add_edge(2, 1) dag.add_edge(1, 3) dag.tsort_by_kahn() dag.tsort_by_dfs()]]></content>
  </entry>
  <entry>
    <title><![CDATA[dp-006]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F24%2Fdp-006%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637from typing import Listfrom itertools import accumulatedef min_dist(weights: List[List[int]]) -&gt; int: &quot;&quot;&quot;Find the minimum weight path from the weights matrix.&quot;&quot;&quot; m, n = len(weights), len(weights[0]) table = [[0] * n for _ in range(m)] # table[i][j] is the minimum distance (weight) when # there are i vertical moves and j horizontal moves # left. table[0] = list(accumulate(reversed(weights[-1]))) for i, v in enumerate(accumulate(row[-1] for row in reversed(weights))): table[i][0] = v for i in range(1, m): for j in range(1, n): table[i][j] = weights[~i][~j] + min(table[i - 1][j], table[i][j - 1]) return table[-1][-1]def min_dist_recur(weights: List[List[int]]) -&gt; int: m, n = len(weights), len(weights[0]) table = [[0] * n for _ in range(m)] def min_dist_to(i: int, j: int) -&gt; int: if i == j == 0: return weights[0][0] if table[i][j]: return table[i][j] min_left = float(&quot;inf&quot;) if j - 1 &lt; 0 else min_dist_to(i, j - 1) min_up = float(&quot;inf&quot;) if i - 1 &lt; 0 else min_dist_to(i - 1, j) return weights[i][j] + min(min_left, min_up) return min_dist_to(m - 1, n - 1)if __name__ == &quot;__main__&quot;: weights = [[1, 3, 5, 9], [2, 1, 3, 4], [5, 2, 6, 7], [6, 8, 4, 3]] print(min_dist(weights)) print(min_dist_recur(weights))]]></content>
  </entry>
  <entry>
    <title><![CDATA[dp-005]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F24%2Fdp-005%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python# -*- coding: UTF-8 -*-from typing import Listdef coins_dp(values: List[int], target: int) -&gt; int: # memo[i]表示target为i的时候，所需的最少硬币数 memo = [0] * (target+1) # 0元的时候为0个 memo[0] = 0 for i in range(1, target+1): min_num = 999999 # 对于values中的所有n # memo[i]为 min(memo[i-n1], memo[i-n2], ...) + 1 for n in values: if i &gt;= n: min_num = min(min_num, 1 + memo[i-n]) else: # values中的数值要从小到大排序 break memo[i] = min_num # print(memo) return memo[-1]min_num = 999999def coins_backtracking(values: List[int], target: int, cur_value: int, coins_count: int): if cur_value == target: global min_num min_num = min(coins_count, min_num) else: for n in values: if cur_value + n &lt;= target: coins_backtracking(values, target, cur_value+n, coins_count+1)if __name__ == &apos;__main__&apos;: values = [1, 3, 5] target = 23 print(coins_dp(values, target)) coins_backtracking(values, target, 0, 0) print(min_num)]]></content>
  </entry>
  <entry>
    <title><![CDATA[dp-004]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F24%2Fdp-004%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def levenshtein_dp(s: str, t: str) -&gt; int: m, n = len(s), len(t) table = [[0] * (n) for _ in range(m)] for i in range(n): if s[0] == t[i]: table[0][i] = i - 0 elif i != 0: table[0][i] = table[0][i - 1] + 1 else: table[0][i] = 1 for i in range(m): if s[i] == t[0]: table[i][0] = i - 0 elif i != 0: table[i][0] = table[i - 1][0] + 1 else: table[i][0] = 1 for i in range(1, m): for j in range(1, n): table[i][j] = min(1 + table[i - 1][j], 1 + table[i][j - 1], int(s[i] != t[j]) + table[i - 1][j - 1]) print(table) return table[-1][-1]def common_substring_dp(s: str, t: str) -&gt; int: m, n = len(s), len(t) table = [[0] * (n + 1) for _ in range(m + 1)] for i in range(1, m + 1): for j in range(1, n + 1): table[i][j] = max(table[i - 1][j], table[i][j - 1], int(s[i - 1] == t[j - 1]) + table[i - 1][j - 1]) return table[-1][-1]if __name__ == &quot;__main__&quot;: s = &quot;mitcmu&quot; t = &quot;mtacnu&quot; print(levenshtein_dp(s, t)) print(common_substring_dp(s, t)) s = &quot;kitten&quot; t = &quot;sitting&quot; print(levenshtein_dp(s, t)) print(common_substring_dp(s, t)) s = &quot;flaw&quot; t = &quot;lawn&quot; print(levenshtein_dp(s, t)) print(common_substring_dp(s, t))]]></content>
  </entry>
  <entry>
    <title><![CDATA[dp003]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F21%2Fdp003%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#!/usr/bin/python# -*- coding: UTF-8 -*-from typing import Listdef longest_increasing_subsequence(nums: List[int]) -&gt; int: &quot;&quot;&quot; 最长子上升序列的一种DP解法，从回溯解法转化，思路类似于有限物品的背包问题 每一次决策都算出当前可能的lis的长度，重复子问题合并，合并策略是lis的末尾元素最小 时间复杂度：O(n^2) 空间复杂度：O(n^2)，可优化至O(n) 没leetcode上的参考答案高效，提供另一种思路作为参考 https://leetcode.com/problems/longest-increasing-subsequence/solution/ :param nums: :return: &quot;&quot;&quot; if not nums: return 0 n = len(nums) # memo[i][j] 表示第i次决策，长度为j的lis的 最小的 末尾元素数值 # 每次决策都根据上次决策的所有可能转化，空间上可以类似背包优化为O(n) memo = [[-1] * (n+1) for _ in range(n)] # 第一列全赋值为0，表示每次决策都不选任何数 for i in range(n): memo[i][0] = 0 # 第一次决策选数组中的第一个数 memo[0][1] = nums[0] for i in range(1, n): for j in range(1, n+1): # case 1: 长度为j的lis在上次决策后存在，nums[i]比长度为j-1的lis末尾元素大 if memo[i-1][j] != -1 and nums[i] &gt; memo[i-1][j-1]: memo[i][j] = min(nums[i], memo[i-1][j]) # case 2: 长度为j的lis在上次决策后存在，nums[i]比长度为j-1的lis末尾元素小/等 if memo[i-1][j] != -1 and nums[i] &lt;= memo[i-1][j-1]: memo[i][j] = memo[i-1][j] if memo[i-1][j] == -1: # case 3: 长度为j的lis不存在，nums[i]比长度为j-1的lis末尾元素大 if nums[i] &gt; memo[i-1][j-1]: memo[i][j] = nums[i] # case 4: 长度为j的lis不存在，nums[i]比长度为j-1的lis末尾元素小/等 break for i in range(n, -1, -1): if memo[-1][i] != -1: return iif __name__ == &apos;__main__&apos;: # 要求输入的都是大于0的正整数(可优化至支持任意整数) nums = [2, 9, 3, 6, 5, 1, 7] print(longest_increasing_subsequence(nums))]]></content>
  </entry>
  <entry>
    <title><![CDATA[dp002]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F21%2Fdp002%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#!/usr/bin/python# -*- coding: UTF-8 -*-from typing import ListLayer_nums = List[int]def yh_triangle(nums: List[Layer_nums]) -&gt; int: &quot;&quot;&quot; 从根节点开始向下走，过程中经过的节点，只需存储经过它时最小的路径和 :param nums: :return: &quot;&quot;&quot; assert len(nums) &gt; 0 n = len(nums) # 层数 memo = [[0]*n for i in range(n)] memo[0][0] = nums[0][0] for i in range(1, n): for j in range(i+1): # 每一层首尾两个数字，只有一条路径可以到达 if j == 0: memo[i][j] = memo[i-1][j] + nums[i][j] elif j == i: memo[i][j] = memo[i-1][j-1] + nums[i][j] else: memo[i][j] = min(memo[i-1][j-1] + nums[i][j], memo[i-1][j] + nums[i][j]) return min(memo[n-1])def yh_triangle_space_optimization(nums: List[Layer_nums]) -&gt; int: assert len(nums) &gt; 0 n = len(nums) memo = [0] * n memo[0] = nums[0][0] for i in range(1, n): for j in range(i, -1, -1): if j == i: memo[j] = memo[j-1] + nums[i][j] elif j == 0: memo[j] = memo[j] + nums[i][j] else: memo[j] = min(memo[j-1] + nums[i][j], memo[j] + nums[i][j]) return min(memo)def yh_triangle_bottom_up(nums: List[Layer_nums]) -&gt; int: assert len(nums) &gt; 0 n = len(nums) memo = nums[-1].copy() for i in range(n-1, 0, -1): for j in range(i): memo[j] = min(memo[j] + nums[i-1][j], memo[j+1] + nums[i-1][j]) return memo[0]if __name__ == &apos;__main__&apos;: nums = [[3], [2, 6], [5, 4, 2], [6, 0, 3, 2]] print(yh_triangle(nums)) print(yh_triangle_space_optimization(nums)) print(yh_triangle_bottom_up(nums))]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dp001]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F21%2Fdp001%2F</url>
    <content type="text"><![CDATA[动态规化 寻求最优解 比如最大值 最小值 降低时间复杂度 0-1背包1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from typing import List, Tupledef bag(items_info: List[int], capacity: int) -&gt; int: &quot;&quot;&quot; 固定容量的背包，计算能装进背包的物品组合的最大重量 :param items_info: 每个物品的重量 :param capacity: 背包容量 :return: 最大装载重量 &quot;&quot;&quot; n = len(items_info) memo = [[-1]*(capacity+1) for i in range(n)] memo[0][0] = 1 if items_info[0] &lt;= capacity: memo[0][items_info[0]] = 1 for i in range(1, n): for cur_weight in range(capacity+1): if memo[i-1][cur_weight] != -1: memo[i][cur_weight] = memo[i-1][cur_weight] # 不选 if cur_weight + items_info[i] &lt;= capacity: # 选 memo[i][cur_weight + items_info[i]] = 1 for w in range(capacity, -1, -1): if memo[-1][w] != -1: return wdef bag_with_max_value(items_info: List[Tuple[int, int]], capacity: int) -&gt; int: &quot;&quot;&quot; 固定容量的背包，计算能装进背包的物品组合的最大价值 :param items_info: 物品的重量和价值 :param capacity: 背包容量 :return: 最大装载价值 &quot;&quot;&quot; n = len(items_info) memo = [[-1]*(capacity+1) for i in range(n)] memo[0][0] = 0 if items_info[0][0] &lt;= capacity: memo[0][items_info[0][0]] = items_info[0][1] for i in range(1, n): for cur_weight in range(capacity+1): if memo[i-1][cur_weight] != -1: memo[i][cur_weight] = memo[i-1][cur_weight] if cur_weight + items_info[i][0] &lt;= capacity: memo[i][cur_weight + items_info[i][0]] = max(memo[i][cur_weight + items_info[i][0]], memo[i-1][cur_weight] + items_info[i][1]) return max(memo[-1])if __name__ == &apos;__main__&apos;: # [weight, ...] items_info = [2, 2, 4, 6, 3] capacity = 9 print(bag(items_info, capacity)) # [(weight, value), ...] items_info = [(3, 5), (2, 2), (1, 4), (1, 2), (4, 10)] capacity = 8 print(bag_with_max_value(items_info, capacity))]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串之字典树]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F21%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B9%8B%E5%AD%97%E5%85%B8%E6%A0%91%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940class TrieNode: def __init__(self, data: str): self._data = data self._children = [None] * 26 self._is_ending_char = False class Trie: def __init__(self): self._root = TrieNode(&quot;/&quot;) def insert(self, text: str) -&gt; None: node = self._root for index, char in map(lambda x: (ord(x) - ord(&quot;a&quot;), x), text): if not node._children[index]: node._children[index] = TrieNode(char) node = node._children[index] node._is_ending_char = True def find(self, pattern: str) -&gt; bool: node = self._root for index in map(lambda x: ord(x) - ord(&quot;a&quot;), pattern): if not node._children[index]: return False node = node._children[index] return node._is_ending_charif __name__ == &quot;__main__&quot;: strs = [&quot;how&quot;, &quot;hi&quot;, &quot;her&quot;, &quot;hello&quot;, &quot;so&quot;, &quot;see&quot;] trie = Trie() for s in strs: trie.insert(s) for s in strs: print(trie.find(s)) print(trie.find(&quot;swift&quot;))]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串匹配-kmp]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F20%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D-kmp%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556from typing import Listdef kmp(s: int, pattern: int) -&gt; int: m = len(pattern) partial_match_table = _get_partial_match_table(pattern) j = 0 for i in range(len(s)): while j &gt;= 0 and s[i] != pattern[j]: j = partial_match_table[j] j += 1 if j == m: return i - m + 1 return -1def _get_partial_match_table(pattern: int) -&gt; List[int]: # Denote πᵏ(i) as π applied to i for k times, # i.e., π²(i) = π(π(i)). # Then we have the result: # π(i) = πᵏ(i-1) + 1, # where k is the smallest integer such that # pattern[πᵏ(i-1)+1] == pattern[i]. # The value of π means the maximum length # of proper prefix/suffix. # The index of π means the length of the prefix # considered for pattern. # For example, π[2] means we are considering the first 2 characters # of the pattern. # If π[2] == 1, it means for the prefix of the pattern, P[0]P[1], # it has a maximum length proper prefix of 1, which is also the # suffix of P[0]P[1]. # We also add a π[0] == -1 for easier handling of boundary # condition. m = len(pattern) π = [0] * (m + 1) π[0] = k = -1 # We use k here to represent πᵏ(i) for i in range(1, m + 1): while k &gt;= 0 and pattern[k] != pattern[i - 1]: k = π[k] k += 1 π[i] = k return πif __name__ == &quot;__main__&quot;: s = &quot;abc abcdab abcdabcdabde&quot; pattern = &quot;bcdabd&quot; print(kmp(s, pattern), s.find(pattern)) s = &quot;hello&quot; pattern = &quot;ll&quot; print(kmp(s, pattern), s.find(pattern))]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串匹配-bm-kmp]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F20%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D-bm-kmp%2F</url>
    <content type="text"><![CDATA[boyer-moore 算法 模式串的主串的匹配过程 看作模式串在主串不停地向后滑动 当遇到不匹配的字符时 bf rk都是模式串往后移动一位 那么有没有更高效的 往后移动多位呢 如果往后滑动的时候 有重合 无法匹配的时候 可以多滑动几位 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#!/usr/bin/python# -*- coding: UTF-8 -*-SIZE = 256def bm(main, pattern): &quot;&quot;&quot; BM算法 匹配规则： 1. 坏字符规则 2. 好字符规则 :param main: :param pattern: :return: &quot;&quot;&quot; assert type(main) is str and type(pattern) is str n, m = len(main), len(pattern) if n &lt;= m: return 0 if main == pattern else -1 # bc bc = [-1] * SIZE generate_bc(pattern, m, bc) # gs suffix = [-1] * m prefix = [False] * m generate_gs(pattern, m, suffix, prefix) i = 0 while i &lt; n-m+1: j = m - 1 while j &gt;= 0: if main[i+j] != pattern[j]: break else: j -= 1 # pattern整个已被匹配，返回 if j == -1: return i # 1. bc规则计算后移位数 x = j - bc[ord(main[i+j])] # 2. gs规则计算后移位数 y = 0 if j != m - 1: # 存在gs y = move_by_gs(j, m, suffix, prefix) i += max(x, y) return -1def generate_bc(pattern, m, bc): &quot;&quot;&quot; 生成坏字符哈希表 :param pattern: :param m: :param bc: :return: &quot;&quot;&quot; for i in range(m): bc[ord(pattern[i])] = idef generate_gs(pattern, m, suffix, prefix): &quot;&quot;&quot; 好后缀预处理 :param pattern: :param m: :param suffix: :param prefix: :return: &quot;&quot;&quot; for i in range(m-1): k = 0 # pattern[:i+1]和pattern的公共后缀长度 for j in range(i, -1, -1): if pattern[j] == pattern[m-1-k]: k += 1 suffix[k] = j if j == 0: prefix[k] = True else: breakdef move_by_gs(j, m, suffix, prefix): &quot;&quot;&quot; 通过好后缀计算移动值 需要处理三种情况： 1. 整个好后缀在pattern仍能找到 2. 好后缀里存在 *后缀子串* 能和pattern的 *前缀* 匹配 3. 其他 :param j: :param m: :param suffix: :param prefix: :return: &quot;&quot;&quot; k = m - 1 - j # j指向从后往前的第一个坏字符，k是此次匹配的好后缀的长度 if suffix[k] != -1: # 1. 整个好后缀在pattern剩余字符中仍有出现 return j - suffix[k] + 1 else: for r in range(j+2, m): # 2. 后缀子串从长到短搜索 if prefix[m-r]: return r return m # 3. 其他情况if __name__ == &apos;__main__&apos;: print(&apos;--- search ---&apos;) m_str = &apos;dfasdeeeetewtweyyyhtruuueyytewtweyyhtrhrth&apos; p_str = &apos;eyytewtweyy&apos; print(&apos;[Built-in Functions] result:&apos;, m_str.find(p_str)) print(&apos;[bm] result:&apos;, bm(m_str, p_str))]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串匹配-bf-rk]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F19%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D-bf-rk%2F</url>
    <content type="text"><![CDATA[主串 子串(模式串) BF算法 在主串中检查起始位置分别是0、1、2…n-m且长度为m的n-m+1个子串 时间复杂度是n*m 但是在实际开发的过程中 是比较常用的 因为 大部分情况下 模式串和主串的长度都不会太长 而且每次模式串与主串中的子串匹配的时候 当中途遇到不能匹配的字符时 就停止了 不需要把字符串都比对一下 大部分情况下 够用 朴素字符串匹配算法思想简单 代码实现也非常简单 简单意味着不容易出错在满足性能要求的前提下 简单是首选 RK 在朴素字符串匹配的基础上 引入哈希 对每个子串分别求哈希值 然后拿子串的哈希值与模式串的哈希值比较 理想情况下的时间复杂度是n 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#!/usr/bin/python# -*- coding: UTF-8 -*-from time import timedef bf(main, pattern): """ 字符串匹配，bf暴搜 :param main: 主串 :param pattern: 模式串 :return: """ n = len(main) m = len(pattern) if n &lt;= m: return 0 if pattern == main else -1 for i in range(n-m+1): for j in range(m): if main[i+j] == pattern[j]: if j == m-1: return i else: continue else: break return -1def simple_hash(s, start, end): """ 计算子串的哈希值 每个字符取acs-ii码后求和 :param s: :param start: :param end: :return: """ assert start &lt;= end ret = 0 for c in s[start: end+1]: ret += ord(c) return retdef rk(main, pattern): n = len(main) m = len(pattern) if n &lt;= m: return 0 if pattern == main else -1 # 子串哈希值表 hash_memo = [None] * (n-m+1) hash_memo[0] = simple_hash(main, 0, m-1) for i in range(1, n-m+1): hash_memo[i] = hash_memo[i-1] - simple_hash(main, i-1, i-1) + simple_hash(main, i+m-1, i+m-1) # 模式串哈希值 hash_p = simple_hash(pattern, 0, m-1) for i, h in enumerate(hash_memo): # 可能存在哈希冲突 if h == hash_p: if pattern == main[i:i+m]: return i else: continue return -1if __name__ == '__main__': m_str = 'a'*10000 p_str = 'a'*200+'b' print('--- time consume ---') t = time() print('[bf] result:', bf(m_str, p_str)) print('[bf] time cost: &#123;0:.5&#125;s'.format(time()-t)) t = time() print('[rk] result:', rk(m_str, p_str)) print('[rk] time cost: &#123;0:.5&#125;s'.format(time()-t)) print('') print('--- search ---') m_str = 'thequickbrownfoxjumpsoverthelazydog' p_str = 'jump' print('[bf] result:', bf(m_str, p_str)) print('[rk] result:', rk(m_str, p_str)) 输出如下： 1234567891011121314151617181920212223--- time consume ---('[bf] result:', -1)[bf] time cost: 0.27776s('[rk] result:', -1)[rk] time cost: 0.012524s--- search ---('[bf] result:', 16)('[rk] result:', 16)# 如上是普通cpython 2的输出# 纯粹的py代码 可以使用pypy来加速--- time consume ---('[bf] result:', -1)[bf] time cost: 0.033931s('[rk] result:', -1)[rk] time cost: 0.02212s--- search ---('[bf] result:', 16)('[rk] result:', 16)]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>string</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-bigintmulti]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F19%2Fleetcode-bigintmulti%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627def karatsuba(x, y): &quot;&quot;&quot;Function to multiply 2 numbers in a more efficient manner than the grade school algorithm&quot;&quot;&quot; if len(str(x)) == 1 or len(str(y)) == 1: return x * y else: n = max(len(str(x)), len(str(y))) nby2 = n / 2 a = x / 10**(nby2) b = x % 10**(nby2) c = y / 10**(nby2) d = y % 10**(nby2) ac = karatsuba(a, c) bd = karatsuba(b, d) ad_plus_bc = karatsuba(a + b, c + d) - ac - bd # this little trick, writing n as 2*nby2 takes care of both even and # odd n prod = ac * 10**(2 * nby2) + (ad_plus_bc * 10**nby2) + bd return prodif __name__ == &quot;__main__&quot;: print(karatsuba(86123457, 12345678)) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190#! /usr/local/bin/python3.6&quot;&quot;&quot;Multiplication of big-digit values with Toom-Cook 3-way method&quot;&quot;&quot;import randomimport sysimport tracebackclass MultiplyToomCook3: D_MAX = 729 # Maximum number of digits (power of 3) D = 729 # Digits of computation (&lt;= D_MAX) def __init__(self): self.a = [random.randrange(10) for _ in range(self.D)] self.b = [random.randrange(10) for _ in range(self.D)] def compute(self): &quot;&quot;&quot; Computation of multiplication &quot;&quot;&quot; try: for i in range(self.D_MAX - len(self.a)): self.a.append(0) for i in range(self.D_MAX - len(self.b)): self.b.append(0) z = self.__multiply_toom_cook_3(self.a, self.b) z = self.__do_carry(z) self.__display(self.a, self.b, z) except Exception as e: raise def __multiply_normal(self, a, b): &quot;&quot;&quot; Normal multiplication :param list a :param list b :return list z &quot;&quot;&quot; try: a_len, b_len = len(a), len(b) z = [0 for _ in range(a_len + b_len)] for j in range(b_len): for i in range(a_len): z[j + i] += a[i] * b[j] return z except Exception as e: raise def __multiply_toom_cook_3(self, a, b): &quot;&quot;&quot; Toom-Cook 3-way multiplication :param list a :param list b :return list z &quot;&quot;&quot; a_m1, a_m2, a_0, a_1, a_inf = [], [], [], [], [] b_m1, b_m2, b_0, b_1, b_inf = [], [], [], [], [] c_m1, c_m2, c_0, c_1, c_inf = [], [], [], [], [] c0, c1, c2, c3, c4 = [], [], [], [], [] try: t_len = len(a) # ９桁（配列９個）になった場合は標準乗算 if t_len &lt;= 9: return self.__multiply_normal(a, b) a0 = a[:(t_len // 3)] a1 = a[(t_len // 3):(t_len * 2 // 3)] a2 = a[(t_len * 2 // 3):] b0 = b[:(t_len // 3)] b1 = b[(t_len // 3):(t_len * 2 // 3)] b2 = b[(t_len * 2 // 3):] for i in range(t_len // 3): a_m2.append((a2[i] &lt;&lt; 2) - (a1[i] &lt;&lt; 1) + a0[i]) b_m2.append((b2[i] &lt;&lt; 2) - (b1[i] &lt;&lt; 1) + b0[i]) for i in range(t_len // 3): a_m1.append(a2[i] - a1[i] + a0[i]) b_m1.append(b2[i] - b1[i] + b0[i]) a_0, b_0 = a0, b0 for i in range(t_len // 3): a_1.append(a2[i] + a1[i] + a0[i]) b_1.append(b2[i] + b1[i] + b0[i]) a_inf, b_inf= a2, b2 c_m2 = self.__multiply_toom_cook_3(a_m2, b_m2) c_m1 = self.__multiply_toom_cook_3(a_m1, b_m1) c_0 = self.__multiply_toom_cook_3(a_0, b_0) c_1 = self.__multiply_toom_cook_3(a_1, b_1) c_inf = self.__multiply_toom_cook_3(a_inf, b_inf) c4 = c_inf for i in range((t_len // 3) * 2): c = -c_m2[i] c += (c_m1[i] &lt;&lt; 1) + c_m1[i] c -= (c_0[i] &lt;&lt; 1) + c_0[i] c += c_1[i] c += (c_inf[i] &lt;&lt; 3) + (c_inf[i] &lt;&lt; 2) c = c // 6 c3.append(c) for i in range((t_len // 3) * 2): c = (c_m1[i] &lt;&lt; 1) + c_m1[i] c -= (c_0[i] &lt;&lt; 2) + (c_0[i] &lt;&lt; 1) c += (c_1[i] &lt;&lt; 1) + c_1[i] c -= (c_inf[i] &lt;&lt; 2) + (c_inf[i] &lt;&lt; 1) c = c // 6 c2.append(c) for i in range((t_len // 3) * 2): c = c_m2[i] c -= (c_m1[i] &lt;&lt; 2) + (c_m1[i] &lt;&lt; 1) c += (c_0[i] &lt;&lt; 1) + c_0[i] c += (c_1[i] &lt;&lt; 1) c -= (c_inf[i] &lt;&lt; 3) + (c_inf[i] &lt;&lt; 2) c = c // 6 c1.append(c) c0 = c_0 z = c0 + c2 + c4 for i in range((t_len // 3) * 2): z[i + t_len // 3] += c1[i] for i in range((t_len // 3) * 2): z[i + t_len] += c3[i] return z except Exception as e: raise def __do_carry(self, a): &quot;&quot;&quot; Process of carrying :param list a :return list a &quot;&quot;&quot; cr = 0 try: for i in range(len(a)): a[i] += cr cr = a[i] // 10 a[i] -= cr * 10 if cr != 0: print(&quot;[ OVERFLOW!! ] &quot;, cr) return a except Exception as e: raise def __display(self, a, b, z): &quot;&quot;&quot; Display :param list a :param list b :param list z &quot;&quot;&quot; a_len = self.D_MAX b_len = self.D_MAX z_len = self.D_MAX * 2 try: while a[a_len - 1] == 0: if a[a_len - 1] == 0: a_len -= 1 while b[b_len - 1] == 0: if b[b_len - 1] == 0: b_len -= 1 while z[z_len - 1] == 0: if z[z_len - 1] == 0: z_len -= 1 print(&quot;a =&quot;) for i in reversed(range(a_len)): print(a[i], end=&quot;&quot;) if (a_len - i) % 10 == 0: print(&quot; &quot;, end=&quot;&quot;) if (a_len - i) % 50 == 0: print() print() print(&quot;b =&quot;) for i in reversed(range(b_len)): print(b[i], end=&quot;&quot;) if (b_len - i) % 10 == 0: print(&quot; &quot;, end=&quot;&quot;) if (b_len - i) % 50 == 0: print() print() print(&quot;z =&quot;) for i in reversed(range(z_len)): print(z[i], end=&quot;&quot;) if (z_len - i) % 10 == 0: print(&quot; &quot;, end=&quot;&quot;) if (z_len - i) % 50 == 0: print() print() except Exception as e: raiseif __name__ == &apos;__main__&apos;: try: obj = MultiplyToomCook3() obj.compute() except Exception as e: traceback.print_exc() sys.exit(1)]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-linklist]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F19%2Fleetcode-linklist%2F</url>
    <content type="text"><![CDATA[输出单链表倒数第k个节点 1234567891011121314151617181920212223// 双指针法ListNode* findKthTail(ListNode *pHead, int K)&#123; if (NULL == pHead || K == 0) return NULL; //p1，p2均指向头节点 ListNode *p1 = pHead; ListNode *p2 = pHead; //p1先出发，前进K个节点 for (int i = 0; i &lt; K; i++) &#123; if (p1)//防止k大于链表节点的个数 p1 = p1-&gt;_next; else return NULL; &#125; while (p1)//如果p1没有到达链表结尾，则p1，p2继续遍历 &#123; p1 = p1-&gt;_next; p2 = p2-&gt;_next; &#125; return p2;//当p1到达末尾时，p2正好指向倒数第K个节点&#125; 链表中存在环的问题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374bool isExistLoop(ListNode* pHead) &#123; ListNode* fast;//慢指针，每次前进一个节点 ListNode* slow;//快指针，每次前进2个节点 slow = fast = pHead ; //两个指针均指向链表头节点 //当没有到达链表结尾，则继续前进 while (slow != NULL &amp;&amp; fast -&gt; next != NULL) &#123; slow = slow -&gt; next ; //慢指针前进一个节点 fast = fast -&gt; next -&gt; next ; //快指针前进两个节点 if (slow == fast) //若两个指针相遇，且均不为NULL则存在环 return true ; &#125; //到达末尾仍然没有相遇，则不存在环 return false ; &#125; // 快慢指针 //找到环中的相遇节点ListNode* getMeetingNode(ListNode* pHead) // 假设为带头节点的单链表&#123; ListNode* fast;//慢指针，每次前进一个节点 ListNode* slow;//快指针，每次前进2个节点 slow = fast = pHead ; //两个指针均指向链表头节点 //当没有到达链表结尾，则继续前进 while (slow != NULL &amp;&amp; fast -&gt; next != NULL)&#123; slow = slow -&gt; next ; //慢指针前进一个节点 fast = fast -&gt; next -&gt; next ; //快指针前进两个节点 if (slow == fast) //若两个指针相遇，且均不为NULL则存在环 return slow; &#125; //到达末尾仍然没有相遇，则不存在环 return NULL ;&#125;//找出环的入口节点ListNode* getEntryNodeOfLoop(ListNode* pHead)&#123; ListNode* meetingNode = getMeetingNode(pHead); // 先找出环中的相遇节点 if (meetingNode == NULL) return NULL; ListNode* p1 = meetingNode; ListNode* p2 = pHead; while (p1 != p2) // p1和p2以相同的速度向前移动，当p2指向环的入口节点时，p1已经围绕着环走了n圈又回到了入口节点。 &#123; p1 = p1-&gt;next; p2 = p2-&gt;next; &#125; //返回入口节点 return p1;&#125;// 计算环的长度int getLoopLength(ListNode* head)&#123; ListNode* slow = head; ListNode* fast = head; while ( fast &amp;&amp; fast-&gt;next )&#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; if ( slow == fast )//第一次相遇 break; &#125; //slow与fast继续前进 slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; int length = 1; //环长度 while ( fast != slow )//再次相遇 &#123; slow = slow-&gt;next; fast = fast-&gt;next-&gt;next; length ++; //累加 &#125; //当slow与fast再次相遇，得到环长度 return length;&#125; 使用链表实现大数相加 12345678910111213141516171819202122232425262728293031323334353637383940ListNode* numberAddAsList(ListNode* l1, ListNode* l2) &#123; ListNode *ret = l1, *pre = l1; int up = 0; while (l1 != NULL &amp;&amp; l2 != NULL) &#123; //数值相加 l1-&gt;val = l1-&gt;val + l2-&gt;val + up; //计算是否有进位 up = l1-&gt;val / 10; //保留计算结果的个位 l1-&gt;val %= 10; //记录当前节点位置 pre = l1; //同时向后移位 l1 = l1-&gt;next; l2 = l2-&gt;next; &#125; //若l1到达末尾，说明l1长度小于l2 if (l1 == NULL) //pre-&gt;next指向l2的当前位置 pre-&gt;next = l2; //l1指针指向l2节点当前位置 l1 = pre-&gt;next; //继续计算剩余节点 while (l1 != NULL) &#123; l1-&gt;val = l1-&gt;val + up; up = l1-&gt;val / 10; l1-&gt;val %= 10; pre = l1; l1 = l1-&gt;next; &#125; //最高位计算有进位，则新建一个节点保留最高位 if (up != 0) &#123; ListNode *tmp = new ListNode(up); pre-&gt;next = tmp; &#125; //返回计算结果链表 return ret;&#125; 有序链表合并 1234567891011121314151617ListNode* mergeTwoOrderedLists(ListNode* pHead1, ListNode* pHead2)&#123; ListNode* newHead = NULL; if (NULL == pHead1)&#123; return pHead2; &#125;else if(NULL ==pHead2)&#123; return pHead2; &#125;else&#123; if (pHead1-&gt;data &lt; pHead2-&gt;data)&#123; newHead = pHead1; newHead-&gt;next = mergeTwoOrderedLists(pHead1-&gt;next, pHead2); &#125;else&#123; newHead = pHead2; newHead-&gt;next = mergeTwoOrderedLists(pHead1, pHead2-&gt;next); &#125; return newHead; &#125; &#125; 删除链表中节点 要求时间复杂度为1 12345678910111213141516171819202122232425262728void deleteNode(ListNode **pHead, ListNode* pDelNode) &#123; if(pDelNode == NULL) return; if(pDelNode-&gt;next != NULL)&#123; ListNode *pNext = pDelNode-&gt;next; //下一个节点值赋给待删除节点 pDelNode-&gt;val = pNext-&gt;val; //待删除节点指针指后面第二个节点 pDelNode-&gt;next = pNext-&gt;next; //删除待删除节点的下一个节点 delete pNext; pNext = NULL; &#125;else if(*pHead == pDelNode)//删除的节点是头节点 &#123; delete pDelNode; pDelNode= NULL; *pHead = NULL; &#125; else//删除的是尾节点 &#123; ListNode *pNode = *pHead; while(pNode-&gt;next != pDelNode) &#123; pNode = pNode-&gt;next; &#125; pNode-&gt;next = NULL; delete pDelNode; pDelNode= NULL; &#125; &#125; 从尾到头打印链表 1234567891011121314151617181920212223242526272829303132333435class Solution &#123;public: vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; vector&lt;int&gt; value; ListNode *p=NULL; p=head; stack&lt;int&gt; stk; while(p!=NULL)&#123; stk.push(p-&gt;val); p=p-&gt;next; &#125; while(!stk.empty())&#123; value.push_back(stk.top()); stk.pop(); &#125; return value; &#125;&#125;;class Solution &#123;public: vector&lt;int&gt; value; vector&lt;int&gt; printListFromTailToHead(ListNode* head) &#123; ListNode *p=NULL; p=head; if(p!=NULL)&#123; if(p-&gt;next!=NULL)&#123; printListFromTailToHead(p-&gt;next); &#125; value.push_back(p-&gt;val); &#125; return value; &#125;&#125;; 反转链表 123456789101112131415161718192021222324252627282930313233343536// 迭代class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; ListNode* pre = NULL; ListNode* cur = head; while(cur != NULL)&#123; ListNode* next = cur-&gt;next; cur-&gt;next = pre; pre = cur; cur = next; &#125; return pre; &#125;&#125;;//递归class Solution &#123;public: ListNode* reverseList(ListNode* head) &#123; // 递归终止条件 if(head == NULL || head-&gt;next == NULL) return head; ListNode* rhead = reverseList(head-&gt;next); // head-&gt;next此刻指向head后面的链表的尾节点 // head-&gt;next-&gt;next = head把head节点放在了尾部 head-&gt;next-&gt;next = head; head-&gt;next = NULL; return rhead; &#125;&#125;;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-queue]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F19%2Fleetcode-queue%2F</url>
    <content type="text"><![CDATA[有效的括号 1234567891011121314151617181920class Solution &#123; public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); char[] chars = s.toCharArray(); for (char aChar : chars) &#123; if (stack.size() == 0) &#123; stack.push(aChar); &#125; else if (isSym(stack.peek(), aChar)) &#123; stack.pop(); &#125; else &#123; stack.push(aChar); &#125; &#125; return stack.size() == 0; &#125; private boolean isSym(char c1, char c2) &#123; return (c1 == &apos;(&apos; &amp;&amp; c2 == &apos;)&apos;) || (c1 == &apos;[&apos; &amp;&amp; c2 == &apos;]&apos;) || (c1 == &apos;&#123;&apos; &amp;&amp; c2 == &apos;&#125;&apos;); &#125;&#125; 两个栈 实现队列 1234567891011121314151617Stack&lt;Integer&gt; in = new Stack&lt;Integer&gt;();Stack&lt;Integer&gt; out = new Stack&lt;Integer&gt;();public void push(int node) &#123; in.push(node);&#125;public int pop() throws Exception &#123; if (out.isEmpty()) while (!in.isEmpty()) out.push(in.pop()); if (out.isEmpty()) throw new Exception(&quot;queue is empty&quot;); return out.pop();&#125; 栈的压入 弹出序列 12345678910111213public boolean IsPopOrder(int[] pushSequence, int[] popSequence) &#123; int n = pushSequence.length; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); for (int pushIndex = 0, popIndex = 0; pushIndex &lt; n; pushIndex++) &#123; stack.push(pushSequence[pushIndex]); while (popIndex &lt; n &amp;&amp; !stack.isEmpty() &amp;&amp; stack.peek() == popSequence[popIndex]) &#123; stack.pop(); popIndex++; &#125; &#125; return stack.isEmpty();&#125; 包含min 函数的栈 1234567891011121314151617181920private Stack&lt;Integer&gt; dataStack = new Stack&lt;&gt;();private Stack&lt;Integer&gt; minStack = new Stack&lt;&gt;();public void push(int node) &#123; dataStack.push(node); minStack.push(minStack.isEmpty() ? node : Math.min(minStack.peek(), node));&#125;public void pop() &#123; dataStack.pop(); minStack.pop();&#125;public int top() &#123; return dataStack.peek();&#125;public int min() &#123; return minStack.peek();&#125; 计算器 12 其他题 12]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-bit]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F19%2Fleetcode-bit%2F</url>
    <content type="text"><![CDATA[数1 1234567891011class Solution &#123;public: int hammingWeight(uint32_t n) &#123; int res = 0; for (int i = 0; i &lt; 32; ++i) &#123; res += (n &amp; 1); n = n &gt;&gt; 1; &#125; return res; &#125;&#125;; 2的幂 12345678910111213141516171819class Solution &#123;public: bool isPowerOfTwo(int n) &#123; int cnt = 0; while (n &gt; 0) &#123; cnt += (n &amp; 1); n &gt;&gt;= 1; &#125; return cnt == 1; &#125; &#125;;class Solution &#123;public: bool isPowerOfTwo(int n) &#123; return (n &gt; 0) &amp;&amp; (!(n &amp; (n - 1))); &#125; &#125;; 数字范围按位与 12345678910class Solution &#123;public: int rangeBitwiseAnd(int m, int n) &#123; int d = INT_MAX; while ((m &amp; d) != (n &amp; d)) &#123; d &lt;&lt;= 1; &#125; return m &amp; d; &#125;&#125;; 重复的dna序列 12345678910111213141516171819202122class Solution &#123;public: vector&lt;string&gt; findRepeatedDnaSequences(string s) &#123; vector&lt;string&gt; res; if (s.size() &lt;= 10) return res; int mask = 0x7ffffff, cur = 0; unordered_map&lt;int, int&gt; m; for (int i = 0; i &lt; 9; ++i) &#123; cur = (cur &lt;&lt; 3) | (s[i] &amp; 7); &#125; for (int i = 9; i &lt; s.size(); ++i) &#123; cur = ((cur &amp; mask) &lt;&lt; 3) | (s[i] &amp; 7); if (m.count(cur)) &#123; if (m[cur] == 1) res.push_back(s.substr(i - 9, 10)); ++m[cur]; &#125; else &#123; m[cur] = 1; &#125; &#125; return res; &#125;&#125;; 12345678910111213141516class Solution &#123;public: vector&lt;string&gt; findRepeatedDnaSequences(string s) &#123; unordered_set&lt;string&gt; res; unordered_set&lt;int&gt; st; unordered_map&lt;int, int&gt; m&#123;&#123;&apos;A&apos;, 0&#125;, &#123;&apos;C&apos;, 1&#125;, &#123;&apos;G&apos;, 2&#125;, &#123;&apos;T&apos;, 3&#125;&#125;; int cur = 0; for (int i = 0; i &lt; 9; ++i) cur = cur &lt;&lt; 2 | m[s[i]]; for (int i = 9; i &lt; s.size(); ++i) &#123; cur = ((cur &amp; 0x3ffff) &lt;&lt; 2) | (m[s[i]]); if (st.count(cur)) res.insert(s.substr(i - 9, 10)); else st.insert(cur); &#125; return vector&lt;string&gt;(res.begin(), res.end()); &#125;&#125;; 还有 格雷码 翻转位 两数相除等等 只出现一次的数 123456789class Solution &#123;public: int singleNumber(vector&lt;int&gt;&amp; nums) &#123; int res = 0; for (auto num : nums) res ^= num; return res; &#125;&#125;;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-sort]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F18%2Fleetcode-sort%2F</url>
    <content type="text"><![CDATA[归并 123456789101112131415161718192021def mergeSort(arr): import math if(len(arr)&lt;2): return arr middle = math.floor(len(arr)/2) left, right = arr[0:middle], arr[middle:] return merge(mergeSort(left), mergeSort(right))def merge(left,right): result = [] while left and right: if left[0] &lt;= right[0]: result.append(left.pop(0)); else: result.append(right.pop(0)); while left: result.append(left.pop(0)); while right: result.append(right.pop(0)); return result 快速排序 1234567891011121314151617181920212223def quickSort(arr, left=None, right=None): left = 0 if not isinstance(left,(int, float)) else left right = len(arr)-1 if not isinstance(right,(int, float)) else right if left &lt; right: partitionIndex = partition(arr, left, right) quickSort(arr, left, partitionIndex-1) quickSort(arr, partitionIndex+1, right) return arrdef partition(arr, left, right): pivot = left index = pivot + 1 i = index while i &lt;= right: if arr[i] &lt; arr[pivot]: swap(arr, i, index) index += 1 i += 1 swap(arr,pivot,index - 1) return index - 1def swap(arr, i, j): arr[i], arr[j] = arr[j], arr[i] 冒泡 1234567891011121314151617181920212223242526272829def bubble_sort(arr): length = len(arr): for i in range(length): for j in range(i+1, length): if arr[i] &gt; arr[j]: arr[i], arr[j] = arr[j], arr[i] return arrdef bubble_sort(alist): # 结算列表的长度 n = len(alist) # 外层循环控制从头走到尾的次数 for j in range(n - 1): # 用一个count记录一共交换的次数，可以排除已经是排好的序列 count = 0 # 内层循环控制走一次的过程 for i in range(0, n - 1 - j): # 如果前一个元素大于后一个元素，则交换两个元素（升序） if alist[i] &gt; alist[i + 1]: # 交换元素 alist[i], alist[i + 1] = alist[i + 1], alist[i] # 记录交换的次数 count += 1 # count == 0 代表没有交换，序列已经有序 if 0 == count: break 堆排序 12345678910111213141516171819202122232425262728293031def buildMaxHeap(arr): import math for i in range(math.floor(len(arr)/2),-1,-1): heapify(arr,i)def heapify(arr, i): left = 2*i+1 right = 2*i+2 largest = i if left &lt; arrLen and arr[left] &gt; arr[largest]: largest = left if right &lt; arrLen and arr[right] &gt; arr[largest]: largest = right if largest != i: swap(arr, i, largest) heapify(arr, largest)def swap(arr, i, j): arr[i], arr[j] = arr[j], arr[i]def heapSort(arr): global arrLen arrLen = len(arr) buildMaxHeap(arr) for i in range(len(arr)-1,0,-1): swap(arr,0,i) arrLen -=1 heapify(arr, 0) return arr]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-hash]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F18%2Fleetcode-hash%2F</url>
    <content type="text"><![CDATA[两数之和 12345678910111213class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; unordered_map&lt;int,int&gt; record; for(int i = 0 ; i &lt; nums.size() ; i ++)&#123; int complement = target - nums[i]; if(record.find(complement) != record.end())&#123; int res[] = &#123;i, record[complement]&#125;; return vector&lt;int&gt;(res, res + 2); &#125; record[nums[i]] = i; &#125; &#125; 无重复字符的最长子串 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; int freq[256] = &#123;0&#125;; int l = 0, r = -1; //滑动窗口为s[l...r] int res = 0; // 整个循环从 l == 0; r == -1 这个空窗口开始 // 到l == s.size(); r == s.size()-1 这个空窗口截止 // 在每次循环里逐渐改变窗口, 维护freq, 并记录当前窗口中是否找到了一个新的最优值 while(l &lt; s.size())&#123; if(r + 1 &lt; s.size() &amp;&amp; freq[s[r+1]] == 0)&#123; r++; freq[s[r]]++; &#125;else &#123; //r已经到头 || freq[s[r+1]] == 1 freq[s[l]]--; l++; &#125; res = max(res, r-l+1); &#125; return res; &#125;&#125;;class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; int res = 0, left = -1, n = s.size(); unordered_map&lt;int, int&gt; m; for (int i = 0; i &lt; n; ++i) &#123; if (m.count(s[i]) &amp;&amp; m[s[i]] &gt; left) &#123; left = m[s[i]]; &#125; m[s[i]] = i; res = max(res, i - left); &#125; return res; &#125;&#125;; 三数之和 123456789101112131415161718192021222324class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123; vector&lt;vector&lt;int&gt;&gt; res; sort(nums.begin(), nums.end()); if (nums.empty() || nums.back() &lt; 0 || nums.front() &gt; 0) return &#123;&#125;; for (int k = 0; k &lt; nums.size(); ++k) &#123; if (nums[k] &gt; 0) break; if (k &gt; 0 &amp;&amp; nums[k] == nums[k - 1]) continue; int target = 0 - nums[k]; int i = k + 1, j = nums.size() - 1; while (i &lt; j) &#123; if (nums[i] + nums[j] == target) &#123; res.push_back(&#123;nums[k], nums[i], nums[j]&#125;); while (i &lt; j &amp;&amp; nums[i] == nums[i + 1]) ++i; while (i &lt; j &amp;&amp; nums[j] == nums[j - 1]) --j; ++i; --j; &#125; else if (nums[i] + nums[j] &lt; target) ++i; else --j; &#125; &#125; return res; &#125;&#125;; 重复的dna序列 12345678910111213141516171819202122class Solution &#123;public: vector&lt;string&gt; findRepeatedDnaSequences(string s) &#123; vector&lt;string&gt; res; if (s.size() &lt;= 10) return res; int mask = 0x7ffffff, cur = 0; unordered_map&lt;int, int&gt; m; for (int i = 0; i &lt; 9; ++i) &#123; cur = (cur &lt;&lt; 3) | (s[i] &amp; 7); &#125; for (int i = 9; i &lt; s.size(); ++i) &#123; cur = ((cur &amp; mask) &lt;&lt; 3) | (s[i] &amp; 7); if (m.count(cur)) &#123; if (m[cur] == 1) res.push_back(s.substr(i - 9, 10)); ++m[cur]; &#125; else &#123; m[cur] = 1; &#125; &#125; return res; &#125;&#125;; 两个数组的交集 1234567891011121314151617181920212223// 时间复杂度: O(nlogn)// 空间复杂度: O(n)class Solution &#123;public: vector&lt;int&gt; intersection(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; set&lt;int&gt; record; for( int i = 0 ; i &lt; nums1.size() ; i ++ )&#123; record.insert(nums1[i]); &#125; set&lt;int&gt; resultSet; for( int i = 0 ; i &lt; nums2.size() ; i ++ )&#123; if(record.find(nums2[i]) != record.end())&#123; resultSet.insert(nums2[i]); &#125; &#125; vector&lt;int&gt; resultVector; for(set&lt;int&gt;::iterator iter = resultSet.begin(); iter != resultSet.end(); iter ++ )&#123; resultVector.push_back(*iter); &#125; return resultVector; &#125;&#125;; 两个数组的交集 II 12345678910111213141516171819// 时间复杂度: O(nlogn)// 空间复杂度: O(n)class Solution &#123;public: vector&lt;int&gt; intersect(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123; map&lt;int, int&gt; record; for(int i = 0 ; i &lt; nums1.size() ; i ++)&#123; record[nums1[i]] += 1; &#125; vector&lt;int&gt; resultVector; for(int i = 0 ; i &lt; nums2.size() ; i ++)&#123; if(record[nums2[i]] &gt; 0)&#123; resultVector.push_back(nums2[i]); record[nums2[i]] --; &#125; &#125; return resultVector; &#125;&#125;; 回旋镖的数量 12345678910111213141516171819202122232425262728// 时间复杂度: O(n^2)// 空间复杂度: O(n)class Solution &#123;public: int numberOfBoomerangs(vector&lt;pair&lt;int, int&gt;&gt;&amp; points) &#123; int res = 0; for( int i = 0 ; i &lt; points.size() ; i ++ )&#123; // record中存储 点i 到所有其他点的距离出现的频次 unordered_map&lt;int, int&gt; record; for(int j = 0 ; j &lt; points.size() ; j ++)&#123; if(j != i)&#123; // 计算距离时不进行开根运算, 以保证精度 record[dis(points[i], points[j])] += 1; &#125; &#125; for(unordered_map&lt;int, int&gt;::iterator iter = record.begin() ; iter != record.end() ; iter ++)&#123; res += (iter-&gt;second) * (iter-&gt;second - 1); &#125; &#125; return res; &#125;private: int dis(const pair&lt;int,int&gt; &amp;pa, const pair&lt;int,int&gt; &amp;pb)&#123; return (pa.first - pb.first) * (pa.first - pb.first) + (pa.second - pb.second) * (pa.second - pb.second); &#125;&#125;; 四个数相加 12345678910111213141516171819202122// 时间复杂度: O(n^2)// 空间复杂度: O(n^2)class Solution &#123;public: int fourSumCount(vector&lt;int&gt;&amp; A, vector&lt;int&gt;&amp; B, vector&lt;int&gt;&amp; C, vector&lt;int&gt;&amp; D) &#123; unordered_map&lt;int,int&gt; hashtable; for(int i = 0 ; i &lt; A.size() ; i ++)&#123; for(int j = 0 ; j &lt; B.size() ; j ++)&#123; hashtable[A[i]+B[j]] += 1; &#125; &#125; int res = 0; for(int i = 0 ; i &lt; C.size() ; i ++)&#123; for(int j = 0 ; j &lt; D.size() ; j ++)&#123; if(hashtable.find(-C[i]-D[j]) != hashtable.end())&#123; res += hashtable[-C[i]-D[j]]; &#125; &#125; &#125; return res; &#125;&#125;;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-tree]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F18%2Fleetcode-tree%2F</url>
    <content type="text"><![CDATA[前序 1234567891011121314151617181920class Solution &#123; public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); List&lt;Integer&gt; list = new LinkedList&lt;&gt;(); if(root == null)&#123; return list; &#125; //第一步是将根节点压入栈中 stack.push(root); //当栈不为空时，出栈的元素插入list尾部。 while(!stack.isEmpty())&#123; root = stack.pop(); list.add(root.val); if(root.right != null) stack.push(root.right); if(root.left != null) stack.push(root.left); &#125; return list; &#125;&#125; 中序 12345678910111213141516171819class Solution &#123; public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) &#123; if (cur != null) &#123; stack.push(cur); cur = cur.left; &#125; else &#123; cur = stack.pop(); list.add(cur.val); cur = cur.right; &#125; &#125; return list; &#125;&#125; 后序 1234567891011121314151617public class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res = new ArrayList&lt;Integer&gt;(); if(root == null) return res; Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); stack.push(root); while(!stack.isEmpty())&#123; TreeNode node = stack.pop(); if(node.left != null) stack.push(node.left);//和传统先序遍历不一样，先将左结点入栈 if(node.right != null) stack.push(node.right);//后将右结点入栈 res.add(0,node.val); //逆序添加结点值 &#125; return res; &#125;&#125; 层次 1234567891011121314151617181920212223public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123; if(root == null) return new ArrayList&lt;&gt;(); List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); while(!queue.isEmpty())&#123; int count = queue.size(); List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); while(count &gt; 0)&#123; TreeNode node = queue.poll(); list.add(node.val); if(node.left != null) queue.add(node.left); if(node.right != null) queue.add(node.right); count--; &#125; res.add(list); &#125; return res;&#125; 平衡二叉树 1234567891011121314151617class Solution &#123; private boolean isBalanced = true; public boolean isBalanced(TreeNode root) &#123; getDepth(root); return isBalanced; &#125; public int getDepth(TreeNode root) &#123; if (root == null) return 0; int left = getDepth(root.left); int right = getDepth(root.right); if (Math.abs(left - right) &gt; 1) &#123; isBalanced = false; &#125; return right &gt; left ? right + 1 : left + 1; &#125;&#125; 对称二叉树 12345678910111213141516class Solution &#123; public boolean isSymmetric(TreeNode root) &#123; if(root == null) return true; //把问题变成判断两棵树是否是对称的 return isSym(root.left, root.right); &#125; //判断的是根节点为r1和r2的两棵树是否是对称的 public boolean isSym(TreeNode r1, TreeNode r2)&#123; if(r1 == null &amp;&amp; r2 == null) return true; if(r1 == null || r2 == null) return false; //这两棵树是对称需要满足的条件： //1.俩根节点相等。 2.树1的左子树和树2的右子树，树2的左子树和树1的右子树都得是对称的 return r1.val == r2.val &amp;&amp; isSym(r1.left, r2.right) &amp;&amp; isSym(r1.right, r2.left); &#125;&#125; 重建二叉树 12345678910111213141516171819// 缓存中序遍历数组每个值对应的索引private Map&lt;Integer, Integer&gt; indexForInOrders = new HashMap&lt;&gt;();public TreeNode reConstructBinaryTree(int[] pre, int[] in) &#123; for (int i = 0; i &lt; in.length; i++) indexForInOrders.put(in[i], i); return reConstructBinaryTree(pre, 0, pre.length - 1, 0);&#125;private TreeNode reConstructBinaryTree(int[] pre, int preL, int preR, int inL) &#123; if (preL &gt; preR) return null; TreeNode root = new TreeNode(pre[preL]); int inIndex = indexForInOrders.get(root.val); int leftTreeSize = inIndex - inL; root.left = reConstructBinaryTree(pre, preL + 1, preL + leftTreeSize, inL); root.right = reConstructBinaryTree(pre, preL + leftTreeSize + 1, preR, inL + leftTreeSize + 1); return root;&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-0006]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F17%2Fleetcode-0006%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435func convert(s string, numRows int) string &#123; if numRows == 1 || len(s) &lt;= numRows &#123; return s &#125; res := bytes.Buffer&#123;&#125; // p pace 步距 p := numRows*2 - 2 // 处理第一行 for i := 0; i &lt; len(s); i += p &#123; res.WriteByte(s[i]) &#125; // 处理中间的行 for r := 1; r &lt;= numRows-2; r++ &#123; // 添加r行的第一个字符 res.WriteByte(s[r]) for k := p; k-r &lt; len(s); k += p &#123; res.WriteByte(s[k-r]) if k+r &lt; len(s) &#123; res.WriteByte(s[k+r]) &#125; &#125; &#125; // 处理最后一行 for i := numRows - 1; i &lt; len(s); i += p &#123; res.WriteByte(s[i]) &#125; return res.String()&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-0005]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F17%2Fleetcode-0005%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233func longestPalindrome(s string) string &#123; if len(s) &lt; 2 &#123; return s &#125; begin, maxLen := 0, 1 for i := 0; i &lt; len(s); &#123; if len(s)-i &lt;= maxLen/2 &#123; break &#125; b, e := i, i for e &lt; len(s)-1 &amp;&amp; s[e+1] == s[e] &#123; e++ &#125; i = e + 1 for e &lt; len(s)-1 &amp;&amp; b &gt; 0 &amp;&amp; s[e+1] == s[b-1] &#123; e++ b-- &#125; newLen := e + 1 - b if newLen &gt; maxLen &#123; begin = b maxLen = newLen &#125; &#125; return s[begin : begin+maxLen]&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-0004]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F17%2Fleetcode-0004%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233class Solution: def findMedianSortedArrays(self, A, B): m, n = len(A), len(B) if m &gt; n: A, B, m, n = B, A, n, m if n == 0: raise ValueError imin, imax, half_len = 0, m, (m + n + 1) / 2 while imin &lt;= imax: i = (imin + imax) / 2 j = half_len - i if i &lt; m and B[j-1] &gt; A[i]: # i is too small, must increase it imin = i + 1 elif i &gt; 0 and A[i-1] &gt; B[j]: # i is too big, must decrease it imax = i - 1 else: # i is perfect if i == 0: max_of_left = B[j-1] elif j == 0: max_of_left = A[i-1] else: max_of_left = max(A[i-1], B[j-1]) if (m + n) % 2 == 1: return max_of_left if i == m: min_of_right = B[j] elif j == n: min_of_right = A[i] else: min_of_right = min(A[i], B[j]) return (max_of_left + min_of_right) / 2.0]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-0003]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F15%2Fleetcode-0003%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617class Solution &#123;public: int lengthOfLongestSubstring(string s) &#123; set&lt;char&gt; t; int res = 0, left = 0, right = 0; while (right &lt; s.size()) &#123; if (t.find(s[right]) == t.end()) &#123; t.insert(s[right++]); res = max(res, (int)t.size()); &#125; else &#123; t.erase(s[left++]); &#125; &#125; return res; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[2019-go-25]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F14%2F2019-go-25%2F</url>
    <content type="text"><![CDATA[beego 模块化设计之 context上下文模块主要是针对 HTTP 请求中，request 和 response 的进一步封装，他包括用户的输入和输出，用户的输入即为 request，context 模块中提供了 Input 对象进行解析，用户的输出即为 response，context 模块中提供了 Output 对象进行输出。 context 对象是对 Input 和 Output 的封装，里面封装了几个方法： Redirect Abort WriteString GetCookie SetCookie context 对象是 Filter 函数的参数对象，这样你就可以通过 filter 来修改相应的数据，或者提前结束整个的执行过程。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-24]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F14%2F2019-go-24%2F</url>
    <content type="text"><![CDATA[beego 模块化设计之httplibhttplib 库主要用来模拟客户端发送 HTTP 请求，类似于 Curl 工具，支持 JQuery 类似的链式操作。使用起来相当的方便； 有点像 requests模块 httplib 包里面支持如下的方法返回 request 对象： Get(url string) Post(url string) Put(url string) Delete(url string) Head(url string) 发送文件 req := httplib.Post(&quot;http://beego.me/&quot;) bt,err:=ioutil.ReadFile(&quot;hello.txt&quot;) if err!=nil{ log.Fatal(&quot;read file err:&quot;,err) } req.Body(bt) 文件直接上传接口 b:=httplib.Post(&quot;http://beego.me/&quot;) b.Param(&quot;username&quot;,&quot;astaxie&quot;) b.Param(&quot;password&quot;,&quot;123456&quot;) b.PostFile(&quot;uploadfile1&quot;, &quot;httplib.pdf&quot;) b.PostFile(&quot;uploadfile2&quot;, &quot;httplib.txt&quot;) str, err := b.String() if err != nil { t.Fatal(err) } 获取数据主要有如下几种方式： 返回 Response 对象，req.Response() 方法 这个是 http.Response 对象，用户可以自己读取 body 的数据等。 返回 bytes, req.Bytes() 方法 直接返回请求 URL 返回的内容 返回 string，req.String() 方法 直接返回请求 URL 返回的内容 保存为文件，req.ToFile(filename) 方法 返回结果保存到文件名为 filename 的文件中 解析为 JSON 结构，req.ToJSON(&amp;result) 方法 返回结构直接解析为 JSON 格式，解析到 result 对象中 解析为 XML 结构，req.ToXml(&amp;result) 方法 返回结构直接解析为 XML 格式，解析到 result 对象中]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-23]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F14%2F2019-go-23%2F</url>
    <content type="text"><![CDATA[beego 模块化设计之logs用来处理日志的库，它的设计思路来自于 database/sql，目前支持的引擎有 file、console、net、smtp， 使用 123456789101112131415161718192021logs.SetLogger(logs.AdapterFile,`&#123;&quot;filename&quot;:&quot;project.log&quot;,&quot;level&quot;:7,&quot;maxlines&quot;:0,&quot;maxsize&quot;:0,&quot;daily&quot;:true,&quot;maxdays&quot;:10,&quot;color&quot;:true&#125;`)package mainimport ( &quot;github.com/astaxie/beego/logs&quot;)func main() &#123; //an official log.Logger l := logs.GetLogger() l.Println(&quot;this is a message of http&quot;) //an official log.Logger with prefix ORM logs.GetLogger(&quot;ORM&quot;).Println(&quot;this is a message of orm&quot;) logs.Debug(&quot;my book is bought in the year of &quot;, 2016) logs.Info(&quot;this %s cat is %v years old&quot;, &quot;yellow&quot;, 3) logs.Warn(&quot;json is a type of kv like&quot;, map[string]int&#123;&quot;key&quot;: 2016&#125;) logs.Error(1024, &quot;is a very&quot;, &quot;good game&quot;) logs.Critical(&quot;oh,crash&quot;)&#125;]]></content>
      <categories>
        <category>beego</category>
      </categories>
      <tags>
        <tag>beego</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-22]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F14%2F2019-go-22%2F</url>
    <content type="text"><![CDATA[beego 模块化设计之cachebeego 的 cache 模块是用来做数据缓存的，设计思路来自于 database/sql，目前支持 file、memcache、memory 和 redis 四种引擎，安装方式如下： go get github.com/astaxie/beego/cache go get -u github.com/astaxie/beego/cache/memcache import _ &quot;github.com/astaxie/beego/cache/memcache&quot; 使用先初始化 然后 增删改缓存即可 bm, err := cache.NewCache(&quot;memory&quot;, `{&quot;interval&quot;:60}`) bm.Put(&quot;astaxie&quot;, 1, 10*time.Second) bm.Get(&quot;astaxie&quot;) bm.IsExist(&quot;astaxie&quot;) bm.Delete(&quot;astaxie&quot;)]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-21]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F14%2F2019-go-21%2F</url>
    <content type="text"><![CDATA[panic 被引用到程序终止运行的大致过程是什么 某个函数中的某行代码有意或无意地引发了一个panic 这时 panic详情会被建立起来 程序的控制权立即从此行代码转移至调用其所属函数的那一行代码上 也就是调用栈的上一级 此行所属函数的执行随即终止 控制权不会有片刻的停留立即转移至再上一级 控制权一级一级沿着调用栈的反方向传播至顶端 也就是编写的最外层函数那里 对于goroutine 来说 就是main函数 但是控制权也不会停留 而是被go语言运行时系统收回 程序崩溃并终止运行 承载程序这次运行的进程也会随之死亡并消失 在控制权传播的过程中 panic详情会被逐渐地积累和完善 并会在程序终止之前被打印出来]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-0002]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F13%2Fleetcode-0002%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728# Definition for singly-linked list.class ListNode(object): def __init__(self, x): self.val = x self.next = Noneclass Solution(object): def addTwoNumbers(self, l1, l2): &quot;&quot;&quot; :type l1: ListNode :type l2: ListNode :rtype: ListNode &quot;&quot;&quot; carry = 0 root = n = ListNode(0) while l1 or l2 or carry: v1 = v2 = 0 if l1: v1 = l1.val l1 = l1.next if l2: v2 = l2.val l2 = l2.next carry, val = divmod(v1+v2+carry, 10) n.next = ListNode(val) n = n.next return root.next]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-0001]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F13%2Fleetcode-0001%2F</url>
    <content type="text"><![CDATA[123456789class Solution: # @return a tuple, (index1, index2) def twoSum(self, num, target): d = dict() for i, n in enumerate(num): if target-n in d: return (d[target-n], i) d[n] = i]]></content>
  </entry>
  <entry>
    <title><![CDATA[2019-go-20]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F11%2F2019-go-20%2F</url>
    <content type="text"><![CDATA[一旦主gorountine 中的代码执行完毕 当前的go程序就会结束运行 那么在go程序结束的那一刻 还有gorountine 未得到运行机会 它们就没有运行机会了 它们中的代码也不会被执行了 go语言不会去保证这些 gorountine 会以怎样的顺序运行 哪个gorountine 先执行完 哪个gorountine 后执行完 往往是不可预知的 除非我们使用了某种go语言提供的方式进行了人为干预]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-19]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F11%2F2019-go-19%2F</url>
    <content type="text"><![CDATA[单向通道最主要的用途 就是约束其他代码的行为]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-18]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F11%2F2019-go-18%2F</url>
    <content type="text"><![CDATA[通道（channel）完全可以与 goroutine（也可称go 程）并驾齐驱，共同代表go语言独有的并发编程模式和编程哲学 通道类型的值本身就是并发安全的 发送接收都是互斥发送和接收操作中对元素值的处理 都是不可分割的发送操作在完全完成之前会被阻塞，接收操作也是如此]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-17]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F11%2F2019-go-17%2F</url>
    <content type="text"><![CDATA[字典的操作和约束map 键值对 字典类型本质上是一个哈希表的特定实现，在这个实现当中，键和元素的最大不同在于，键的类型是受限制的，元素的类型却可以是任意类型的 哈希表中比较重要的一个过程 就是映射 键可以理解为元素的一个索引，在哈希表中通过键查找与它成对的那个元素 这种对应关系，在数学里就被称为映射 也是map这个词的本意 哈希表的映射过程就存在于对键–元素的增、删、改、查的操作之中 映射的第一步 就是把键值转换为哈希值 键值的类型 不可以是函数类型、字典类型和切片类型 键的值之间支持判等的操作 另外 键的类型是揭接口类型的，那么键值的实际类型也不能是上述的三种类型，否则在程序运行过程当中会引发panic 键的类型 优先选用数值类型和指针类型，类型的宽度越小越好 字符串类型的话 对键值的长度进行额外的约束 字典是引用的类型 声明而不初始化 值是nil除了添加键–元素对，在一个值为nil的字典上做任何操作都不会引起错误 试图在一个值为nil的字典中添加键–元素对的时候，运行时系统会抛出一个panic]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-16]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F11%2F2019-go-16%2F</url>
    <content type="text"><![CDATA[函数是第一等公民 函数不仅可以封装代码、分割功能、解耦逻辑 还可以化身普通的值 在其他函数之间传递、赋予变量、做类型判断和转换等等 就像切片和字典的值一样 函数值可以由此成为能够被随意传播的独立逻辑组件（或者说功能模块）]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[算法之队列]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F08%2F%E7%AE%97%E6%B3%95%E4%B9%8B%E9%98%9F%E5%88%97%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[算法之栈]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F08%2F%E7%AE%97%E6%B3%95%E4%B9%8B%E6%A0%88%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[算法之链表的针对练习]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F08%2F%E7%AE%97%E6%B3%95%E4%B9%8B%E9%93%BE%E8%A1%A8%E7%9A%84%E9%92%88%E5%AF%B9%E7%BB%83%E4%B9%A0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[算法之链表的lru]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F08%2F%E7%AE%97%E6%B3%95%E4%B9%8B%E9%93%BE%E8%A1%A8%E7%9A%84lru%2F</url>
    <content type="text"><![CDATA[先进先出 缓存是一种提高数据读取性能的技术 cpu缓存 数据库缓存 浏览器缓存 最少使用策略 最近最少使用策略 链表通过“指针”将一组零散的内存块串联起来使用。 单链表、双向链表、循环链表 头节点 尾节点（空地址） 维护一个有序单链表 越靠近链表尾部的节点是越早之前访问的当有一个心的数据被访问的时候，我们从链表头部开始顺序遍历链表 如果数据之前已经被缓存在链表当中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部 没有缓存在链表中 缓存未满直接插入到链表的头部；已满，则删除链表尾部结点，将新的数据插入到链表的头部 还可以引入散列表记录每个数据的位置，将缓存访问的时间复杂度降到1]]></content>
  </entry>
  <entry>
    <title><![CDATA[算法之数组]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F08%2F%E7%AE%97%E6%B3%95%E4%B9%8B%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[数组是一块连续的内存空间，来存储相同类型的一组数据。最大的特点是支持随机访问，但是插入和删除比较低效，平均复杂度是n 平时的开发过程中 可以直接使用编程语言提供的容器类，但是如果是特别底层的开发，直接使用数组更方便。]]></content>
  </entry>
  <entry>
    <title><![CDATA[django-ldap]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F07%2Fdjango-ldap%2F</url>
    <content type="text"><![CDATA[简单记录一下ldap LDAP用户验证基本原理每个用户在LDAP系统中有一个唯一的DN值，例如配置文件中默认的admin用户在LDAP中的DN值是uid=admin,ou=system,dc=eoncloud,dc=com, 其中eoncloud.com是域名，system是组名，admin是用户名，有些LDAP用cn而不是uid来生成DN，在这种系统中admin的DN看起来像这样cn=admin,ou=system,dc=eoncloud,dc=com，无论是uid还是cn或是别的前缀，django-ldap-auth都是用dn来验证用户和获取用户信息的. 假设用户输入的帐号及密码是： test, password. django-auth-ldap有２个方式来获取用户的DN 使用AUTH_LDAP_USER_DN_TEMPLATE提供的模板生成DN．如uid=%(user)s,ou=users,dc=eoncloud,dc=com, 其中%(user)s会被替换成用户名，这样最终的DN就是uid=test,ou=users,dc=eonclooud,dc=com.使用AUTH_LDAP_GROUP_SEARCH．如果没有配置AUTH_LDAP_USER_DN_TEMPLATE，那么django-auth-ldap会使用AUTH_LDAP_BIND_DN和AUTH_LDAP_BIND_PASSWORD提供的dn与密码根据AUTH_LDAP_GROUP_SEARCH提供的查询条件去查找test用户，如果查不到，验证失败，如果查到用户，就使用返回的数据生成test的DN. 利用第2步生成DN值与密码尝试访问LDAP系统，如果访问成功，则验证共过，否则验证失败．基本配置AUTH_LDAP_SERVER_URI． LDAP系统的地址及端口号AUTH_LDAP_BIND_DN, AUTH_LDAP_BIND_PASSWORD. 查找用户及相关信息的默认用户信息AUTH_LDAP_USER_SEARCH． 第一个参数指指定询目录，第三个参数是过滤条件，过滤条件可以很复杂，有需要请查看相关文档．AUTH_LDAP_USER_DN_TEMPLATE． 用户DN模板，配置该参数后django-auth-ldap会用生成的DN配合密码验证该用户．AUTH_LDAP_USER_ATTR_MAP. LDAP与User model映射．AUTH_LDAP_ALWAYS_UPDATE_USER. 是否同步LDAP修改．用户组配置如果需要，django-auth-ldap可以从ldap系统获取用户的组信息，也可以限定某个组里的用户访问，或者阻止某个组里的用户访问，无论是使用哪个功能都需要先配置组类型AUTH_LDAP_GROUP_TYPE及AUTH_LDAP_GROUP_SEARCH, 因为LDAP里组的种类非常多，具体信息请查询相关资料． AUTH_LDAP_GROUP_TYPE 值类型: LDAPGroupType的子类实例．LDAPGroupType有２个初始化参数:member_attr, name_attr．member_attr是组成员的属性名, name_attr是组名称的属性名．作用: AUTH_LDAP_GROUP_SEARCH返回的组的类型，并用来判断用户与组的从属关系AUTH_LDAP_GROUP_SEARCH 值类型: LDAPSearch实例．作用: 用户组的查询条件AUTH_LDAP_REQUIRE_GROUP 值类型: 组的DN作用: 只有指定组的用户可以访问AUTH_LDAP_DENY_GROUP指定的 值类型: 组的DN作用： 禁止指定组的用户访问AUTH_LDAP_MIRROR_GROUPS 值类型: bool值作用: 导入用户的组信息 AUTH_LDAP_MIRROR_GROUPS=True 这个参数是为了在用户登录的时候把用户的域组关系也获取并记录下来。不过开启这个参数会带来另外一个问题：每次用户登录时，都会把用户的组关系删除，重新从ldap中进行同步。由于我们的系统中除了域组还有些自定义的组关系，这样一来自定义组的用户关系就不能持久保留了。按照我们的需求，其实只希望在用户第一次登录的时候同步组关系，以后的登录并不需要。这个需求可以通过对django-auth-ldap的源码（backend.py）进行微调来实现。]]></content>
  </entry>
  <entry>
    <title><![CDATA[2019-go-15]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F06%2F2019-go-15%2F</url>
    <content type="text"><![CDATA[go语言中的链表 container/list 代码包 List（双向链表） Element（链表中元素的结构） moveafter movebefore movetofront movetoback 零值拥有特定结构 零值只做了声明 还未做初始化的变量被给予的缺省值 延迟初始化 ring类型 实现的事一个循环链表 list在内部就是一个循环链表 它的根元素永远不会持有任何实际的元素值，而该元素的存在就是为了连接这个循环链表的首尾两端。 給定的元素 都是*element类型的 ring类型的数据结构仅由它本身即可代表，而list类型则需要它和element类型联合表示 这是表示方式上的不同 也是结构复杂度的不同 ring类型的值 严格来讲 只是代表所属循环链表中的一个元素，而list类型则代表了一个完整的链表 这是表示维度上的不同 创建并初始化一个ring值的时候，可以指定包含的元素的数量 对于一个list值来说却不能这样做 初始化的时候 ring是长度为1 list的长度为0 ring值的len方法 复杂度是n， list则是1 性能方面显而易见的差别 切片本身有着占用内存少和创建便捷等特点 但是它的本质上还是数组 切片的一大好处是可以通过窗口快速定位并获取 或者修改底层数组中的元素 想删除切片的元素时，元素复制无法避免。元素“槽位”的清空有可能造成内存泄漏 另外 切片频繁扩容 新的底层数组会不断产生 内存分配的量以及元素复制的次数就很可观了，对程序的性能产生负面的影响。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-14]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F06%2F2019-go-14%2F</url>
    <content type="text"><![CDATA[数组和切片数组类型的值的长度是固定的 而切片类型的值是可变长的 做个不算特别正确的对比 可以理解为python当中的元组和列表 切片类型属于引用类型，同属引用类型的还有字典类型、通道类型、函数类型等；数组类型属于值类型，同属值类型的还有基础数据类型以及结构体类型 如果传递的值是引用类型，就是“传引用” 内建函数 len 取长度内建函数 cap 取容量 数组的长度永远等于长度，切片的容量却不是 扩容 在1024之后 调整的倍率从2下调到1.25 切片的数组永远不会被替换 几个例子 123456789101112131415package mainimport &quot;fmt&quot;func main() &#123; // 示例 1。 s1 := make([]int, 5) fmt.Printf(&quot;The length of s1: %d\n&quot;, len(s1)) fmt.Printf(&quot;The capacity of s1: %d\n&quot;, cap(s1)) fmt.Printf(&quot;The value of s1: %d\n&quot;, s1) s2 := make([]int, 5, 8) fmt.Printf(&quot;The length of s2: %d\n&quot;, len(s2)) fmt.Printf(&quot;The capacity of s2: %d\n&quot;, cap(s2)) fmt.Printf(&quot;The value of s2: %d\n&quot;, s2)&#125; 输出是 The length of s1: 5 The capacity of s1: 5 The value of s1: [0 0 0 0 0] The length of s2: 5 The capacity of s2: 8 The value of s2: [0 0 0 0 0] 切片的扩容 生成新的切片 会做拷贝 123456789101112131415161718192021222324252627282930313233343536package mainimport &quot;fmt&quot;func main() &#123; // 示例1。 s6 := make([]int, 0) fmt.Printf(&quot;The capacity of s6: %d\n&quot;, cap(s6)) for i := 1; i &lt;= 5; i++ &#123; s6 = append(s6, i) fmt.Printf(&quot;s6(%d): len: %d, cap: %d\n&quot;, i, len(s6), cap(s6)) &#125; fmt.Println() // 示例2。 s7 := make([]int, 1024) fmt.Printf(&quot;The capacity of s7: %d\n&quot;, cap(s7)) s7e1 := append(s7, make([]int, 200)...) fmt.Printf(&quot;s7e1: len: %d, cap: %d\n&quot;, len(s7e1), cap(s7e1)) s7e2 := append(s7, make([]int, 400)...) fmt.Printf(&quot;s7e2: len: %d, cap: %d\n&quot;, len(s7e2), cap(s7e2)) s7e3 := append(s7, make([]int, 600)...) fmt.Printf(&quot;s7e3: len: %d, cap: %d\n&quot;, len(s7e3), cap(s7e3)) fmt.Println() // 示例3。 s8 := make([]int, 10) fmt.Printf(&quot;The capacity of s8: %d\n&quot;, cap(s8)) s8a := append(s8, make([]int, 11)...) fmt.Printf(&quot;s8a: len: %d, cap: %d\n&quot;, len(s8a), cap(s8a)) s8b := append(s8a, make([]int, 23)...) fmt.Printf(&quot;s8b: len: %d, cap: %d\n&quot;, len(s8b), cap(s8b)) s8c := append(s8b, make([]int, 45)...) fmt.Printf(&quot;s8c: len: %d, cap: %d\n&quot;, len(s8c), cap(s8c))&#125; 输出如下： The capacity of s6: 0 s6(1): len: 1, cap: 1 s6(2): len: 2, cap: 2 s6(3): len: 3, cap: 4 s6(4): len: 4, cap: 4 s6(5): len: 5, cap: 8 The capacity of s7: 1024 s7e1: len: 1224, cap: 1280 s7e2: len: 1424, cap: 1696 // 为啥不是1600 s7e3: len: 1624, cap: 2048 //为啥不是2000 The capacity of s8: 10 s8a: len: 21, cap: 22 s8b: len: 44, cap: 44 s8c: len: 89, cap: 96 package main import &quot;fmt&quot; func main() { // 示例1。 a1 := [7]int{1, 2, 3, 4, 5, 6, 7} fmt.Printf(&quot;a1: %v (len: %d, cap: %d)\n&quot;, a1, len(a1), cap(a1)) s9 := a1[1:4] //s9[0] = 1 fmt.Printf(&quot;s9: %v (len: %d, cap: %d)\n&quot;, s9, len(s9), cap(s9)) for i := 1; i &lt;= 5; i++ { s9 = append(s9, i) fmt.Printf(&quot;s9(%d): %v (len: %d, cap: %d)\n&quot;, i, s9, len(s9), cap(s9)) } fmt.Printf(&quot;a1: %v (len: %d, cap: %d)\n&quot;, a1, len(a1), cap(a1)) fmt.Println() } 输入如下所示 a1: [1 2 3 4 5 6 7] (len: 7, cap: 7) s9: [2 3 4] (len: 3, cap: 6) s9(1): [2 3 4 1] (len: 4, cap: 6) s9(2): [2 3 4 1 2] (len: 5, cap: 6) s9(3): [2 3 4 1 2 3] (len: 6, cap: 6) s9(4): [2 3 4 1 2 3 4] (len: 7, cap: 12) s9(5): [2 3 4 1 2 3 4 5] (len: 8, cap: 12) a1: [1 2 3 4 1 2 3] (len: 7, cap: 7) 数组和切片的几个不同点？？？]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-13]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F06%2F2019-go-13%2F</url>
    <content type="text"><![CDATA[运算符go语言的运算符 如下]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-12]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F06%2F2019-go-12%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930package type_testimport &quot;testing&quot;type MyInt int64func TestImplicit(t *testing.T) &#123; var a int32 = 1 var b int64 b = int64(a) var c MyInt c = MyInt(b) t.Log(a, b, c)&#125;func TestPoint(t *testing.T) &#123; a := 1 aPtr := &amp;a //aPtr = aPtr + 1 t.Log(a, aPtr) t.Logf(&quot;%T %T&quot;, a, aPtr)&#125;func TestString(t *testing.T) &#123; var s string t.Log(&quot;*&quot; + s + &quot;*&quot;) //初始化零值是“” t.Log(len(s))&#125; 也可以对单个的go测试文件进行 测试 命令如下 go test -v type_test/type_test.go -test.run TestPoint]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-11]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F06%2F2019-go-11%2F</url>
    <content type="text"><![CDATA[首先看看 go开发当中的测试 12345678910111213// main.gopackage mainimport "fmt"func Add(x, y int) int &#123; return x+y&#125;func main() &#123; fmt.Println(Add(1, 2))&#125; 12345678910111213// main_test.gopackage mainimport "testing"func TestAdd(t * testing.T) &#123; sum := Add(1, 2) if sum != 3 &#123; t.Error("Add 1 and 2 result is not 3!!!") &#125;&#125; 命令运行 go test main_test.go main.go -v -cover 因为以前补过单元测试什么的 在此记录一下覆盖率 语句覆盖 判定（分支）覆盖 增加false的情况 判定/条件覆盖 语句覆盖是指选择足够的测试用例，使得运行这些测试用例时，被测程序的每一个语句至少执行一次，其覆盖标准无法发现判定中逻辑运算的错误； 判定覆盖是指选择足够的测试用例，使得运行这些测试用例时，每个判定的所有可能结果至少出现一次，但若程序中的判定是有几个条件联合构成时，它未必能发现每个条件的错误； 条件覆盖是指选择足够的测试用例，使得运行这些测试用例时，判定中每个条件的所有可能结果至少出现一次，但未必能覆盖全部分支； 判定/条件覆盖是使判定中每个条件的所有可能结果至少出现一次，并且每个判定本身的所有可能结果也至少出现一次； 条件组合覆盖是使每个判定中条件结果的所有可能组合至少出现一次，因此判定本身的所有可能解说也至少出现一次，同时也是每个条件的所有可能结果至少出现一次； 路径覆盖是每条可能执行到的路径至少执行一次； 其中语句覆盖是一种最弱的覆盖，判定覆盖和条件覆盖比语句覆盖强，满足判定/条件覆盖标准的测试用例一定也满足判定覆盖、条件覆盖和语句覆盖，条件组合覆盖是除路径覆盖外最强的，路径覆盖也是一种比较强的覆盖，但未必考虑判定条件结果的组合，并不能代替条件覆盖和条件组合覆盖。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-二分查找]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F06%2Fleetcode-%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[123456789101112131415int find(vector&lt;int&gt; &amp;nums, int target) &#123; if (nums.empty()) return -1 int low = 0; int high = nums.size() -1; while (low &lt;= high) &#123; int mid = low + (high -low) /2; if (nums[mid] &lt; target) low = mid + 1; else high = mid - 1; &#125; return low;&#125; 二分查找有很多变种 注意一些细节问题]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-六度分割]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F06%2Fleetcode-%E5%85%AD%E5%BA%A6%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425# _*_ coding: utf-8 _*_import requestsfrom bs4 import BeautifulSoupimport reimport randomimport datetimepage = set()random.seed(datetime.datetime.now())def getlink(articleurl): html = requests.get(&quot;https://en.wikipedia.org&quot;+articleurl) soup = BeautifulSoup(html.text, &quot;html.parser&quot;) return soup.find(&quot;div&quot;, &#123;&apos;id&apos;:&apos;bodyContent&apos;&#125;).findAll(&quot;a&quot;, &#123;&quot;href&quot;:re.compile(&apos;^(/wiki/)&apos;)&#125;)links = getlink(&quot;/wiki/Christopher_Nolan&quot;)i = 0while len(links) &gt; 0: newArticle = links[random.randint(0, len(links)-1)][&quot;href&quot;] i += 1 print &quot;第 %d 个页面：&quot; %i print newArticle if i == 6: break links = getlink(newArticle) 通过维基百科 只需要最多六次跳转]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-lru]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F05%2Fleetcode-lru%2F</url>
    <content type="text"><![CDATA[设计一个LRU cache，实现两个功能： (cache中存放着（key,value）键值对) get(key):获取key对应的value，如果key不在cache中那么返回-1（value 总是为正数）； set(key, value):如果key在cache中则更新它的value；如果不在则插入，如果cache已满则先删除最近最少使用的一项后在插入。 对于get，如果key在cache中，那个get(key）表示了对key的一次访问；而set(key，value)则总是表示对key的一次访问。 使用一个list来记录访问的顺序，最先访问的放在list的前面，最后访问的放在list的后面，故cache已满时，则删除list[0]，然后插入新项； 12345678910111213141516171819202122class LRUCache(object): def __init__(self, capacity): self.cache = dict() self.used_list = list() self.capacity = capacity def get(self, key): if key in self.cache: if key != self.used_list[-1]: self.used_list.remove(key) self.used_list.append(key) return self.cache[key] else: return -1 def set(self, key, value): if key in self.cache: self.used_list.remove(key) elif len(self.cache) == self.capacity: self.cache.pop(self.used_list.pop(0)) self.used_list.append(key) self.cache[key] = value]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之架构设计文档模版]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3%E6%A8%A1%E7%89%88%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之app架构的演进]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8Bapp%E6%9E%B6%E6%9E%84%E7%9A%84%E6%BC%94%E8%BF%9B%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之如何选择、使用、二次开发开源项目]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E3%80%81%E4%BD%BF%E7%94%A8%E3%80%81%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之内功心法运筹帷幄]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%86%85%E5%8A%9F%E5%BF%83%E6%B3%95%E8%BF%90%E7%AD%B9%E5%B8%B7%E5%B9%84%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之内功心法合纵连横]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%86%85%E5%8A%9F%E5%BF%83%E6%B3%95%E5%90%88%E7%BA%B5%E8%BF%9E%E6%A8%AA%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之内功心法有的放矢]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%86%85%E5%8A%9F%E5%BF%83%E6%B3%95%E6%9C%89%E7%9A%84%E6%94%BE%E7%9F%A2%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之平台技术]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%B9%B3%E5%8F%B0%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之用户层业务层技术]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E7%94%A8%E6%88%B7%E5%B1%82%E4%B8%9A%E5%8A%A1%E5%B1%82%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之网络层技术]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E7%BD%91%E7%BB%9C%E5%B1%82%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之开发层服务层技术]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BC%80%E5%8F%91%E5%B1%82%E6%9C%8D%E5%8A%A1%E5%B1%82%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之存储层技术]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%AD%98%E5%82%A8%E5%B1%82%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之互联网技术演进的模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E4%BA%92%E8%81%94%E7%BD%91%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E7%9A%84%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之技术演进的方向]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%8A%80%E6%9C%AF%E6%BC%94%E8%BF%9B%E7%9A%84%E6%96%B9%E5%90%91%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之微内核架构详解]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BE%AE%E5%86%85%E6%A0%B8%E6%9E%B6%E6%9E%84%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之微服务架构方法篇]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E6%96%B9%E6%B3%95%E7%AF%87%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之微服务架构实践]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之微服务架构]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之可拓展架构分层和soa]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%8F%AF%E6%8B%93%E5%B1%95%E6%9E%B6%E6%9E%84%E5%88%86%E5%B1%82%E5%92%8Csoa%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之可拓展架构的基本思想和模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%8F%AF%E6%8B%93%E5%B1%95%E6%9E%B6%E6%9E%84%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3%E5%92%8C%E6%A8%A1%E5%BC%8F%E2%80%9C%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之应对接口级别的故障]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BA%94%E5%AF%B9%E6%8E%A5%E5%8F%A3%E7%BA%A7%E5%88%AB%E7%9A%84%E6%95%85%E9%9A%9C%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之异地多活架构四步走]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9E%B6%E6%9E%84%E5%9B%9B%E6%AD%A5%E8%B5%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之异地多活架构四大技巧]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9E%B6%E6%9E%84%E5%9B%9B%E5%A4%A7%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之异地多活架构]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%BC%82%E5%9C%B0%E5%A4%9A%E6%B4%BB%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之计算高可用]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E8%AE%A1%E7%AE%97%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之fmea]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8Bfema%2F</url>
    <content type="text"><![CDATA[架构隐患 高可用更复杂一些 只要有一个场景遗漏，架构设计就存在可用性隐患 FMEA故障模式 影响分析 failure mode and effects analysis 造成的影响 分析表格 1 功能点（用户角度） 2 故障模式 3 故障影响（描述要准确） 4 严重程度 5 故障原因 6 故障概率（硬件 开源系统 自研系统） 7 风险程度 8 已有措施 9 规避措施 10 解决措施 11 后续规划 有效量化]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之cap细节]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8Bcap%E7%BB%86%E8%8A%82%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之cap理论]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8Bcap%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之高性能负载均衡算法]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之高性能负载均衡分类与架构]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%AB%98%E6%80%A7%E8%83%BD%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%88%86%E7%B1%BB%E4%B8%8E%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之单服务器高性能模式reactor-proactor]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Freactor-proactor%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之单服务器高性能模式ppc-tpc]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%8D%95%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%AB%98%E6%80%A7%E8%83%BD%E6%A8%A1%E5%BC%8Fppc-tpc%2F</url>
    <content type="text"><![CDATA[高性能 榨干单服务器的性能 设计集群 服务器采取的并发模型 管理连接 处理请求 每次有新的连接就新建一个进程去专门处理这个连接的请求 《unix网络编程卷一》]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计流程：详细方案设计]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%EF%BC%9A%E8%AF%A6%E7%BB%86%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计流程：评估和选择备选方案]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%EF%BC%9A%E8%AF%84%E4%BC%B0%E5%92%8C%E9%80%89%E6%8B%A9%E5%A4%87%E9%80%89%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计流程：设计备选方案]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%EF%BC%9A%E8%AE%BE%E8%AE%A1%E5%A4%87%E9%80%89%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计流程：识别复杂度]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B%EF%BC%9A%E8%AF%86%E5%88%AB%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计原则案例]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[合适原则 简单原则 演化原则]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计的历史背景]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%8E%86%E5%8F%B2%E8%83%8C%E6%99%AF%2F</url>
    <content type="text"><![CDATA[机器语言（1940年以前） 汇编语言（20世纪40年代） 高级语言（20世纪50年代） 第一次软件危机和结构化程序设计 第二次 戴克斯特拉这位上古大神 设计软件架构]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之架构到底是指什么]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F04%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E6%9E%B6%E6%9E%84%E5%88%B0%E5%BA%95%E6%98%AF%E6%8C%87%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[模块与组件的区分 从逻辑的角度来拆分系统后，得到的单元就是模块 从物理的角度来拆分，得到的单元就是组件（另外组件的英文单词 也可以翻译为零件 这样就比较好理解了） 框架与架构 框架是指为了实现某个业界标准或者完成特定基本任务的软件组成规范 也指为了实现某个软件组成规范时，提供规范所要求之基础功能的软件产品 框架关注的是规范 架构关注的是结构 系统与子系统 关联、规则、能力 子系统 是由一群有关联的个体所组成的系统，多半是更大系统中的一部分 基础结构 软件架构是指软件系统的顶层架构]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之可扩展架构]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F03%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%8F%AF%E6%89%A9%E5%B1%95%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[拆 面向流程拆分 服务 功能]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之高可用存储架构集群和分区]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F03%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E9%9B%86%E7%BE%A4%E5%92%8C%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之高可用存储架构双机架构]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F03%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%AB%98%E5%8F%AF%E7%94%A8%E5%AD%98%E5%82%A8%E6%9E%B6%E6%9E%84%E5%8F%8C%E6%9C%BA%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之高性能缓存架构]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F03%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之高性能nosql]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F03%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%AB%98%E6%80%A7%E8%83%BDnosql%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之读写分离]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F03%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构设计的目的]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F03%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E7%9B%AE%E7%9A%84%2F</url>
    <content type="text"><![CDATA[架构是为了应对软件系统复杂度而提出的一个解决方案 架构即是决策，是在一个有约束的盒子里去求解或接近最合适的解。这个有约束的盒子是团队经验、成本、资源、进度、业务所处的阶段等所编织、掺杂在一起的综合体。架构无优劣，但是存在恰当的架构用在合适的软件系统当中，而这些就是决策的结果 需求驱动架构，架构分析与设计实现的桥梁]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之设计的三个原则]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F03%2F01%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E8%AE%BE%E8%AE%A1%E7%9A%84%E4%B8%89%E4%B8%AA%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[优秀的程序员和架构师之间 有一个明显的鸿沟需要跨越 就是 不确定性 合适原则 简单原则 演化原则 将军难打无兵之战！！！ 罗马不是一天建成的 冰山下面才是关键]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之低成本、安全、规模]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F27%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E4%BD%8E%E6%88%90%E6%9C%AC%E3%80%81%E5%AE%89%E5%85%A8%E3%80%81%E8%A7%84%E6%A8%A1%2F</url>
    <content type="text"><![CDATA[低成本 往往只有“创新”才能达到低成本目标 nosql 全文搜索引擎 hadoop 安全 常见的xss攻击 csrf攻击 sql注入 密码破解 windows 漏洞 规模 没有高性能要求 没有双中心高可用功能 看不懂 该不动 不敢改 修不了 量变引起质变 功能之间的连接 数据文件存储 列式数据存储 大数据运算 mysql 单表数据建议在五千万行左右 复杂度的原因]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之可扩展性]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F27%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7%2F</url>
    <content type="text"><![CDATA[设计的系统一定要有足够的可扩展性应对将来需求变化而提供的一种扩展能力 正确预测变化，应对变化 拥抱变化 完美封装变化 把握预测的程度和准确度]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之高可用高性能]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F27%2F%E6%9E%B6%E6%9E%84%E4%B9%8B%E9%AB%98%E6%80%A7%E8%83%BD%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[架构师 高性能 系统与子系统 模块与组件 框架与架构 软件架构是指软件系统的顶层结构 单台计算机内部为了高性能带来的复杂度 多台计算机集群为了高性能带来的复杂度 redis单进程 memcache 多线程 高性能 任务分配 任务分解 增加服务硬件配置 软件调优 增加服务器的方式增加集群（分配） 程度优化 微服务模式 数据方面的问题（缓存） 数据库 读写分离 分库分表 高可用 系统无中断地执行其功能的能力，代表系统的可用性程度，是进行系统设计时的准则之一 一台不够就两台 两台不够就四台 高性能是扩展 高可用是冗余 高可用的解决方法不是解决，而是减少或者规避，而规避某个问题的时候，一般都会引发另一个问题，只是这个问题比之前的小，高可用的设计过程其实也是一个取舍的过程。这也就是为什么系统可用性永远只是说几个九，永远缺少那个一。而高性能，这个基本上就是定义计算能力，可以通过架构的优化，算法的改进，硬件的升级都可以得到很好的解决，从而达到我们心里对性能的预期…]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[架构之分库分表]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F27%2F20190227-%E6%9E%B6%E6%9E%84%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[读写分离 分库分表 索引也变得很大 性能同样会下降 业务分库 业务模块进行拆分 join操作问题 事务问题 成本问题 业务分表 垂直分表 水平分表（分散存储压力和带来性能提升）]]></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>architecture</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-198]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F26%2F20190226-leetcode-198%2F</url>
    <content type="text"><![CDATA[12345678910class Solution(object): def rob(self, nums): &quot;&quot;&quot; :type nums: List[int] :rtype: int &quot;&quot;&quot; last, now = 0, 0 for i in nums: last, now = now, max(last + i, now) return now 采用java做的一版 12345678910111213141516171819202122class Solution &#123; public static int[] result; public int solve(int idx, int[] nums)&#123; if(idx &lt; 0)&#123; return 0; &#125; if(result[idx] &gt;= 0)&#123; return result[idx]; &#125; result[idx] = Math.max(nums[idx]+solve(idx-2, nums), solve(idx-1, nums)); return result[idx]; &#125; public int rob(int[] nums) &#123; result = new int[nums.length]; for(int i=0;i&lt;nums.length;++i)&#123; result[i] = -1; &#125; return solve(nums.length-1, nums); &#125;&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位运算之异或]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F26%2F%E4%BD%8D%E8%BF%90%E7%AE%97%E4%B9%8B%E5%BC%82%E6%88%96%2F</url>
    <content type="text"><![CDATA[12345678910111213#include&lt;stdio.h&gt;int main() &#123; int a[] = &#123;1, 1, 2, 2, 3, 3, 4, 4, 5&#125;; int sz = sizeof(a) / sizeof(a[0]); int i = 0; int x = 0; for (i = 0; i &lt; sz; i++) &#123; x ^= a[i]; //将所有的数异或一下 &#125; printf("%d\n", x); return 0;&#125; 任何一个数字 异或它自己都等于0123456789101112131415161718192021222324252627282930#include&lt;stdio.h&gt;int main() &#123; int a[] = &#123;1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 7&#125;; int i = 0; int sz = sizeof(a) / sizeof(a[0]); int n = 0; int pos = 0; int x = 0; int y = 0; for (i = 0; i &lt; sz; i++) &#123; n ^= a[i]; //将所有的数异或 得到 6^7 的结果 &#125; for (i = 0; i &lt; 32; i++) &#123; if (((n &gt;&gt; i) &amp; 1) == 1) &#123; pos = i; //找到 6^7 的二进制数中为1的一位 break; &#125; &#125; for (i = 0; i &lt; sz; i++) //开始分组 &#123; if (((a[i] &gt;&gt; pos) &amp; 1) == 1) &#123; x ^= a[i]; //得到一个数 &#125; else &#123; y ^= a[i]; //得到另一个数 &#125; &#125; printf(&quot;%d %d\n&quot;, x, y); return 0;&#125;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-309]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F25%2Fleetcode-309%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031n = len(prices) if n &lt; 2: return 0 # k is big enougth to cover all ramps. if k &gt;= n / 2: return sum(i - j for i, j in zip(prices[1:], prices[:-1]) if i - j &gt; 0) globalMax = [[0] * n for _ in xrange(k + 1)] for i in xrange(1, k + 1): # The max profit with i transations and selling stock on day j. localMax = [0] * n for j in xrange(1, n): profit = prices[j] - prices[j - 1] localMax[j] = max( # We have made max profit with (i - 1) transations in # (j - 1) days. # For the last transation, we buy stock on day (j - 1) # and sell it on day j. globalMax[i - 1][j - 1] + profit, # We have made max profit with (i - 1) transations in # (j - 1) days. # For the last transation, we buy stock on day j and # sell it on the same day, so we have 0 profit, apparently # we do not have to add it. globalMax[i - 1][j - 1], # + 0, # We have made profit in (j - 1) days. # We want to cancel the day (j - 1) sale and sell it on # day j. localMax[j - 1] + profit) globalMax[i][j] = max(globalMax[i][j - 1], localMax[j]) return globalMax[k][-1]]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-188]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F25%2Fleetcode-188%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123;public: int maxProfit(int k, vector&lt;int&gt;&amp; prices) &#123; // Step 1: Find out all profit opportunities vector&lt;int&gt; profits; stack&lt;pair&lt;int, int&gt;&gt; vps; // valley-peak pairs int v; int p = -1; for (;;) &#123; // find next valley-peak pair for (v = p+1; (v+1 &lt; prices.size()) &amp;&amp; (prices[v] &gt;= prices[v+1]); ++v); for (p = v ; (p+1 &lt; prices.size()) &amp;&amp; (prices[p] &lt;= prices[p+1]); ++p); if (v == p) &#123; // v==p means that both v and p reach the end of the array break; &#125; // Consider two transactions (v1, p1) (back of the stack) and (v2, p2) (the new-found). // If prices[v1] &gt;= prices[v2], // it is meaningless to combine the two transactions. // Save of profit of (v1, p1), and pop it out of the record. while ((!vps.empty()) &amp;&amp; (prices[v] &lt;= prices[vps.top().first])) &#123; profits.push_back(prices[vps.top().second] - prices[vps.top().first]); vps.pop(); &#125; // If prices[v1]&lt;prices[v2] and prices[p1]&lt;prices[p2], // then it is meaningful to combine the two transactions // update (v1, p1) to (v1, p2), and save the profit of (v2, p1) while ((!vps.empty()) &amp;&amp; (prices[p] &gt;= prices[vps.top().second])) &#123; profits.push_back(prices[vps.top().second] - prices[v]); v = vps.top().first; vps.pop(); &#125; // save the new-found valley-peak pair vps.emplace(v, p); &#125; // save all remaining profits while (!vps.empty()) &#123; profits.push_back(prices[vps.top().second] - prices[vps.top().first]); vps.pop(); &#125; // Step 2: Calculate the k highest profits int ret; if (profits.size() &lt;= k) &#123; ret = accumulate(profits.begin(), profits.end(), 0); &#125; else &#123; nth_element(profits.begin(), profits.end() - k, profits.end()); ret = accumulate(profits.end() - k, profits.end(), 0); &#125; return ret; &#125;&#125;;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-122]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F25%2Fleetcode-122%2F</url>
    <content type="text"><![CDATA[123456789int total = 0; //遍历所有交易日 for (int i = 0; i &lt; prices.length - 1; i++) &#123; //只要是后一天比前一天贵,就卖出 if (prices[i + 1] &gt; prices[i]) total += prices[i + 1] - prices[i]; &#125; return total;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-121]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F25%2Fleetcode-121%2F</url>
    <content type="text"><![CDATA[这题使用双指针法 12345678910def maxProfit(self, prices): """ :type prices: List[int] :rtype: int """ max_profit, min_price = 0, float('inf') for price in prices: min_price = min(min_price, price) max_profit = max(max_profit, price - min_price) return max_profit 123456789101112class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int maxPro = 0; int minPrice = INT_MAX; for(int i = 0; i &lt; prices.size(); i++)&#123; minPrice = min(minPrice, prices[i]); maxPro = max(maxPro, prices[i] - minPrice); &#125; return maxPro; &#125;&#125;; 123456789class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int res=0,buyp=INT_MAX; for(auto i:prices) (i&lt;buyp)?(buyp=i):(res=max(i-buyp,res)); return res; &#125;&#125;; 更加简洁的cpp]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2darraySearch]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F25%2F2darraySearch%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 public class Solution &#123; public boolean Find(int target, int [][] array) &#123; // 特殊情况处理 if (array == null || array.length == 0 || array[0].length == 0) &#123; return false; &#125; int h = array.length - 1; int w = array[0].length - 1; // 如果目标值小于最小值 或者 目标值大于最大值，那肯定不存在 if (array[0][0] &gt; target || array[h][w] &lt; target) &#123; return false; &#125; return binarySearchIn2DArray(array, target, 0, h, 0, w); &#125; public static boolean binarySearchIn2DArray(int[][] array, int target, int startX, int endX, int startY, int endY) &#123; if (startX &gt; endX || startY &gt; endY) &#123; return false; &#125; //首先，根据二分法找出中间行 int x = startX + (endX - startX) / 2; //对该行进行二分查找 int result = binarySearch(array[x], target, startY, endY); //找到的值位于 x 行，result 列 if (array[x][result] == target) &#123; return true; // 如果找到则成功 &#125; //对剩余的两部分分别进行递归查找 return binarySearchIn2DArray(array, target, startX, x - 1, result + 1, endY) || binarySearchIn2DArray(array, target, x + 1, endX, startY, result); &#125; public static int binarySearch(int[] array, int target, int start, int end) &#123; int i = start + (end - start) / 2; if (array[i] == target || start &gt; end) &#123; return i; &#125; else if (array[i] &gt; target) &#123; return binarySearch(array, target, start, i - 1); &#125; else &#123; return binarySearch(array, target, i + 1, end); &#125; &#125;&#125;]]></content>
      <categories>
        <category>suanfa</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-994]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F25%2Fleetcode-994%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627class Solution(object): def orangesRotting(self, A): R, C = len(A), len(A[0]) # queue - all starting cells with rotting oranges queue = collections.deque() for r, row in enumerate(A): for c, val in enumerate(row): if val == 2: queue.append((r, c, 0)) def neighbors(r, c): for nr, nc in ((r-1,c),(r,c-1),(r+1,c),(r,c+1)): if 0 &lt;= nr &lt; R and 0 &lt;= nc &lt; C: yield nr, nc d = 0 while queue: r, c, d = queue.popleft() for nr, nc in neighbors(r, c): if A[nr][nc] == 1: A[nr][nc] = 2 queue.append((nr, nc, d+1)) if any(1 in row for row in A): return -1 return d]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-10]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F23%2F2019-go-10%2F</url>
    <content type="text"><![CDATA[beego 的模块化设计-gracegrace 模块是 beego 新增的一个独立支持热重启的模块。 1234567891011121314151617181920212223242526import( &quot;log&quot; &quot;net/http&quot; &quot;os&quot; &quot;strconv&quot; &quot;github.com/astaxie/beego/grace&quot; ) func handler(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte(&quot;WORLD!&quot;)) w.Write([]byte(&quot;ospid:&quot; + strconv.Itoa(os.Getpid()))) &#125; func main() &#123; mux := http.NewServeMux() mux.HandleFunc(&quot;/hello&quot;, handler) err := grace.ListenAndServe(&quot;localhost:8080&quot;, mux) if err != nil &#123; log.Println(err) &#125; log.Println(&quot;Server on 8080 stopped&quot;) os.Exit(0) &#125; 打开两个终端 一个终端输入：ps -ef|grep 应用名 一个终端输入请求：curl “http://127.0.0.1:8080/hello“ 热升级 kill -HUP 进程 ID 打开一个终端输入请求：curl “http://127.0.0.1:8080/hello?sleep=0“]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-09]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F23%2F2019-go-09%2F</url>
    <content type="text"><![CDATA[beego 的模块化设计-sessionsession 模块是用来存储客户端用户，session 模块目前只支持 cookie 方式的请求，如果客户端不支持 cookie，那么就无法使用该模块。 session 模块参考了 database/sql 的引擎写法，采用了一个接口，多个实现的方式。目前实现了 memory、file、Redis 和 MySQL 四种存储引擎。 通过下面的方式安装 session： go get github.com/astaxie/beego/session 初始化 1234567891011121314func init() &#123; sessionConfig := &amp;session.ManagerConfig&#123; CookieName:&quot;gosessionid&quot;, EnableSetCookie: true, Gclifetime:3600, Maxlifetime: 3600, Secure: false, CookieLifeTime: 3600, ProviderConfig: &quot;./tmp&quot;, &#125; globalSessions, _ = session.NewManager(&quot;memory&quot;,sessionConfig) go globalSessions.GC()&#125; 一个 JSON 字符串,传入 Manager 的配置信息 cookieName: 客户端存储 cookie 的名字。 enableSetCookie,omitempty: 是否开启 SetCookie,omitempty 这个设置 gclifetime: 触发 GC 的时间。 maxLifetime: 服务器端存储的数据的过期时间 secure: 是否开启 HTTPS，在 cookie 设置的时候有 cookie.Secure 设置。 sessionIDHashFunc: sessionID 生产的函数，默认是 sha1 算法。 sessionIDHashKey: hash 算法中的 key。 cookieLifeTime: 客户端存储的 cookie 的时间，默认值是 0，即浏览器生命周期。 providerConfig: 配置信息，根据不同的引擎设置不同的配置信息，详细的配置请看下面的引擎设置 最后的逻辑处理 123456789101112func login(w http.ResponseWriter, r *http.Request) &#123; sess, _ := globalSessions.SessionStart(w, r) defer sess.SessionRelease(w) username := sess.Get(&quot;username&quot;) if r.Method == &quot;GET&quot; &#123; t, _ := template.ParseFiles(&quot;login.gtpl&quot;) t.Execute(w, nil) &#125; else &#123; sess.Set(&quot;username&quot;, r.Form[&quot;username&quot;]) &#125;&#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-08]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F23%2F2019-go-08%2F</url>
    <content type="text"><![CDATA[golang 制霸云计算 go语言是现代的、快速的 带有一个强大的标准库 内置对并发的支持 使用接口作为代码复用的基础模块 包是组织代码的基本单位 环境变量GOPATH决定了go源码在磁盘上被保存、编译和安装的位置 可以为每个工程设置不同的GOPATH 以保持源代码和依赖的隔离 go get获取他人的包 将源代码放到公用代码库 遵守简单规则 可以供他人使用 分享代码作为语言的核心动力和驱动力 依赖管理工具 godep vender gb 数组是构造切片和映射的基石 切片经常来处理数据的集合，映射用来处理具有键值对结构的数据 make用来创建切片和映射，并指定原始的长度和容量 切片有容量限制 可以使用append函数扩展容量 映射的增长没有容量或者任何限制 len可以取切片和映射的长度 cap只能用于切片 通过组合 可以创建多维数组和多维切片 也可以使用切片或者其他映射作为映射的值 但是切片不能作为映射的键 将切片或者映射传递給函数成本很小，并且不会复制底层的数据结构]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-07]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F23%2F2019-go-07%2F</url>
    <content type="text"><![CDATA[多核硬件架构 超大规模分布式集群 web模式导致前所未有的开发规模和更新速度 简单高效生产力 追求极致的简单]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-06]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F23%2F2019-go-06%2F</url>
    <content type="text"><![CDATA[golang 的面试题目 收集 uint不能直接相减，结果是负数会变成一个很大的uint，这点对动态语言出身的会可能坑。 channel一定记得close。 goroutine记得return或者中断，不然容易造成goroutine占用大量CPU。 从slice创建slice的时候，注意原slice的操作可能导致底层数组变化。 如果你要创建一个很长的slice，尽量创建成一个slice里存引用，这样可以分批释放，避免gc在低配机器上stop the world 面试的时候尽量了解协程，线程，进程的区别。 明白channel是通过注册相关goroutine id实现消息通知的。 slice底层是数组，保存了len，capacity和对数组的引用。 如果了解协程的模型，就知道所谓抢占式goroutine调用是什么意思。 尽量了解互斥锁，读写锁，死锁等一些数据竞争的概念，debug的时候可能会有用。 尽量了解golang的内存模型，知道多小才是小对象，为什么小对象多了会造成gc压力。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask-0.1]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F19%2Fflask-0-1%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526# Flask v0.1class _RequestContext(object): &quot;&quot;&quot;The request context contains all request relevant information. It is created at the beginning of the request and pushed to the `_request_ctx_stack` and removed at the end of it. It will create the URL adapter and request object for the WSGI environment provided. &quot;&quot;&quot; def __init__(self, app, environ): self.app = app self.url_adapter = app.url_map.bind_to_environ(environ) self.request = app.request_class(environ) self.session = app.open_session(self.request) self.g = _RequestGlobals() self.flashes = None def __enter__(self): _request_ctx_stack.push(self) def __exit__(self, exc_type, exc_value, tb): # do not pop the request stack if we are in debug mode and an # exception happened. This will allow the debugger to still # access the request object in the interactive shell. if tb is None or not self.app.debug: _request_ctx_stack.pop() 请求上下文 根据_RequestContext上下文对象的定义，可以发现，在构造这个对象的时候添加了和Flask应用相关的一些属性： app ——上下文对象的app属性是当前的Flask应用；url_adapter ——上下文对象的url_adapter属性是通过Flask应用中的Map实例构造成一个MapAdapter实例，主要功能是将请求中的URL和Map实例中的URL规则进行匹配；request ——上下文对象的request属性是通过Request类构造的实例，反映请求的信息；session ——上下文对象的session属性存储请求的会话信息；g ——上下文对象的g属性可以存储全局的一些变量。flashes ——消息闪现的信息。 12345current_app = LocalProxy(lambda: _request_ctx_stack.top.app)request = LocalProxy(lambda: _request_ctx_stack.top.request)session = LocalProxy(lambda: _request_ctx_stack.top.session)g = LocalProxy(lambda: _request_ctx_stack.top.g) 在上下文对象中处理请求的过程分为以下几个步骤： 在请求正式被处理之前的一些操作，调用preprocess_request()方法，例如打开一个数据库连接等操作；正式处理请求。这个过程调用dispatch_request()方法，这个方法会根据URL匹配的情况调用相关的视图函数；将从视图函数返回的值转变为一个Response对象；在响应被发送到WSGI服务器之前，调用process_response(response)做一些后续处理过程；调用response(environ, start_response)方法将响应发送回WSGI服务器。关于此方法的使用，可以参考：Werkzeug库——wrappers模块；退出上下文环境时，LocalStack会清理当前线程/协程产生的数据（请求上下文对象）。]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-986]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F18%2Fleetcode-986%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031# Definition for an interval.class Interval(object): def __init__(self, s=0, e=0): self.start = s self.end = eclass Solution(object): def intervalIntersection(self, A, B): &quot;&quot;&quot; :type A: List[Interval] :type B: List[Interval] :rtype: List[Interval] &quot;&quot;&quot; a, b, res, i, j = len(A), len(B), [], 0, 0 while i &lt; a and j &lt; b: left_a, right_a = A[i].start, A[i].end left_b, right_b = B[j].start, B[j].end if left_a &lt; left_b: left = left_b else: left = left_a if right_a &lt; right_b: right = right_a i += 1 else: right = right_b j += 1 if right &gt;= left: res.append(Interval(left, right)) return res]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django2.x-on_delete]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F14%2Fdjango2-x-on-delete%2F</url>
    <content type="text"><![CDATA[1234567891011on_delete=None, # 删除关联表中的数据时,当前表与其关联的field的行为on_delete=models.CASCADE, # 删除关联数据,与之关联也删除on_delete=models.DO_NOTHING, # 删除关联数据,什么也不做on_delete=models.PROTECT, # 删除关联数据,引发错误ProtectedError# models.ForeignKey(&apos;关联表&apos;, on_delete=models.SET_NULL, blank=True, null=True)on_delete=models.SET_NULL, # 删除关联数据,与之关联的值设置为null（前提FK字段需要设置为可空,一对一同理）# models.ForeignKey(&apos;关联表&apos;, on_delete=models.SET_DEFAULT, default=&apos;默认值&apos;)on_delete=models.SET_DEFAULT, # 删除关联数据,与之关联的值设置为默认值（前提FK字段需要设置默认值,一对一同理）on_delete=models.SET, # 删除关联数据, a. 与之关联的值设置为指定值,设置：models.SET(值) b. 与之关联的值设置为可执行对象的返回值,设置：models.SET(可执行对象)]]></content>
  </entry>
  <entry>
    <title><![CDATA[pg-update-tz]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F14%2Fpg-update-tz%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324例如要将默认的PRC修改为UTC可以从几个方面来修改1. 全局参数postgresql.conftimezone=&apos;UTC&apos;2. 数据库级配置alter database dbname set timezone=&apos;UTC&apos;;pipeline=# select * from pg_db_role_setting ; setdatabase | setrole | setconfig -------------+---------+-------------------------------------- 14930 | 0 | &#123;TimeZone=UTC&#125;3. 用户级配置alter role rolname set timezone=&apos;UTC&apos;;或者alter role all set timezone=&apos;UTC&apos;;pipeline=# select * from pg_db_role_setting ; setdatabase | setrole | setconfig -------------+---------+-------------------------------------- 14930 | 0 | &#123;TimeZone=UTC&#125; 0 | 0 | &#123;TimeZone=UTC&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[2019-go-05]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F13%2F2019-go-05%2F</url>
    <content type="text"><![CDATA[目前而言 主力语言还是python 但是可能对未来十年的预期 是Golang 编译成单一的二进制 Golang 是编译型语言并且 Googe 的开发者花了很大的功夫在上面。它使用静态链接实际上是基于操作系统类型和环境组合所有的依赖库文件和模块到一个单一的二进制文件中，这也意味着如果你想要编译你的后端应用到你的 Linux 操作系统和 X86 架构的 CPU 中，你只要下载编译好的二进制应用到服务器，然后可以后端应用可以工作了,这是不需要任何的依赖文件的。 静态类型系统Python 是很棒的并且有趣的语言但是有些时候你会看到一些不寻常的异常因为当你尝试将变量作为一个整型变量的时候结果它是一个字符串类型. 123# Django will crash process because of this def some_view(request): user_id = request.POST.get(&apos;id&apos;, 0) Go 在编译的时候告诉你这是一个编译器错误，这就是在愚蠢的问题上赢得时间的地方。 优化Go 语言由于自己的多线程模块和 CPU 可伸缩性获得了较好的性能。无论什么时候我们需要执行一些内部的请求，我们可以使用 Goroutine 来分别执行，这个比 Python 中的 Threads 在资源开销上要少上十多倍。由于这些内置的语言特性，我们可以节省大量的资源(内存和 CPU )。 不再需要web框架对于编程语言这是一件十分酷的事情。Go 语言的创造者和社区内置了很多原生的被核心语言支持的工具，在大多数情况下你都不再需要任何第三方类库。比如它有内置的 http、json、html 模板，你甚至可以不用费心去 Github 上寻找第三方类库就可以构建十分复杂的 API 服务。 当然，Go 也有很多类库和框架用来构建 web 项目，但是我会建议你不使用第三方类库来构建你的 web 项目或者 API 服务，因为在大多数情况下使用原生包会使你的生活更加轻松。 更好的 IDE 支持和调试？？？ IDE 支持是当你尝试更改编程语言时最重要的考虑因素之一。友好的 IDE 平均可以节省你80%的编程时间。 Go Plugin For JetBrains IDEA ，同样提供了其他支持，比如 (Webstorm、PHPStorm 等等…)。这个插件提供了任何你在项目开发中需要的服务，强大的 JetBrains IDEA ，可以让你的开发如虎添翼。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-04]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F13%2F2019-go-04%2F</url>
    <content type="text"><![CDATA[使用 Raw SQL 查询，无需使用 ORM 表定义 多数据库，都可直接使用占位符号 ?，自动转换 查询时的参数，支持使用 Model Struct 和 Slice, Array 1234insOrm:=orm.NewOrm()var user models.UsersinsOrm.Raw("SELECT name FROM Users WHERE id = ?", 1)..Exec()this.Ctx.WriteString(user.Name)]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-03]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F13%2F2019-go-03%2F</url>
    <content type="text"><![CDATA[基本使用1234567//创建Orm对象o := orm.NewOrm()// 获取 QuerySeter 对象，user 为表名qs := o.QueryTable(&quot;user&quot;)// 也可以直接使用对象作为表名user := new(User)qs = o.QueryTable(user) // 返回 QuerySeter 复杂一些的 12345678910qs.Filter(&quot;id&quot;, 1) // WHERE id = 1qs.Filter(&quot;user__id&quot;,1) //where user.id =1qs.Filter(&quot;id_in&quot;,10，20) //where age in(10,20)qs.Filter(&quot;id__gte&quot;,18) //where id&gt;=18qs.Filter(&quot;id__gt&quot;,18) //where id&gt;18qs.Filter(&quot;id__,5) //where id&lt;5//gt 是greater缩写即大于 //get是 Greater or equal的缩写即大于等于 //lt 是less than 即小于 具体的例子 123456789101112131415exact -&gt; =iexact -&gt; like&apos;in -&gt; in gt -&gt; &gt; gte-&gt; &gt;=lt -&gt; &lt;lte -&gt; &lt;=contains -&gt; like BINARY &apos;%xxx%&apos; （区分大小写）icontains -&gt; like &apos;%xxx%&apos; (不区分大小写)startswith -&gt; LIKE BINARY &apos;xxx%&apos; （区分大小写）istartswith -&gt; LIKE &apos;xxx%&apos;endswith -&gt; LIKE BINARY &apos;%xxx&apos; （区分大小写）iendswith -&gt; LIKE &apos;%xxx&apos;isnull -&gt; is not null 12345678910qs.Filter(&quot;id&quot;, 1) // WHERE id = 1qs.Filter(&quot;user__id&quot;,1) //where user.id =1qs.Filter(&quot;_id_in&quot;,10，20) //where age in(10,20)qs.Filter(&quot;__id__gte&quot;,18) //where id&gt;=18qs.Filter(&quot;__id__gt&quot;,18) //where id&gt;18qs.Filter(&quot;__id__,5) //where id&lt;5//gt 是greater缩写即大于 //get是 Greater or equal的缩写即大于等于 //lt 是less than 即小于 123456789101112var DefaultRelsDepth = 5 // 默认情况下直接调用 RelatedSel 将进行最大 5 层的关系查询 qs := o.QueryTable(&quot;post&quot;) qs.RelatedSel()// INNER JOIN user ... LEFT OUTER JOIN profile ... qs.RelatedSel(&quot;user&quot;)// INNER JOIN user ...// 设置 expr 只对设置的字段进行关系查询 // 对设置 null 属性的 Field 将使用 LEFT OUTER JOIN 123456num, err := o.QueryTable(&quot;user&quot;).Filter(&quot;name&quot;, &quot;slene&quot;).Update(orm.Params&#123; &quot;name&quot;: &quot;astaxie&quot;,&#125;)fmt.Printf(&quot;Affected Num: %s, %s&quot;, num, err)// SET name = &quot;astaixe&quot; WHERE name = &quot;slene&quot; 123var users []*Usernum, err := o.QueryTable(&quot;user&quot;).Filter(&quot;name&quot;, &quot;slene&quot;).All(&amp;users)fmt.Printf(&quot;Returned Rows Num: %s, %s&quot;, num, err) 受到limit限制 默认最大行数为1000]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-02]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F13%2F2019-go-02%2F</url>
    <content type="text"><![CDATA[新增12345678910111213141516171819202122232425func (this *InsertController) Post() &#123;/* Name :=&quot;admin&quot; Pwd :=&quot;12346&quot; Sex :=&quot;男&quot; Age :=20*/ Name :=this.GetString(&quot;Name&quot;) Pwd :=this.GetString(&quot;Pwd&quot;) Sex :=this.GetString(&quot;Sex&quot;) Age,err:=this.GetInt(&quot;Age&quot;) if err!=nil &#123; this.Ctx.WriteString(&quot;非法年龄字段&quot;) return &#125; user:=models.Users&#123;Name:Name,Pwd:Pwd,Sex:Sex,Age:Age&#125; insOrm:=orm.NewOrm() n,err:=insOrm.Insert(&amp;user) if err==nil&amp;&amp;n&gt;0 &#123; this.Ctx.WriteString(&quot;数据插入成功&quot;) &#125;else&#123; this.Ctx.WriteString(&quot;数据插入失败&quot;) &#125;&#125; 读取read1234567891011121314151617func (this *QueryController)Get() &#123; id,err:=this.GetInt(&quot;id&quot;) if err!=nil &#123; this.Ctx.WriteString(&quot;id异常&quot;) return &#125; user:= models.Users&#123;Id:id&#125; //获取指定id的数据 orm:=orm.NewOrm() err=orm.Read(&amp;user) //读取数据 if err==nil &#123; this.Ctx.WriteString(&quot;id=&quot;+strconv.Itoa(user.Id)+&quot;\nname=&quot;+user.Name+&quot;\nsex=&quot;+user.Sex) &#125;else&#123; this.Ctx.WriteString(&quot;查询失败&quot;) &#125; &#125; 更新 update1234567891011121314151617181920212223func (this *UpdataController)Get() &#123; Id,err:=this.GetInt(&quot;Id&quot;) if err!=nil &#123; this.Ctx.WriteString(&quot;id异常&quot;) return &#125; Name :=this.GetString(&quot;Name&quot;) Pwd :=this.GetString(&quot;Pwd&quot;) Sex :=this.GetString(&quot;Sex&quot;) Age,err:=this.GetInt(&quot;Age&quot;) if err!=nil &#123; this.Ctx.WriteString(&quot;非法年龄字段&quot;) return &#125; user:= models.Users&#123;Id:Id,Name:Name,Pwd:Pwd,Age:Age,Sex:Sex&#125; orm:=orm.NewOrm() n,err:=orm.Update(&amp;user) if n&gt;0&amp;&amp;err==nil&#123; this.Ctx.WriteString(&quot;更新成功&quot;) &#125;else&#123; this.Ctx.WriteString(&quot;更新失败&quot;) &#125;&#125; 删除 delete12345678910111213141516func (this *DeleteController) Get() &#123; id,err:=this.GetInt(&quot;id&quot;) if err!=nil &#123; this.Ctx.WriteString(&quot;删除失败&quot;) return &#125; user:= models.Users&#123;Id:id&#125; orm:=orm.NewOrm() n,err:=orm.Delete(&amp;user) if n&gt;0&amp;&amp;err==nil &#123; this.Ctx.WriteString(&quot;删除成功&quot;) &#125;else&#123; this.Ctx.WriteString(&quot;删除失败&quot;) &#125; &#125;]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-01]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F13%2F2019-go-01%2F</url>
    <content type="text"><![CDATA[beego orm已支持数据库驱动： MySQL：github.com/go-sql-driver/mysql PostgreSQL：github.com/lib/pq 导入驱动 import ( _ &quot;github.com/go-sql-driver/mysql&quot; ) 123456789101112131415161718192021222324252627282930313233// models/User.go type Users struct &#123; Id int Name string Pwd string Age int Sex string&#125; /*//我们也可以使用Tag对属性进行详细的设置type Users struct &#123; Id int `pk:"auto;column(id)"` //设置主键自增长 列名设为id Name string `orm:"size(15);column(name)"` //设置varchar长度为15 列名为name Pwd string `orm:"size(15);column(pwd)"` Age int `orm:"column(age)"` Sex string `orm:"size(15);column(sex)"`&#125;*/ //初始化func init() &#123; //注册数据驱动 // orm.RegisterDriver("mysql", orm.DR_MySQL) // mysql / sqlite3 / postgres 这三种是默认已经注册过的，所以可以无需设置 //注册数据库 ORM 必须注册一个别名为 default 的数据库，作为默认使用 orm.RegisterDataBase("default", "mysql", "root:123456@tcp(127.0.0.1:3306)/HelloBeego") //注册模型 orm.RegisterModel(new(Users)) //自动创建表 参数二为是否开启创建表 参数三是否更新表 orm.RunSyncdb("default", true, true)&#125; 1234567orm.RegisterDataBase("default", "mysql", "root:root@/orm_test?charset=utf8", maxIdle, maxConn) // 参数1 数据库的别名，用来在 ORM 中切换数据库使用// 参数2 数据库驱// 参数3 对应的连接字符串// 参数4(可选) 设置最大空闲连接// 参数5(可选) 设置最大数据库连接 (go &gt;= 1.2) 模型设置详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354忽略字段设置 - 即可忽略 struct 中的字段AnyField string `orm:&quot;-&quot;` auto当 Field 类型为 int, int32, int64, uint, uint32, uint64 时，可以设置字段为自增健当模型定义里没有主键时，符合上述类型且名称为 Id 的 Field 将被视为自增健。 pk设置为主键，适用于自定义其他类型为主键 null数据库表默认为 NOT NULL，设置 null 代表 ALLOW NULLName string `orm:&quot;null&quot; index为单个字段增加索引 unique为单个字段增加 unique 键Name string `orm:&quot;unique&quot;` column为字段设置 db 字段的名称Name string `orm:&quot;column(user_name)&quot;` sizestring 类型字段默认为 varchar(255)设置 size 以后，db type 将使用 varchar(size)Title string `orm:&quot;size(60)&quot;` digits / decimals设置 float32, float64 类型的浮点精度Money float64 `orm:&quot;digits(12);decimals(4)&quot;`总长度 12 小数点后 4 位 eg: 99999999.9999 auto_now / auto_now_addCreated time.Time `orm:&quot;auto_now_add;type(datetime)&quot;`Updated time.Time `orm:&quot;auto_now;type(datetime)&quot;`auto_now 每次 model 保存时都会对时间自动更新auto_now_add 第一次保存时才设置时间对于批量的 update 此设置是不生效的type设置为 date 时，time.Time 字段的对应 db 类型使用 date Created time.Time `orm:&quot;auto_now_add;type(date)&quot;`设置为 datetime 时，time.Time 字段的对应 db 类型使用 datetimeCreated time.Time `orm:&quot;auto_now_add;type(datetime)&quot;` default为字段设置默认值，类型必须符合（目前仅用于级联删除时的默认值）Status int `orm:&quot;default(1)&quot;`]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019-go-00]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F13%2F2019-go-00%2F</url>
    <content type="text"><![CDATA[session &amp; cookie1.Http是无状态的协议，服务器不能记录浏览器的访问状态，也就是服务器不能区分两次请求是否是来自同一个客户端。 2.Cookie实际上是服务器保存在浏览器上的一段信息，浏览器有了Cookie之后，每次向服务器发送请求都会带着该信息进行访问，服务器在收到请求之后，就可以通过该信息进行处理。 3.Cookie由服务器创建，并发给浏览器，最终由浏览器保存。 Cookie的用途 电商网站的购物车 保持用户登陆状态 使用beego.Router()注册路由 beego.Router(&quot;/cookie&quot;,&amp;controllers.CookieController{}) 控制器 package controllers import &quot;github.com/astaxie/beego&quot; type CookieController struct { beego.Controller } func (this *CookieController)Get() { if this.Ctx.GetCookie(&quot;user&quot;) ==&quot;&quot;{ this.Ctx.SetCookie(&quot;user&quot;,&quot;admin&quot;) this.Ctx.WriteString(&quot;Cookie设置成功&quot;) }else{ user:= this.Ctx.GetCookie(&quot;user&quot;) this.Ctx.WriteString(&quot;user=&quot;+user) } } 我们先通过this.Ctx.GetCookie(“key”)判断浏览器是否有Cookie ，如果没有就使用this.Ctx.SetCookie(“key”,”value”)设置，如果有就获取并输出。 注意Cookie的键和值不能为中文 this.Ctx.SetCookie(&quot;user&quot;,&quot;admin&quot;，10) SetCookie的第三个参数是时间，单位是秒 ，如果不设置时间，Cookie只在本次会话有效，默认存活时间为3600秒 this.Ctx.SetCookie(&quot;user&quot;,&quot;admin&quot;,&quot;100&quot;,&quot;/cookie&quot;) Session的使用 Beego默认关闭Session，如果想要使用Session，需要在配置文件或程序中设置，分别为 beego.BConfig.WebConfig.Session.SessionOn = true和sessionon=true 设置Session this.SetSession(“usesrname”, “admin”) 删除Session This.GetSession(“username”),如果没有获取到session，会返回nil，和cookie不一样，getCookie返回空字符串。 Session是一段保存在服务器上的一段信息，当客户端第一次访问服务器时创建。同时也创建一个名为beegosessionID,值为创建Session的id的Cookie这个beegosessionID对应服务器中的一个Session对象，通过它就可以获取到保存用户信息的Session 通过this.DelSession(“password”)和this.DestroySession()均可以删除Session，其区别在于DelSession删除指定的Session, DestroySession删除所有session。 可以通过beego.BConfig.WebConfig.Session.SessionName = “admin”和sessionname设置Cookie名称，如果在配置文件和主函数都设置了，主函数优先，因为beego先加载配置文件后执行主函数，所以主函数中设置的内容回对配置文件中设置的内容进行覆盖。]]></content>
      <categories>
        <category>golang</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[one-line-python]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F11%2Fone-line-python%2F</url>
    <content type="text"><![CDATA[一行python代码能够做什么1python -c &quot;import this&quot; 1234python -m SimpleHTTPServer 8080 # python2python3 -m http.server 8080 # python3 1for x in range(1, 101): print(&quot;fizz&quot;[x % 3 * 4:]+&quot;buzz&quot;[x % 5 * 4:] or x) 1print(&apos;\n&apos;.join([&apos;&apos;.join([(&apos;Love&apos;[(x-y) % len(&apos;Love&apos;)] if ((x*0.05)**2+(y*0.1)**2-1)**3-(x*0.05)**2*(y*0.1)**3 &lt;= 0else&apos; &apos;) forx in range(-30, 30)]) fory in range(30, -30, -1)])) 1print(&apos;\n&apos;.join([&apos;&apos;.join([&apos;*&apos;if abs((lambda a: lambda z, c, n: a(a, z, c, n))(lambda s, z, c, n: z if n == 0 else s(s, z*z+c, c, n-1))(0, 0.02*x+0.05j*y, 40)) &lt; 2 else &apos; &apos; for x in range(-80, 20)]) for y in range(-20, 20)])) 1print(&apos;\n&apos;.join([&apos; &apos;.join([&apos;%s*%s=%-2s&apos; % (y, x, x*y) fory in range(1, x+1)]) forx in range(1, 10)])) 123print(&apos; &apos;.join([str(item) for item in filter(lambda x: not [x % i for i in range(2, x) if x % i == 0], range(2, 101))]))print(&apos; &apos;.join([str(item) for item in filter(lambda x: all(map(lambda p: x % p != 0, range(2, x))), range(2, 101))])) 1print([x[0] for x in [(a[i][0], a.append([a[i][1], a[i][0]+a[i][1]])) for a in ([[1, 1]], ) for i in range(30)]]) 1qsort = lambda arr: len(arr) &gt; 1and qsort(list(filter(lambda x: x &lt;= arr[0], arr[1:]))) + arr[0:1] + qsort(list(filter(lambda x: x &gt; arr[0], arr[1:]))) or arr 1[__import__(&apos;sys&apos;).stdout.write(&apos;\n&apos;.join(&apos;.&apos; * i + &apos;Q&apos; + &apos;.&apos; * (8-i-1) for i in vec) + &quot;\n========\n&quot;) for vec in __import__(&apos;itertools&apos;).permutations(range(8)) if 8 == len(set(vec[i]+i for i in range(8))) == len(set(vec[i]-i for i in range(8)))] 1flatten = lambda x: [y for l in x for y in flatten(l)] if isinstance(x, list) else [x] 1array = lambda x: [x[i:i+3] for i in range(0, len(x), 3)] 1print(sum(map(int, str(2**1000))))]]></content>
  </entry>
  <entry>
    <title><![CDATA[how-to-be-a-daniu]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F11%2Fhow-to-be-a-daniu%2F</url>
    <content type="text"><![CDATA[误区 拜大牛为师 业务代码一样很牛逼？ 上班太忙没时间学习 正确做法 do more —&gt; 熟悉更多业务 —&gt; 熟悉端到端 —&gt; 自学 do better do exercise learning trying teaching]]></content>
  </entry>
  <entry>
    <title><![CDATA[前端总规划总结]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F02%2F10%2F%E5%89%8D%E7%AB%AF%E6%80%BB%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[conda_cmd]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F30%2Fconda-cmd%2F</url>
    <content type="text"><![CDATA[常用操作命令： 一、环境操作 1.查看环境管理的全部命令帮助： conda env -h 2.查看当前系统下的环境： conda info -e 3.创建环境： conda create env_name (env_name)是环境名称,这条命令将会给Biopython创建一个新的环境，位置在Anaconda安装文件的/envs/snowflakes 创建指定python版本的环境： conda create env_name python=3.6 (3.6为python的版本，根据自己的需要更改) 创建包含某些包的环境： conda create env_name numpy scipy 创建指定python版本下包含某些包的环境： conda create env_name python=3.6 numpy scipy 激活（进入）某个环境： 新的开发环境会被默认安装在conda目录下envs文件目录下,你可以指定一个其他的路径； 如果没有指定安装python的版本，conda会安装最初安装conda时所装的那个版本的python。 windows: activate env_name mac: source activate env_name 退出某个环境： deactivate env_name 复制某个环境： conda create new_env_name old_env_name 删除某个环境： conda remove env_name 二、包管理 查看已安装的包： conda list 查看指定环境下的包： conda list -n xxx 查找包： conda search xxx 更新包： conda update xxx 安装包： conda install xxx pip install xxx 指定的安装环境： conda install -n env_name xxx 安装anaconda发行版中所有的包: conda install anaconda 卸载包： conda remove xxx 三、管理conda 检查conda版本： conda –version 升级当前版本的conda： conda update conda]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>conda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaggle总结]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F30%2Fkaggle%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[主要是机器学习的过程 采用scikit-learn 结合pandas numpy matplotlib seaborn 1234567891011121314151617import pandas as pdinput_df = pd.read_csv(&apos;data/raw/train.csv&apos;, header=0)submit_df = pd.read_csv(&apos;data/raw/test.csv&apos;, header=0)# 合并他们df = pd.concat([input_df, submit_df])# 重建indexdf.reset_index(inplace=True)# 删除reset_index()产生的index columndf.drop(&apos;index&apos;, axis=1, inplace=True)print df.shape[1], &quot;columns:&quot;, df.columns.valuesprint &quot;Row count:&quot;, df.shape[0] 输出如下 123412 columns: [&apos;PassengerId&apos; &apos;Survived&apos; &apos;Pclass&apos; &apos;Name&apos; &apos;Sex&apos; &apos;Age&apos; &apos;SibSp&apos; &apos;Parch&apos; &apos;Ticket&apos; &apos;Fare&apos; &apos;Cabin&apos; &apos;Embarked&apos;]Row count: 1309 可以看到有12个特征 查看数据的完整性情况 12345def observe(df): print &quot;column: &quot;, df.shape[1] columns = df.columns for i in columns: print i, &quot;missing &quot;,pd.isnull(df[i]).sum(), &quot; type:&quot;, df[i].dtypes Cabin 缺失很严重，我想可以忽略这一个特征了。 Age 缺失的并不多，而且Age是一个重要的特征，应该保留。 如何处理缺失的数据 直接扔掉出现缺失Value的数据：只有少量的数据出现缺失Value的情况，这样做比较简单快捷。 给缺失的Value赋特殊值来表明它是缺失的：比较适用于分类变量，因为缺失Value就是不存在的数据，如果给他分配平均值之类的数值并没有什么意义。除非是某些潜在原因使某些缺失值会影响其与另外一个值的关联(correlation)。并且这种方法不适用于连续变量。不过对于二元变量(binary variables)，我们可以把他的缺失值赋为0，正常情况下True为1，False为-1。 给缺失的Value赋平均值：这种简单的做法很普遍，对于不重要的特征来说用这种方法足矣。还可以结合其他变量来算平均值。对于分类变量，使用最常见的值或许比平均值更好。 使用机器学习算法/模型来预测缺失数据：感觉只有数据量很大的情况下这样做才有效。 定量转换变量转换的目的是将数据转换为模型适用的格式，不同方法实现的随机森林(Random Forest)接受不同类型的数据，Scikit-learn要求数据都是数字型numeric，所以我们要将原始数据转换为数字型numeric。 所有的数据可以分为两类：1.定性(Quantitative)变量可以以某种方式排序，Age就是一个很好的列子。2.定量(Qualitative)变量描述了物体的某一（不能被数学表示的）方面，Embarked就是一个例子。 Dummy Variables就是类别变量或者二元变量，当qualitative variable是一些频繁出现的几个独立变量时，Dummy Variables比较适合使用。我们以Embarked为例，Embarked只包含三个值’S’,’C’,’Q’，我们可以使用下面的代码将其转换为dummies: 123embark_dummies = pd.get_dummies(df[&apos;Embarked&apos;])df = df.join(embark_dummies)df.drop([&apos;Embarked&apos;], axis=1,inplace=True) Factorizingdummy不好处理Cabin（船舱号）这种标称属性，因为他出现的变量比较多。所以Pandas有一个方法叫做factorize()，它可以创建一些数字，来表示类别变量，对每一个类别映射一个ID，这种映射最后只生成一个特征，不像dummy那样生成多个特征。 12345678910import re# Replace missing values with &quot;U0&quot;df[&apos;Cabin&apos;][df.Cabin.isnull()] = &apos;U0&apos;# create feature for the alphabetical part of the cabin numberdf[&apos;CabinLetter&apos;] = df[&apos;Cabin&apos;].map( lambda x : re.compile(&quot;([a-zA-Z]+)&quot;).search(x).group())# convert the distinct cabin letters with incremental integer valuesdf[&apos;CabinLetter&apos;] = pd.factorize(df[&apos;CabinLetter&apos;])[0] ScalingScaling可以将一个很大范围的数值映射到一个很小的范围(通常是-1 - 1，或则是0 - 1)，很多情况下我们需要将数值做Scaling使其范围大小一样，否则大范围数值特征将会由更高的权重。比如：Age的范围可能只是0-100，而income的范围可能是0-10000000，在某些对数组大小敏感的模型中会影响其结果。 下面的代码是对Age进行Scaling： 123# StandardScaler will subtract the mean from each value then scale to the unit variancescaler = preprocessing.StandardScaler()df[&apos;Age_scaled&apos;] = scaler.fit_transform(df[&apos;Age&apos;]) BinningBinning通过观察“邻居”(即周围的值)来连续数据离散化。存储的值被分布到一些“桶”或箱中，就像直方图的bin将数据划分成几块一样。下面的代码对Fare进行Binning。 1234567# Divide all fares into quartilesdf[&apos;Fare_bin&apos;] = pd.qcut(df[&apos;Fare&apos;], 4)# qcut() creates a new variable that identifies the quartile range, but we can&apos;t use the string so either# factorize or create dummies from the resultdf[&apos;Fare_bin_id&apos;] = pd.factorize(df[&apos;Fare_bin&apos;])df = pd.concat([df, pd.get_dummies(df[&apos;Fare_bin&apos;]).rename(columns=lambda x: &apos;Fare_&apos; + str(x))], axis=1) 特征提取很重要的一个方面是深入理解数据，并且能提取出新的特征来做预测。机器学习的核心就是模型选取和参数选择，特征提取可以说是重中之重。 一个特征提取的例子是，从电话号码中提取中国家、地区、城市的信息，或者是从GPS中提取中国家、地区、城市的信息。只要能描述一个事物的qualitative变量，都有可能从中挖掘出有用的特征，另外，时序等信息也是非常有用的。 泰坦尼克号的这些数据非常简单，我们并不需要对数据做太多的处理，我们下面只对name，cabin和ticket提取一些变量。 name 提取称呼 Cabin客舱信息包含了甲板和房间号，不同甲板位置不同，逃生船数量不同，人群年龄分布不同等等。不同房间号离甲板距离不同，离逃生船距离不同，等等。所以从客舱中提取中甲板和房间号这两个特征很重要。 机器学习的模型很多，用于分类有： 回归算法：Logistic Regression、 Ordinary Least Square等等。 决策树: CART、ID3、Random Forest等等。 贝叶斯：Navie Bayesian、BBN等等。 基于实例的算法：KNN、LVQ等等。 组合模型、关联规则、神经网络、深度学习等等。模型太多都看晕了，这种场景下选什么模型合适？ 随机森林 12345678910111213141516from sklearn.ensemble import RandomForestClassifierX = df[:input_df.shape[0]].values[:, 1::]y = df[:input_df.shape[0]].values[:, 0]X_test = df[input_df.shape[0]:].values[:, 1::]random_forest = RandomForestClassifier(oob_score=True, n_estimators=1000)random_forest.fit(X, y)Y_pred = random_forest.predict(X_test)print random_forest.score(X, y)submission = pd.DataFrame(&#123; &quot;PassengerId&quot;: X_origin[&quot;PassengerId&quot;], &quot;Survived&quot;: Y_pred.astype(int) &#125;)submission.to_csv(&apos;result.csv&apos;, index=False) GBDT 123456789101112131415from sklearn.ensemble import GradientBoostingClassifierX = df[:input_df.shape[0]].values[:, 1::]y = df[:input_df.shape[0]].values[:, 0]X_test = df[input_df.shape[0]:].values[:, 1::]GBDT = GradientBoostingClassifier(n_estimators=1000)GBDT.fit(X, y)Y_pred = GBDT.predict(X_test)print GBDT.score(X, y)submission = pd.DataFrame(&#123; &quot;PassengerId&quot;: X_origin[&quot;PassengerId&quot;], &quot;Survived&quot;: Y_pred.astype(int) &#125;)submission.to_csv(&apos;result2.csv&apos;, index=False) 调优 优化再观察一下数据，看看还有那些特征可以用到，又去Google了一番，整理出三个新特征：称谓、家庭大小、姓。 称谓：不同的称谓意味着不同的社会地位、不同的社会地位的人对人生、事物的理解不同。并且不同的社会地位乘坐逃生舱的概率也不同？可能某一类人的生存概率更高？ 家庭大小：一家七个人的逃生概率大还是一家两个人的逃生概率大呢？人多的家庭会不会更难逃生呢？ 姓：其实姓这个特征是为了辅助家庭这个特征的，同一个姓是一个家庭的概率更大？ 参数调优，Sklean提供了两种方法，GridSearch和RandomizedSearch。在这两种情况下，都可以指定每个参数的取值范围，创建一个字典。将参数字典提供给search方法，它就会执行模型所指定的值的组合。GridSearch会测试参数每一个可能的组合。 而RandomizedSearch需要指定有多少不同的组合要测试，然后随机选择并组合他们。 使用Random Forest, 加上参数max_depth=5 防止模型过拟合，并将n_estimators放到了30000 首先 Error = Bias + Variance，Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。举一个例子，一次打靶实验，目标是为了打到10环，但是实际上只打到了7环，那么这里面的Error就是3。具体分析打到7环的原因，可能有两方面：一是瞄准出了问题，比如实际上射击瞄准的是9环而不是10环；二是枪本身的稳定性有问题，虽然瞄准的是9环，但是只打到了7环。那么在上面一次射击实验中，Bias就是1,反应的是模型期望与真实目标的差距，而在这次试验中，由于Variance所带来的误差就是2，即虽然瞄准的是9环，但由于本身模型缺乏稳定性，造成了实际结果与模型期望之间的差距。 High variance，low bias意味着”overfitting”，模型过拟合导致不能很好的用于新数据。而High bias，low variance意味着”underfitting”，模型欠拟合导致不能很好从样本中学习，很难去预测新数据。Bias与Variance往往是不能兼得的。如果要降低模型的Bias，就一定程度上会提高模型的Variance，反之亦然。 例如，如果模型存在high variance，一个常见的解决方法是给他增加更多的特征。但是这样也会增加bias，这中间的平衡需要仔细考虑。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from sklearn.learning_curve import learning_curvedef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)): &quot;&quot;&quot; Generate a simple plot of the test and traning learning curve. Parameters ---------- estimator : object type that implements the &quot;fit&quot; and &quot;predict&quot; methods An object of that type which is cloned for each validation. title : string Title for the chart. X : array-like, shape (n_samples, n_features) Training vector, where n_samples is the number of samples and n_features is the number of features. y : array-like, shape (n_samples) or (n_samples, n_features), optional Target relative to X for classification or regression; None for unsupervised learning. ylim : tuple, shape (ymin, ymax), optional Defines minimum and maximum yvalues plotted. cv : integer, cross-validation generator, optional If an integer is passed, it is the number of folds (defaults to 3). Specific cross-validation objects can be passed, see sklearn.cross_validation module for the list of possible objects n_jobs : integer, optional Number of jobs to run in parallel (default 1). &quot;&quot;&quot; plt.figure() plt.title(title) if ylim is not None: plt.ylim(*ylim) plt.xlabel(&quot;Training examples&quot;) plt.ylabel(&quot;Score&quot;) train_sizes, train_scores, test_scores = learning_curve( estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes) train_scores_mean = np.mean(train_scores, axis=1) train_scores_std = np.std(train_scores, axis=1) test_scores_mean = np.mean(test_scores, axis=1) test_scores_std = np.std(test_scores, axis=1) plt.grid() plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=&quot;r&quot;) plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=&quot;g&quot;) plt.plot(train_sizes, train_scores_mean, &apos;o-&apos;, color=&quot;r&quot;, label=&quot;Training score&quot;) plt.plot(train_sizes, test_scores_mean, &apos;o-&apos;, color=&quot;g&quot;, label=&quot;Cross-validation score&quot;) plt.legend(loc=&quot;best&quot;) return plttitle = &quot;Learning Curves&quot;plot_learning_curve(RandomForestClassifier(oob_score=True, n_estimators=30000, max_depth=5), title, X, y, ylim=(0.5, 1.01), cv=None, n_jobs=4, train_sizes=[50, 100, 150, 200, 250, 350, 400])plt.show()]]></content>
      <categories>
        <category>kaggle</category>
      </categories>
      <tags>
        <tag>kaggle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分享notebook]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F29%2F%E5%88%86%E4%BA%ABnotebook%2F</url>
    <content type="text"><![CDATA[通过File &gt; Download as &gt; HTML 菜单转换到html文件。 用gists（https://www.dataquest.io/blog/jupyter-notebook-tips-tricks-shortcuts/gist.github.com）或者github分享你的notebook文件。这两个都可以呈现notebook，示例见链接（https://github.com/dataquestio/solutions/blob/master/Mission202Solution.ipynb） 如果你把自己的notebook文件上传到github的仓库，可以使用很便利的Mybinder（http://mybinder.org/）服务，允许另一个人进行半个小时的Jupyter交互连接到你的仓库。 用jupyterhub（https://github.com/jupyterhub/jupyterhub）建立你自己的系统，这样你在组织微型课堂或者工作坊，无暇顾及学生们的机器时就非常便捷了。 将你的notebook存储在像dropbox这样的网站上，然后把链接放在nbviewer（http://nbviewer.jupyter.org/），nbviewer可以呈现任意来源的notebook。 用菜单File &gt; Download as &gt; PDF 保存notebook为PDF文件。如果你选择本方法，我强烈建议你读一读Julius Schulz的文章（http://blog.juliusschulz.de/blog/ultimate-ipython-notebook） 用Pelican从你的notebook创建一篇博客（https://www.dataquest.io/blog/how-to-setup-a-data-science-blog/）。]]></content>
  </entry>
  <entry>
    <title><![CDATA[al之排序]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F26%2Fal%E4%B9%8B%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[第一梯队选择排序 搜索整个列表 找到最小项的位置 如果该位置不是列表的第一个位置 就交换这两个位置的项 因为每次经过一个主循环 都要选择一个要移动的项。 冒泡排序 策略是从列表的开头处开始 并且比较一对数据项 直到移动到列表的末尾 顺序不正确的时候 就交换其位置 插入排序 简单来说 就是我们平时打扑克牌时插入牌的算法 这三种排序算法 都是n的平方的排序算法 第二梯队快速排序 需要先找一个基准点 归并排序（merge_sort） 采用递归 分治]]></content>
  </entry>
  <entry>
    <title><![CDATA[al之查找]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F26%2Fal%E4%B9%8B%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[查找最小值12345678def index_of_min(lyst): minIndex = 0 currentIndex = 1 while currentIndex &lt; len(lyst): if lyst[currentIndex] &lt; lyst[minIndex]: minIndex = currentIndex currentIndex += 1 return minIndex python当中的min函数返回列表中的最小的项 顺序搜索一个列表list类名为 __contains__ 的方法实现了in的运算符操作 有序列表中各种 二分查找的变种 一定需要自己多次手写 比较数据项 __eq__ __lt__ __gt__ __le__ __ge__]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-801]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F25%2Fleetcode-801%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-799]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F25%2Fleetcode-799%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718class Solution &#123;public: double champagneTower(int poured, int query_row, int query_glass) &#123; double result[101][101] = &#123;0.0&#125;; result[0][0] = poured; for (int i = 0; i &lt; 100; i++) &#123; for (int j = 0; j &lt;= i; j++) &#123; if (result[i][j] &gt;= 1) &#123; result[i + 1][j] += (result[i][j] - 1) / 2.0; result[i + 1][j + 1] += (result[i][j] - 1) / 2.0; result[i][j] = 1; &#125; &#125; &#125; return result[query_row][query_glass]; &#125;&#125;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-798]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F25%2Fleetcode-798%2F</url>
    <content type="text"><![CDATA[1234567891011121314class Solution(object): def bestRotation(self, A): &quot;&quot;&quot; :type A: List[int] :rtype: int &quot;&quot;&quot; N = len(A) change = [1] * N for i in xrange(N): change[(i - A[i] + 1) % N] -= 1 for i in xrange(1, N): change[i] += change[i - 1] return change.index(max(change))]]></content>
  </entry>
  <entry>
    <title><![CDATA[leetcode-797]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F25%2Fleetcode-797%2F</url>
    <content type="text"><![CDATA[123456789101112131415class Solution &#123;public: void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; g, vector&lt;vector&lt;int&gt;&gt;&amp; res, vector&lt;int&gt; path, int cur) &#123; path.push_back(cur); if (cur == g.size() - 1) res.push_back(path); else for (auto it: g[cur]) dfs(g, res, path, it); &#125; vector&lt;vector&lt;int&gt;&gt; allPathsSourceTarget(vector&lt;vector&lt;int&gt;&gt;&amp; g) &#123; vector&lt;vector&lt;int&gt;&gt; paths; vector&lt;int&gt; path; dfs(g, paths, path, 0); return paths; &#125;&#125;;]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之dfs]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F24%2Fds%E4%B9%8Bdfs%2F</url>
    <content type="text"><![CDATA[深度优先搜索 更符合计算机的习惯 也就是一般使用栈来处理问题(递归) 123456789101112131415161718class Solution(object): def levelOrder(self, root): if not root: return [] self.result = [] self._dfs(root, 0) return self.result def _dfs(self, node, level): if not node: return if len(self.result) &lt; level + 1: self.result.append([]) self.result[level].append(node.val) self._dfs(node.left, level+1) self._dfs(node.right, level+1)]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之bfs]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F24%2Fds%E4%B9%8Bbfs%2F</url>
    <content type="text"><![CDATA[广度优先搜索 本质上就是队列queue的应用 在写代码的时候 也可以使用双端队列 以leetcode 102题 层次遍历为例子 123456789101112131415161718192021222324class Solution(object): def levelOrder(self, root): if not root: return [] res = [] queue = collections.deque() queue.append(root) # visited = set(root) while queue: level_size = len(queue) current_size = [] for _ in range(level_size): node = queue.popleft() current_level.append(node.val) if node.left: queue.append(node.left) if node.right: queue.append(node.right) res.append(current_level) return res]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-765]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F23%2Fleetcode-765%2F</url>
    <content type="text"><![CDATA[123456789101112131415class Solution(object): def minSwapsCouples(self, row): &quot;&quot;&quot; :type row: List[int] :rtype: int &quot;&quot;&quot; res = 0 for i in xrange(0, len(row), 2): p = row[i] ^ 1 j = row.index(p) if (j-i) &gt; 1: row[i+1], row[j] = row[j], row[i+1] res += 1 return res]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之字典树]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F21%2Fds%E4%B9%8B%E5%AD%97%E5%85%B8%E6%A0%91%2F</url>
    <content type="text"><![CDATA[字典树 字典树的目的其实并非用于存储字符，而是存储每个词语（虽然原理一致），并且支持获取某个词语序列的前后缀及其频率。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122class TrieNode(object): def __init__(self, value=None, count=0, parent=None): # 值 self.value = value # 频数统计 self.count = count # 父结点 self.parent = parent # 子节点，&#123;value:TrieNode&#125; self.children = &#123;&#125;class Trie(object): def __init__(self): # 创建空的根节点 self.root = TrieNode() def insert(self, sequence): """ 基操，插入一个序列 :param sequence: 列表 :return: """ cur_node = self.root for item in sequence: if item not in cur_node.children: # 插入结点 child = TrieNode(value=item, count=1, parent=cur_node) cur_node.children[item] = child cur_node = child else: # 更新结点 cur_node = cur_node.children[item] cur_node.count += 1 def search(self, sequence): """ 基操，查询是否存在完整序列 :param sequence: 列表 :return: """ cur_node = self.root mark = True for item in sequence: if item not in cur_node.children: mark = False break else: cur_node = cur_node.children[item] # 如果还有子结点，说明序列并非完整 if cur_node.children: mark = False return mark def delete(self, sequence): """ 基操，删除序列，准确来说是减少计数 :param sequence: 列表 :return: """ mark = False if self.search(sequence): mark = True cur_node = self.root for item in sequence: cur_node.children[item].count -= 1 if cur_node.children[item].count == 0: cur_node.children.pop(item) break else: cur_node = cur_node.children[item] return mark def search_part(self, sequence, prefix, suffix, start_node=None): """ 递归查找子序列，返回前缀和后缀结点 此处简化操作，仅返回一位前后缀的内容与频数 :param sequence: 列表 :param prefix: 前缀字典，初始传入空字典 :param suffix: 后缀字典，初始传入空字典 :param start_node: 起始结点，用于子树的查询 :return: """ if start_node: cur_node = start_node prefix_node = start_node.parent else: cur_node = self.root prefix_node = self.root mark = True # 必须从第一个结点开始对比 for i in range(len(sequence)): if i == 0: if sequence[i] != cur_node.value: for child_node in cur_node.children.values(): self.search_part(sequence, prefix, suffix, child_node) mark = False break else: if sequence[i] not in cur_node.children: for child_node in cur_node.children.values(): self.search_part(sequence, prefix, suffix, child_node) mark = False break else: cur_node = cur_node.children[sequence[i]] if mark: if prefix_node.value: # 前缀数量取序列词中最后一词的频数 if prefix_node.value in prefix: prefix[prefix_node.value] += cur_node.count else: prefix[prefix_node.value] = cur_node.count for suffix_node in cur_node.children.values(): if suffix_node.value in suffix: suffix[suffix_node.value] += suffix_node.count else: suffix[suffix_node.value] = suffix_node.count # 即使找到一部分还需继续查找子结点 for child_node in cur_node.children.values(): self.search_part(sequence, prefix, suffix, child_node)]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之二叉树]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F21%2Fds%E4%B9%8B%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之哈希表]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F21%2Fds%E4%B9%8B%E5%93%88%E5%B8%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希表 从Python 3.6开始，字典的Key将会保留插入时候的顺序。例如：在Python 3.6和以上的版本中， 1234567&gt;&gt;&gt; a = &#123;&apos;hello&apos;: &apos;world&apos;, &apos;xyz&apos;: &apos;abc&apos;, &apos;163&apos;: &apos;netease&apos;&#125;&gt;&gt;&gt; print(a)&#123;&apos;hello&apos;: &apos;world&apos;, &apos;xyz&apos;: &apos;abc&apos;, &apos;163&apos;: &apos;netease&apos;&#125;&gt;&gt;&gt; keys = list(a.keys())&gt;&gt;&gt; assert keys[0] == &apos;hello&apos;&gt;&gt;&gt; assert keys[1] == &apos;xyz&apos;&gt;&gt;&gt; assert keys[2] == &apos;163&apos; 在Python 3.5或者以下的版本中： 123&gt;&gt;&gt; a = &#123;&apos;hello&apos;: &apos;world&apos;, &apos;xyz&apos;: &apos;abc&apos;, &apos;163&apos;: &apos;netease&apos;&#125;&gt;&gt;&gt; print(a)&#123;&apos;xyz&apos;: &apos;abc&apos;, &apos;hello&apos;: &apos;world&apos;, &apos;163&apos;: &apos;netease&apos;&#125; 需要注意的是，Python 3.6以后的字典，保留的是插入时候的顺序 并不是可以被排序的那种顺序。 哈希冲突解决 开放定址法 链地址法]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之并查集]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F21%2Fds%E4%B9%8B%E5%B9%B6%E6%9F%A5%E9%9B%86%2F</url>
    <content type="text"><![CDATA[六个关系网就能达到全世界 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859// quick_find.javaimport java.io.File;import java.util.Scanner;public class UF &#123; int count; //连通分量数 int[] id; //每个数所属的连通分量 public UF(int N) &#123; //初始化时，N个点有N个分量 count = N; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; //返回连通分量数 public int getCount()&#123; return count; &#125; //查找x所属的连通分量 public int find(int x)&#123; return id[x]; &#125; //连接p,q(将q的分量改为p所在的分量) public void union(int p,int q)&#123; int pID=find(p); int qID=find(q); for(int i=0;i&lt;id.length;i++)&#123; if(find(i)==pID)&#123; id[i]=qID; &#125; &#125; count--; //记得每进行一次连接，分量数减“1” &#125; //判断p,q是否连接，即是否属于同一个分量 public boolean connected(int p,int q)&#123; return find(p)==find(q); &#125; public static void main(String[] args) throws Exception &#123; //数据从外部文件读入，“data.txt”放在项目的根目录下 Scanner input = new Scanner(new File(&quot;data.txt&quot;)); int N=input.nextInt(); UF uf = new UF(N); while(input.hasNext())&#123; int p=input.nextInt(); int q=input.nextInt(); if(uf.connected(p, q)) continue; //若p,q已属于同一连通分量不再连接，则故直接跳过 uf.union(p, q); System.out.println(p+&quot;-&quot;+q); &#125; System.out.println(&quot;总连通分量数：&quot;+uf.getCount()); &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576// quick_union.javaimport java.io.File;import java.util.Scanner;public class UF &#123; int count; //连通分量数 int[] id; //每个数所属的连通分量 public UF(int N) &#123; //初始化时，N个点有N个分量 count = N; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; //返回连通分量数 public int getCount()&#123; return count; &#125; //查找x所属的连通分量 public int find(int x)&#123; while(x!=id[x]) x = id[x]; //若找不到，则一直往根root回溯 return x; &#125; //连接p,q(将q的分量改为p所在的分量) public void union(int p,int q)&#123; int pID=find(p); int qID=find(q); if(pID==qID) return ; id[qID]=pID; count--; &#125; /* //查找x所属的连通分量 public int find(int x)&#123; return id[x]; &#125; //连接p,q(将q的分量改为p所在的分量) public void union(int p,int q)&#123; int pID=find(p); int qID=find(q); if(pID==qID) return ; for(int i=0;i&lt;id.length;i++)&#123; if(find(i)==pID)&#123; id[i]=qID; &#125; &#125; count--; //记得每进行一次连接，分量数减“1” &#125; */ //判断p,q是否连接，即是否属于同一个分量 public boolean connected(int p,int q)&#123; return find(p)==find(q); &#125; public static void main(String[] args) throws Exception &#123; //数据从外部文件读入，“data.txt”放在项目的根目录下 Scanner input = new Scanner(new File(&quot;data.txt&quot;)); int N=input.nextInt(); UF uf = new UF(N); while(input.hasNext())&#123; int p=input.nextInt(); int q=input.nextInt(); if(uf.connected(p, q)) continue; //若p,q已属于同一连通分量不再连接，则故直接跳过 uf.union(p, q); System.out.println(p+&quot;-&quot;+q); &#125; System.out.println(&quot;总连通分量数：&quot;+uf.getCount()); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// weighted_uf.javaimport java.io.File;import java.util.Scanner;public class UF &#123; int count; // 连通分量数 int[] id; // 每个数所属的连通分量 int[] sz; public UF(int N) &#123; // 初始化时，N个点有N个分量 count = N; sz = new int[N]; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; for (int i = 0; i &lt; N; i++) sz[i] = 1; &#125; // 返回连通分量数 public int getCount() &#123; return count; &#125; // 查找x所属的连通分量 public int find(int x) &#123; while (x != id[x]) x = id[x]; // 若找不到，则一直往根root回溯 return x; &#125; // 连接p,q(将q的分量改为p所在的分量) public void union(int p, int q) &#123; int pID = find(p); int qID = find(q); if (pID == qID) return; if (sz[p] &lt; sz[q]) &#123; //通过结点数量，判断树的大小并将小树并到大树下 id[p] = qID; sz[q] += sz[p]; &#125; else &#123; id[q] = pID; sz[p] += sz[q]; &#125; count--; &#125; /* * //查找x所属的连通分量 public int find(int x)&#123; return id[x]; &#125; * * //连接p,q(将q的分量改为p所在的分量) public void union(int p,int q)&#123; int pID=find(p); * int qID=find(q); if(pID==qID) return ; for(int i=0;i&lt;id.length;i++)&#123; * if(find(i)==pID)&#123; id[i]=qID; &#125; &#125; count--; //记得每进行一次连接，分量数减“1” &#125; */ // 判断p,q是否连接，即是否属于同一个分量 public boolean connected(int p, int q) &#123; return find(p) == find(q); &#125; public static void main(String[] args) throws Exception &#123; // 数据从外部文件读入，“data.txt”放在项目的根目录下 Scanner input = new Scanner(new File(&quot;data.txt&quot;)); int N = input.nextInt(); UF uf = new UF(N); while (input.hasNext()) &#123; int p = input.nextInt(); int q = input.nextInt(); if (uf.connected(p, q)) continue; // 若p,q已属于同一连通分量不再连接，则故直接跳过 uf.union(p, q); System.out.println(p + &quot;-&quot; + q); &#125; System.out.println(&quot;总连通分量数：&quot; + uf.getCount()); &#125;&#125; 网络通信（比如：是否需要在通信点p,q建立通信连接） 媒体社交（比如：向通一个社交圈的朋友推荐商品） 数学集合（比如：判断元素p,q之后选择是否进行集合合并） 六度分隔理论，该理论认为世界上任何互不相识的两人，只需要很少的中间人就能够建立起联系。 哈佛大学心理学教授斯坦利·米尔格拉姆于1967年根据这个概念做过一次连锁信实验，尝试证明平均只需要6步就可以联系任何两个互不相识的美国人。]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-714]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F19%2Fleetcode-714%2F</url>
    <content type="text"><![CDATA[leetcode 含有手续费的买卖股票时机 12345678910111213141516171819class Solution(object): def maxProfit(self, prices, fee): """ :type prices: List[int] :type fee: int :rtype: int """ n = len(prices) if n &lt; 2: return 0 ans, minimum = 0, prices[0] for i in xrange(1, n): if prices[i] &lt; minimum: minimum = prices[i] elif prices[i] &gt; minimum + fee: ans += prices[i] - fee - minimum minimum = prices[i] - fee return ans]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[py连接mysql的条条大路]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F19%2Fpy%E8%BF%9E%E6%8E%A5mysql%E7%9A%84%E6%9D%A1%E6%9D%A1%E5%A4%A7%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[1.mysqldb最古老的 c api开发 2.mysqlclient也不支持asyncio 3.pymysql 纯python开发的mysql连接库 4.aiomysql 需要异步访问数据库时 就可以使用此库 5.mysql-connector-python 建议使用3和4]]></content>
  </entry>
  <entry>
    <title><![CDATA[dl之15种回归]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Fdl%E4%B9%8B15%E7%A7%8D%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[es6总结]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Fes6%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1.变量声明let和const我们都是知道在ES6以前，var关键字声明变量。无论声明在何处，都会被视为声明在函数的最顶部(不在函数内即在全局作用域的最顶部)。这就是函数变量提升例如: 1234567function aa() &#123; if(bool) &#123; var test = &apos;hello man&apos; &#125; else &#123; console.log(test) &#125; &#125; 现在的情况下 则是我们通常用let和const来声明，let表示变量、const表示常量。let和const都是块级作用域。怎么理解这个块级作用域？ 在一个函数内部在一个代码块内部 12345678function aa() &#123; if(bool) &#123; let test = &apos;hello man&apos; &#125; else &#123; //test 在此处访问不到 console.log(test) &#125; &#125; let的作用域是在它所在当前代码块，但不会被提升到当前函数的最顶部。 2.模版字符串 123456789101112131415161718192021222324const name = &apos;lux&apos;console.log(`hello $&#123;name&#125;`) //hello lux 基本的字符串格式化。将表达式嵌入字符串中进行拼接。用$&#123;&#125;来界定。多行字符串或者字符串一行行拼接。ES6反引号(``)直接搞定。// es5var msg = &quot;Hi \man!&quot;// es6const template = `&lt;div&gt; &lt;span&gt;hello world&lt;/span&gt;&lt;/div&gt;` // es5var msg = &quot;Hi \man!&quot;// es6const template = `&lt;div&gt; &lt;span&gt;hello world&lt;/span&gt;&lt;/div&gt;` 3.函数 为函数提供默认值 123456function action(num = 200) &#123; console.log(num) &#125; action() //200action(300) //300 箭头函数 箭头函数最直观的三个特点。 不需要function关键字来创建函数省略return关键字继承当前上下文的 this 关键字 4.拓展的对象功能 键值对简写 省掉function关键字 5.更方便的数据访问 解构 6.展开运算符 12345678910111213const number = [1,2,3,4,5] const [first, ...rest] = number console.log(rest) //2,3,4,5 //对象 const user = &#123; username: &apos;lux&apos;, gender: &apos;female&apos;, age: 19, address: &apos;peking&apos; &#125; const &#123; username, ...rest &#125; = user console.log(rest) //&#123;&quot;address&quot;: &quot;peking&quot;, &quot;age&quot;: 19, &quot;gender&quot;: &quot;female&quot;&#125; 7.import export 1234567891.当用export default people导出时，就用 import people 导入（不带大括号）2.一个文件里，有且只能有一个export default。但可以有多个export。3.当用export name 时，就用import &#123; name &#125;导入（记得带上大括号）4.当一个文件里，既有一个export default people, 又有多个export name 或者 export age时，导入就用 import people, &#123; name, age &#125; 5.当一个文件里出现n多个 export 导出很多模块，导入时除了一个一个导入，也可以用import * as example 8.promise 在promise之前代码过多的回调或者嵌套，可读性差、耦合度高、扩展性低。通过Promise机制，扁平化的代码机构，大大提高了代码可读性；用同步编程的方式来编写异步代码，保存线性的代码逻辑，极大的降低了代码耦合性而提高了程序的可扩展性。 12345678910111213setTimeout(function() &#123; console.log(1)&#125;, 0);new Promise(function executor(resolve) &#123; console.log(2); for( var i=0 ; i&lt;10000 ; i++ ) &#123; i == 9999 &amp;&amp; resolve(); &#125; console.log(3);&#125;).then(function() &#123; console.log(4);&#125;);console.log(5); 首先先碰到一个 setTimeout，于是会先设置一个定时，在定时结束后将传递这个函数放到任务队列里面，因此开始肯定不会输出 1 。 然后是一个 Promise，里面的函数是直接执行的，因此应该直接输出 2 3 。 然后，Promise 的 then 应当会放到当前 tick 的最后，但是还是在当前 tick 中。 因此，应当先输出 5，然后再输出 4 。 最后在到下一个 tick，就是 1 。 “2 3 5 4 1” 9.迭代器 生成器（ generator）是能返回一个迭代器的函数。生成器函数也是一种函数，最直观的表现就是比普通的function多了个星号*，在其函数体内可以使用yield关键字,有意思的是函数会在每个yield后暂停。 这里生活中有一个比较形象的例子。咱们到银行办理业务时候都得向大厅的机器取一张排队号。你拿到你的排队号，机器并不会自动为你再出下一张票。也就是说取票机“暂停”住了，直到下一个人再次唤起才会继续吐票。 OK。说说迭代器。当你调用一个generator时，它将返回一个迭代器对象。这个迭代器对象拥有一个叫做next的方法来帮助你重启generator函数并得到下一个值。next方法不仅返回值，它返回的对象具有两个属性：done和value。value是你获得的值，done用来表明你的generator是否已经停止提供值。继续用刚刚取票的例子，每张排队号就是这里的value，打印票的纸是否用完就这是这里的done。]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之堆]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Fds%E4%B9%8B%E5%A0%86%2F</url>
    <content type="text"><![CDATA[堆 为什么堆排序没有快速排序快？ 堆排序是一种原地的、时间复杂度为O(nlogn)的排序算法 堆是一棵完全二叉树 堆中每一个节点的值都必须大于等于（或者小于等于）其子树中每个节点的值 如何实现一个堆？以大顶堆为例子 完全二叉树比较适合用数组来存储。用数组存储非常节省存储空间，单纯通过数组下标就可以找到一个节点的左右子节点和父节点。 堆的插入数据 12345678910111213141516171819202122public class Heap &#123; private int[] a; // 数组，从下标 1 开始存储数据 private int n; // 堆可以存储的最大数据个数 private int count; // 堆中已经存储的数据个数 public Heap(int capacity) &#123; a = new int[capacity + 1]; n = capacity; count = 0; &#125; public void insert(int data) &#123; if (count &gt;= n) return; // 堆满了 ++count; a[count] = data; int i = count; while (i/2 &gt; 0 &amp;&amp; a[i] &gt; a[i/2]) &#123; // 自下往上堆化 swap(a, i, i/2); // swap() 函数作用：交换下标为 i 和 i/2 的两个元素 i = i/2; &#125; &#125; &#125; 删除堆顶元素 123456789101112131415161718public void removeMax() &#123; if (count == 0) return -1; // 堆中没有数据 a[1] = a[count]; --count; heapify(a, count, 1);&#125;private void heapify(int[] a, int n, int i) &#123; // 自上往下堆化 while (true) &#123; int maxPos = i; if (i*2 &lt;= n &amp;&amp; a[i] &lt; a[i*2]) maxPos = i*2; if (i*2+1 &lt;= n &amp;&amp; a[maxPos] &lt; a[i*2+1]) maxPos = i*2+1; if (maxPos == i) break; swap(a, i, maxPos); i = maxPos; &#125;&#125; 建堆 1234567891011121314151617private static void buildHeap(int[] a, int n) &#123; for (int i = n/2; i &gt;= 1; --i) &#123; heapify(a, n, i); &#125;&#125;private static void heapify(int[] a, int n, int i) &#123; while (true) &#123; int maxPos = i; if (i*2 &lt;= n &amp;&amp; a[i] &lt; a[i*2]) maxPos = i*2; if (i*2+1 &lt;= n &amp;&amp; a[maxPos] &lt; a[i*2+1]) maxPos = i*2+1; if (maxPos == i) break; swap(a, i, maxPos); i = maxPos; &#125;&#125; 堆排序 1234567891011// n 表示数据的个数，数组 a 中的数据从下标 1 到 n 的位置。public static void sort(int[] a, int n) &#123; buildHeap(a, n); int k = n; while (k &gt; 1) &#123; swap(a, 1, k); --k; heapify(a, k, 1); &#125;&#125; 堆排序数据访问的方式没有快速排序友好。 快速排序 数据是顺序访问的 对于堆来说 数据是跳着访问的 对于同样的数据 排序过程中 堆排序算法的数据交换次数要多于快速排序。]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之队列]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Fds%E4%B9%8B%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[python当中的队列 源码在 Lib/queue.py 提供三种队列 Queue（普通先进先出队列） LifoQueue（后进先出队列） PriorityQueue（优先级队列） 提供封装的方法为 qsize empty full put put_nowait get get_nowait task_done join 这里着重说一下join() 阻塞调用线程，直到队列中的所有任务被处理掉。 只要有数据被加入队列，未完成的任务数就会增加。当消费者线程调用task_done()以指示该项目已检索并且其上的所有工作都已完成时，计数将减少。当未完成的任务数降到0，join()解除阻塞。 示例如下： 1234567891011121314151617181920212223242526def worker(): while True: item = q.get() if item is None: break do_work(item) q.task_done()q = queue.Queue()threads = []for i in range(num_worker_threads): t = threading.Thread(target=worker) t.start() threads.append(t)for item in source(): q.put(item)# block until all tasks are doneq.join()# stop workersfor i in range(num_worker_threads): q.put(None)for t in threads: t.join()]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之栈]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Fds%E4%B9%8B%E6%A0%88%2F</url>
    <content type="text"><![CDATA[一般而言 很多数据结构 都可以使用数组实现（也就是顺序表） 也可以使用链表实现 py里找一圈你可能没有看到栈的实现 是因为可以直接使用list实现栈 简单！！！ 123456789101112131415161718192021222324class Stack(object): # 初始化栈为空列表 def __init__(self): self.items = [] # 判断栈是否为空，返回布尔值 def is_empty(self): return self.items == [] # 返回栈顶元素 def peek(self): return self.items[len(self.items) - 1] # 返回栈的大小 def size(self): return len(self.items) # 把新的元素堆进栈里面（程序员喜欢把这个过程叫做压栈，入栈，进栈……） def push(self, item): self.items.append(item) # 把栈顶元素丢出去（程序员喜欢把这个过程叫做出栈……） def pop(self, item): return self.items.pop()]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[taskflow详细4]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Ftaskflow%E8%AF%A6%E7%BB%864%2F</url>
    <content type="text"></content>
      <categories>
        <category>compute</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[taskflow详细3]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Ftaskflow%E8%AF%A6%E7%BB%863%2F</url>
    <content type="text"></content>
      <categories>
        <category>compute</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[taskflow详细2]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Ftaskflow%E8%AF%A6%E7%BB%862%2F</url>
    <content type="text"><![CDATA[Engine的必要初始化参数一个是flow,一个就是backends,backends对应的是storage使用何种后端存储,我简化后的代码storage只支持sqlalchemy,所以不直接传入sqlalchemy的session即可,另外一个参数就是我们马上要说的flow Engine是通过flow来找到需要执行的task的,所以,我们的task都是add到flow的 12345678910111213from simpleflow.patterns import graph_flow as gfclass Adder(task.Task): def execute(self, x, y): print &apos;do!!!&apos;, x, y return x + ygflow = gf.Flow(&apos;root&apos;)gflow.add(Adder(name=&apos;atask&apos;))gflow2 = gf.Flow(&apos;leaf&apos;)gflow.add(gflow2) 当然flow的add参数可以是task,还可以flow. flow的代码比较复杂,关键属性_graph就是networkx的图了,不建议现在读代码,粗读一部分,稍微看一下对应的图和关键变量是什么就好和add部分就好。 flow一共有三种,使用到有向图和无向图,当flow调用add添加的task/flow的时候,就是在图中增加节点,对于有向图,添加节点后自动增加边 这里我就直接用我已经砍掉backends层的代码来说明了,我们来看storage里用到的几个对象（taskflow在persistence包,也就持久化包里,我的代码都集中到storage包里了） Connection taskflow中,Connection上面还套了一层backends,backends就一个函数get_connection用于返回Connection实例, 因为原来代码可以支持文件、内存等接口,所以有这么一层Connection用于存放通用方法,具体有什么方法可以直接看代码我这里就不描述了,方法的名字很明确的描述了方法的作用 models中LogBook,FlowDetail,AtomDetail 原taskflow的models我改为了middleware,这里的models对应的是tables这样改是为了统一orm框架写法,orm框架中都在models里放表结构所以这里的这3个对象对应了三张表LogBook：一次工作流有且只有一个LogBook,其实条记录用处不大,主要用来识别一次工作流,由于外键关系,删除一条logbook将会删除对应的其他表的记录,工作流正常结束后是可以删除相关记录的FlowDetail：一次工作流只能接收一个flow,虽然前面我们flow中可以添加flow,但是并不会生成FlowDetail记录,顶层flow直接会获取下层flow的具体atomAtomDetail: task和retry都是继承自atom,所以AtomDetail的的每一行就对应一个task或retry(retry后面单独说),还有之前说的用于传输初始参数的_TaskFlow_INJECTORD middleware middleware里的LogBook,FlowDetail,AtomDetail就是models里表的dict版增加了一些方法,TaskDetail/RetryDetail自然也是继承了AtomDetail,它们都是存到AtomDetail里,为什么要拆两份而不统一起来呢？一个原因是原taskflow了因为要支持各种backends,所以分了一层出来。还有一个原因是在没有写入（task初始化,返回,取消,报错）的的情况下,图的相关动作都在内存中进行,直接用orm的对象太过笨重,middleware中的对应对象就轻量很多 现在我们来看Storage类了 我们看看engine里对Storage的初始化 1234567891011@misc.cachedpropertydef storage(self): def _scope_fetcher(atom_name): if self._compiled: return self._runtime.fetch_scopes_for(atom_name) else: return None return storage.Storage(self._flow_detail, connection=self.connection, scope_fetcher=_scope_fetcher)]]></content>
      <categories>
        <category>compute</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[taskflow详细1]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F10%2Ftaskflow%E8%AF%A6%E7%BB%861%2F</url>
    <content type="text"><![CDATA[taskflow,需要先熟悉两个最基本的概念 工作流 这玩意最直观的一个应用就是oa里审批,上面我们说的游戏业的常见操作也可以作为例子 停服 备份数据库 升级数据库 升级应用 启动服务器 上述操作也是一个工作流, 停服成功才能备份,备份成功才能升级， 升级应用和备份可以同时进行,升级数据库和升级应用都成功了才能启动服务器. 升级失败还要自动回滚. 有限状态机 推举导读. 工作流就是用状态机来实现流程控制和执行任务的 上面两条光看懂了还不行,还要写过一轮深入了解,taskflow使用了openstack的通用状态机项目,所以要能看taskflow先要熟悉openstack的通用状态机项目Automaton 为了熟悉Automaton,我用它写了一个tailfile,作用就是实现tail -f的效果,倒读N行和判断文件是否变化都用到状态机,因为状态和事件都比较少,用Automaton写这些功能有点杀鸡用牛刀,写这个项目的主要目的是用来熟悉状态机. 熟悉完Automaton以后,可以开始来看taskflow(基于最新版本2.14)了。 首先,因为taskflow作为通用项目而不是openstack内部项目,所以taskflow没有使用oslo中的一些通用工具 而且里面同样为了兼容写了一些复杂的接口还用了futurist实现异步,我为了和自己的其他几个项目统一起来并并,基于taskflow2.14生成了一个简化过的项目simpleflow 代码变化了几个如下部分 日志用回oslo_log的方式删除了sqlalchemy以外的存储方式,table的和所有sql expression都改为orm方式（只支持mysql）,后来我熟悉taskflow以后发现删除其他backends只保留mysql不是一个正确做法,有缺陷,后续会说明为什么因为删除了sqlalchemy以外的存储方式, 所以persitence中backends就么有存在的必要了,直接传sqlalchemy的session即可persitence中的内容和storage合并jobs和conductors删除,这个部分可以和主要的taskflow功能无关Executor不使用futurist,自己写了一个简化的futurist,代码兼容原来的写法,只支持协程,删除多线程和多进程相关支持读写锁业复制了过来,用协程实现砍掉了worker based的Engine因为极大的简化了futurist和删掉了backends层所以比较好读一些,读代码的时候建议看我简化后的项目 我们先来看taskflow的几个主要单位 Engine Engine是taskflow是启动口, 主要工作 1.创建状态机, 2.循环状态机, 3.在指定状态下通过Executor执行任务, 4.其他接口（存储、调度器等）的初始化 Engine分为好几种. work based的Engine比较特殊我们不看,只看action engine 其实几种action engine其实没有什么区别,通过Executor分为 序列化（阻塞,顺序执行）引擎基于线程的并行引擎基于协程的并行引擎基于多进程的并行引擎并行引擎的优势是,当个任务没有顺序关联的情况下可以同时执行多个任务 当然,引擎不影响任务之间的顺序关系,除非你想强制一个一个任务执行,否则都应该使用并行引擎 我自己的代码里简化以后只剩下序列化引擎和协程引擎,Executor是什么看下面 Executor 前面说了,Engine会通过Executor执行任务,因为如果Engine直接执行任务的话,整个状态机的循环会受到正在执行的任务的影响,所以包了一层Executor来执行具体的任务(当然具体代码里对Executor的应用会更复杂一点,为了扩展和异常处理包了3层) 在taskflow的源代码中Executor是通过futurist库来实现的,而futurist又是基于futures的,这个库内部实现还是比较复杂的,如果没用过对应库的,建议直接参考我简化的futurist,因为是用eventlet实现的,所以需要熟悉eventlet. 具体的任务代码（比如备份数据库什么的）在一般情况下可以不处理异常,因为执行任务的代码通过except Exception捕获了任务的所有异常. 特殊异常就是CancelledError,这个异常是调度到已经取消任务时由futurist抛出,在读代码的时候需注意下这个的特殊处理 Scheduler 这个没什么好说的,Executor的封装的最上层,最后执行会落实到具体的Executor上 Storage 这个是存储接口,后面说到flow的时候会详细讲到,Storage的初始化在Engine中,一个功能是数据存储的接口,一个功能是作为flow的外层封装 Runtime与machine 在看这个之前,如果你还不熟悉状态机,建议先拿前面说的automaton练练手,如果已经熟悉状态机但是还没看过automaton代码的，建议去看看automaton的代码 machine就是Engine中循环的(automaton)状态机了,一个engine只运行一个状态机,初始化代码在builder.MachineBuilder,MachineBuilder又是在Runtime中调用生成machine的,我们先别管Runtime,先理解一下taskflow的状态机 taskflow状态机并不复杂,但还不熟悉taskflow的时候很容易被搞懵.因为taskflow用到networkx这个图库,而状态机其实就是一个图,所以一开始看的时候,很容易以为taskflow的状态机会非常复杂要看懂图的相关代码才能搞明白,但实际情况是 taskflow的状态机和图无关!因为taskflow状态机的状态很少不需要用图来解决 那么taskflow为什么要用到图库呢,在解决这个疑问前我们先抛开taskflow,自己用状态机设计一个解决前面——”停服 备份数据库 升级数据库 升级应用 启动服务器” 的工作流 首先定义停服状态和对应停服状态执行的代码定义停服成功的返回,失败的返回,定义进入停服状态的event（这个是起始时间,event就是start）定义备份数据库状态对应备份执行代码定义进入备份状态的event（前面的停服成功）定义备份成功和备份失败的返回,到目前还简单,备份失败大不了多备份几次直到成功,失败了整个状态机终止都可以影响不大定义升级数据库状态对应备份执行代码定义进入升级状态的event（前面的备份成功）定义升级成功和备份失败的返回,这里开始坑了,升级失败要回滚了发现少了回滚升级失败的状态定义…..增加升级失败回滚失败的定义 …… 回滚升级数据库失败….升级应用是失败…回滚升级应用是失败…..启动失败设计下来你发现没几个步骤。要定义的状态就越来越多…这也就是状态机复杂以后和图有关的原因了 taskflow非常巧妙的避免了复杂化状态机,taskflow的设计的状态机可以简单的理解只处理2个状态就好 开始….找到任务-执行任务-找到任务….执行任务…终止 执行任务就是调用Executor, 至于找下一个任务的工作,就是封装了图库的flow的工作了.这样设计状态机状态就很少,具体的状态可以看MachineBuilder的注释中有对应表格,对应状态目前粗看一下即可,知道哪个状态是找任务、哪个状态执行任务就可,有些状态涉要看了后面的retry相关才比较好理解,至于flow,这个我们在后面说明 回头来看Runtime,MachineBuilder是由Runtime生成的,状态机的有些callback最终执行的Runtime中的函数,里面会有一些嵌套和封装, Scheduler的封装就在Runtime中,Runtime可以简单理解为状态机调用其它诸如Scheduler,storage等接口的中间件,Runtime在整体理解taskflow的的时候可以不用细看]]></content>
      <categories>
        <category>compute</category>
      </categories>
      <tags>
        <tag>openstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之链表]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F09%2Fds%E4%B9%8B%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[链表对比一下数组 链表这块的话 不需要一块连续的存储空间 只需要“指针”把一组零散的内存块串联起来使用，有效利用了空间 常见的有三种： 单链表、双链表、循环链表 内存块称之为链表的“结点”，为了将所有的节点串联起来，每个链表的节点除了存储数据之外，还需要记录链表的下一个节点的地址，这个记录下个节点地址的指针叫做后继指针next。 双链表节点 还有前驱指针prev 在链表中插入和删除 不需要为了保持内存的连续性而搬移结点，因此插入和删除比较高效。 循环链表是一种特殊的链表 区别在于尾结点 单链表的尾结点指向空地址，而循环链表尾结点指向链表的头结点。像一个环一样首尾相连。 优点在于从链表尾到链表头比较方便，比如约瑟夫问题，使用循环链表就非常方便。 虽然双向链表比较浪费存储空间，但是也带来了 双向的灵活性 java当中的LinkedHashMap这个容器就使用了双链表这种数据结构 为什么使用这个？ 一个原因就是使用 空间换时间！！ 在内存空间充足的时候，我们使用空间换时间；内存如果比较紧缺的话，我们就用时间换空间。 缓存本质就是使用空间换时间的设计思想，数据存储在硬盘，比较节省内存。但是查找不是很方便，可以通过缓存的技术，事先将数据加载在内存中，这样虽然比较耗费内存空间，但是每次数据查询的速度就大大提升了。 数组使用连续内存 借助cpu的缓存机制 预读数组中的数据 访问效率更高。数组缺点是大小固定，容易内存不足。 链表中的结点在被频繁插入、删除的操作情况下 容易造成内存碎片，使用java会导致频繁的gc。]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之数组]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F09%2Fds%E4%B9%8B%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[为什么数组从零开始数组是一种线性表数据结构 连续的内存空间来存储一组具有相同类型的数据 数组支持随机访问 根据下标随机访问的时间复杂度为1 适合查找 插入和删除这两个操作比较低效 避免数据搬移 可以先记录下已经删除的数据 每次的删除并不是真正地搬移数据 只是记录数据已经被删除 当数组没有更多空间存储数据时 再触发执行一次真正的删除操作 这样就大大减少了删除操作导致的数据迁移 警惕数组越界的问题 在c语言当中 只要不是访问受限的内存 所有的内存空间都是可以自由访问的 根据数组寻址公式 会定位到某个不属于数组的内存地址上 导致代码的无限循环 访问数组的本质就是访问一段连续内存 只要数组通过偏移计算得到的内存地址是可用的 那么程序有可能不会报任何错误 计算机病毒很多也是利用数组越界访问非法地址的漏洞 来攻击系统 一定要警惕数组越界 c语言当中数组越界检查的工作是給程序员来做的 java则是本身会做越界检查 java提供了容器类 ArrayList 最大的优势是将很多数组的操作封装起来 支持动态扩容 作为高级语言编程者，是不是数组就无用武之地了呢？当然不是 1.Java ArrayList 无法存储基本类型，比如 int long 需要进行封装2.数据大小事先已知 并且操作简单 可以直接使用数组3.多维数组情况下 数组更加直观比如 Object[][] array 业务开发情况下 直接使用容器即可 省时省力 做非常底层的开发 性能的优化做到极致 数组优于容器 下标其实是偏移 从1开始计数 每次随机访问元素都需要多一次减法操作 效率优化做到极致？ 主要还是历史原因 c语言设计值用0开始计数数组下标。 无论是java js等都是进行模仿 python支持负数下标。 顺便复习学习一下java语言 google家的规范是 2个空格作为缩进！！！ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package array;/** * 1) 数组的插入、删除、按照下标随机访问操作； * 2）数组中的数据是int类型的； * */public class ArrayOperate &#123; //定义整型数据data保存数据 public int data[]; //定义数组长度 private int n; //定义中实际个数 private int count; //构造方法，定义数组大小 public ArrayOperate(int capacity)&#123; this.data = new int[capacity]; this.n = capacity; this.count=0;//一开始一个数都没有存所以为0 &#125; //根据索引，找到数据中的元素并返回 public int find(int index)&#123; if (index&lt;0 || index&gt;=count) return -1; return data[index]; &#125; //插入元素:头部插入，尾部插入 public boolean insert(int index, int value)&#123; //数组中无元素 //if (index == count &amp;&amp; count == 0) &#123; // data[index] = value; // ++count; // return true; //&#125; // 数组空间已满 if (count == n) &#123; System.out.println("没有可插入的位置"); return false; &#125; // 如果count还没满，那么就可以插入数据到数组中 // 位置不合法 if (index &lt; 0||index &gt; count ) &#123; System.out.println("位置不合法"); return false; &#125; // 位置合法 for( int i = count; i &gt; index; --i)&#123; data[i] = data[i - 1]; &#125; data[index] = value; ++count; return true; &#125; //根据索引，删除数组中元素 public boolean delete(int index)&#123; if (index&lt;0 || index &gt;=count) return false; //从删除位置开始，将后面的元素向前移动一位 for (int i=index+1; i&lt;count; ++i)&#123; data[i-1] = data[i]; &#125; //删除数组末尾元素 这段代码不需要也可以 /*int[] arr = new int[count-1]; for (int i=0; i&lt;count-1;i++)&#123; arr[i] = data[i]; &#125; this.data = arr;*/ --count; return true; &#125; public void printAll() &#123; for (int i = 0; i &lt; count; ++i) &#123; System.out.print(data[i] + " "); &#125; System.out.println(); &#125; public static void main(String[] args) &#123; ArrayOperate array = new ArrayOperate(5); array.printAll(); array.insert(0, 3); array.insert(0, 4); array.insert(1, 5); array.insert(3, 9); array.insert(3, 10); //array.insert(3, 11); array.printAll(); &#125;&#125;]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之动态规划]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[编辑距离 123456789101112131415161718192021222324252627282930313233343536def get_str_distance(a, b): &quot;&quot;&quot; 使用状态转移方程，计算两个字符串之间的编辑距离 :param a: 第一个字符串 :param b: 第二个字符串 :return: 两者之间的编辑距离 &quot;&quot;&quot; if a is None or b is None: return -1 # 初始化 用于记录状态转移的二维表 , d 中 0 下标位置对应表示空串 d = [[0 for j in range(len(b) + 1)] for i in range(len(a) + 1)] # 如果 i 为 0 ，且 j 大于等于 0 ，那么 d[i][j] 为 j d[0][:] = [j for j in range(len(b) + 1)] # 如果 i 大于等于 0 ，且 j 为 0 ，那么 d[i][j] 为 i for i in range(len(a) + 1): d[i][0] = i # 实现状态转移方程 # 注意，代码里的状态转移是从 d[i][j] 到 d[i+1][j+1] ，而不是从 d[i-1][j-1] 到 d[i][j]，本质上是一样的 for i in range(len(a)): for j in range(len(b)): r = 0 if a[i] != b[j]: r = 1 first_append = d[i][j+1] + 1 second_append = d[i+1][j] + 1 replace = d[i][j] + r min_d = min(first_append, second_append, replace) d[i+1][j+1] = min_d return d[len(a)][len(b)]if __name__ == &quot;__main__&quot;: print(get_str_distance(&quot;mouse&quot;, &quot;mouuuse&quot;))]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之组合]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E7%BB%84%E5%90%88%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之排列]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%8E%92%E5%88%97%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之递归]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E9%80%92%E5%BD%92%2F</url>
    <content type="text"><![CDATA[递归自顶向下 自底向上两种递归 一般情况下 自底向上 也就是说从结果往上推一步 这种更符合计算机的思维习惯 求八可以分解为哪几个树 1最多只能出现一次 # coding=utf-8 import copy def get_all_prod_factors(n, result=None): &quot;&quot;&quot; 使用递归编程，为给定的整数 n 找到所有可能的分解 :param n: 整数 :param result: 保存当前的分解 :return: None &quot;&quot;&quot; if result is None: result = [] if n == 1: print(&apos;x&apos;.join([str(_) for _ in result])) if 1 not in result: result.append(1) print(&apos;x&apos;.join([str(_) for _ in result])) elif n &lt; 0: return else: for i in range(1, n + 1): if (i == 1 and i not in result) or (i != 1 and n % i == 0): new_result = copy.copy(result) new_result.append(i) get_all_prod_factors(n // i, new_result) # python3 // 表示整除，不带小数 if __name__ == &apos;__main__&apos;: num = 8 get_all_prod_factors(num)]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之数学归纳法]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%95%B0%E5%AD%A6%E5%BD%92%E7%BA%B3%E6%B3%95%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之迭代法]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E8%BF%AD%E4%BB%A3%E6%B3%95%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之余数]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E4%BD%99%E6%95%B0%2F</url>
    <content type="text"></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员的数学之二进制]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E4%BA%8C%E8%BF%9B%E5%88%B6%2F</url>
    <content type="text"><![CDATA[吴军先生在数学之美当中 也介绍了二进制 原始时代 用路边的小石子计数。 后来罗马人发明了罗马数字 公元三世纪左右，印度的数学家发明了阿拉伯数字 可以从0-9 二进制 就是2的n次方的形式。 计算机为什么使用二进制 因为 组成计算机系统的逻辑电路只有两个状态 即开关的接通与断开。 系统在受到一定程度的干扰时，仍然能够可靠地分辨出数字是”0”还是”1”。 在具体的系统实现当中，二进制数据表达具有抗干扰能力强、可靠性高的优点。 二进制也非常适合逻辑运算。 位运算 左移 其实就是将数字翻倍 右移 其实就是将数字除以2并求整数商 java当中的左移 是 &lt;&lt; 逻辑右移 是 &gt;&gt;&gt; &gt;&gt;是算术右移]]></content>
      <categories>
        <category>math</category>
      </categories>
      <tags>
        <tag>math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拓扑排序]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F05%2F%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[20190102]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F02%2F20190102%2F</url>
    <content type="text"><![CDATA[欲做精金美玉的人品，定从烈火中锻来； 思立掀天揭地的事功，须向薄冰上履过。 一念错，便觉百行皆非，防之当如渡海浮囊，勿容一针之罅漏； 万善全，始得一生无愧。修之当如凌云宝树，须假众木以撑持。]]></content>
      <categories>
        <category>life</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ds之树]]></title>
    <url>%2Fzhangdavids.github.io%2F2019%2F01%2F02%2Fds%E4%B9%8B%E6%A0%91%2F</url>
    <content type="text"><![CDATA[数据结构的树 题目给予一个二叉树的根节点，验证该树是否是二叉树搜索树，在O(n)时间内。 分析与解答二叉搜索树是一种特殊的二叉树 它满足如下的条件： 结点的左子树所有结点的值都小于等于该结点的值。 结点的右子树所有结点的值都大于该结点的值。 结点的左右子树同样都必须是二叉搜索树。 也就是说 任何一个节点的key值都比它左子树上的节点的key值要大，但是比它右子树上的key值要小。 节点查找、插入、删除等操作的时间复杂度都是O(logn) 主要的一个特点 就是中序遍历一棵树 会得到一个递增的序列 在此题目的条件是給出一个根节点 简化起见 考虑简单的情况 即是給出的二叉树形式为列表的形式 顺序为前序 也就是一个元素就是根节点 比如 [5,1,4,#,#,3,6] 这个是給出的二叉树 根节点为第一个元素 也就是5 注意一下 实际上在 python 当中給出的应该是这样的列表 [5, 1, 4, None, None, 3, 6] 123456789101112def traverse_binary_tree(node, callback): if node is None: return traverse_binary_tree(node.leftChild, callback) callback(node.value) traverse_binary_tree(node.rightChild, callback) def get_inorder_traversal(root): result = [] traverse_binary_tree(root, lambda element: result.append(element)) return result 解法 123456789101112131415class Solution1(object): def valid_bst(self, root): # 直接先中序遍历 得到序列 def inorder_traversal(root): if root is None: return [] res = [] res += inorder_traversal(root.left) res.append(root.val) res += inorder_traversal(root.right) return res # 根据中序遍历的结果进行比对 return (inorder_traversal(root) == sorted(list(set(inorder_traversal(root))))) 另外也可以依次比较左右子树各个子节点的值 保证 左 &lt; zhong &lt; 右 1234567891011class Solution2(object): def valid_bst(self, root): return self.helper(root, -2**64, 2**64-1) def helper(self, root, left, right): if root is None: return True if left &gt;= root.val or right &lt;= root.val: return False retun self.helper(root.left, left, root.val) and self.helper(root.right, root.val, right) 工程化的项目当中 一般是测试先行 也就是说需要先把测试用例这些东西准备好 在此 为了完善起见 肯定是需要补上测试用例的 能跑过测试 说明代码是正确的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384class Node(object): def __init__(self, x): self.val = x self.left = None self.right = None def get_val(self): return self.val def dict_form(self): dict_set = &#123; "val": self.val, "left": self.left, "right": self.right, &#125; return dict_set def __str__(self): return str(self.val)class Tree(object): def __init__(self, data_list): # 初始化即将传入的列表的迭代器 self.root = data_list[0] if data_list else None self.it = iter(data_list) def create_tree(self, bt=None): try: # 获取下一个元素 next_data = next(self.it) # 如果当前列表元素为 "#", 则认为其为 None if next_data == '#' or next_data is None: bt = None else: bt = Node(next_data) bt.left = self.create_tree(bt.left) bt.right = self.create_tree(bt.right) except Exception as e: print(e) return bt # 前序遍历 def preorder_traverse(self, bt): if bt is not None: print(bt.val, end=" ") self.preorder_traverse(bt.left) self.preorder_traverse(bt.right) # 中序遍历 def inorder_traverse(self, bt): if bt is not None: self.inorder_traverse(bt.left) print(bt.val, end=" ") self.inorder_traverse(bt.right) # 后序遍历 def postorder_traverse(self, bt): if bt is not None: self.postorder_traverse(bt.left) self.postorder_traverse(bt.right) print(bt.val, end=" ") # 综合打印 def print_traverse(self, bt): print("前序遍历: ", end="") self.preorder_traverse(bt) print('\n') print("中序遍历: ", end="") self.inorder_traverse(bt) print('\n') print("后序遍历: ", end="") self.postorder_traverse(bt) print('\n')if __name__ == "__main__": data_list = list("124#7###35##68###") btree = Tree(data_list) root = btree.create_tree() btree.print_traverse(root) 首先可以运行tests.py 文件 里面暂时只放了6个测试用例 可以看到是通过的 本次 运行环境为 python3.5 当然工程环境下可能有上百个以上的测试用例]]></content>
      <categories>
        <category>data structure</category>
      </categories>
      <tags>
        <tag>data structure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sql优化之oracle]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F24%2Fsql%E4%BC%98%E5%8C%96%E4%B9%8Boracle%2F</url>
    <content type="text"><![CDATA[Oracle Hints是一种机制，用来告诉优化器按照我们的告诉它的方式生成执行计划。我们可以用Oracle Hints来实现：使用的优化器的类型基于代价的优化器的优化目标，是all_rows还是first_rows表的访问路径，是全表扫描，还是索引扫描，还是直接利用rowid表之间的连接类型表之间的连接顺序语句的并行程度]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0030]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0030%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[js0029]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0029%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[js0028]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0028%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[js0027]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0027%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[js0026]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0026%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[js0025]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0025%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[js0024]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0024%2F</url>
    <content type="text"><![CDATA[生成器和promise 的结合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Combining generators and promises&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;getJSON.js&quot;&gt;&lt;/script&gt; &lt;script&gt; &quot;use strict&quot; async(function*()&#123; try &#123; const ninjas = yield getJSON(&quot;data/ninjas.json&quot;); const missions = yield getJSON(ninjas[0].missionsUrl); const missionDescription = yield getJSON(missions[0].detailsUrl); assert(ninjas !== null &amp;&amp; missions !== null &amp;&amp; missionDescription !== null, &quot;All ready!&quot;); &#125; catch(e) &#123; fail(&quot;We weren&apos;t able to get mission details&quot;); &#125; &#125;); function async(generator) &#123; const iterator = generator(); function handle(iteratorResult) &#123; if(iteratorResult.done) &#123; return; &#125; const iteratorValue = iteratorResult.value; if(iteratorValue instanceof Promise) &#123; iteratorValue.then(res =&gt; handle(iterator.next(res))) .catch(err =&gt; iterator.throw(err)) &#125; &#125; try &#123; handle(iterator.next()); &#125; catch (e) &#123; iterator.throw(e); &#125; &#125; &lt;/script&gt; &lt;/head&gt; &lt;body&gt;Has to be run on a server (e.g MAMP or WAMP)&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0023]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fjs0023%2F</url>
    <content type="text"><![CDATA[创建真实的promise 案例 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Creating a JSON promise&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;script&gt; function getJSON(url) &#123; return new Promise((resolve, reject) =&gt; &#123; const request = new XMLHttpRequest(); request.open(&quot;GET&quot;, url); request.onload = function() &#123; try &#123; if(this.status === 200 )&#123; resolve(JSON.parse(this.response)); &#125; else&#123; reject(this.status + &quot; &quot; + this.statusText); &#125; &#125; catch(e)&#123; reject(e.message); &#125; &#125;; request.onerror = function() &#123; reject(this.status + &quot; &quot; + this.statusText); &#125;; request.send(); &#125;); &#125; getJSON(&quot;data/ninjas.json&quot;).then((ninjas) =&gt; &#123; assert(ninjas !== null, &quot;Ninjas obtained!&quot;); &#125;).catch(e =&gt; fail(&quot;Shouldn’t be here:&quot; + e)); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Has to be executed on a server (e.g MAMP, WAMP)&lt;/p&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[django-template]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F21%2Fdjango-template-4%2F</url>
    <content type="text"><![CDATA[有些情况会自定义tag 1234567891011121314151617181920#!/usr/bin/env python#coding:utf-8from django import templatefrom django.utils.safestring import mark_safe register = template.Library() @register.simple_tagdef my_simple_time(v1,v2,v3): return v1 + v2 + v3 @register.simple_tagdef my_input(id,arg): result = &quot;&lt;input type=&apos;text&apos; id=&apos;%s&apos; class=&apos;%s&apos; /&gt;&quot; %(id,arg,) return mark_safe(result) 如何使用 1234&#123;% load xx %&#125;&#123;% my_simple_time 1 2 3%&#125;&#123;% my_input &apos;id_username&apos; &apos;hide&apos;%&#125;]]></content>
  </entry>
  <entry>
    <title><![CDATA[vim-server-python简版]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F20%2Fvim-server-python%E7%AE%80%E7%89%88%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244&quot; leaderlet mapleader = &apos;,&apos;let g:mapleader = &apos;,&apos;&quot; syntaxsyntax on&quot; history : how many lines of history VIM has to rememberset history=2000&quot; filetypefiletype on&quot; Enable filetype pluginsfiletype plugin onfiletype indent on&quot; baseset nocompatible &quot; don&apos;t bother with vi compatibilityset autoread &quot; reload files when changed on disk, i.e. via `git checkout`set shortmess=atIset magic &quot; For regular expressions turn magic onset title &quot; change the terminal&apos;s titleset nobackup &quot; do not keep a backup fileset novisualbell &quot; turn off visual bellset noerrorbells &quot; don&apos;t beepset visualbell t_vb= &quot; turn off error beep/flashset t_vb=set tm=500&quot; show locationset cursorcolumnset cursorline&quot; movementset scrolloff=7 &quot; keep 3 lines when scrolling&quot; showset ruler &quot; show the current row and columnset number &quot; show line numbersset nowrapset showcmd &quot; display incomplete commandsset showmode &quot; display current modesset showmatch &quot; jump to matches when entering parenthesesset matchtime=2 &quot; tenths of a second to show the matching parenthesis&quot; searchset hlsearch &quot; highlight searchesset incsearch &quot; do incremental searching, search as you typeset ignorecase &quot; ignore case when searchingset smartcase &quot; no ignorecase if Uppercase char present&quot; tabset expandtab &quot; expand tabs to spacesset smarttabset shiftround&quot; indentset autoindent smartindent shiftroundset shiftwidth=4set tabstop=4set softtabstop=4 &quot; insert mode tab and backspace use 4 spaces&quot; NOT SUPPORT&quot; foldset foldenableset foldmethod=indentset foldlevel=99let g:FoldMethod = 0map &lt;leader&gt;zz :call ToggleFold()&lt;cr&gt;fun! ToggleFold() if g:FoldMethod == 0 exe &quot;normal! zM&quot; let g:FoldMethod = 1 else exe &quot;normal! zR&quot; let g:FoldMethod = 0 endifendfun&quot; encodingset encoding=utf-8set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1set termencoding=utf-8set ffs=unix,dos,macset formatoptions+=mset formatoptions+=B&quot; select &amp; completeset selection=inclusiveset selectmode=mouse,keyset completeopt=longest,menuset wildmenu &quot; show a navigable menu for tab completion&quot;set wildmode=longest,list,fullset wildignore=*.o,*~,*.pyc,*.class&quot; othersset backspace=indent,eol,start &quot; make that backspace key work the way it shouldset whichwrap+=&lt;,&gt;,h,l&quot; if this not work ,make sure .viminfo is writable for youif has(&quot;autocmd&quot;) au BufReadPost * if line(&quot;&apos;\&quot;&quot;) &gt; 1 &amp;&amp; line(&quot;&apos;\&quot;&quot;) &lt;= line(&quot;$&quot;) | exe &quot;normal! g&apos;\&quot;&quot; | endifendif&quot; NOT SUPPORT&quot; Enable basic mouse behavior such as resizing buffers.&quot; set mouse=a&quot; ============================ theme and status line ============================&quot; themeset background=darkcolorscheme desert&quot; set mark column colorhi! link SignColumn LineNrhi! link ShowMarksHLl DiffAddhi! link ShowMarksHLu DiffChange&quot; status lineset statusline=%&lt;%f\ %h%m%r%=%k[%&#123;(&amp;fenc==\&quot;\&quot;)?&amp;enc:&amp;fenc&#125;%&#123;(&amp;bomb?\&quot;,BOM\&quot;:\&quot;\&quot;)&#125;]\ %-14.(%l,%c%V%)\ %Pset laststatus=2 &quot; Always show the status line - use 2 lines for the status bar&quot; ============================ specific file type ===========================autocmd FileType python set tabstop=4 shiftwidth=4 expandtab aiautocmd FileType ruby set tabstop=2 shiftwidth=2 softtabstop=2 expandtab aiautocmd BufRead,BufNew *.md,*.mkd,*.markdown set filetype=markdown.mkdautocmd BufNewFile *.sh,*.py exec &quot;:call AutoSetFileHead()&quot;function! AutoSetFileHead() &quot; .sh if &amp;filetype == &apos;sh&apos; call setline(1, &quot;\#!/bin/bash&quot;) endif &quot; python if &amp;filetype == &apos;python&apos; call setline(1, &quot;\#!/usr/bin/env python&quot;) call append(1, &quot;\# encoding: utf-8&quot;) endif normal G normal o normal oendfuncautocmd FileType c,cpp,java,go,php,javascript,puppet,python,rust,twig,xml,yml,perl autocmd BufWritePre &lt;buffer&gt; :call &lt;SID&gt;StripTrailingWhitespaces()fun! &lt;SID&gt;StripTrailingWhitespaces() let l = line(&quot;.&quot;) let c = col(&quot;.&quot;) %s/\s\+$//e call cursor(l, c)endfun&quot; ============================ key map ============================nnoremap k gknnoremap gk knnoremap j gjnnoremap gj jmap &lt;C-j&gt; &lt;C-W&gt;jmap &lt;C-k&gt; &lt;C-W&gt;kmap &lt;C-h&gt; &lt;C-W&gt;hmap &lt;C-l&gt; &lt;C-W&gt;lnnoremap &lt;F2&gt; :set nu! nu?&lt;CR&gt;nnoremap &lt;F3&gt; :set list! list?&lt;CR&gt;nnoremap &lt;F4&gt; :set wrap! wrap?&lt;CR&gt;set pastetoggle=&lt;F5&gt; &quot; when in insert mode, press &lt;F5&gt; to go to &quot; paste mode, where you can paste mass data &quot; that won&apos;t be autoindentedau InsertLeave * set nopastennoremap &lt;F6&gt; :exec exists(&apos;syntax_on&apos;) ? &apos;syn off&apos; : &apos;syn on&apos;&lt;CR&gt;&quot; kj 替换 Escinoremap kj &lt;Esc&gt;&quot; Quickly close the current windownnoremap &lt;leader&gt;q :q&lt;CR&gt;&quot; Quickly save the current filennoremap &lt;leader&gt;w :w&lt;CR&gt;&quot; select allmap &lt;Leader&gt;sa ggVG&quot;&quot; remap U to &lt;C-r&gt; for easier redonnoremap U &lt;C-r&gt;&quot; Swap implementations of ` and &apos; jump to markers&quot; By default, &apos; jumps to the marked line, ` jumps to the marked line and&quot; column, so swap themnnoremap &apos; `nnoremap ` &apos;&quot; switch # *&quot; nnoremap # *&quot; nnoremap * #&quot;Keep search pattern at the center of the screen.&quot;nnoremap &lt;silent&gt; n nzznnoremap &lt;silent&gt; N Nzznnoremap &lt;silent&gt; * *zznnoremap &lt;silent&gt; # #zznnoremap &lt;silent&gt; g* g*zz&quot; remove highlightnoremap &lt;silent&gt;&lt;leader&gt;/ :nohls&lt;CR&gt;&quot;Reselect visual block after indent/outdent.调整缩进后自动选中，方便再次操作vnoremap &lt; &lt;gvvnoremap &gt; &gt;gv&quot; y$ -&gt; Y Make Y behave like other capitalsmap Y y$&quot;Map ; to : and save a million keystrokes&quot; ex mode commands made easy 用于快速进入命令行nnoremap ; :&quot; Shift+H goto head of the line, Shift+L goto end of the linennoremap H ^nnoremap L $&quot; savecmap w!! w !sudo tee &gt;/dev/null %&quot; command mode, ctrl-a to head， ctrl-e to tailcnoremap &lt;C-j&gt; &lt;t_kd&gt;cnoremap &lt;C-k&gt; &lt;t_ku&gt;cnoremap &lt;C-a&gt; &lt;Home&gt;cnoremap &lt;C-e&gt; &lt;End&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[how-to-make-django-auth-with-both-email-and-username]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F19%2Fhow-to-make-django-auth-with-both-email-and-username%2F</url>
    <content type="text"><![CDATA[做一个小小的记录 扩展认证 1234567891011121314from django.contrib.auth.backends import ModelBackendfrom django.db.models import Qfrom .models import UserProfileclass CustomBackend(ModelBackend): &quot;&quot;&quot;邮箱也能登录&quot;&quot;&quot; def authenticate(self, request, username=None, password=None, **kwargs): try: user=UserProfile.objects.get(Q(username=username)|Q(email=username)) if user.check_password(password): return user except Exception as e: return None]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0022]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0022%2F</url>
    <content type="text"><![CDATA[拒绝promise 显示拒绝 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;Explicitly rejecting promises&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;getJSON.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; &quot;use script&quot;; const promise = new Promise((resolve, reject) =&gt; &#123; reject(&quot;Explicitly reject a promise!&quot;); &#125;); promise.then( () =&gt; fail(&quot;Happy path, won&apos;t be called!&quot;), error =&gt; pass(&quot;A promise was explicitly rejected!&quot;) ); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0021]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0021%2F</url>
    <content type="text"><![CDATA[深入研究promise的执行顺序 promise 作为用于异步任务对象的占位符 代表了一个我们还未获得但是在未来有希望获得的值 基于这个原因 对象从等待状态开始 此时对承诺的值 一无所知 promise 的 resolve 函数 被调用的时候 会进入完成状态 fulfilled 状态 如果是reject 函数被调用 状态不能再进行切换了 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;A closer look at promise order of execution&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; &quot;use script&quot;; report(&quot;At code start&quot;); const ninjaDelayedPromise = new Promise((resolve, reject) =&gt; &#123; report(&quot;ninjaDelayedPromise executor&quot;); setTimeout(() =&gt; &#123; report(&quot;Resolving ninjaDelayedPromise&quot;); resolve(&quot;Hatori&quot;); &#125;, 500); &#125;); assert(ninjaDelayedPromise !== null, &quot;After creating ninjaDelayedPromise&quot;); ninjaDelayedPromise.then(ninja =&gt; &#123; assert(ninja === &quot;Hatori&quot;, &quot;ninjaDelayedPromise resolve handled with Hatori&quot;); &#125;); const ninjaImmediatePromise = new Promise((resolve, reject) =&gt; &#123; report(&quot;ninjaImmediatePromise executor. Immediate resolve.&quot;); resolve(&quot;Yoshi&quot;); &#125;); ninjaImmediatePromise.then(ninja =&gt; &#123; assert(ninja === &quot;Yoshi&quot;, &quot;ninjaImmediatePromise resolve handled with Yoshi&quot;); &#125;); report(&quot;At code end&quot;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0020]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0020%2F</url>
    <content type="text"><![CDATA[使用promise 的简单例子 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;Creating a simple promise&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; &quot;use script&quot;; const ninjaPromise = new Promise((resolve, reject) =&gt; &#123; resolve(&quot;Hatori&quot;); //reject(&quot;An error resolving a promise!&quot;); &#125;); ninjaPromise.then(ninja =&gt; &#123; assert(ninja === &quot;Hatori&quot;, &quot;We were promised Hatori!&quot;); &#125;, err =&gt; &#123; fail(&quot;There shouldn’t be an error&quot;); &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0019]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0019%2F</url>
    <content type="text"><![CDATA[作为生成器函数参数发送值 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;title&gt;Sending data to and recieving data from a generator&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;script&gt; function* NinjaGenerator(action) &#123; const imposter = yield (&quot;Hatori &quot; + action); assert(imposter === &quot;Hanzo&quot;, &quot;The generator has been infiltrated&quot;); yield (&quot;Yoshi (&quot; + imposter + &quot;) &quot; + action); &#125; const ninjaIterator = NinjaGenerator(&quot;skulk&quot;); const result1 = ninjaIterator.next(); assert(result1.value === &quot;Hatori skulk&quot;, &quot;Hatori is skulking&quot;); const result2 = ninjaIterator.next(&quot;Hanzo&quot;); assert(result2.value === &quot;Yoshi (Hanzo) skulk&quot;, &quot;We have an imposter!&quot;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0018]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0018%2F</url>
    <content type="text"><![CDATA[通过函数访问私有变量 而不是通过对象访问 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Private variables are accessed through functions and not through objects&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; function Ninja() &#123; var feints = 0; this.getFeints = function()&#123; return feints; &#125;; this.feint = function()&#123; feints++; &#125;; &#125; var ninja1 = new Ninja(); ninja1.feint(); var imposter = &#123;&#125;; imposter.getFeints = ninja1.getFeints; assert(imposter.getFeints () === 1, &quot;The imposter has access to the feints variable!&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0017]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0017%2F</url>
    <content type="text"><![CDATA[对比上一个 使用const let 关键字 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using const and let keywords&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; &quot;use strict&quot; const globalNinja = &quot;Yoshi&quot;; function reportActivity()&#123; const functionActivity = &quot;jumping&quot;; for(let i = 1; i &lt; 3; i++) &#123; let forMessage = globalNinja + &quot; &quot; + functionActivity; assert(forMessage === &quot;Yoshi jumping&quot;, &quot;Yoshi is jumping within the for block&quot;); assert(i, &quot;Current loop counter:&quot; + i); &#125; assert(typeof i === &quot;undefined&quot; &amp;&amp; typeof forMessage === &quot;undefined&quot;, &quot;Loop variables not accessible outside the loop&quot;); &#125; reportActivity(); assert(typeof functionActivity === &quot;undefined&quot; &amp;&amp; typeof i === &quot;undefined&quot; &amp;&amp; typeof forMessage === &quot;undefined&quot;, &quot;We cannot see function variables outside of a function&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0016]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0016%2F</url>
    <content type="text"><![CDATA[使用关键字var时 该变量时在距离最近的函数内部或是在全局词法环境中定义的 1234567891011121314151617181920212223242526272829303132333435&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using the var keyword&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; var globalNinja = &quot;Yoshi&quot;; function reportActivity()&#123; var functionActivity = &quot;jumping&quot;; for(var i = 1; i &lt; 3; i++) &#123; var forMessage = globalNinja + &quot; &quot; + functionActivity; assert(forMessage === &quot;Yoshi jumping&quot;, &quot;Yoshi is jumping within the for block&quot;); assert(i, &quot;Current loop counter:&quot; + i); &#125; assert(i === 3 &amp;&amp; forMessage === &quot;Yoshi jumping&quot;, &quot;Loop variables accessible outside of the loop&quot;); &#125; // for 循环外部 仍然能够访问for循环中定义的变量 reportActivity(); assert(typeof functionActivity === &quot;undefined&quot; &amp;&amp; typeof i === &quot;undefined&quot; &amp;&amp; typeof forMessage === &quot;undefined&quot;, &quot;We cannot see function variables outside of a function&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0015]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0015%2F</url>
    <content type="text"><![CDATA[执行上下文来跟踪代码123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;The creation of execution contexts&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=&quot;text/javascript&quot;&gt; function skulk(ninja) &#123; report(ninja + &quot; skulking&quot;); &#125; function report(message) &#123; console.log(message); &#125; skulk(&quot;Kuma&quot;); skulk(&quot;Yoshi&quot;); &lt;/script&gt; &lt;p&gt;Outputs to the console (press F12)&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0014]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0014%2F</url>
    <content type="text"><![CDATA[闭包来做动画的效果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using a closure in a timer interval callback&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt; &lt;style&gt; #box1&#123; width: 100px; height: 100px; position: relative; margin:5; color: white; font-weight: bolder; background-color:blue; margin-bottom: 100px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=&quot;box1&quot;&gt;First Box&lt;/div&gt; &lt;script&gt; function animateIt(elementId) &#123; var elem = document.getElementById(elementId); var tick = 0; var timer = setInterval(function()&#123; if (tick &lt; 100) &#123; elem.style.left = elem.style.top = tick + &quot;px&quot;; tick++; &#125; else &#123; clearInterval(timer); assert(tick === 100, &quot;Tick accessed via a closure.&quot;); assert(elem, &quot;Element also accessed via a closure.&quot;); assert(timer, &quot;Timer reference also obtained via a closure.&quot; ); &#125; &#125;, 10); &#125; animateIt(&quot;box1&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0013]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0013%2F</url>
    <content type="text"><![CDATA[封装私有变量12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using closures to approximate private variable&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; function Ninja() &#123; var feints = 0; this.getFeints = function()&#123; return feints; &#125;; this.feint = function()&#123; feints++; &#125;; &#125; var ninja1 = new Ninja(); ninja1.feint(); assert(ninja1.feints === undefined, &quot;And the private data is inaccessible to us.&quot;); assert(ninja1.getFeints() === 1, &quot;We&apos;re able to access the internal feint count.&quot;); var ninja2 = new Ninja(); assert(ninja2.getFeints() === 0, &quot;The second ninja object gets it’s own feints variable.&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0012]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0012%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;A not so simple closure&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; var outerValue = &quot;samurai&quot;; var later; function outerFunction() &#123; var innerValue = &quot;ninja&quot;; function innerFunction() &#123; assert(outerValue === &quot;samurai&quot;, &quot;I can see the samurai.&quot;); assert(innerValue === &quot;ninja&quot;, &quot;I can see the ninja.&quot;); &#125; later = innerFunction; &#125; outerFunction(); later(); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0011]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F15%2Fjs0011%2F</url>
    <content type="text"><![CDATA[闭包js必会到闭包的问题 通过闭包可以访问创建闭包时所处环境中的全部变量。闭包为函数提供所处环境的作用域的函数和变量。创建“安全气泡”。通过这种方式，即使创建函数时所处的作用域已经消失，但是函数仍然能够获得执行时所需要的全部内容。 通过构造函数内的变量以及构造方法来模拟对象的私有属性 处理回调函数 简化代码 引擎是通过执行上下文（调用栈）跟踪函数的执行。每次调用函数时，都会创建新的函数执行上下文，并推入调用栈顶端。当函数执行完成后，对应的执行上下文将从调用栈中推出。 引擎通过词法环境跟踪标识符（俗称作用域） 定义全局级别、函数级别甚至块级别的变量 var 定义距离最近的函数级别变量或者全局变量 let const 定义距离最近级别的变量 包括块级别变量 闭包是js作用域规则的副作用。当函数创建时所在的作用域消失之后，仍然能够调用函数]]></content>
  </entry>
  <entry>
    <title><![CDATA[see_python版本的排序算法]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F14%2Fsee-python%E7%89%88%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[see_python的基础数据结构]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F14%2Fsee-python%E7%9A%84%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[列表list 以完全随机的列表考虑平均情况。 列表是以数组（Array）实现的。最大的开销发生在超过当前分配大小的增长，这种情况下所有元素都需要移动；或者是在起始位置附近插入或者删除元素，这种情况下所有在该位置后面的元素都需要移动。如果你需要在一个队列的两端进行增删的操作，应当使用collections.deque（双向队列） 操作 平均情况 最坏情况 复制 O(n) O(n) append O(1) O(1) 插入 O(n) O(n) 取元素 O(1) O(1) 更改元素 O(1) O(1) 删除元素 O(n) O(n) 遍历 O(n) O(n) 取切片 O(k) O(k) 删除切片 O(n) O(n) 更改切片 O(k+n) O(k+n) extend O(k) O(k) 排序 O(n logn) O(n logn) 列表乘法 O(nk) O(nk) x in s O(n) min(s), max(s) O(n) 计算长度 O(1) O(1) 双端队列queuedeque （double-ended queue，双向队列）是以双向链表的形式实现的 (Well, a list of arrays rather than objects, for greater efficiency)。双向队列的两端都是可达的，但从查找队列中间的元素较为缓慢，增删元素就更慢了。 操作 平均情况 最坏情况 复制 O(n) O(n) append O(1) O(1) appendleft O(1) O(1) pop O(1) O(1) popleft O(1) O(1) extend O(k) O(k) extendleft O(k) O(k) rotate O(k) O(k) remove O(n) O(n) 集合set 操作 平均情况 最坏情况 x in s O(1) O(n) 并集 s\ t O(len(s)+len(t)) 交集 s&amp;t O(min(len(s), len(t)) O(len(s) * len(t)) 差集 s-t O(len(s)) s.difference_update(t) O(len(t)) 对称差集 s^t O(len(s)) O(len(s) * len(t)) s.symmetric_difference_update(t) O(len(t)) O(len(t) * len(s)) 字典dict下列字典的平均情况基于以下假设： 对象的散列函数足够鲁棒性（robust），不会发生冲突。 字典的键是从所有可能的键的集合中随机选择的。 小窍门：只使用字符串作为字典的键。这么做虽然不会影响算法的时间复杂度，但会对常数项产生显著的影响，这决定了你的一段程序能多快跑完。 操作 平均情况 最坏情况 复制 O(n) O(n) 取元素 O(1) O(n) 更改元素 O(1) O(n) 删除元素 O(1) O(n) 遍历 O(n) O(n)]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-ds]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F11%2Fpython-ds%2F</url>
    <content type="text"><![CDATA[谈谈python的基础数据结构？这个是有时候 被问到的“基础”问题 python的内置类型 python的一个“显著”问题 就是它留給开发者的选择太多。 很多代码 要么就是效率低下 要么就是过于啰嗦。 字符串与字节python3 只有一种能够保存文本信息的数据类型，就是str 它是不可变的数据类型（序列） 保存的是unicode码位 字节字符串 在python3 当中使用bytes对象来处理 鉴于字符串的不变性 字符串可以作为字典的键或者set的元素，因为一旦初始化之后字符串的值就不会改变。 字符串比较常用的方法 是拼接 集合类型 元组 列表 字典 集合set 通常元组和列表会被对比来看 列表是动态的，其大小可变；元组是不可变的，一旦创建就不能被修改。 需要考虑一个问题 就使用来说 列表非常广泛？为什么还需要元组！ Cpython的列表根本就不是列表，而是长度可变的数组。 高级一些必备 列表的推导式 枚举enumeratezip函数 字典 也就是hash 字典推导式和列表推导式具有相同的优点 更加高效、简短、整洁 以前很多返回值不再是列表类型，python3当中返回的是迭代器 Cpython使用伪随机探测的散列表作为字典的底层数据结构。 python3.6重新实现了字典 改变了以前字典是无序的状态 集合 当元素顺序的重要性不如元素的唯一性和测试元素是否包含在集合中的效率时，大部分情况会使用集合 集合有两种；可变的set 不可变的frozenset 集合也具有推导式的写法 更多的扩展数据类型 在collections模块当中 命名元组 双端队列 chainmap counter 有序字典 默认字典 类以下当中有哪些高级语法 迭代器和生成器yield装饰器上下文管理器 for…else…函数注解]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python字符串问题]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F11%2Fpython%E5%AD%97%E7%AC%A6%E4%B8%B2%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一、字符串类型 python3:python语言有两种不同的字符串，一个用于存储文本，一个用于存储原始字节。文本字符串内部使用Unicode存储，字节字符串存储原始字节并显示ASCII。python3中，文本型字符串类型被命名为str，字节字符串类型被命名为bytes。正常情况下，实例化一个字符串会得到一个str实例，如果希望得到一个bytes实例，需要在文本之前添加b字符。 python2中也有两种字符串，不过，python3中的str类在python2中名称为unicode,但是，python3中的bytes类在python2中名称为str类。这意味着在python3中str类是一个文本字符串，而在python2中str类是一个字节字符串。若不使用前缀实例化字符串，则返回一个str类（这里是字节字符串！！！），如果想要得到一个文本字符串，需要在字符串前面加上u字符。 二、字符串转换 python3:可以在str与bytes之间进行类型转换，str类包含一个encode方法，用于使用特定编码将其转换为一个bytes。于此类似，bytes类包含一个decode方法，接受一个编码作为单个必要参数，并返回一个str。另一个需要注意的是，python3中永远不会尝试隐式地在一个str与一个bytes之间进行转换，需要显式使用str.encode 或者 bytes.decode方法。 python2:与python3不同的是，python2会在文本字符串和字节字符串之间尝试进行隐式转换。该工作机制是，如果解释器遇到一个不同种类的字符串混合操作，解释器首先会将字节字符串转换为文本字符串，然后对文本字符串进行操作。解释器在将字节字符串转换为文本字符串的过程中使用隐式解码，python2中默认编码几乎总是ASCII.我们可以使用sys.getdefaultencoding 方法来查看默认编码方式。 三、读取文件 python3:文件总是存储字节，因此，为了使用文件中读取的文本数据，必须首先将其解码为一个文本字符串。python3中，文本正常情况下会自动为你解码，所以打开或读取文件会得到一个文本字符串。使用的解码方式取决系统，在mac os 或者 大多数linux系统中，首选编码是utf-8，但windows不一定。可以使用locale.getpreferredencoding()方法得到系统的默认解码方式。 python2:python2中，无论以何种方式打开文件，read方法总是返回一个字节字符串]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js0010]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F11%2Fjs0010%2F</url>
    <content type="text"><![CDATA[使用箭头函数来绕过函数上下文 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using arrow functions to work around callback function contexts&lt;/title&gt; &lt;meta charset="utf-8"&gt; &lt;script src="../assert.js"&gt;&lt;/script&gt; &lt;link rel="stylesheet" type="text/css" href="../assert.css"&gt;&lt;/head&gt;&lt;body&gt; &lt;button id="test"&gt;Click Me!&lt;/button&gt; &lt;script&gt; function Button() &#123; this.clicked = false; this.click = () =&gt; &#123; this.clicked = true; assert(button.clicked, "The button has been clicked"); &#125; &#125; var button = new Button(); var elem = document.getElementById("test"); elem.addEventListener("click", button.click); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0009]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F11%2Fjs0009%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using a constructor to set up common objects&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=&quot;text/javascript&quot;&gt; function Ninja() &#123; this.skulk = function() &#123; return this; &#125;; &#125; var ninja1 = new Ninja(); var ninja2 = new Ninja(); assert(ninja1.skulk() === ninja1, &quot;The 1st ninja is skulking&quot;); assert(ninja2.skulk() === ninja2, &quot;The 2nd ninja is skulking&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 将函数作为构造函数进行调用是比较强大的一个特性]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0008]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F11%2Fjs0008%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using the arguments parameter&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; function whatever(a, b, c)&#123; assert(a === 1, &apos;The value of a is 1&apos;); assert(b === 2, &apos;The value of b is 2&apos;); assert(c === 3, &apos;The value of c is 3&apos;); assert(arguments.length === 5, &apos;We’ve passed in 5 parameters&apos;); assert(arguments[0] === a, &apos;The first argument is assigned to a&apos;); assert(arguments[1] === b, &apos;The second argument is assigned to b&apos;); assert(arguments[2] === c, &apos;The third argument is assigned to c&apos;); assert(arguments[3] === 4, &apos;We can access the fourth argument&apos;); assert(arguments[4] === 5, &apos;We can access the fifth argument&apos;); &#125; whatever(1,2,3,4,5); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; js函数 隐式的函数参数arguments this 这两者会静默地传递給函数 arguments 参数表示函数调用过程中传递的所有参数 this 表示被调用函数的上下文对象 arguments对象 不是数组 ！！！ 是一个类数组的结构 可以作为函数参数的别名 但是在严格模式下无法使用 四种方式调用函数 作为函数直接调用 关联在一个对象上 实现面向对象编程oop 方法调用 作为一个构造函数 通过函数的apply 或者是 call方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0007]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F10%2Fjs0007%2F</url>
    <content type="text"><![CDATA[javascript 是函数式编程语言 也就是fp 函数是第一类对象 通过字面量创建赋值給变量或者属性作为函数参数传递作为函数的结果进行返回赋值給属性和方法 回调函数是被代码随后”回来调用“的函数，特别是在事件处理场景之下 函数具有属性，而且可以存储任何信息， 存储另一个函数用于之后的引用和调用 用函数属性来创建一个缓存（记忆），用于减少不必要的计算 函数声明和函数表达式是最主要的函数类型 另外还有箭头函数和函数生成器 还有很不常见的函数构造函数 形参是函数定义时列出的变量 实参是函数调用时传递給函数的值 形参和实参列表长度可以不同 未赋值的形参求值得到undefined传入的额外实参不会被赋值給任何一个命令形参 剩余参数 不与任何形参名相匹配的额外实参可以通过剩余参数来引用 默认参数 没有传入参数的时候 提供的缺省值]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0006]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F10%2Fjs0006%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Using the rest parameters&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;script type=&quot;text/javascript&quot;&gt; &quot;use strict&quot; function multiMax(first, ...remainingNumbers)&#123; var sorted = remainingNumbers.sort(function(a, b)&#123; return b - a; &#125;); return first * sorted[0]; &#125; assert(multiMax(3, 1, 2, 3) == 9, &quot;3*3=9 (First arg, by largest.)&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 剩余参数 省略号 …]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0005]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F10%2Fjs0005%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Storing a collection of unique functions&lt;/title&gt; &lt;meta charset=&quot;utf-8&quot;&gt; &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;../assert.css&quot;&gt; &lt;script src=&quot;../assert.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;script&gt; var store = &#123; nextId: 1, cache: &#123;&#125;, add: function(fn) &#123; if (!fn.id) &#123; fn.id = this.nextId++; this.cache[fn.id] = fn; return true; &#125; &#125; &#125;; function ninja()&#123;&#125; assert(store.add(ninja), &quot;Function was safely added.&quot;); assert(!store.add(ninja), &quot;But it was only added once.&quot;); &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0004]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F10%2Fjs0004%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Registering event handlers&lt;/title&gt; &lt;style&gt; #first &#123; color: green;&#125; #second &#123; color: red;&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;ul id=&quot;first&quot;&gt;&lt;/ul&gt; &lt;script&gt; function addMessage(element, message)&#123; var messageElement = document.createElement(&quot;li&quot;); messageElement.textContent = message; element.appendChild(messageElement); &#125; var first = document.getElementById(&quot;first&quot;); addMessage(first, &quot;Page loading&quot;); &lt;/script&gt; &lt;ul id=&quot;second&quot;&gt;&lt;/ul&gt; &lt;script&gt; document.body.addEventListener(&quot;mousemove&quot;, function() &#123; //#A var second = document.getElementById(&quot;second&quot;); addMessage(second, &quot;Event: mousemove&quot;); &#125;); document.body.addEventListener(&quot;click&quot;, function()&#123; //#B var second = document.getElementById(&quot;second&quot;); addMessage(second, &quot;Event: click&quot;); &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 以上三个是页面构建的过程中 展示的部分测试代码]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0003]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F10%2Fjs0003%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Different types of JavaScript code – global and function code&lt;/title&gt; &lt;style&gt; #first &#123; color: green;&#125; #second &#123; color: red;&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;ul id=&quot;first&quot;&gt;&lt;/ul&gt; &lt;script&gt; function addMessage(element, message)&#123; var messageElement = document.createElement(&quot;li&quot;); //#A messageElement.textContent = message; //#A element.appendChild(messageElement); //#A &#125; var first = document.getElementById(&quot;first&quot;); //#B addMessage(first, &quot;Page loading&quot;); //#B &lt;/script&gt; &lt;ul id=&quot;second&quot;&gt;&lt;/ul&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0002]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F09%2Fjs0002%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;A small web application with a GUI reacting to events&lt;/title&gt; &lt;style&gt; #first &#123; color: green;&#125; #second &#123; color: red;&#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;ul id="first"&gt;&lt;/ul&gt; &lt;script&gt; function addMessage(element, message)&#123; //#A var messageElement = document.createElement("li"); //#A messageElement.textContent = message; //#A element.appendChild(messageElement); //#A &#125; //#A var first = document.getElementById("first"); addMessage(first, "Page loading"); &lt;/script&gt; &lt;ul id="second"&gt;&lt;/ul&gt; &lt;script&gt; document.body.addEventListener("mousemove", function() &#123; //#B var second = document.getElementById("second"); addMessage(second, "Event: mousemove"); &#125;); document.body.addEventListener("click", function()&#123; //#C var second = document.getElementById("second"); addMessage(second, "Event: click"); &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[js0001]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F09%2Fjs0001%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;A simple performance counter&lt;/title&gt; &lt;script&gt; maxCount = 10000; console.time("My operation"); for (var n = 0; n &lt; maxCount; n++) &#123; /*perform the operation to be measured*/ //#B &#125; console.timeEnd("My operation"); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; Outputs to the console (press F12)&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[html规范]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F09%2Fhtml%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[正所谓 无规矩不成方圆 一个team 开发的过程中得遵循一定的规范 而目前参照国外的标准 就是google 家的了 背景这篇文章定义了 HTML 和 CSS 的格式和代码规范，旨在提高代码质量和协作效率。 通用样式规范协议省略图片、样式、脚本以及其他媒体文件 URL 的协议部分（ http:,https: ），除非文件在两种协议下都不可用。这种方案称为 protocol-relative URL，好处是无论你是使用 HTTPS 还是 HTTP 访问页面，浏览器都会以相同的协议请求页面中的资源，同时可以节省一部分字节。 12345678&lt;!-- Not recommended --&gt;&lt;script src=&quot;https://www.google.com/js/gweb/analytics/autotrack.js&quot;&gt;&lt;/script&gt;&lt;!-- Recommended --&gt;&lt;script src=&quot;//www.google.com/js/gweb/analytics/autotrack.js&quot;&gt;&lt;/script&gt;/* Not recommended */ .example &#123; background: url(https://www.google.com/images/example);&#125;/* Recommended */ .example &#123; background: url(//www.google.com/images/example);&#125; 通用格式规范缩进一次缩进2个空格，不要使用 tab 或者混合 tab 和空格的缩进。(目前已知的 除了python， java html javascript css 都是四格的缩进！！！) 1234&lt;ul&gt; &lt;li&gt;Fantastic &lt;li&gt;Great &lt;/ul&gt;.example &#123; color: blue;&#125; 大小写以下都应该用小写： HTML 元素名称，属性，属性值（除非 text/CDATA），CSS 选择器，属性，属性值。 123456&lt;!-- Not recommended --&gt;&lt;A HREF=&quot;/&quot;&gt;Home&lt;/A&gt;&lt;!-- Recommended --&gt;&lt;img src=&quot;google.png&quot; alt=&quot;Google&quot;&gt;/* Not recommended */ color: #E5E5E5;/* Recommended */ color: #e5e5e5; 结尾空格结尾空格不仅多余，而且在比较代码时会更麻烦。 1234&lt;!-- Not recommended --&gt;&lt;p&gt;What?_&lt;!-- Recommended --&gt;&lt;p&gt;Yes please. 通用元规范编码在 HTML 中通过 指定编码方式，CSS 中不需要指定，因为默认是 UTF-8。 注释使用注释来解释代码：包含的模块，功能以及优点。 任务项用 TODO 来标记待办事项，而不是用一些其他的标记，像 @@。 12345&lt;!-- TODO: remove optional tags --&gt;&lt;ul&gt; &lt;li&gt;Apples&lt;/li&gt; &lt;li&gt;Oranges&lt;/li&gt;&lt;/ul&gt; HTML 风格规范文档类型HTML 文档应使用 HTML5 的文档类型：&lt;!DOCTYPE html&gt;。 孤立标签无需封闭自身， 不要写成 。 HTML 正确性尽可能使用正确的 HTML。 12345678&lt;!-- Not recommended --&gt;&lt;title&gt;Test&lt;/title&gt;&lt;article&gt;This is only a test.&lt;!-- Recommended --&gt;&lt;!DOCTYPE html&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;title&gt;Test&lt;/title&gt;&lt;article&gt;This is only a test.&lt;/article&gt; 语义化根据使用场景选择正确的 HTML 元素（有时被错误的称为“标签”）。例如，使用 h1 元素创建标题，p 元素创建段落，a 元素创建链接等等。正确的使用 HTML 元素对于可访问性、可重用性以及编码效率都很重要。 1234&lt;!-- Not recommended --&gt;&lt;div onclick=&quot;goToRecommendations();&quot;&gt;All recommendations&lt;/div&gt;&lt;!-- Recommended --&gt;&lt;a href=&quot;recommendations/&quot;&gt;All recommendations&lt;/a&gt; 多媒体元素降级对于像图片、视频、canvas 动画等多媒体元素，确保提供其他可访问的内容。图片可以使用替代文本（alt），视频和音频可以使用文字版本。 1234&lt;!-- Not recommended --&gt;&lt;img src=&quot;spreadsheet.png&quot;&gt;&lt;!-- Recommended --&gt;&lt;img src=&quot;spreadsheet.png&quot; alt=&quot;Spreadsheet screenshot.&quot;&gt; 关注分离标记、样式和脚本分离，确保相互耦合最小化。 实体引用如果团队中文件和编辑器使用同样的编码方式，就没必要使用实体引用，如 &mdash; ， &rdquo; ， &#x263a; ，除了一些在 HTML 中有特殊含义的字符（如 &lt; 和 &amp;）以及不可见的字符（如空格）。 The currency symbol for the Euro is “&eur;”. The currency symbol for the Euro is “€”.type 属性在引用样式表和脚本时，不要指定 type 属性，除非不是 CSS 或 JavaScript。因为 HTML5 中已经默认指定样式变的 type 是 text/css，脚本的type 是 text/javascript。 HTML 格式规范HTML 引号属性值用双引号。 Sign inSign inCSS 风格规范ID 和 Class 命名使用有含义的 id 和 class 名称。 / Not recommended: meaningless / #yee-1901 {} / Not recommended: presentational / .button-green {} .clear {}/ Recommended: specific / #gallery {} #login {} .video {} / Recommended: generic / .aux {} .alt {}ID 和 Class 命名风格id 和 class 应该尽量简短，同时要容易理解。 / Not recommended / #navigation {} .atr {}/ Recommended / #nav {} .author {}选择器除非需要，否则不要在 id 或 class 前加元素名。 / Not recommended / ul#example {} div.error {}/ Recommended / #example {} .error {}属性简写尽量使用 CSS 中可以简写的属性 (如 font)，可以提高编码效率以及代码可读性。 / Not recommended / border-top-style: none; font-family: palatino, georgia, serif; font-size: 100%; line-height: 1.6; padding-bottom: 2em; padding-left: 1em; padding-right: 1em; padding-top: 0;/ Recommended / border-top: 0; font: 100%/1.6 palatino, georgia, serif; padding: 0 1em 2em;0 和单位值为 0 时不用添加单位。 margin: 0; padding: 0;开头的 0值在 -1 和 1 之间时，不需要加 0。 font-size: .8em;16进制表示法/ Not recommended / color: #eebbcc;/ Recommended / color: #ebc;前缀使用带前缀的命名空间可以防止命名冲突，同时提高代码可维护性。 .adw-help {} / AdWords / #maia-note {} / Maia /ID 和 Class 命名分隔符选择器中使用连字符可以提高可读性。 / Not recommended: does not separate the words “demo” and “image” / .demoimage {} / Not recommended: uses underscore instead of hyphen / .error_status {}/ Recommended / #video-id {} .ads-sample {}CSS 格式规范书写顺序按照属性首字母顺序书写 CSS 易于阅读和维护，排序时忽略带有浏览器前缀的属性。 background: fuchsia; border: 1px solid; -moz-border-radius: 4px; -webkit-border-radius: 4px; border-radius: 4px; color: black; text-align: center; text-indent: 2em;块级内容缩进为了反映层级关系和提高可读性，块级内容都应缩进。 @media screen, projection { html { background: #fff; color: #444; } }声明结束每行 CSS 都应以分号结尾。 / Not recommended / .test { display: block; height: 100px }/ Recommended / .test { display: block; height: 100px;}属性名结尾属性名和值之间都应有一个空格。 / Not recommended / h3 { font-weight:bold;}/ Recommended / h3 { font-weight: bold;}声明样式块的分隔在选择器和 {} 之间用空格隔开。 / Not recommended: missing space / #video{ margin-top: 1em;} / Not recommended: unnecessary line break / #video { margin-top: 1em;}/ Recommended / #video { margin-top: 1em;}选择器分隔每个选择器都另起一行。 / Not recommended / a:focus, a:active { position: relative; top: 1px;}/ Recommended / h1, h2, h3 { font-weight: normal; line-height: 1.2;}规则分隔规则之间都用空行隔开。 html { background: #fff;} body { margin: auto; width: 50%;}CSS 引号属性选择器和属性值用单引号，URI 的值不需要引号。 / Not recommended / @import url(“//www.google.com/css/maia.css”); html { font-family: “open sans”, arial, sans-serif;}/ Recommended / @import url(//www.google.com/css/maia.css); html { font-family: ‘open sans’, arial, sans-serif;}CSS 元规则分段注释用注释把 CSS 分成各个部分。 / Header / #adw-header {} / Footer / #adw-footer {} / Gallery / .adw-gallery {}结语坚持遵循代码规范。 写代码前先看看周围同事的代码，然后决定代码风格。 代码规范的意义在于提供一个参照物。这里提供了一份全局的规范，但是你也得参照公司内部的规范，否则阅读你代码的人会很痛苦。]]></content>
  </entry>
  <entry>
    <title><![CDATA[AIOps]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F08%2FAIOps%2F</url>
    <content type="text"><![CDATA[1）开始尝试应用AI能力，还无较成熟单点应用 2）具备单场景的AI运维能力，可以初步形成供内部使用的学件 3）有由多个单场景AI运维模块串联起来的流程化AI运维能力，可以对外提供可靠的运维AI学件 4）主要运维场景均已实现流程化免干预AI运维能力，可以对外提供可靠的AIOps服务。 5） 有核心中枢AI，可以在成本、质量、效率间从容调整，达到业务不同生命周期对三个方面不同的指标要求，可实现多目标下的最优或按需最优。 “学件”（Learnware）一词是南京大学周志华老师的原创，学件（Learnware）= 模型（model）+规约（specification），具有可重用、可演进、可了解的特性。 “可重用”的特性使得能够获取大量不同的样本； “可演进”的特性使得可以适应环境的变化； “可了解”的特性使得能有效地了解模型的能力。 +++++++ AIOps作为一个团队，由不同角色组成，一般有三种不同角色，他们是运维专家、数据科学家、智能运维研发工程师，以下介绍三种角色分工： 1）运维工程师 特征：具有丰富的运维领域知识、熟悉较为复杂的运维问题、具备解决运维难题能力。 职责：运用机器帮助运维人员完成基础性和重复性的基层运维工作；人工处理机器还不能处理好的运维难题；基于经验对于较为复杂的运维问题给出最终决策—不断训练机器。 2）运维数据工程师 特征：具备编程、数学、统计学、数据可视化、机器学习等能力。 职责： 致力于智能运维平台架构、模型标准、数据分析方法；不断应用最新的机器学习技术设计优化智能运维算法；监督智能运维系统性能并实施优化和改进。 3）运维开发工程师 特征：良好的开发语言基础、大数据处理技术能力。 职责：数据采集、自动化处理、实现和运用算法等。 一、稳定性：运维的本质就是维护系统的稳定性，如何能让系统平稳的运行，变更更加稳定，故障全面治理是首要考量的，所以稳定性方面的智能运维技术演进大致是： 异常检测(Reactive)-&gt; 根因分析(Root Cause Analysis)-&gt;根源定位(real time) -&gt; 故障自愈(auto-healing)-&gt; 故障预测(proactive) 无人值守发布中应用的是异常检测的算法，而智能故障定位需要用到的就是后两种技术。 二、效率：在稳定的基础上我们希望能看到极致的运维的效率，极低的运维成本。 智能运维的场景很多，在运维的每层都有用武之地。每个点的微创新的累积最终会给智能运维带来颠覆性的变化。真正实现这种专家经验和”拍脑袋“运维模式转变为基于算法和人工智能的自动化运维，最终走向无人化运维。 “无人化”当然短期内只是一个“自动化程度非常高的”的代名词，在可以看到的未来，“无人化”还是由人来干预或者参与的，尤其是故障处理。 其实自动化被叫做“自働化”更为合理， 人和机器更多是职能上的区别，需要优势互补，人不再做具体的操作了，由机器替代，但人依然是运维的灵魂，是运维的制定者和修改者，机器只是执行者，机器只是帮助人或者提醒人来完成运维操作。 Gartner Group 提出的 AIOps 中的 AI，其实是 Algorithmic IT 的缩写，而不是很多人以为的 Artificial Intelligence 的缩写，但不管是哪种写法，都意味着利用机器学习算法对线上运行的真实数据和日志等作出故障预判，从而执行相应的运维操作。 AIOps 可以说是自动化运维的升级版，所以并非 DevOps 的取代者，而是 DevOps 更高级别的落实者。 ChatOps 的理念由 DevOps 延伸而来，又结合 AI（人工智能）落地，可以说是人工智能和新型工作理念结合的产物。它也是一种新型智能工作方式，帮助团队利用 ChatBot 机器人使成员和各项辅助工具连接在一起，以沟通驱动的方式完成工作。同时解决人与人、人与工具、工具与工具之间的信息孤岛问题，从而有更高的工作效率和更好的协作体验。 2013 年，GitHub 在其内部最早开始推行 ChatOps，希望能以聊天的方式更容易更快速地去完成 DevOps 承载的工作。 ChatOps 主要由四个部分组成：自动化的理念、一个沟通承载平台、一系列连接人与工具的机器人，以及一些后台工具和服务（基础设施）。它不仅可以应用在技术团队中，还可以发展为适应不同种类团队的方法模型，这也是 ChatOps 这个概念提出的背景之一。随着全行业的发展和人力成本的攀升，ChatOps 也可以说是应用于全行业的 DevOps。]]></content>
  </entry>
  <entry>
    <title><![CDATA[asyncio篇]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F08%2Fasyncio%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Python 3.5添加了async和await这两个关键字，分别用来替换asyncio.coroutine和yield from。自此，协程成为新的语法，而不再是一种生成器类型了。 事件循环与协程的引入，可以极大提高高负载下程序的I/O性能。除此之外还增加了async with(异步上下文管理)、async for(异步迭代器)语法。特别说的是，在Python 3.6里面终于可以用异步生成器了！ 1.给一个函数添加了async关键字，就会把它变成一个异步函数。2.每个线程有一个事件循环，主线程调用asyncio.get_event_loop时会创建事件循环，你需要把异步的任务丢给这个循环的run_until_complete方法，事件循环会安排协同程序的执行。和方法名字一样，异步的任务完成方法才会就执行完成了。3.为了在asyncio中使用concurrent.futures的执行器，我这用到了run_in_executor，它可以接收要同步执行的任务。4.给task设置num属性，是因为后面的completed中的Future对象只包含结果，但是我们并不知道num是什么，所以hack了下，之后的例子中会有其他的方案，本文是给大家提供各种解题的思路，在合适的场景还是有用处的。5.await asyncio.wait(blocking_tasks)就是协同的执行那些同步的任务，直到完成。6.最后根据num找到和执行结果的对应关系，排序然后打印结果。 async/await是Python提供的异步编程API，而asyncio只是一个利用 async/await API进行异步编程的框架 现存的一些库其实并不能原生的支持asyncio（因为会发生阻塞或者功能不可用），比如requests，如果要写爬虫，配合asyncio的应该用aiohttp，其他的如数据库驱动等各种Python对应的库也都得使用对应的aioXXX版本了 简单的说，进程/线程是操作系统充当了EventLoop调度，而协程是自己用epoll进行调度。 协程是异步非阻塞的另外一种展现形式。Golang，Erlang，Lua协程都是这个模型。 协程之间的切换，往往是用户通过代码来显式指定的（跟各种 callback 类似），不需要内核参与，可以很方便的实现异步。 协程本质上也是异步非阻塞技术，它是将事件回调进行了包装，让程序员看不到里面的事件循环。程序员就像写阻塞代码一样简单。比如调用 client-&gt;recv() 等待接收数据时，就像阻塞代码一样写。实际上是底层库在执行recv时悄悄保存了一个状态，比如代码行数，局部变量的值。然后就跳回到EventLoop中了。什么时候真的数据到来时，它再把刚才保存的代码行数，局部变量值取出来，又开始继续执行。]]></content>
  </entry>
  <entry>
    <title><![CDATA[why-not-gevent]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F08%2Fwhy-not-gevent%2F</url>
    <content type="text"><![CDATA[在python 的并发编程领域 以前有tornado 后来有gevent python 在发展的过程当中 有过一些失败的修复CPython 的缺陷和提高性能的尝试，比如消除GIL（这么多年 这么多的大牛 没有一个解决的方案？？？） 也有成功的案例 比如 Pypy 协程 每个人都在谈论协程的好处 优点 为了KPI 强行上协程 并不可取。 Coroutine 也就是 corporate routine，直译为「协同的例程」，中文一般叫做「协程」, 实际上这个概念和进程与线程有相似之处, 因为linux线程就是所谓的「轻量级进程」。 gevent源码分析的描述当中 相同点:二者都是可以看做是一种执行流, 该执行流可以挂起,并且在将来又可以在 你挂起的地方恢复执行, 这实际上都可以看做是continuation, 我们来看看当我们挂 起一个执行流时我们要保存的东西：栈, 因为如果你不保存栈,那么局部变量你就无法恢复,同时函数的调用链你也无 法恢复,寄存器的状态: 这好理解, 比如说EIP,如果你不保存,那么你恢复执行流就不知道 到底执行哪一条指令, 在比如说ESP,EBP, 如果你不保存,那么你即便有完整的栈 你也不知道怎么用.这二者实际就是所谓的上下文,也可以说是continuation. 在执行流切换时必须保存 这两个东西, 内核调度进程时也是一回事. 不同点:执行流的调度者不同, 进程是内核调度, 而协程是在用户态调度, 也就是说进程 的上下文是在内核态保存恢复的,而协程是在用户态保存恢复的. 很显然用户态的 代价更低进程会被抢占,而协程不会,也就是说协程如果不主动让出CPU,那么其他的协程是不 可能得到执行机会,这实际和早期的操作系统类似,比如DOS, 它有一个yield原语, 一个进程调用yield,那么它就会让出CPU, 其他的进程也就有机会执行了, 如果一 个进程进入了死循环,那么整个系统也就挂起了,永远无法运行其他的进程了, 但 对协程而言,这不是问题对内存的占用不同,实际上协程可以只需要4K的栈就够了, 而进程占用的内存要大 的多.从操作系统的角度讲, 多协程的程序是单线程,单进程的 协程的优势在于 由开发者决定协程的切换，操作系统无法干预切换，且占用内存小的多。 Gevent是一种基于协程的Python网络库，它用到Greenlet提供的，封装了libevent事件循环的高层同步API。它让开发者在不改变编程习惯的同时，用同步的方式写异步I/O的代码。 gevent 缺点 Monkey-patching。中文「猴子补丁」，常用于对测试环境做一些hack。我个人不太喜欢这种「黑魔法」，因为如果其他人不了解细节，极为容易产生困惑。Gvanrossum说用它就是”patch-and-pray”，太形象了。由于Gevent直接修改标准库里面大部分的阻塞式系统调用，包括socket、ssl、threading和 select等模块，而变为协作式运行。但是我们无法保证你在复杂的生产环境中有哪些地方使用这些标准库会由于打了补丁而出现奇怪的问题，那么你只能祈祷（pray）了。其次，在Python之禅中明确说过：「Explicit is better than implicit.」，猴子补丁明显的背离了这个原则。最后，Gvanrossum说Stackless之父Christian Tismer也赞同他。 我喜欢显式的「yield from」 第三方库支持。得确保项目中用到其他用到的网络库也必须使用纯Python或者明确说明支持Gevent，而且就算有这样的第三方库，我还会担心这个第三方库的代码质量和功能性。 Greenlet不支持Jython和IronPython，这样就无法把gevent设计成一个标准库了。 建议py 3.6 之后 选择标准库 asyncio]]></content>
  </entry>
  <entry>
    <title><![CDATA[协程篇]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F05%2F%E5%8D%8F%E7%A8%8B%E7%AF%87%2F</url>
    <content type="text"><![CDATA[协程其实就是可以由程序自主控制的线程 在python里主要由yield 和yield from 控制，可以通过生成者消费者例子来理解协程 利用yield from 向生成器（协程）传送数据 传统的生产者-消费者是一个线程写消息，一个线程取消息，通过锁机制控制队列和等待，但一不小心就可能死锁。如果改用协程，生产者生产消息后，直接通过yield跳转到消费者开始执行，待消费者执行完毕后，换回生产者继续生产，效率极高123456789101112import asyncioasync def hello(): print(&quot;Hello world!&quot;) r = await asyncio.sleep(1) print(&quot;Hello again!&quot;)loop=asyncio.get_event_loop()loop.run_until_complete(hello()) 进程 启动多个进程 进程之间是由操作系统负责调用线程 启动多个线程 真正被CPU执行的最小单位实际是线程 开启一个线程 创建一个线程 寄存器 堆栈 关闭一个线程协程 本质上是一个线程 能够在多个任务之间切换来节省一些IO时间 协程中任务之间的切换也消耗时间,但是开销要远远小于进程线程之间的切换 在高IO的时候可以使用 例如爬虫, 爬虫需要请求很多url,使用协程可以让请求同时发出,而不会因为在等待一个url的请求响应而阻塞程序 基本上就是多线程适用的场景！！！ 不适用于高计算的环境, 因为在计算时cpu是一直工作的, 频繁的切换运行的程序,会白白增加切换程序的时间,导致计算效率下降]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程篇]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F05%2F%E8%BF%9B%E7%A8%8B%E7%AF%87%2F</url>
    <content type="text"><![CDATA[多线程并不能充分利用多核处理器，如果是一个CPU计算型的任务，应该使用多进程模块 multiprocessing 。它的工作方式与线程库完全不同，但是两种库的语法却非常相似。multiprocessing给每个进程赋予单独的Python解释器，这样就规避了全局解释锁所带来的问题。 12from multiprocessing import Poolfrom multiprocessing.dummy import Pool 分不清楚的情况下 进行测试 一般可以先直接上多进程 进程之间的通信 进程间的通信（IPC）常用的是rpc、socket、pipe（管道）和消息队列（queue）。多进程模块中涉及到了后面3种。 管道pipe 12345678910111213from multiprocessing import Process, Pipedef f(conn): conn.send([&apos;hello&apos;]) conn.close()parent_conn, child_conn = Pipe()p = Process(target=f, args=(child_conn,))p.start()print parent_conn.recv()p.join() queue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354import timefrom multiprocessing import Process, JoinableQueue, Queuefrom random import randomtasks_queue = JoinableQueue()results_queue = Queue()def double(n): return n * 2def producer(in_queue): while 1: wt = random() time.sleep(wt) in_queue.put((double, wt)) if wt &gt; 0.9: in_queue.put(None) print &apos;stop producer&apos; breakdef consumer(in_queue, out_queue): while 1: task = in_queue.get() if task is None: break func, arg = task result = func(arg) in_queue.task_done() out_queue.put(result)processes = []p = Process(target=producer, args=(tasks_queue,))p.start()processes.append(p)p = Process(target=consumer, args=(tasks_queue, results_queue))p.start()processes.append(p)tasks_queue.join()for p in processes: p.join()while 1: if results_queue.empty(): break result = results_queue.get() print &apos;Result:&apos;, result 1234567891011121314151617181920from multiprocessing import Queue, Process, cpu_countdef apply_func(f, q_in, q_out): while not q_in.empty(): i, item = q_in.get() q_out.put((i, f(item)))def parmap(f, items, nprocs = cpu_count()): q_in, q_out = Queue(), Queue() proc = [Process(target=apply_func, args=(f, q_in, q_out)) for _ in range(nprocs)] sent = [q_in.put((i, item)) for i, item in enumerate(items)] [p.start() for p in proc] res = [q_out.get() for _ in sent] [p.join() for p in proc] return [item for _, item in sorted(res)] 同步机制 multiprocessing的Lock、Condition、Event、RLock、Semaphore等同步原语和threading模块的机制是一样的，用法也类似， 进程之间共享状态 共享内存（value array） 服务器进程 常见的共享方式有以下几种： Namespace。创建一个可分享的命名空间。Value/Array。和上面共享ctypes对象的方式一样。dict/list。创建一个可分享的dict/list，支持对应数据结构的方法。Condition/Event/Lock/Queue/Semaphore。创建一个可分享的对应同步原语的对象。 123456789101112131415161718192021222324from multiprocessing import Manager, Processdef modify(ns, lproxy, dproxy): ns.a **= 2 lproxy.extend([&apos;b&apos;, &apos;c&apos;]) dproxy[&apos;b&apos;] = 0manager = Manager()ns = manager.Namespace()ns.a = 1lproxy = manager.list()lproxy.append(&apos;a&apos;)dproxy = manager.dict()dproxy[&apos;b&apos;] = 2p = Process(target=modify, args=(ns, lproxy, dproxy))p.start()print &apos;PID:&apos;, p.pidp.join()print ns.aprint lproxyprint dproxy 分布式进程通信 服务器端1234567891011121314151617from multiprocessing.managers import BaseManagerhost = &apos;127.0.0.1&apos;port = 9030authkey = &apos;secret&apos;shared_list = []class RemoteManager(BaseManager): passRemoteManager.register(&apos;get_list&apos;, callable=lambda: shared_list)mgr = RemoteManager(address=(host, port), authkey=authkey)server = mgr.get_server()server.serve_forever() 客户端12345678910111213141516171819from multiprocessing.managers import BaseManagerhost = &apos;127.0.0.1&apos;port = 9030authkey = &apos;secret&apos;class RemoteManager(BaseManager): passRemoteManager.register(&apos;get_list&apos;)mgr = RemoteManager(address=(host, port), authkey=authkey)mgr.connect()l = mgr.get_list()print ll.append(1)print mgr.get_list()]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程篇]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F05%2F%E7%BA%BF%E7%A8%8B%E7%AF%87%2F</url>
    <content type="text"><![CDATA[GIL是必须的，这是Python设计的问题：Python解释器是非线程安全的。这意味着当从线程内尝试安全的访问Python对象的时候将有一个全局的强制锁。 在任何时候，仅仅一个单一的线程能够获取Python对象或者C API。每100个字节的Python指令解释器将重新获取锁，这（潜在的）阻塞了I/O操作。因为锁，CPU密集型的代码使用线程库时，不会获得性能的提高（但是当它使用多进程库时，性能可以获得提高）。 那是不是由于GIL的存在，多线程库就是个「鸡肋」呢？当然不是。事实上我们平时会接触非常多的和网络通信或者数据输入/输出相关的程序，比如网络爬虫、文本处理等等。这时候由于网络情况和I/O的性能的限制，Python解释器会等待读写数据的函数调用返回，这个时候就可以利用多线程库提高并发效率了。 同步机制 信号量 123456789101112131415161718192021222324import timefrom random import randomfrom threading import Thread, Semaphoresema = Semaphore(3)def foo(tid): with sema: print &apos;&#123;&#125; acquire sema&apos;.format(tid) wt = random() * 2 time.sleep(wt) print &apos;&#123;&#125; release sema&apos;.format(tid)threads = []for i in range(5): t = Thread(target=foo, args=(i,)) threads.append(t) t.start()for t in threads: t.join() 锁 12345678910111213141516171819202122232425import timefrom threading import Thread, Lockvalue = 0lock = Lock()def getlock(): global value with lock: new = value + 1 time.sleep(0.001) value = newthreads = []for i in range(100): t = Thread(target=getlock) t.start() threads.append(t)for t in threads: t.join()print value 可重入锁 RLock acquire() 能够不被阻塞的被同一个线程调用多次。但是要注意的是release()需要调用与acquire()相同的次数才能释放锁。 条件 12345678910111213141516171819202122232425262728import timeimport threadingdef consumer(cond): t = threading.currentThread() with cond: cond.wait() # wait()方法创建了一个名为waiter的锁，并且设置锁的状态为locked。这个waiter锁用于线程间的通讯 print &apos;&#123;&#125;: Resource is available to consumer&apos;.format(t.name)def producer(cond): t = threading.currentThread() with cond: print &apos;&#123;&#125;: Making resource available&apos;.format(t.name) cond.notifyAll() # 释放waiter锁，唤醒消费者condition = threading.Condition()c1 = threading.Thread(name=&apos;c1&apos;, target=consumer, args=(condition,))c2 = threading.Thread(name=&apos;c2&apos;, target=consumer, args=(condition,))p = threading.Thread(name=&apos;p&apos;, target=producer, args=(condition,))c1.start()time.sleep(1)c2.start()time.sleep(1)p.start() event 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding=utf-8import timeimport threadingfrom random import randintTIMEOUT = 2def consumer(event, l): t = threading.currentThread() while 1: event_is_set = event.wait(TIMEOUT) if event_is_set: try: integer = l.pop() print &apos;&#123;&#125; popped from list by &#123;&#125;&apos;.format(integer, t.name) event.clear() # 重置事件状态 except IndexError: # 为了让刚启动时容错 passdef producer(event, l): t = threading.currentThread() while 1: integer = randint(10, 100) l.append(integer) print &apos;&#123;&#125; appended to list by &#123;&#125;&apos;.format(integer, t.name) event.set() # 设置事件 time.sleep(1)event = threading.Event()l = []threads = []for name in (&apos;consumer1&apos;, &apos;consumer2&apos;): t = threading.Thread(name=name, target=consumer, args=(event, l)) t.start() threads.append(t)p = threading.Thread(name=&apos;producer1&apos;, target=producer, args=(event, l))p.start()threads.append(p)for t in threads: t.join() 队列（示例为优先级队列） 123456789101112131415161718192021222324252627282930313233343536373839import timeimport threadingfrom random import randintfrom Queue import PriorityQueueq = PriorityQueue()def double(n): return n * 2def producer(): count = 0 while 1: if count &gt; 5: break pri = randint(0, 100) print &apos;put :&#123;&#125;&apos;.format(pri) q.put((pri, double, pri)) # (priority, func, args) count += 1def consumer(): while 1: if q.empty(): break pri, task, arg = q.get() print &apos;[PRI:&#123;&#125;] &#123;&#125; * 2 = &#123;&#125;&apos;.format(pri, arg, task(arg)) q.task_done() time.sleep(0.1)t = threading.Thread(target=producer)t.start()time.sleep(1)t = threading.Thread(target=consumer)t.start() 实现进程池12345678910111213141516171819202122232425262728293031323334353637383940414243444546# coding=utf-8import timeimport threadingfrom random import randomfrom Queue import Queuedef double(n): return n * 2class Worker(threading.Thread): def __init__(self, queue): super(Worker, self).__init__() self._q = queue self.daemon = True self.start() def run(self): while 1: f, args, kwargs = self._q.get() try: print &apos;USE: &#123;&#125;&apos;.format(self.name) # 线程名字 print f(*args, **kwargs) except Exception as e: print e self._q.task_done()class ThreadPool(object): def __init__(self, num_t=5): self._q = Queue(num_t) # Create Worker Thread for _ in range(num_t): Worker(self._q) def add_task(self, f, *args, **kwargs): self._q.put((f, args, kwargs)) def wait_complete(self): self._q.join()pool = ThreadPool()for _ in range(8): wt = random() pool.add_task(double, wt) time.sleep(wt)pool.wait_complete()]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react-learning-001]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F12%2F01%2Freact-learning-001%2F</url>
    <content type="text"><![CDATA[reactjavascript 是一种弱类型的语言 意味着可以修改变量值的数据类型。比如可以定义某个变量为字符串类型，然后将它的值改为数组。并不会对此类操作有任何异议，因此低效管理数据类型会导致花费大量时间在调试应用程序上。 react 为变量类型设置了自动属性验证的机制 类型 验证器 数组 React.PropTypes.array 布尔值 React.PropTypes.bool 函数 React.PropTypes.func 数字 React.PropTypes.number 对象 React.PropTypes.object 字符串 React.PropTypes.string 为组件提供三种属性 标题 食材成分数组 烹饪步骤数组 需要对属性进行验证 确保类型是正确的 无法通过属性验证时，提供默认参数 123456789101112131415161718192021222324252627282930313233const summary = createClass(&#123; displayName: "Summary", propTypes: &#123; ingredients: PropTypes.array.isRequired, steps: PropTypes.array.isRequired, title: (props, propName) =&gt; (typeof props[propName] != 'string') ? new Error("A title must be a string"): (props[propName].length &gt; 20) ? new Erroe('title is over 20 characters'): null &#125;, getDefaultProps() &#123; return &#123; ingredients:[a,b,c,d], steps: [1,2,3,4], title: "[recipe]" &#125; &#125;, render() &#123; const &#123; ingredients, steps, title &#125; = this.props return ( &lt;div className="summary"&gt; &lt;h1&gt;&#123;title&#125;&lt;/h1&gt; &lt;p&gt; &lt;span&gt;&#123;ingredients.length&#125; Ingredients&lt;/span&gt; &lt;span&gt;&#123;steps.length&#125; Steps&lt;/span&gt; &lt;/p&gt; &lt;/div&gt; ) &#125; &#125;) ES6 类时，propTypes defaultProps 是在类的实体之外定义的 一旦定义了类 就可以设置对象属性了。 引用ref 这个特性允许react组件能够和子元素交互 1234567891011121314151617181920212223242526272829import &#123; Component &#125; from 'react'class AddColorForm extends Component &#123; constructor(props) &#123; super(props) this.submit = this.submit.bind(this) &#125; submit(e) &#123; const &#123; _title, _color &#125; = this.refs e.preventDefault(); alert("New Color: $&#123;_title.value&#125; $&#123;_color.value&#125;") _title.value = ''; _color.value = '#000000'; _title.focus(); &#125; render() &#123; return ( &lt;form onSubmit=&#123;this.submit&#125;&gt; &lt;input ref="_title" type="text" placeholder="color title..." required/&gt; &lt;input ref="_color" type="color" required/&gt; &lt;button&gt;ADD&lt;/button&gt; &lt;/form&gt; ) &#125;&#125; 一个文本输入框和一个用于选择十六进制颜色值的按钮来渲染html元素]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-optimize000]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F29%2Flinux-optimize000%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[linux-optimize005]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F29%2Flinux-optimize005%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[linux-optimize004]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F29%2Flinux-optimize004%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[linux-optimize003]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F29%2Flinux-optimize003%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[linux-optimize002]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F29%2Flinux-optimize002%2F</url>
    <content type="text"><![CDATA[cpu 上下文切换设置好 cpu寄存器和程序计数器 依赖环境 因此叫做上下文 进程上下文切换 线程上下文切换 中断上下文切换 进程上下文切换linux 按照特权等级 将进程的运行空间分为内核空间和用户空间 内核空间ring 0 具有最高权限 可以直接访问所有资源 用户空间 ring 3 只能访问受限资源 不能直接访问内存等硬件设备 必须通过系统调用陷入到内核中 才能访问这些特权资源 进程既可以在用户空间运行 也可以在内核空间中运行 用户态 内核态 从用户态到内核态的转变 需要通过系统调用来完成。 比如查看文件内容的时候，需要多次系统调用来完成，首先open()打开文件 然后read 读取文件内容 write 将内容写到标准输出 最后再close关闭文件 系统调用的过程中 有cpu上下文的切换 cpu寄存器里原来用户态的指令位置 需要先保存起来 接着为了执行内核态代码 cpu寄存器需要更新为内核态的新位置 最后才是跳到内核态运行内核任务 系统调用恢复之后cpu寄存器需要恢复 需要再切换一次 一次系统调用 发生了两次上下文切换 系统调用 被称为特权模式切换 而不是上下文切换 进程的切换只能发生在内核态 因此进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态 进程的上下文切换 比系统调用多了一步 在保存当前进程的内核状态和cpu寄存器之前 需要先把该进程的虚拟内存、栈等保存起来 而加载下一进程的内核态之后 还需要刷新进程的虚拟内存和用户栈 进程一和进程二之间 包含进程1上下文保存和加载进程2上下文 每次上下文的切换 都需要几十纳秒到数微秒的cpu时间 这个时间还是相当可观的 线程和进程的最大区别在于 线程是调度的基本单位 而进程则是资源拥有的基本单位 进程只是給线程提供了虚拟内存、全局变量等资源 当进程只有一个线程时 可以认为进程就等于线程 线程会共享相同的虚拟内存和全局变量等资源 这些资源在上下文切换的时候 是不需要修改的 线程也有自己的私有数据 比如栈和寄存器 线程的切换 不属于同一进程的时候 因为资源不共享 所以切换和进程时一样的 属于同一进程 因为虚拟内存是共享的 只需要切换线程的私有数据结构 栈 寄存器这些不共享的数据 同进程内的线程切换 要比对进程之间的切换消耗更少的资源 这也是多线程代替多进程的一个优势 中断上下文切换 为了快速响应硬件的事件 中断处理会打断进程的正常调度和执行 转而调用中断处理程序 响应设备事件 中断上下文切换不涉及到进程的用户态 对同一个cpu来说 中断处理比进程拥有更高的优先级 cpu上下文切换 是保证linux系统正常工作的核心功能之一过多的上下文切换 会把cpu时间消耗在寄存器 内核栈 虚拟内存等数据结构的保存和恢复上 1vmstat 5 context switch interrupt r(running or runnable) b blocked 则是处于不可中断睡眠状态的进程数 1pidstat -w 5 1apt install sysbench 1sysbench --threads=10 --max-time=300 threads run 自愿上下文切换变多 说明进程都在等待资源 有可能发生了io等其他问题 非自愿上下文切换变多 说明进程都在被强制调度 都在争取cpu 中断次数变多说明cpu被中断处理程序占用 还需要通过查看 /proc/interrupts 具体问题具体分析]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-optimize001]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F29%2Flinux-optimize001%2F</url>
    <content type="text"><![CDATA[什么是平均负载？如何彻底理解现象背后的本质原理，用起来更加灵活，也更有底气。 uptime 命令 每一列的输出含义 当前时间 系统运行时间 正在登录的用户数 依次是过去一分钟 五分钟 15分钟的平均负载 平均负载是其实简单理解 就是平均活跃进程数 平均负载为2 时 代表什么？ 在2核的cpu的系统上 代表所有的cpu都刚好被完全占用 在4核的cpu的系统上 代表有50%的空闲 在1核的cpu的系统上 意味着有一半的进程竞争不到cpu 那么 平均负载为多少时合理？一般而言 最理想的情况是等于cpu的个数 首先得知道系统有几个cpu 1grep &apos;model name&apos; /proc/cpuinfo | wc -l 有了cpu的个数 可以判断出平均负载比cpu的个数还大的时候，系统已经出现了过载。 一半当平均负载高于cpu数量70%的时候，就应该分析排查负载高的问题了 平均负载是单位时间内，处于可运行状态和不可中断状态的进程数，因此不止包括了正在使用cpu的进程，还包括等待cpu和等待io的进程 cpu使用率 是单位时间内cpu繁忙情况的统计 跟平均负载并不一定完全对应 cpu密集型时 两者一致 io密集时 等待io也会导致平均负载很高 但是cpu使用率不一定很高 大量等待cpu的进程调度也会导致平均负载升高，此时的cpu使用率也会比较高 善于使用工具使用iostat mpstat pidstat 等工具 找到平均负载升高的根源在哪里 1apt install stress sysstat -y 压力测试工具 异常进程模拟平均负载升高的场景 1stress --cpu 1 --timeout 600 1watch -d uptime 1mpstat -P ALL 5 1pidstat -u 5 1 1stress -i 1 --timeout 600 模拟大量进程 1stress -c 8 --timeout 600 iowait 无法升高的原因 是因为使用的是sync()系统调用 作用是刷新缓冲内存到磁盘中 可以使用下一代 stress-ng htop atop 命令 也可以使用]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-212]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F27%2Fleetcode-212%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from collections import defaultdictdx = [-1, 1, 0, 0]dy = [0, 0, -1, 1]END_OF_WORD = &quot;#&quot;class Solution(object): def findWords(self, board, words): if not board or not board[0]: return [] if not words: return [] self.result = set() root = defaultdict() for word in words: node = root for char in word: node = node.setdefault(char, defaultdict()) node[END_OF_WORD] = END_OF_WORD self.m, self.n = len(board), len(board[0]) for i in xrange(self.m): for j in xrange(self.n): if board[i][j] in root: self._dfs(board, i, j, &quot;&quot;, root) return list(self.result) def _dfs(self, board, i, j, cur_word, cur_dict): cur_word += board[i][j] cur_dict = cur_dict[board[i][j]] if END_OF_WORD in cur_dict: self.result.add(cur_word) tmp, board[i][j] = board[i][j], &quot;@&quot; for k in xrange(4): x, y = i + dx[k], j + dy[k] if 0 &lt;= x &lt; self.m and 0 &lt;= y &lt; self.n \ and board[x][y] != &quot;@&quot; and board[x][y] in cur_dict: self._dfs(board, x, y, cur_word, cur_dict) board[i][j] = tmp]]></content>
  </entry>
  <entry>
    <title><![CDATA[oracle-django-研发记录]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F11%2F14%2Foracle-django-%E7%A0%94%E5%8F%91%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[123oracle-instantclient12.1-basic-12.1.0.2.0-1.x86_64.rpmoracle-instantclient12.1-devel-12.1.0.2.0-1.x86_64.rpmoracle-instantclient12.1-sqlplus-12.1.0.2.0-1.x86_64.rpm 三个客户文件是否都需要安装 每个到底做了什么]]></content>
  </entry>
  <entry>
    <title><![CDATA[架构设计的学习]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F16%2F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"></content>
      <categories>
        <category>architecture</category>
      </categories>
      <tags>
        <tag>general</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis在web中的应用]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F16%2Fredis%E5%9C%A8web%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列08]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9708%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列07]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9707%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列06]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9706%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列05]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9705%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列04]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9704%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列03]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9703%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列02]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9702%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819mysql -u user -p passwdshow databases;create databases databasename;drop databases databasename;use databasename;show tables;create table tablename (column_name column_type);drop table tablename;rename table tablename1 to tablename2;alter table tablename1 rename to tablename2;truncate table tablename; 清空 此句效率最高 普遍来说 crud boy 指的是基本的 增查（读）改删 mysql 基本的数据类型 数值型（integer smallint decimal numeric） 近似数值（float real double precision） 日期类型 datetime date timestamp time year 字符串类型 char varchar binary varbinary blob text enum 枚举 set 空间数据类型（空间类型使用 个人感觉还是 pg 好一些） json支持由RFC 7159 规定的原生json数据类型 json列不能有默认值 mysql 的常见问题 索引有哪些类型？（扩展） 索引的原理]]></content>
  </entry>
  <entry>
    <title><![CDATA[mysql系列01]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fmysql%E7%B3%BB%E5%88%9701%2F</url>
    <content type="text"><![CDATA[mysql 用户 相关 操作 mysql创建用户和授权1.创建用户： (注意：下面的指令，请在root用户下输入) CREATE USER &quot;用户名&quot; IDENTIFIED BY &quot;密码&quot;; 如果要限制地址登录：例如只允许本地的用户登录@localhost CREATE USER 用户名@地址 IDENTIFIED BY &apos;密码&apos;; 当mysql创建完用户之后，需要对该用户进行授权。授权之后，改用户才能有执行命令的权利！ 2.授权 GRANT ALL PRIVILEGES ON 数据库.* TO &apos;用户名&apos;@&apos;登录主机&apos; IDENTIFIED BY &quot;密码&quot;; grant select,insert,update,delete on . to test1@”%” Identified by “abc”; 格式：grant select on 数据库.* to 用户名@登录主机 identified by “密码” 如果想授权用户可以操作所有的数据：.(数据库写为：*) 如果不限制登录主机：’用户名’@’%’(登录主机写为：%) FLUSH PRIVILEGES; 3. 数据库： 物理操作系统文件或者其他形式文件类型的集合 NDB引擎的时候，可能是存放在内存之中的文件 实例： 由后台线程以及一个共享内存区组成 mysql 是单进程多线程架构的数据库 实例在系统上的表现就是一个进程 读取配置文件的顺序 1234/etc/my.cnf/etc/mysql/my.cnf/usr/local/mysql/etc/my.cnf~/.my.cnf 读取到的最后一个配置文件中的参数为准 也就是说会覆盖 数据库所在的路径 默认为 /usr/local/mysql/data 实际上 是一个 链接 指向的是 /opt/mysql_data 目录 实际上很多会问一下 myisam innodb 引擎的对比 innodb 特点 支持行锁、支持mvcc 支持外键 提供一致性非锁定读 5.5.8版本开始为默认引擎 表示目前是最优选择 各个引擎各有优点 innodb 是多线程的模型 后台有多个不同的后台线程 复杂处理不同的任务 master thread 是一个非常核心的后台线程 主要负责将缓存池里的数据异步刷新到磁盘，保证数据的一致性。包括脏页的刷新、合并插入缓冲、undo页的回收等 io thread 大量使用async io来处理io请求 这样可以极大提高数据库的性能 purge thread 主要用来回收已经使用并分配的undo页 page cleaner thread 将脏页的刷新操作都放入到单独的线程来完成]]></content>
  </entry>
  <entry>
    <title><![CDATA[django model peewee的一些思考]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F12%2Fdjango-model-peewee%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83%2F</url>
    <content type="text"></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis入坑到放弃]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F09%2Fredis%20%E5%85%A5%E5%9D%91%E5%88%B0%E6%94%BE%E5%BC%83%2F</url>
    <content type="text"><![CDATA[传统来说 redis 能够做什么？远程内存数据库 不仅性能强劲 而且还有复制特性以及为解决各种问题而生的独一无二的数据结构（致力于帮助用户解决问题，而不会像其他数据库那样，要求用户扭曲问题来适应数据库）。 同时 复制 持久化 客户端分片等特性 可以很快将redis 进行扩展成一个包含数百GB的数据、每秒处理上百万次请求的系统 服务器被关闭的时候 数据咋办？ redis 提供两种不同形式的持久化方案 一是时间点转储 二是只追加文件（append-only） 工具会极大形式地改变人们解决问题的方式但是不能盲目地只是使用工具 还要弄清楚工具的工作原理 优劣 能否有改进的地方 这些都是很有必要的redis VS memcached使用redis 存储聚合数据有三个好处： 将彼此相关的聚合数据放在同一个结构当中，这样访问数据就会变得更为容易； 将聚合数据放到有序集合里，构建出一个实时排行榜 聚合数据可以是整数或者浮点数 而memcached 只能是整数型的 数据结构： 字符串 一个常见的用途就是 缓存用户信息。 将用户信息结构体使用json 序列化 字符串，然后将序列化后的字符串塞进redis缓存。同样，取用户信息会经过一次反序列化的过程。 redis 的字符串 是动态字符串，是可以修改的字符串，内部结构实现上类似java 的 arraylist，采用预分配冗余空间的方式来减少内存的频繁分配 过期和 set 命令扩展 可以对key 设置过期时间，到点自动删除。这个功能常用来控制缓存的实效时间。 计数功能： 如果value 是一个值， 还可以进行自增操作，自增是有范围的，它的范围是signed long 的最大最小值，超过了这个值 redis 会报错 字符串 是 由多个字节组成的，每个字节又是由8个bit组成，因此也可看成很多bit 的组合，这便是bitmap（位图）数据结构 列表 相当与 java 中的 linkedlist 注意它是链表而不是数组 意味着插入和删除非常快 索引定位很慢 redis 的列表 常用来做异步队列使用 将需要延后处理的任务结构体 序列化成字符串 塞进 redis 的列表，另一个线程从这个列表中轮询数据进行处理 右进左出 队列 右边进 右边出 栈 慢操作 index 相当于 java 链表的 get(int index) 方法 它需要对链表进行遍历 性能随着参数index 增大而变差 ltrim 和字面上的含义不太一样，定义了一个区间 在这个区间内的值要保留 区间之外的统统砍掉 可以使用ltrim 来实现一个定长的链表 这一点非常有用 index=-1 表示倒数第一个元素 redis 底层存储的还不是一个 简单的 linkedlist 而是一个快速链表 quicklist 的结构 首先在列表元素较少的情况下 使用一块连续的内存存储 这个结构是ziplist 也即是压缩列表 所有的元素紧挨着一起存储 分配的是一块连续的内存 当数据量比较多的时候 才会改成 quicklist 因为普通的链表需要的附加指针空间太大，会比较浪费空间 而且会加重内存的碎片化 比如这个列表存的只是int 类型的数据 结构上还需要两个额外的指针prev 和 next 所以redis 将链表和ziplist 结合起来 组成了quicklist 也就是将多个ziplist 使用双指针串起来使用，这样既满足了快速的插入删除性能 也不会出现太大的空间冗余 字典（散列） 相当于 java 中的 hashmap 是无序字典 内部实现也是一样 同样的数组+链表二维结构 第一维hash 的数组位置碰撞时 就会将碰撞的元素使用链表串接起来 不同的是 redis 中的字典 只能是字符串另外它们 rehash的方式 不一样 java的 hashmap 在字典很大的时候 rehash 是一个耗时的操作 需要一次性 rehash redis 为了提高性能 不能阻塞服务 采用了渐进式rehash 的策略 渐进式 rehash 会在rehash 的同时 保留新旧两个hash 结构 查询时会同时查询两个hash 结构 查询时会同时查询两个hash 结构 然后在后续的定时任务中 以及hash 操作指令中 循序渐进地将旧hash 的内容一点点迁移到新的hash 结构中 当搬迁完成了 就会用新的hash 结构取而代之 当hash 移除了最后一个元素 该数据结构自动被删除 内存被回收 集合 set 集合和列表都可以存储多个字符串 集合通过不同的散列表来保证自己存储的每个字符串都是各不相同的（散列表只有键 没有与键相关联的值）集合是无序的 因此 基本的几个命令为 sadd srem smembers sismember 集合常见操作 还有 并集 交集 差集 有序集合 zset 有序集合和字典一样 都用于存储键值对 ； 有序集合的值被称为分值（score），分值必须为浮点数。 有序集合是redis中唯一一个既可以根据成员访问元素 又可以根据分值以及分值的排列顺序来访问元素的结构 有序集合命令 zadd zrem zrange(根据元素在有序排列中所处的位置，从有序集合里面获取多个元素) zrangebyscore(获取有序集合在給定分值范围内的所有元素) 计数器 （数据搜集 指标量化） 计数器的更新 清理旧计数器 存储统计数据 查找ip所属城市以及国家（关系映射）redis 的配置信息在线配置 一个标志位 web服务器是否在进行维护 为每个独立部分都分别运行一个redis服务器，比如专门负责记录日志、统计数据、专门进行缓存、存储cookies等 一台机器上是可以运行多个redis服务器的 只要端口号各不相同 就可以了 自动连接redis管理 自动补全的实现 分布式锁 一般对数据加锁 首先acquire 然后 release 对于多个线程访问的共享内存数据结构来说，这种先获取锁，然后执行操作，最后释放锁的动作非常常见。redis 使用watch 命令来代替对数据进行加锁 （乐观锁）]]></content>
  </entry>
  <entry>
    <title><![CDATA[hadoop 3.0实践]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F10%2F01%2Fhadoop-3-0%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[本地是使用mac air 做的基础尝试 使用的 是 3.0.0 的版本 /usr/local/Cellar/hadoop/3.0.0/libexec/etc/hadoop 主要都在这个目录下 1.配置hadoop-env.sh java_home路径 2.core-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 3.hdfs-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 4.mapred-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5.yarn-site.xml 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt; &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 6 格式化文件系统 bin/hdfs namenode -format 启动 namenode 和 datanode sbin/start-dfs.sh 节点可在 9870端口查看 让 HDFS 可以被用来执行 MapReduce jobs： bin/hdfs dfs -mkdir /user bin/hdfs dfs -mkdir /user/root 启动 resourcemanager 和 nodemanager sbin/start-yarn.sh 端口 8088]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python量化风控]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F29%2Fpython%E9%87%8F%E5%8C%96%E9%A3%8E%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[python在风控领域，本身业界能熟悉从底层编译原理又到金融模型算法，又到机器学习都精通的人员参数并不多，需要能迅速适应和连接各大数据和金融领域的语言。 目前没有公开的行业标准状态，需要建立最适合自己的管理方式 产品形态多变，需求多变，需要找到切合的开发语言 核心模块，需要加快速度的 使用C 或者 C++完成 GIL。这个问题不该你去考虑，有这瞎想的时间，关键点已经用C++完成了。 过早优化是罪恶之源 Donald Knuth前期开发需要把注意力放在功能实现以及代码的可读性和维护上 风控不出事，觉得浪费成本；出了事情，还知道重要性！核心是如何做好风控 web安全相关 要重视安全问题]]></content>
  </entry>
  <entry>
    <title><![CDATA[linux常用命令总结]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F28%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[ssh123ssh-keygen -t rsassh-copy-id -i ~/.ssh/id_rsa.pub root@192.168.1.101 文件相关操作系统相关]]></content>
  </entry>
  <entry>
    <title><![CDATA[协程的探索]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E5%8D%8F%E7%A8%8B%E7%9A%84%E6%8E%A2%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[协程：又称微线程，在单线程上执行多个任务，用函数切换，开销极小。不通过操作系统调度，没有进程、线程的切换开销。genvent，monkey.patchall 多线程请求返回是无序的，那个线程有数据返回就处理那个线程，而协程返回的数据是有序的。 缺陷：单线程执行，处理密集CPU和本地磁盘IO的时候，性能较低。处理网络I/O性能还是比较高. 使用gevent 或者是python3.6 及以上的asyncio 问题： 什么场景下使用协程反而会更差的性能？ 123456789101112131415161718192021def consumer(): r = &apos;&apos; while True: n = yield r if not n: return print(&apos;[CONSUMER] Consuming %s...&apos; % n) r = &apos;200 OK&apos;def produce(c): c.send(None) n = 0 while n &lt; 5: n = n + 1 print(&apos;[PRODUCER] Producing %s...&apos; % n) r = c.send(n) print(&apos;[PRODUCER] Consumer return: %s&apos; % r) c.close()c = consumer()produce(c) 新的写法 1234567891011import asyncioasync def hello(): print(&quot;Hello world!&quot;) r = await asyncio.sleep(1) print(&quot;Hello again!&quot;) loop=asyncio.get_event_loop()loop.run_until_complete(hello()) 协程不是趋势，它是一个在历史中被挖掘出来的、对现有问题的一个有用的补充。 适用的场景： 高性能计算，牺牲公平性换取吞吐； 面向 IO Bound 任务，减少 IO 等待上的闲置，这其实和高性能计算领域内的优势是一致的； Generator 式的流式计算； 消除 Callback Hell，使用同步模型降低开发成本的同时保留更灵活控制流的好处，比如同时发三个请求；这时节约地使用栈，可以充分地发挥 “轻量” 的优势； 但并不是万灵丹： 如果栈使用得不节制，消耗的内存量和系统线程无异，甚至内存管理还不如系统线程（系统线程可以动态地调整虚拟内存，用户线程的 Segmented Stack 方案存在严重的抖动问题，Continous Stack 方案管理不当也会抖动，为了避免抖动则成了空间换时间，而内核在这方面做了多少 heuristic 呢）； IO Bound 任务可以通过调线程池大小在一定程度上缓解，目标是把 CPU 跑满即可，这点线程池的表现可能不完美，但在业务逻辑这个领域是及格的； 此外，一般的 python/ruby 任务并不是严格的 IO Bound，比如 ORM 的对象创建、模版渲染、GC 甚至解释器本身，都是 CPU 大户；单个请求扣去 redis 请求和数据库请求的时间，其它时间是否仍不少呢？ CPU 上长时间的计算，导致用户线程的调度变差，不能更快地响应，单个请求的平均时间反而可能更长（诚然并发可能更高）；然而这在 python 这类 GIL 语言来看并不算劣势，甚至比 GIL 的调度更好，至少 gevent 可以知道各 IO 任务的优先级，而 GIL 的调度是事实上的 FIFO；]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现08-模板模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B008-%E6%A8%A1%E6%9D%BF%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现07-访问者模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B007-%E8%AE%BF%E9%97%AE%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现06-观察者模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B006-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现05-外观模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B005-%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现04-代理模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B004-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现03-适配器模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B003-%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现02-单例模式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B002-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1234567class Borg(object): _state = &#123;&#125; def __new__(cls, *args, **kwargs): ob = super().__new__(cls, *args, **kwargs) ob.__dict__ = cls._state return ob]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式python实现]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8Fpython%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[from abc import ABCMeta class StandardFactory(object): &apos;&apos;&apos;这就是那个抽象工厂&apos;&apos;&apos; @staticmethod def get_factory(factory): &apos;&apos;&apos;根据参数找到对实际操作的工厂&apos;&apos;&apos; if factory == &apos;cat&apos;: return CatFactory() elif factory == &apos;dog&apos;: return DogFactory() raise TypeError(&apos;Unknown Factory.&apos;) class DogFactory(object): def get_pet(self): return Dog(); class CatFactory(object): # 注意这个方法和上面的名字一样，但是返回的类不同，这就是工厂的作用 def get_pet(self): return Cat(); # 可以认为dog和cat都是动物的一种，可以有个基类 class Pet(object): # ABCMeta会让这个类在注册后添加很多基础抽象基类，可以看[ABCMeta](http://docs.python.org/2/library/abc.html#abc.ABCMeta) __metaclass__ = ABCMeta def eat(self): pass # Dog应该做什么就是这里 class Dog(Pet): def eat(self): return &apos;Dog food...&apos; class Cat(Pet): # 这里的eat依然是同名，她们都是同样的操作，只是返回不同 def eat(self): return &apos;Cat food...&apos; if __name__ ==&quot;__main__&quot;: factory = StandardFactory.get_factory(&apos;cat&apos;) pet = factory.get_pet() print pet.eat() # 注意这里，你只需要修改抽象工厂传入的那个参数，其他什么都不用改 factory = StandardFactory.get_factory(&apos;dog&apos;) pet = factory.get_pet() print pet.eat()]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python高级工程师职责]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F25%2Fpython%E9%AB%98%E7%BA%A7%E5%B7%A5%E7%A8%8B%E5%B8%88%E8%81%8C%E8%B4%A3%2F</url>
    <content type="text"><![CDATA[1.数据驱动的方式来赋能和驱动行业发展 2.大数据平台的设计和开发 3.人工智能等前沿技术 4.tensorflow如何落地 地产生态链“互联网+”服务商 明源云客 房地产营销互联网智慧化转型升级解决方案提供商 云链 地产供应链的上下游各方及业务场景在线化 云空间 云租赁、云物业等互联网产品平台 结合一些开源软件 实现自己的需求（对接目前项目的需求） 完成需要的逻辑]]></content>
  </entry>
  <entry>
    <title><![CDATA[need-learning]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F12%2Fneed-learning%2F</url>
    <content type="text"><![CDATA[需要重点研究不太擅长的技术： 分布式 高并发 大数据量 数据库优化 高性能 负载均衡 深度学习的图片处理]]></content>
  </entry>
  <entry>
    <title><![CDATA[深度学习的核心组件]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F12%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[1.张量2.基于张量的操作3.计算图和优化4.自动微分工具5.BLAS/cuBLAS和cuDNN的扩展 简单说 张量是n维矩阵的概括，可以简单认为是n维数组。（rgb位图是高 宽 通道数 的三维张量，2583203） 作为扩展 100张图片 可以表示为4d张量 前面第一个是图像的id 张量对象以张量形式存储数据，numpy.imread imsave将图像作为ndarrays 读取并将ndarrays存储为图像。 神经网络可以被认为是在输入张量上执行一系列操作以给出输出，学习是通过纠正网络产生的输出和预期输出的误差来完成的，这些操作可能很简单，如矩阵乘法（sigmoid）或者更复杂，如卷积、池化或者LSTM]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[binary_search_tree]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F11%2Fbinary-search-tree%2F</url>
    <content type="text"><![CDATA[对树节点 二叉搜索树的简单抽象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179# -*- coding: utf-8 -*-class TreeNode(object): def __init__(self, key, value, parent=None, left_node=None, right_node=None, balance_factor=0): self.key = key self.payload = value self.left_child = left_node self.right_child = right_node self.parent = parent self.balance_factor = balance_factor def has_left_child(self): return self.left_child def has_right_child(self): return self.right_child def is_left_child(self): return self.parent and self.parent.left_child == self def is_right_child(self): return self.parent and self.parent.right_child == self def is_root(self): return not self.parent def is_leaf(self): return not (self.right_child or self.left_child) def has_any_children(self): return self.right_child or self.left_child def has_both_children(self): return self.right_child or self.left_child def replace_node_data(self, key, value, lc, rc): self.key = key self.payload = value self.left_child = lc self.right_child = rc if self.has_left_child(): self.left_child.parent = self if self.has_right_child(): self.right_child.parent = selfclass BinarySearchTree(object): def __init__(self): self.root = None self.size = 0 def length(self): return self.size def __len__(self): return self.size # 中序遍历 def in_order(self, node): if node.left_child: self.inorder(node.left_child) self.print_node(node) if node.right_child: self.inorder(node.right_child) def level_order(self, node): nodes = [] nodes.append(node) while len(nodes) &gt; 0: current_node = nodes.pop(0) self.print_node(current_node) if current_node.left_child: nodes.append(current_node.left_child) if current_node.right_child: nodes.append(current_node.right_child) def print_node(self, node): if node.parent: print([node.key, node.payload, node.parent.key]) else: print([node.key, node.payload]) # --------------------- 插入节点 ---------------- def put(self, key, value): if self.root: self._put(key, value, self.root) else: self.root = TreeNode(key, value) self.size += 1 def _put(self, key, value, current_node): if key &lt; current_node.key: if current_node.has_left_child(): self._put(key, value, current_node.left_child) else: current_node.left_child = TreeNode(key, value, parent=current_node) else: if current_node.has_right_child(): self._put(key, value, current_node.right_child) else: current_node.right_child = TreeNode(key, value, parent=current_node) # --------------------- 插入节点 ---------------- def __setitem__(self, key, value): self.put(key, value) # --------------------- 删除节点 ---------------- def find_min(self): # Gets minimum node (leftmost leaf) in a subtree current_node = self while current_node.left_child: current_node = current_node.left_child return current_node def replace_node_in_parent(self, new_value=None): if self.parent: if self == self.parent.left_child: self.parent.left_child = new_value else: self.parent.right_child = new_value if new_value: new_value.parent = self.parent def binary_tree_delete(self, key): if key &lt; self.key: self.left_child.binary_tree_delete(key) elif key &gt; self.key: self.right_child.binary_tree_delete(key) else: # delete the key here if self.left_child and self.right_child: # if both children are present successor = self.right_child.find_min() self.key = successor.key successor.binary_tree_delete(successor.key) elif self.left_child: # if the node has only a *left* child self.replace_node_in_parent(self.left_child) elif self.right_child: # if the node has only a *right* child self.replace_node_in_parent(self.right_child) else: # this node has no children self.replace_node_in_parent(None) # --------------------- 删除节点 ---------------- def get(self, key): if self.root: res = self._get(key, self.root) if res: return res.payload else: return None else: return None def _get(self, key, current_node): if not current_node: return None elif current_node.key == key: return current_node elif key &lt; current_node.key: return self._get(key, current_node.left_child) else: return self._get(key, current_node.right_child)def run(): print(&apos;test bst&apos;) mytree = BinarySearchTree() mytree[3] = &quot;red&quot; mytree[4] = &quot;blue&quot; mytree[2] = &quot;rat&quot; mytree[5] = &quot;cat&quot; mytree[1] = &quot;dog&quot; mytree.level_order(mytree.root)if __name__ == &apos;__main__&apos;: run()]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉搜索树的处理]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F11%2F%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[一种特殊的二叉树，它满足下面的性质：任何一个节点的key值都比它左子树上的节点的key值要大，但是比它右子树上的节点的key值要小。节点查找，插入，删除等操作的时间复杂度都是O(lgn)]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ansible-自定义模块开发]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F11%2Fansible-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9D%97%E5%BC%80%E5%8F%91%2F</url>
    <content type="text"><![CDATA[Ansible就没有 ansible_private_ipv4_address 这样一个Facts，用来保存私网IP地址。 而我们恰恰就需要这样的一个Facts，因为我们有很多服务器的默认网卡并非是eth0，有的是bond0，eth1，em0，em1等，而公网IP地址与私网IP地址也并没有固定的绑定在某个网卡上，很多时候还是虚拟网卡。 还好，我们可以通过编写Ansible模块并自定义Facts来实现。 1234567891011121314151617181920212223242526272829303132333435363738394041#!/usr/bin/python import jsonimport commandsimport re def get_ansible_private_ipv4_address(): iprex = &quot;(^192\.168)|(^10\.)|(^172\.1[6-9])|(^172\.2[0-9])|(^172\.3[0-1])&quot; output = commands.getoutput(&quot;&quot;&quot;/sbin/ifconfig |grep &quot;Link encap&quot; |awk &apos;&#123;print $1&#125;&apos; |grep -wv &apos;lo&apos;&quot;&quot;&quot;) nics = output.split(&apos;\n&apos;) for i in nics: ipaddr = commands.getoutput(&quot;&quot;&quot;/sbin/ifconfig %s |grep -w &quot;inet addr&quot; |cut -d: -f2 | awk &apos;&#123;print $1&#125;&apos;&quot;&quot;&quot; % (i)) if re.match(iprex,ipaddr): ansible_private_ipv4_address = ipaddr return ansible_private_ipv4_address def main(): global module module = AnsibleModule( argument_spec = dict( get_facts=dict(default=&quot;yes&quot;, required=False), ), supports_check_mode = True, ) ansible_facts_dict = &#123; &quot;changed&quot; : False, &quot;ansible_facts&quot;: &#123; &#125; &#125; if module.params[&apos;get_facts&apos;] == &apos;yes&apos;: ansible_private_ipv4_address = get_ansible_private_ipv4_address() ansible_facts_dict[&apos;ansible_facts&apos;][&apos;ansible_private_ipv4_address&apos;] = ansible_private_ipv4_address print json.dumps(ansible_facts_dict) from ansible.module_utils.basic import *from ansible.module_utils.facts import *main()]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow-interview-problem]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F10%2Ftensorflow-interview-problem%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import numpy as np import pandas as pd import tensorflow as tf NUM_DIGITS = 10def binary_encode(i, num_digits): return np.array([i &gt;&gt; d &amp; 1 for d in range(num_digits)])def fizz_buzz_encode(i): if i % 15 == 0: return np.array([0, 0, 0, 1]) elif i % 5 == 0: return np.array([0, 0, 1, 0]) elif i % 3 == 0: return np.array([0, 1, 0, 0]) else: return np.array([1, 0, 0, 0])train_X = np.array([binary_encode(i, NUM_DIGITS) for i in range(101, 2 ** NUM_DIGITS)])train_y = np.array([fizz_buzz_encode(i) for i in range(101, 2 ** NUM_DIGITS)])def init_weights(shape): return tf.Variable(tf.random_normal(shape, stddev=0.01))# Our model is a standard 1-hidden-layer multi-layer-perceptron with ReLU# activation. The softmax (which turns arbitrary real-valued outputs into# probabilities) gets applied in the cost function.def model(X, w_h, w_o): h = tf.nn.relu(tf.matmul(X, w_h)) return tf.matmul(h, w_o) # Our variables. The input has width NUM_DIGITS, and the output has width 4.X = tf.placeholder(&quot;float&quot;, [None, NUM_DIGITS])Y = tf.placeholder(&quot;float&quot;, [None, 4]) # How many units in the hidden layer.NUM_HIDDEN = 100 # Initialize the weights.w_h = init_weights([NUM_DIGITS, NUM_HIDDEN])w_o = init_weights([NUM_HIDDEN, 4]) # Predict y given x using the model.py_x = model(X, w_h, w_o) # We&apos;ll train our model by minimizing a cost function.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=py_x, labels=Y))# print(&quot;cost is: &quot;, cost)train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost) # And we&apos;ll make predictions by choosing the largest output.predict_op = tf.argmax(py_x, 1) # Finally, we need a way to turn a prediction (and an original number)# into a fizz buzz outputdef fizz_buzz(i, prediction): return [str(i), &quot;fizz&quot;, &quot;buzz&quot;, &quot;fizzbuzz&quot;][prediction] BATCH_SIZE = 128 # Launch the graph in a sessionwith tf.Session() as sess: tf.initialize_all_variables().run() # how many times for train? for epoch in range(10000): # Shuffle the data before each training iteration. p = np.random.permutation(range(len(train_X))) train_X, train_y = train_X[p], train_y[p] # Train in batches of 128 inputs. for start in range(0, len(train_X), BATCH_SIZE): end = start + BATCH_SIZE sess.run(train_op, feed_dict=&#123;X: train_X[start:end], Y: train_y[start:end]&#125;) # And print the current accuracy on the training data. print(epoch, np.mean(np.argmax(train_y, axis=1) == sess.run(predict_op, feed_dict=&#123;X: train_X, Y: train_y&#125;))) # And now for some fizz buzz numbers = np.arange(1, 101) teX = np.transpose(binary_encode(numbers, NUM_DIGITS)) teY = sess.run(predict_op, feed_dict=&#123;X: teX&#125;) output = np.vectorize(fizz_buzz)(numbers, teY) print(output)]]></content>
  </entry>
  <entry>
    <title><![CDATA[sql 面试题]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F10%2Fsql-%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[说说对SQL语句优化有哪些方法？（选择几条） （1）Where子句中：where表之间的连接必须写在其他Where条件之前，那些可以过滤掉最大数量记录的条件必须写在Where子句的末尾.HAVING最后。 （2）用EXISTS替代IN、用NOT EXISTS替代NOT IN。 （3） 避免在索引列上使用计算 （4）避免在索引列上使用IS NULL和IS NOT NULL （5）对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 （6）应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描 （7）应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描 sql 索引 有哪几种类型？]]></content>
  </entry>
  <entry>
    <title><![CDATA[深度学习0005]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F10%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A00005%2F</url>
    <content type="text"></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习0004]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F10%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A00004%2F</url>
    <content type="text"></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习0003]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F10%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A00003%2F</url>
    <content type="text"></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习0002]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F10%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A00002%2F</url>
    <content type="text"></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习0001]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F10%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A00001%2F</url>
    <content type="text"><![CDATA[首先是一些基本的概念 人工神经网络 ann tensorflow 主要做了什么？ 特征提取 运算 框架的主要目的 是提供一个工具箱，使得开发时能够简化代码，呈现出来的模型尽可能简单易懂。 神经元函数以及优化方法： 激活函数的选取 卷积函数 池化函数 分类函数 优化方法有哪些？ 队列和线程 队列 队列管理器 线程和协调器 普通纯粹的神经网络 卷积神经网络 循环神经网络 gan 强化学习的未来 人脸识别 自然语言处理 图像与语音的结合 生成式对抗网络 tensorflowonspark 在 MNIST 上的实践 0.预留 为在executor 上执行的每个tf进程保留一个端口，并且启动数据消息的监听器 1.启动 在executor 上启动tensorflow 主函数 2.数据获取 readers 和 queuerunners feeding 发送到tf节点]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习和人工智能]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F08%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%2F</url>
    <content type="text"><![CDATA[机器学习主要有两种形式，一种是监督学习，另外一种是非监督学习。 监督学习，需要提供一组学习样本，也就是说数据是需要手动打上标签。程序可以通过这组样本学习相关的规律或者是模式，然后通过得到的规律或者模式来判断没有被打过标签的数据是什么样子的数据。 非监督学习，数据没有被标注过。 监督学习是在被告诉过了正确的答案后的学习，而非监督学习是在没有被告诉正确答案时的学习。 非监督学习是在大量的非常乱的数据中寻找一些潜在的关系，这个成本非常高。 决策树 自动化放贷、风控 朴素贝叶斯分类器 判断垃圾邮件、新闻分类 最小二乘法 （是一种线性回归） 逻辑回归 支持向量机 集成方法 聚类算法 主成分分析 奇异值分解 独立成分分析]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一点小小的感悟]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F07%2F%E4%B8%80%E7%82%B9%E5%B0%8F%E5%B0%8F%E7%9A%84%E6%84%9F%E6%82%9F%2F</url>
    <content type="text"><![CDATA[有人说 有修养的程序员才可能成长为真正的工程师和架构师，否则只能沦为码农。 比较重要的几个方面： 英文能力 问问题的能力 写代码的修养 安全防范意识 软件工程和上线规范 编程规范 取法其上，得乎其中，取法其中，得乎其下，取法其下，法不得也。 C C++ JAVA GO Python]]></content>
      <categories>
        <category>growth</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习0000]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F07%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A00000%2F</url>
    <content type="text"><![CDATA[tensorflow 是一个google开源的深度学习的框架，执行性能良好，值得使用。 caffe，caffe2 通过配置就可以拼凑一个深度学习框架，大大简化流程但也依赖大量的开源库，性能也不错。2013开始面世，很有活力的一个框架。 keras 这个一个积木式的框架，有很多现成的函数 可以直接拿来用，开发速度杠杠的，就是缺少灵活性。 MXNet 是一个全功能,灵活可编程和高扩展性的深度学习框架，可能学术上用的比较多吧！ Torch 是一个facebook在维护的框架，灵活性也很大，不过要lua语言结合使用； CNTK微软推出的一个深度学习框架，可以在window上执行，性能据说是最优的，可是使用者不多，可能是市场都被主流的几个占有了； Deeplearning4j java的一个深度学习库，不甚了解； Theano 是一个很古老的框架，性能比较差，速度最慢的，生产环境不会用的，只是现在有些研究室还在用。 其他： SciKit-learn 是老牌的开源 Python 算法框架 openCV 是一个图片及视觉算法的框架]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的一些问题]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F04%2Fpython%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[交换两个变量的值 没有C语言那么麻烦 链状比较 三元操作符进行条件赋值 多行字符串 存储列表元素到新的变量中 打印引入模块的文件路径 _ 是上一个执行的表达式的输出 字典集合推导 调试脚本 开启文件分享 1python3 -m http.server 检查python中的对象 简化if语句 一行代码计算阶乘 1234import functoolsresult = (lambda k: functools.reduce(int.__mul__, range(1, k+1))(3) 找到列表中出现最频繁的数 max(set(test), key=test.count) python递归限制次数到1000 检查一个对象的内存使用情况： 2.7中一个32比特的整数占用24字节3.5中一个32比特的整数占用28字节 确定内存使用情况 可以调用getsizeof 使用 __slot__减少内存开支 使用lambda 来模仿输出方法 从两个相关的序列构建一个字典 搜索字符串的多个前后缀 endswith()后面可以连接字符串 元组也是可以的 不使用循环构建一个列表 itertools.chain.from_iterable 实现 switch-case 语句 def xswitch(x): return xswitch._system_dict.get(x, None)]]></content>
  </entry>
  <entry>
    <title><![CDATA[神经网络预测共享单车使用情况]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F03%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8B%E5%85%B1%E4%BA%AB%E5%8D%95%E8%BD%A6%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[使用数据构建神经网络预测以后的使用情况 pandas 读取各种类型的数据 简单查看数据 数据绘制 虚拟变量（哑变量） 调整目标变量 数据拆分（6:2:2） 构建神经网络 计算平方误差 单元测试 调参 训练网络 检查预测结果]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis again]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F09%2F01%2Fredis-again%2F</url>
    <content type="text"><![CDATA[Redis有哪些数据结构？ 字符串String、字典Hash、列表List、集合Set、有序集合SortedSet。 如果你是Redis中高级用户，还需要加上下面几种数据结构HyperLogLog、Geo、Pub/Sub。 如果你说还玩过Redis Module，像BloomFilter，RedisSearch，Redis-ML，面试官得眼睛就开始发亮了。 使用过Redis分布式锁么，它是什么回事？ 先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。 这时候对方会告诉你说你回答得不错，然后接着问如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？ 这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，然后回答：我记得set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！对方这时会显露笑容，心里开始默念：摁，这小子还不错。 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？ 使用keys指令可以扫出指定模式的key列表。 对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？ 这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。 使用过Redis做异步队列么，你是怎么用的？ 一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。 如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。 如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。 如果对方追问redis如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。但是你很克制，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。 到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。 如果有大量的key需要设置同一时间过期，一般需要注意什么？ 如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。 Redis如何做持久化的？ bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。 对方追问那如果突然机器掉电会怎样？取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。 对方追问bgsave的原理是什么？你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 Pipeline有什么好处，为什么要用pipeline？ 可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。 Redis的同步机制了解么？ Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 是否使用过Redis集群，集群的原理是什么？ Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。 Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。]]></content>
  </entry>
  <entry>
    <title><![CDATA[lua table库]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F30%2Flua-table%E5%BA%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lua string库]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F30%2Flua-string%E5%BA%93%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lua 模块]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F30%2Flua-%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lua 函数]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F30%2Flua-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lua 控制结构]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F30%2Flua-%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[lua 表达式]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F30%2Flua-%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[lua的算术运算符 传统的加减乘除 指数（^） 余数（%） 关系运算符 不等于(~=) 逻辑运算符 and or not 字符串连接 在 Lua 中连接两个字符串，可以使用操作符“..”（两个点）。如果其任意一个操作数是数字的话，Lua 会将这个数字转换成字符串。注意，连接操作符只会创建一个新字符串，而不会改变原操作数。也可以使用 string 库函数 string.format 连接字符串。 优先级(由高到低) ^ not # - * / % + - .. &lt; &gt; &lt;= &gt;= == ~= and or]]></content>
  </entry>
  <entry>
    <title><![CDATA[lua 基础数据类型]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F30%2Flua-%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[函数type 可以返回一个值或一个变量所属的类型 这个和python 是一样的 nil（空） boolean（布尔） number（数字） string（字符串） table（表） 一种抽象的“关联数组”，具有特殊索引方式的数组，索引通常是字符串string或者number类型，但是也可以是除nil以外的任意类型的值 类似字典 但是里面不是k:v 而是k=v 这种 function（函数） 函数也是一种数据类型，函数可以存储在变量中，也可以通过]]></content>
  </entry>
  <entry>
    <title><![CDATA[autokeras tiyan]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F29%2Fautokeras-tiyan%2F</url>
    <content type="text"><![CDATA[12345678910111213from keras.datasets import mnistfrom autokeras.image_classifier import ImageClassifierif __name__ == &apos;__main__&apos;: (x_train, y_train), (x_test, y_test) = mnist.load_data() x_train = x_train.reshape(x_train.shape + (1,)) x_test = x_test.reshape(x_test.shape + (1,)) clf = ImageClassifier(verbose=True, augment=False) clf.fit(x_train, y_train, time_limit=12 * 60 * 60) clf.final_fit(x_train, y_train, x_test, y_test, retrain=True) y = clf.evaluate(x_test, y_test) print(y * 100)]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 异步io的未来]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F28%2Fpython-%E5%BC%82%E6%AD%A5io%E7%9A%84%E6%9C%AA%E6%9D%A5%2F</url>
    <content type="text"><![CDATA[说起python 很多人 觉得因为GIL的存在，效率不高。删除GIL 这个主题 偶尔出现在python-dev的电子邮件列表，并且开发人员已经多次提过，可悲的是没有人设法提供一个合理和简单的解决方案，让我们摆脱这种限制。 Python的异步I/O支持是相当的好。有一堆库可以做这个工作（Twisted, Tornado, Gevent, Eventlet，这里仅列举几个）。每个库都支持很多协议。你可以使用MySQL, Mongo, PostgreSQL, Redis, Memcache, ElasticSearch…，几乎每个DB，和许多其他得服务。一些奇异的协议，像SSH或者Beanstalk只在几个库中支持。不过这些都不是问题，写另一个协议或从一个I/O框架移植到另一个也不是很难。 当然，每一个I/O库都支持客户端和服务端HTTP。想必，这就是为什么HTTP是最常见的用于微服务之间通信的协议。不过大多数框架也支持各种其他协议（msgpack-rpc, thrift, zeromq, ice，这里仅列举几个）。 当聪明的黑客们创建了像 zeromq 、 nanomsg 和发布-订阅总线（ publish-subscribe buses ）这样优秀的项目的时候，实干的工程师们却仍然使用旧的技术干活。 到目前为止我还没有看到使用 zeromq 作为数据库存取通讯方式的数据库。嗯，现在是有很少一些使用了 zeromq 的开源服务。基本上所有现代的数据库在通讯方式的实现上目前分成了以下两个阵营： 创建并使用自身协议 使用 HTTP 协议 在这个方面数据库算是个比较突出的例子。另外的例子比如 Docker ， Docker 使用了基于 unix sockets 的 HTTP 协议作为其通讯协议，然而，当她需要使用全双工流（ full-duplex streams ）来替代请求-回应（ request-reply ）模式的时候，就只能很不优雅地打破了其使用的协议的语义（ protocol semantics ）。 异步核心其实非常简单，首先，网络服务都是同步的，没有什么异步。异步其实就是把一个回复分成两个回，这样可以不会被阻塞。 就像调度一样，当执行I/O指令时，马上切换到其他线程，等I/O设备回复后，再切换回来]]></content>
  </entry>
  <entry>
    <title><![CDATA[vue2.0-start05]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F21%2Fvue2-0-start05%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[vue2.0-start04]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F21%2Fvue2-0-start04%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[vue2.0-start03]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F21%2Fvue2-0-start03%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[vue2.0-start02]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F21%2Fvue2-0-start02%2F</url>
    <content type="text"><![CDATA[列表渲染 v-for 事件处理器（指令，绑定事件） v-on 事件修饰符 .stop(冒泡).prevent(默认事件).capture(捕获).self.once(执行一次) 条件渲染 v-show 动态绑定 v-bind:class** 除了内置的指令外 还可以自己设置指令 注册全局指令 123456789101112131415161718192021&lt;body&gt; &lt;div class=&quot;app&quot;&gt; &lt;div v-color=&quot;colorStatus&quot;&gt;我是一个普通的div元素&lt;/div&gt; &lt;/div&gt; &lt;script src=&quot;./node_modules/vue/dist/vue.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; document.addEventListener(&apos;DOMContentLoaded&apos;,function () &#123; Vue.directive(&apos;color&apos;,function (el,binding) &#123;//指令名称注意不要加**v-** console.log(el);//当前绑定自定义指令的元素，可以用来直接操作DOM console.log(binding);//一些参数，常用的 =&gt; binding.value（指令的值） el.style.backgroundColor = &apos;lawngreen&apos;; &#125;) var vm = new Vue(&#123; el: &apos;.app&apos;, data: &#123; colorStatus: true &#125; &#125;); &#125;,false); &lt;/script&gt;&lt;/body&gt; 当前组件下可用 123456789101112131415161718192021&lt;body&gt; &lt;div class=&quot;app&quot;&gt; &lt;div v-color=&quot;colorStatus&quot;&gt;我是一个普通的div元素&lt;/div&gt; &lt;/div&gt; &lt;script src=&quot;./node_modules/vue/dist/vue.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot;&gt; document.addEventListener(&apos;DOMContentLoaded&apos;,function () &#123; var vm = new Vue(&#123; el: &apos;.app&apos;, data: &#123; colorStatus: true &#125;, directives:&#123; &apos;color&apos;:function (el,binding) &#123; el.style.backgroundColor = &apos;lawngreen&apos;; &#125; &#125; &#125;); &#125;,false); &lt;/script&gt; &lt;/body&gt; 计算数据（属性） 为什么需要计算属性 模版式未来描述视图的结构，在模版中放入太多逻辑，导致模版过重难以维护 在计算一个计算属性的时候，更新依赖列表并且缓存结果，只有当其中一个依赖发生了变化，缓存的结果才无效 组件化开发组件其实是页面组成的一部分 使用组件的好处： 提升效率 方便重复使用 简化调试步骤 提升整个项目的可维护性 便于协同开发 组件的特性： 高内聚性、低耦合性 全局注册 123456789101112131415&lt;body&gt; &lt;div class=&quot;app&quot;&gt; &lt;my-component&gt;&lt;/my-component&gt; &lt;/div&gt;&lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; //全局注册 Vue.component(&apos;myComponent&apos;,&#123;//html中是横杠的，在js中就是驼峰 template: `&lt;h2&gt;我是全局组件&lt;/h2&gt;` &#125;) var vm = new Vue(&#123; el: &apos;.app&apos; &#125;);&lt;/script&gt;&lt;/body&gt; 局部注册 123456789101112131415161718192021222324&lt;body&gt; &lt;div class=&quot;app&quot;&gt; &lt;my-component&gt;&lt;/my-component&gt; &lt;common&gt;&lt;/common&gt; &lt;/div&gt;&lt;script src=&quot;vue.js&quot;&gt;&lt;/script&gt;&lt;script&gt; var Child = &#123; template:`&lt;h3&gt;我是局部组件&lt;/h3&gt;` &#125;; var common = &#123; template: `&lt;p&gt;第二个局部组件&lt;/p&gt;` &#125; var vm = new Vue(&#123; el: &apos;.app&apos;, components: &#123; // &lt;my-component&gt; 将只在父模板可用 myComponent: Child, common //如果组件定义的名字和在html显示的标签名一致就可以省略 &#125; &#125;);&lt;/script&gt;&lt;/body&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[vue2.0-start01]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F21%2Fvue2-0-start01%2F</url>
    <content type="text"><![CDATA[不够系统的学习 vue 趁着有些闲暇的时间 对此进行整理一下 12345678910111213141516171819202122232425262728&lt;html&gt;&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt;&lt;div id="app"&gt; &lt;input type="text" placeholder="请输入" v-model="message" /&gt; &lt;br /&gt; &lt;p&gt;data: &#123;&#123; message &#125;&#125;&lt;/p&gt;&lt;/div&gt;&lt;script src="https://cdn.jsdelivr.net/npm/vue@2.5.17/dist/vue.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt; document.addEventListener('DOMContentLoaded',function () &#123; //vm实例 var vm = new Vue(&#123; el: '#app', //挂载元素 data: &#123; message: "hello, Data" &#125; &#125;); &#125;,false);&lt;/script&gt;&lt;/html&gt; vue的特色 数据双向绑定 数据模型model与视图view组件的自动同步 el: 挂载元素选择器data: 代理数据method: 定义方法 声明式渲染声明式 只需要声明在哪里做什么 无需关心如何实现 命令式 需要具体代码表达在哪里 做什么 如何实现 vue模版使用 Mustache 语法 插值 替换实例上的属性值 数据对象属性class: {}, =&gt; 绑定class，和v-bind:class一样的APIstyle: {}, =&gt; 绑定样式，和v-bind:style一样的APIattrs: {}, =&gt; 添加行间属性domProps: {}, =&gt; DOM元素属性on: {}, =&gt; 绑定事件nativeOn: {}, =&gt; 监听原生事件directives: {}, =&gt; 自定义指令scopedSlots: {}, =&gt; slot作用域slot: {}, =&gt; 定义slot名称 和组件有关系，插曹key: “key”, =&gt; 给元素添加唯一标识ref: “ref”, =&gt; 引用信息 console.dir() 查看文档对象下所有的东西 console.time(‘test’); console.timeEnd(‘test’);]]></content>
  </entry>
  <entry>
    <title><![CDATA[jwt认证和python实践]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F20%2Fjwt%E8%AE%A4%E8%AF%81%E5%92%8Cpython%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[授权认证 几种常用的认证机制 HTTP Basic Auth 在HTTP中，基本认证是一种用来允许Web浏览器或其他客户端程序在请求时提供用户名和口令形式的身份凭证的一种登录验证方式，通常用户名和明码会通过HTTP头传递。 在发送之前是以用户名追加一个冒号然后串接上口令，并将得出的结果字符串再用Base64算法编码。例如，提供的用户名是Aladdin、口令是open sesame，则拼接后的结果就是Aladdin:open sesame，然后再将其用Base64编码，得到QWxhZGRpbjpvcGVuIHNlc2FtZQ==。最终将Base64编码的字符串发送出去，由接收者解码得到一个由冒号分隔的用户名和口令的字符串。 OAuth 是一个关于授权（authorization）的开放网络标准。允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。现在的版本是2.0版。 严格来说，OAuth2不是一个标准协议，而是一个安全的授权框架。它详细描述了系统中不同角色、用户、服务前端应用（比如API），以及客户端（比如网站或移动App）之间怎么实现相互认证。 (A)用户打开客户端以后，客户端要求用户给予授权。 （B）用户同意给予客户端授权。 （C）客户端使用上一步获得的授权，向认证服务器申请令牌。 （D）认证服务器对客户端进行认证以后，确认无误，同意发放令牌。 （E）客户端使用令牌，向资源服务器申请获取资源。 （F）资源服务器确认令牌无误，同意向客户端开放资源。 jwt 认证 1.头部 包括类别和加密算法2.载荷 payload3.签名 signature JWT的主要优势在于使用无状态、可扩展的方式处理应用中的用户会话。服务端可以通过内嵌的声明信息，很容易地获取用户的会话信息，而不需要去访问用户或会话的数据库。在一个分布式的面向服务的框架中，这一点非常有用。 python 后端使用 pyjwt]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-17-tips]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F20%2Fpython-17-tips%2F</url>
    <content type="text"><![CDATA[1.交换变量值 a, b = b, a 2.列表元素转字符串 &quot;&quot;.join(a) 3.查找列表中频率最高的值 from collections import Counter cnt = Counter(a) cnt.most_common(3) 4.检查两个字符串是不是由相同字母不同顺序组成的 from collections import Counter Counter(str1) == Counter(str2) 5.反转字符串 a[::-1] reversed(a) a.reverse() 6.反转列表 7.转置二维数组 list(zip(*original)) 8.链式比较 9.链式函数调用 10.复制列表 deepcopy() 不影响原来的 copy（） 浅拷贝实际上是引用 会改变 11.字典get方法 12.通过键排序字典元素 from operator import itemgetter sorted(d.items(), key=itemgetter(1) 13.for else 14.转换列表为逗号分割符格式 15.合并字典 {**a, **b} 16.列表中最小和最大值的索引 def minIndex(lst): return min(range(len(lst)), key=lst.__getitem__) 17.移除列表中重复的元素 from collections import OrderedDict OrderedDict.fromkeys(items).keys()]]></content>
  </entry>
  <entry>
    <title><![CDATA[django-cache]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F17%2Fdjango-cache%2F</url>
    <content type="text"><![CDATA[谈一谈 django 的缓存架构动态网站的一个基本权衡就是他们是动态的，每次一个用户请求一个页面，web服务器进行各种各样的计算， 从数据库查询到模板渲染到业务逻辑 从生成站点到访问者看到的页面。从处理开销的角度来说，相比标准的从文件系统读取文件的服务器调度，这是昂贵了不少。但是对大多数网站来说，这种开销不是什么大的问题。因为大多数的网站都是小到中型的站点，流量特别少。但是对于中到大型的网站来说，必须尽可能的减少开销，这就是缓存的由来。 缓存的意义在于把昂贵的计算结果保存起来一遍下次的访问，有缓存的站点的流程大概是这样子的： 给定一个url，检查页面是否在缓存中 如果在，返回缓存的页面 否则，生成该页面，把生成的页面保存在缓存中，返回生成的页面 django自带一个强大的缓存系统，提供不同层次的缓存粒度：你可以缓存某个视图函数的输出，或者只是某个特别难生成的部分或者是整个站点。 同时django也有类似“上流”缓存的东西，类似于Squid和基于浏览器的缓存，这类缓存是你无法直接控制但是你可以通过一些提示（比如http头 部）指定你网站的那些部分需要和如何缓存。 设置缓存缓存系统需要少量的配置才能使用，你必须告诉系统你的缓存数据存放在哪里-数据库还是文件系统亦或是直接存在缓存中-这是一个重要的决定，直接影响到你的缓存性能；当然，一些缓存类型本来就是比其他的快，这我们无法回避。 在项目的配置文件里面可以通过CACHES配置缓存，下面我们一一讲解django中可用的缓存系统 Memcached 是一个高性能的分布式内存对象缓存系统，用于动态Web应用以减轻数据库负载从而显著提供网站性能，也是django中到目前为止最有效率的可用缓存。 Memcached作为一个后台进程运行，并分配一个指定的内存量，它所做的全是提供一个添加，检索和删除缓存中任意数据的快速接口，所有的数据都是直接存储在内存中，所以就没有了数据库或者文件系统使用的额外开销了。 在安装Memcached之后，你还需要安装一个绑定Memcached的东西，这里当做是插件之类的东西，最常用的两个是python-mencached和pylibmc。 在django中使用Memcached，你需要在配置文件里的CACHES做如下设置： 根据你选择的插件，选择对应的后端(BACKEND)django.core.cache.backens.memcached.MemcachedCache或者django.core.cache.backends.memcached.PyLibMCCache 给LOCATION设置ip:port值，其中ip是Memcached进程的IP地址，port是Memcached运行的端口，或者unix:path值，其中path是Memcached Unix socket文件所在的路径 CACHES = { &apos;default&apos;: { &apos;BACKEND&apos;: &apos;django.core.cache.backends.memcached.MemcachedCache&apos;, &apos;LOCATION&apos;: [ &apos;172.19.26.240:11211&apos;, &apos;172.19.26.242:11211&apos;, &apos;172.19.26.244:11213&apos;, ] } }]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django or say python web architecture]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fdjango-or-say-python-web-architecture%2F</url>
    <content type="text"><![CDATA[一个django 网站 比如 著名的 disqus 它是如何支持 两个亿的月活 于2007年 创办 第三方社会化评论系统 为网站提供评论托管服务 中国目前有 多说 友言 评论啦 与之相似。 1.缓存为什么要存在 因为 用户量的增加 所做的计算越来越多 但是 应用服务器资源是有限的 数据库每秒接受请求的次数也是有限的 如何解决 减少计算量 缩短请求流程（减少网络io或者硬盘io） 在标准的流程中 任何一个环节都可以被切断， 这样请求可以直接从缓存里取到数据直接返回 2.缓存存在于哪些地方 理论上来说 缓存可以存在于请求的任意一个环节 根据数据的变化特征 将数据特征总结为一段时间内变或者不变 3.缓存的属性 命中率 最大元素（可以存放的最大元素的个数） 清空策略（FIFO LRU） 4.缓存介质 内存 硬盘文件 数据库 根据缓存和应用的耦合程度划分为本地和远程缓存 本地有ehcache oscache 远程有 memcached 缓存的使用是架构师的必备技能 根据数据的类型，业务的场景来确定使用何种类型的缓存。 但是没有一种缓存可以解决任何的业务场景或者数据类型，每种都各有优缺点！！！]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[drf custom auth]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fdrf-custom-auth%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819class MyTokenAuthentication(TokenAuthentication): def authenticate_credentials(self, key): # get cache token_cache = &quot;token&quot; + key token_all = cache.get(token_cache) if token_all: return (token_all.user, token_all) model = self.get_model() try: token = model.objects.select_related(&apos;user&apos;).get(key=key) except model.DoesNotExist: raise exceptions.AuthenticationFailed(_(&apos;Invalid token.&apos;)) if not token.user.is_active: raise exceptions.AuthenticationFailed(_(&apos;User inactive or deleted.&apos;)) # set cache if token: token_cache = &apos;token&apos; + key cache.set(token_cache, token) return (token.user, token) 第一次 查询mysql 数据库 将结果缓存至redis 数据库中 第二次的话，同样的请求过来 直接查询缓存 大大提高查询效率，增加web网站的QPS]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 12]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-12%2F</url>
    <content type="text"><![CDATA[花一两年时间去向一些有经验和资历的人（以及他的队伍）学习， 在此之后，再尝试一个人走下去。 Hadoop是一项非常重要的工具，并且对于数据科学有非常非同一般的影响力。 干这一行工作最重要的技能就是拥有扎实的技术知识（尤其是一些相关的工具），这包括了能够熟练使用合适的工具来解决手边遇到的各种问题。 数据科学家每天的生活包括优化现有的运行流程，以及创造能够提高用户体验的产品。 在实战中，“数据科学家”和“机器学习专家”基本上是同义词。 零售业之所以需要数据科学是因为他们有大量亟待分析的数据，并且有很多数据相关的问题亟待解决。但是大部分的数据分析师仅仅是通过把现有的模型套进这些数据中去做出结果，而不是去思考开发新的模型。 数据科学中最有挑战性的问题也可能是未来几年这个领域将会不得不面对的难题，那就是如何从大数据中归纳出合适的问题，找对正确的研究方向以及最终使用合适的方法做出可靠的结果。 如果你想要成为一名出色的数据科学家，一定要记住，在你转向一个新的技术之前，一定要确保自己已经非常熟练于当前的技术了。 你的工作环境以及行业对于你的职业发展是有很大影响的，尤其是在事业的起步阶段。 数据科学的未来很光明的，这个领域在未来一定会越来越多元化。]]></content>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 11]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-11%2F</url>
    <content type="text"><![CDATA[Raj Bondugula博士预计在未来数据提取、转换和加载工具（ETL）都将不再具有任何市场前景了，因为他们都将被Hadoop替代。Hadoop在博士眼里是当今世界最有前景的数据科学工具，当然还有它的一些“家庭成员”——Mahout、HDFS等。正是这些工具的存在让越来越多具有挑战性的工作（例如并行计算）相对容易起来，虽然也算不上简单。说到Hadoop前景，他同样预言可能会有MapReduce以外的很多其他大数据分析理念出现，而它们都将被广泛地运用到大数据分析中。 对于Raj Bondugula博士来说，在数据科学领域最有挑战性的事情，其实这可能也是整个数据分析领域需要面对的巨大挑战，就是如何从海量的数据中找到合适的问题去入手分析，以及获得有价值有意义的结果。诸如“这批数据有什么价值？”之类的开放式问题可能在未来不再流行了，因为你并不能以此获得具有洞见的结论（即使结果是正确的）。他相信任何假设的来源一定要基于商业知识。而这就需要更高的创新能力，在这方面人类的直觉和能力是计算机完全无法替代的。 从他个人来说，Bondugula博士却是一个非常自信的人，虽然他知道很多技术或者领域知识都需要从皮毛开始一层一层地学下去，但是他觉得数据科学这个领域是很好的。正如大家所期待的那样，他计划在未来的很多年都从事这一行业。 給出的建议： “在某个方面成为该领域的专家，可以是统计，也可以是机器学习或者Java编程，然后再一件接一件地慢慢尝试更多的事情”。你也需要接受别人的帮助，因为你不可能一个人解决所有的问题。此外，交际圈和沟通技巧同样也是非常重要的，所以你也需要着力于培养自己的一些包括“软实力”在内的一些技能。]]></content>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 10]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-10%2F</url>
    <content type="text"><![CDATA[流程 数据的准备 数据探索 数据表示 数据发现 数据学习 创造数据产品 洞察结果做出结论 最终的可视化]]></content>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 09]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-09%2F</url>
    <content type="text"><![CDATA[让你的知识与时俱进是成为数据科学家非常重要的一个方面，特别是当这个领域在不断创新的时候。 研讨会是学习新知识的最有效途径，特别是技术性主题。研讨会可能会涉及花费，但它们是颇具投资价值的，因为你可以通过它们来修饰简历，并且它们时常能提供比大学课程更具实用性的知识。 会议是一种扩展数据科学知识的好方法，你可以在会议中了解最近的创新成果，结交许多领域内有趣的人，同时学习一些有用的东西，让你有机会把它们用到你的难题或是正在面对的数据科学挑战中。 在线课程，特别是MOOC，是最能增长和改善你对各种主题知识的途径之一。在Coursera上有各种现成的数据相关课程，Coursera也是最有威望的MOOC提供方。 数据科学小组是一个学习领域新知的既有效又充满乐趣的方法。你需要找到一个的举办大量教育活动的小组，有大量活跃在数据科学领域内的成员（不只是初学者），同时与小组内的其他成员积极地参与交流。 资源问题十分普遍，并涉及以有限的资源来处理数据分析业务。 需求问题是老生常谈的问题，牵涉到沟通不畅、误解以及曲解了包括你的经理和客户所提出的需求的实现。这可以积极地通过创造力、外交手段、沟通以及耐心地得到解决。 缺乏专业知识可以通过阅读好的文章、书籍、网站来克服，或是咨询专业人士。 综合运用各种工具在IT世界中极为普遍，它牵涉使各种程序、数据集以及各种数据格式协同工作，这会在新开发一个程序时显得十分棘手。你可以通过良好积极的沟通、创造性以及耐心来克服这类问题。]]></content>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 08]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-08%2F</url>
    <content type="text"><![CDATA[一般经常使用的是hadoop 套件的备选工具 面向对象的编程语言 数据分析软件 虚拟化程序以及大数据集成系统 MapReduce由Google创建，并且是Hadoop的主要组件。正如在之前的部分我们曾提到过的那样，这是任何大数据技术的核心。尽管这是Hadoop固有的特性，但它也可以在其他的大数据程序，例如MPP和NoSQL数据库（例如，MongoDB）。MapReduce最初是具有商业所有权的，但随着Yahoo在2006年提供了慷慨的资金支持，它以Hadoop的开源形式出现，并在两年内迅速受到广泛欢迎。作为一个著名的并行计算算法，它得以让数据库的查询建立在一个计算机集群上，任务可以分拆成小份，并跨越整个集群的节点。 HDFS是Hadoop 分布式文件系统的简称，这是Hadoop系统所使用的文件系统。被Hadoop所处理的数据必须先导入到HDFS中，并备份在运行了Hadoop的计算机网络中。它的数据极限大约在30PB。 Pig是针对Hadoop进行计算的一个高级编程语言（High-level programming language）。你可以将它视为Hadoop生态系统中各种操作的控制元件。它的性能是可扩展的。 Hive是一个数据仓库程序，是以“类-SQL”语言进行访问使用的，他是为横跨Hadoop集群的数据设计的。并且它的性能是可扩展的。 HBase、Sqoop以及Flume是Hadoop的数据库组件。HBase是一个可以运行在Hadoop环境上的列式数据库。它是基于Google的BigTable设计的，并且数据极限约为1PB。另外，它比直接在HDFS上访问数据要慢一些。这对于处理存在HBase里面的数据来说不是很好，对HBase对于归档和时间系列数据的计数很合适。Sqoop是一个将关系型数据库中的数据导入到HDFS中的程序。Flume与此类似，它关注于收集和导入各种数据源的日志和任务数据。 Mahout是一个机器学习和数据挖掘算法的函数库，用于对存储在HDFS的数据进行处理。 Zookeeper服务于Hadoop有一“群”各种各样功能的组件，所以调试管理以及协调程序是十分必要的。Zookeeper保证了整个套件的整合以及相对得简便操作。 选择合适的工具分解问题解决问题]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 07]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-07%2F</url>
    <content type="text"><![CDATA[社交圈 是职业的组成部分，使得他能够学习更多的技术、工具以及成为一个更优秀的数据科学家所应该知道的其他内容，通过同样的碰面，他可能会遇到一个导师，这就非常有价值，特别是在他职业生涯的早期 社交圈对成为数据科学家是至关重要的，特别是在职业生涯的早期阶段。 社交圈可以帮助你培养沟通技巧，并让你适应各种类型的人群，而这对于数据科学家来说十分重要。 在获取大数据科学领域以及其他相邻的领域中最近的革命性技术方面，社交圈可以是一个无价的资源。 数据科学家需要与学术界保持健康的关系，通过社交圈让自己跟进最新进展以及结识潜在的合作伙伴。 数据科学家需要立足现实，这可以通过社交圈去保持与商业世界的关系来达到。这可以帮助他更好地了解需要什么，并且除了带来工作机会之外，还可以让自己触及有趣的商业机会。 两种表示矩阵的方法 一种是matrix类 *默认的乘法是矩阵的乘法 另外一种是二维数组array *默认的乘法是hadamard乘法 大多数的情况下 我们使用第二种 也就是二维数组来表示矩阵]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 06]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-06%2F</url>
    <content type="text"><![CDATA[经验的取得 企业实战和学术研究的经验 UCI 机器学习知识库 kaggle 在Kaggle上参加一些数据科学竞赛，可以是以团队形式参加。 获得一个与之相关的实习职位。 如果你是一个硕士生，你的论文案例可以是一个有数据相关问题的公司。 在数据科学团体中做志愿者。 追随一位导师，例如在DataScienceCentral里的那种。 生产方面的项目经验：如果有人不相信数学是简单的 那是因为他们还没有意识到人生有多复杂。 标量scalar 其实就是数字 矢量vector 矩阵matrix 向量排列成为矩形矩阵 单位矩阵 矩阵的对角线元素等于1 对角矩阵 除去对角线元素外 其他元素都为0 三角矩阵 对角线上方或者下方元素全部为0 矩阵的运算 加减法 乘法 除法（逆矩阵） 矩阵的转置 numpy上已经有了矩阵所有的矩阵运算 我们使用的时候 就是调用就可以了。]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 05]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-05%2F</url>
    <content type="text"><![CDATA[综合的编程能力 辨别什么时候用什么工具 微调你要使用的工具，订制成解决手中问题的利器 如何去后续处理选择的工具所产生的结果 思考解决问题的几个备选方案，并基于所能利用的资源对它们进行排序 对数据分析工具足够的了解（例如，R、SPSS、SAS、Stata或Matlab）并掌握它们中的至少一个工具。 大数据存储架构经验（例如，Hadoop、Hive等） 其他可能是也可能不是有关数据科学工作的专业知识，例如视觉化、关系型数据库、用户建模、大数据集成处理系统。同时，还要有大数据领域的数据集的工作经验。 数据科学领域进化的速度很快，所以你需要紧跟变化，特别是所用的工具，这样你就可以相应地调节自己的学习策略。]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 04]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-04%2F</url>
    <content type="text"><![CDATA[普通大众对数据科学家的概念认识往往十分肤浅，特征其实在于一系列独有的特点、气质、思维方式、抱负。 健康的好奇心必须伴随着自律，这样才能更脚踏实地。长期的兴趣比短暂、冲动或肤浅的好奇更加务实，会自然地被他所观察到的数据现象所吸引，并想要触及它们的全部。 适应性（Adaptability） 团队合作（teamwork） 变通(Flexibility) 研究(Research) 关注细节（Attention to Detail） 汇报（Reporting） 思维综合式和跃进式 掌握大数据的众多层面 持续学习新知 让自己熟悉大数据世界中的各种开放性问题与挑战，以及存在的各种机会]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 03]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F16%2Fhow-to-be-a-data-scientist-03%2F</url>
    <content type="text"><![CDATA[世界上没有两片相同的雪花，世界上也没有两个数据科学家拥有相同的技能和工作。大数据的工作包含许多问题，这也创造出许多天生就不一样的数据科学家分工。 数据开发者 数据研究者 数据创意师 数据商务人士 混合/普适类型 数据开发者是编程专家，但他们可能缺少数据科学家的其他几部分的技能，通常来自于IT行业。 数据研究者是数据分析的专家，同时他们也能处理机器学习以及其他领域的最新技术。他们通常拥有博士学位，而且正在或曾经从事着学术研究。 数据创意师相比于前两个类型的数据科学家显得更为全面，偏爱于使用开源软件，而且多才多艺。他们来自于各行各业，尽管通常来说，他们已经是数据科学家了。 数据商务人士（即高级数据科学家）是数据科学家的最高等级，同时常常担任管理角色，相较于数据科学本身，他们更多地接近于商务世界。通常他们具有包括管理学学位在内的多重背景。 混合/普适类型的数据科学家是最为平衡的，同时或多或少地培养了数据科学所需的各个方面。他们多面发展，具有各个类型的背景，但在经验的广度上，都亚于数据商务人士。通常，混合/普适的数据科学家会晋升为数据商务人士。]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 02]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F15%2Fhow-to-be-a-data-scientist-02%2F</url>
    <content type="text"><![CDATA[数据科学这一术语的流行要早于大数据的出现，1962年 当john W. Tukey 写了《数据分析的未来》，他遇见了数据分析的新方法的崛起相比于方法论来说更像是一门科学。 2009年 朱扬勇与熊赟 两位重点实验室的研究员在数据学导论中提到 数据科学是一门新的科学，明显地不同于自然科学与社会科学。09年一月 Hal Varian（谷歌首席经济学家）提出，在接下来的十年，统计学家（当别人并不熟悉数据学时，也会被用来指数据科学家）将会是一个迷人的职业。09年六月， Nathan yau的文章《数据科学家的崛起》被刊载于 flowing data，数据科学家开始被大众所知。 大规模数据程序语言 比如 r pig ecl 的开发就是为了解决大数据问题，同时它们与hadoop 环境可以很好地融合。 新的替代性数据库结构包括 哈希表（jboss 数据网格、riak） B-树（mongodb、couchdb） 日志结构的合并树（Hbase cassandra） 在数据库内读写数据的方式是比较灵活弹性的，每一种类型都有它们适于 不适于的范畴。 举例来说，如果你有一个由上百万行列记录的大型数据库（如大型的数据仓库），要在这样的数据库中找到某一列中的最大值可能会超过很多人愿意等待的时间。同样的查询在列式数据库中（如HBase）用不了1秒。 聪明的工具、方法论和运用方法，查阅现有文档，并与熟悉亟待解决问题的不同领域的人士建立联系，把问题分解成可以被处理的小问题来逐渐解决。]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how to be a data scientist 01]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F15%2Fhow-to-be-a-data-scientist-01%2F</url>
    <content type="text"><![CDATA[如何成为一名数据科学家我们今天面临着诸多来自大数据和其他数据分析带来的困难，而数据科学正是对这些挑战的回应。 大数据是当今商业的基础资产，大数据与大数据相关的技术能够得到这么广泛地利用绝对不是巧合，现今诸多行业要么正在使用大数据，要么准备去使用大数据，尽管炒作得非常厉害，但是并不是昙花一现。对这些资源善加利用会带来诸多优势，而目前这种资源的日益丰富也是值得关注的信号，不仅要用，而且要快！在某些行业里，大数据目前还不能带来价值，因为这些行业的数据目前还是非常混乱的，属于“脏”数据。如何将这些数据进行清洗，并善加利用，这就是数据治理存在的意义。 大数据具有四个特性： 体量 高速 多样 准确 数据量非常大 并伴随着更快的增长趋势， 由于访问者来来去去以及不断有新的访问者加入，数据会持续流动 数据肯定是多种多样的 很自然，数据并不都是值得信任的 很自然地，并不是所有的行业都会被大数据运动施以相同的影响。基于这些公司在多大程度上依赖他们的数据以及数据会给予他们多大程度上的回报，他们可能视大数据为一座金矿，或者一项可有可无的投资。根据最近的统计，下面一些行业已经从中受益，或资产中的大部分即将受益于大数据： 零售业（特别是在提高生产力方面） 电信业（特别是在提高收益方面） 咨询业 医疗护理 航空运输 建筑业 食品加工 钢铁以及广义上的制造业 工业设备 汽车产业 客户关怀 金融服务 出版业 物流行业 因此需要的是把表面上看起来混乱的数据变成有效的（可操作的）数据科学家 数据科学家第一次在正式会议中吸引关注是1996年在IFCS发表的《数据科学、分类以及相关方法》（Data Science，Classification and Related Methods）。直到2005年，“数据科学家”这个名称才第一次出现在文章中。特别是，在文章发表的那年，数据科学家被定义为“信息和数据科学家、数据库及软件工程师以及程序员、学科专家、博物馆馆长和专业注解者、图书馆管理员、档案管理员以及其他一些对成功管理数字化数据集的关键人物”。在2009年6月，数据科学家这一职务的重要性变得更加明显，正如Nathan Yau在FlowingData发表的文章《数据科学家的崛起》（Rise of the Data Scientist）一文中说的那样。自此，在数据科学方面的文章和引用得以快速增长。看看现在有多少会议是以这个名义组织的，这不只发生在学术界，同样也发生在工业界。不仅如此，由于许多在各自领域处于领导者的大公司（如亚马逊）都在各自的工作流程中使用了数据科学，这个趋势很可能会持续下去。同样，由于数据科学家这个职位适合于千变万化的数据世界需求，它也正变得包含许多新特征（如前沿数据分析技术的应用），而不再是一些原始需求了。]]></content>
      <categories>
        <category>data science</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow-new]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F15%2Ftensorflow-new%2F</url>
    <content type="text"><![CDATA[如果你在研究深度学习或者是你的dataset非常庞大，那么tensorflow应该成为你最佳的机器模型选择。 目前已经广泛被用于发现新的行星、帮助医生筛查糖尿病患者等。开源、out of the box(开箱即用) 新工具 tf eager execution 可以像纯粹的python编程一样愉快地与代码进行交互，代码可以即时执行和逐行调试 keras + tf 更简单的神经网络 不仅仅是python 目前已经支持r swift js… 在浏览器中完成一切 实时人体姿态估计 [地址] (https://storage.googleaois.com/tfjs-models/demos/posenet/camera.html) lite for 小型设备 专业的硬件 cloud tpu tf.data 为你提供了快速灵活易于使用的处理流水线 tf hub 调用他人的代码为自己所用 可重用的预训练机器学习模型组件的存储库]]></content>
  </entry>
  <entry>
    <title><![CDATA[why-sanic]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F14%2Fwhy-sanic%2F</url>
    <content type="text"><![CDATA[使用sanic异步框架，简单，轻量，高效。 使用uvloop为核心引擎，使sanic在很多情况下单机并发甚至不亚于Golang。 使用asyncpg为数据库驱动，进行数据库连接，执行sql语句执行。 使用aiohttp为Client，对其他微服务进行访问。 使用peewee为ORM，但是只是用来做模型设计和migration。 使用opentracing为分布式追踪系统。 使用unittest做单元测试，并且使用mock来避免访问其他微服务。 使用swagger做API标准，能自动生成API文档。]]></content>
  </entry>
  <entry>
    <title><![CDATA[your_first_nn]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F14%2Fyour-first-nn%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627import numpy as np class NeuralNetwork(object): def __init__(self, x, y): self.input = x self.weight1 = np.random.rand(self.input.shape[1],4) self.weight2 = np.random.rand(4,1) self.y = y self.output = np.zeros(self.y.shape) def feedforward(self): self.layer1 = sigmoid(np.dot(self.input, self.weight1)) self.layer2 = sigmoid(np.dot(self.layer1, self.weight2)) def backprop(self): d_weight2 = np.dot(self.layer1.T, (2*(self.y - self.output))) d_weight1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output)*sigmoid_derivative(self.output), self.weight2.T)*sigmoid_derivative(self.layer1))) self.weight1 += d_weight1 self.weight2 += d_weight2 def sigmoid_derivative(x): return x*(1-x) def sigmoid(z): return 1.0/(1.0+math.exp(-z))]]></content>
  </entry>
  <entry>
    <title><![CDATA[cha-duoshao]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F13%2Fcha-duoshao%2F</url>
    <content type="text"><![CDATA[1.用于去研究不懂的代码 2.精通代码调试 3.优化迭代速度 4.系统性的思考方式 5.重视能够节省时间的工具]]></content>
      <categories>
        <category>growth</category>
      </categories>
      <tags>
        <tag>suibi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oj_test_5]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F13%2Foj-test-5%2F</url>
    <content type="text"><![CDATA[辗转相乘相除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#!/usr/bin/env python# -*- coding: utf-8 -*-&quot;&quot;&quot; 你需要实现一个转换器，将一个正整数在不同的进制(通用的/自定义的)之间转换。 后面有一些预定义的进制及其字符集。 示例： func(&quot;15&quot;, dec_chr, bin_chr) --&gt; &quot;1111&quot; func(&quot;15&quot;, dec_chr, oct_chr) --&gt; &quot;17&quot; func(&quot;1010&quot;, bin_chr, dec_chr) --&gt; &quot;10&quot; func(&quot;1010&quot;, bin_chr, hex_chr) --&gt; &quot;a&quot; func(&quot;0&quot;, dec_chr, alpha_chr) --&gt; &quot;a&quot; func(&quot;27&quot;, dec_chr, allow_chr) --&gt; &quot;bb&quot; func(&quot;hello&quot;, allow_chr, hex_chr) --&gt; &quot;320048&quot;&quot;&quot;&quot;import unittestbin_chr = &apos;01&apos;oct_chr = &apos;01234567&apos;dec_chr = &apos;0123456789&apos;hex_chr = &apos;0123456789abcdef&apos;allow_chr = &apos;abcdefghijklmnopqrstuvwxyz&apos;allup_chr = &apos;ABCDEFGHIJKLMNOPQRSTUVWXYZ&apos;alpha_chr = &apos;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&apos;alphanum_chr = &apos;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&apos;def func(input, source, target): &quot;&quot;&quot; 二进制 八进制 十进制 十六进制 小写（26） 大写（26） 字母（52） 字母和数字（62） 辗转相除 &quot;&quot;&quot; # your code # oct() # hex() # bin() if len(target) != len(source): transfer = input2dec(input, source) # print(transfer) get_re = dec2target(transfer, target) print(get_re) else: if target.startswith(&quot;A&quot;): get_re = input.upper() if target.startswith(&quot;a&quot;): get_re = input.lower() return get_redef input2dec(input, source): get_power = len(source) get_sum = 0 s = [i for i in input] s.reverse() for index, i in enumerate(s): num = source.find(i) get_value = num * (get_power**index) get_sum += get_value return get_sumdef dec2target(n, target): b=[] x = len(target) while True: s=n//x #商 y=n%x #余数 b=b+[y] if s==0: break n=s b.reverse() s = &apos;&apos; a = [i for i in target] for i in b:# print(a[i], end=&apos;&apos;) s += a[i] return sclass DefaultTestCase(unittest.TestCase): def test_func(self): self.assertEqual(func(&quot;15&quot;, dec_chr, bin_chr), &quot;1111&quot;) self.assertEqual(func(&quot;15&quot;, dec_chr, oct_chr), &quot;17&quot;) self.assertEqual(func(&quot;1010&quot;, bin_chr, dec_chr), &quot;10&quot;) self.assertEqual(func(&quot;1010&quot;, bin_chr, hex_chr), &quot;a&quot;) self.assertEqual(func(&quot;0&quot;, dec_chr, alpha_chr), &quot;a&quot;) self.assertEqual(func(&quot;27&quot;, dec_chr, allow_chr), &quot;bb&quot;) self.assertEqual(func(&quot;hello&quot;, allow_chr, hex_chr), &quot;320048&quot;) self.assertEqual(func(&quot;SAME&quot;, allup_chr, allup_chr), &quot;SAME&quot;) self.assertEqual(func(&quot;WORLD&quot;, allup_chr, alphanum_chr), &apos;Hgrz&apos;)if __name__ == &apos;__main__&apos;: unittest.main()]]></content>
  </entry>
  <entry>
    <title><![CDATA[oj-test-04]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F13%2Foj-test-04%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python# -*- coding: utf-8 -*-&quot;&quot;&quot;给定一个仅包含整数，且按照大小顺序排好序的列表，列表内不存在重复的整数。实现一个函数，将列表格式化为由`,`(逗号)分隔的字符串；如果相邻的整数(至少3个)是连续的(值相差1为连续)，则将这几个相邻的整数格式化为由`-`(减号)分隔、左右分别为起始和终止位整数的字符串。示例：func([-6,-3,-2,-1,0,1,3,4,5,7,8,9,10,11,14,15,17,18,19,20]) --&gt; &apos;-6,-3-1,3-5,7-11,14,15,17-20&apos;func([-3,-2,-1,2,10,15,16,18,19,20]) --&gt; &apos;-3--1,2,10,15,16,18-20&apos;特殊情况示例：func([]) --&gt; &apos;&apos;&quot;&quot;&quot;import unittestfrom itertools import groupbydef func(lst): # your code sum = sub_arr(lst) return &apos;,&apos;.join(sum)def sub_arr(lst): fun = lambda x: x[1] - x[0] sum = [] for k, g in groupby(enumerate(lst), fun): s = [v for i, v in g]# print(s) if len(s) &lt;= 1: sum.append(str(s[0])) elif len(s) == 2: sum.append(str(s[0])) sum.append(str(s[1])) else: target = [str(s[0]), str(s[-1])] n = &apos;-&apos;.join(target) sum.append(n) return sumclass DefaultTestCase(unittest.TestCase): def test_func(self): self.assertEqual(func([-6,-3,-2,-1,0,1,3,4,5,7,8,9,10,11,14,15,17,18,19,20]), &apos;-6,-3-1,3-5,7-11,14,15,17-20&apos;) self.assertEqual(func([-3,-2,-1,2,10,15,16,18,19,20]), &apos;-3--1,2,10,15,16,18-20&apos;) self.assertEqual(func([]), &apos;&apos;) self.assertEqual(func([-6,-4,-2,0,2,4,6]), &apos;-6,-4,-2,0,2,4,6&apos;) self.assertEqual(func([-6,-5,-3,-2,0,1,3,4,6]), &apos;-6,-5,-3,-2,0,1,3,4,6&apos;)if __name__ == &apos;__main__&apos;: unittest.main()]]></content>
  </entry>
  <entry>
    <title><![CDATA[why-python3]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F13%2Fwhy-python3%2F</url>
    <content type="text"><![CDATA[Python的一个重要设计目标是让程序简单、清晰和优雅，坚持一套整齐划一的设计风格。Python程序具有易写、易读、易维护的特点，受到广大程序员欢迎。这些特质也是导致Python的使用越来越广泛的原因。21世纪以来，Python已发展为世界上最受欢迎的编程语言之一，其使用非常广泛。国际上一些公司做过（或一直在做）各种编程语言使用情况的调查，统计结果中Python都位于前四五名之内。它还被TIOBE编程语言排行榜（最有影响力的语言排行榜之一）评为2010年的年度语言。 Python被广泛认为是一种容易入门的语言。实际上，Python语言机制的跨度比较大，从完成最简单计算的表达式开始，一直延伸到许多当前最先进的编程概念，如面向对象的程序设计、数据抽象、迭代器、异步编程等。这些情况有利于学习者在一个语言里逐步深入地学习许多编程概念和技术。Python用正文缩进形式表现程序的结构，具有较好的可读性。 Python是一种比较高级的编程语言。除了最基本的编程机制外，它还提供了使用方便的数据功能，可以很方便地组织和管理大批数据。Python的所有编程机制和结构都围绕着对象的概念，程序里定义和操作的各种实体都是对象，不仅所有数据都是对象，函数和类等也是对象。它也能很好支持面向对象编程的理念和相关技术。 由于其基本设计的一些特点，Python代码和部件比较容易重用，已开发的程序容易修改和扩充，有利于软件的升级改造，可以减轻软件开发者的工作负担，提高程序开发的效率。此外，Python语言的设计也为开发大规模软件系统提供了很好支持。这些是许多IT公司乐于选择和使用Python作为其主要开发语言的重要原因。 在用Python开发程序时，可以采用交互式的执行方式，随时把代码发送给系统，立刻看到执行效果。这种方式使人更容易在编程中做各种试验，可以提高工作效率。一个Python程序文件（称为模块）的内容就是一系列简单或复杂的命令的序列。人们也把这样的语言称为脚本语言（script language），其程序就像一个工作脚本。 实际上，Python并不是简单的脚本语言，而是一个能支持大规模软件开发的通用编程语言，其实现具有较高的执行效率。PSF的Python系统带有一个很大的标准库，提供了很多在实际开发中非常有用的功能。此外，全世界的开发者已经为Python开发了面向各种应用领域的大量专用程序包，例如面向图形用户界面的设计和编程，面向网络应用、数值计算、数据统计和处理、图形图像处理、可视化等。针对所有重要应用领域，都可以找到相关的程序包，大大方便了人们用Python开发领域应用软件和综合性软件的工作。 Python语言和标准库的设计特别考虑了可扩充性，提供了丰富的接口和工具，使有经验的程序员比较容易使用其他语言，例如C、C++、CPython（一种专门用于扩充Python的C语言工具）等编写Python模块，然后能像Python标准库包一样方便地使用。这种情况也使一些大公司把Python用作高级的粘接语言（glue language），用一些较低级的语言实现一批性能要求较高的完成具体工作任务的模块，而后用Python实现整个系统的高层控制和调度。这样做，既能获得很好的开发效率，也有利于修改和扩充。 Python基金会提供最新版本的Python语言系统和基本开发环境，任何人都可以免费获取。该系统可以在各种主流计算机和软件平台上运行，包含了丰富的标准程序库和完整文档。此外，也存在另外一些商业的或非商业的Python系统可供选择。经过多年使用，全世界的Python开发者和使用者已经形成了一个活跃的专业社群，活跃在世界各地（包括中国），探讨、交流学习和使用Python的经验。互联网有很多与Python有关的信息，有许多Python讨论组。这些都促进了Python语言的学习和传播。]]></content>
  </entry>
  <entry>
    <title><![CDATA[start-julia-01]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F13%2Fstart-julia-01%2F</url>
    <content type="text"><![CDATA[julia 入门学习 1.打印 println 2.字符串 $ 借鉴perl 3.特点 极其卓越的性能。Julia在很多数据分析任务以及其他编程实践中都表现出了令人难以置信的性能。它的表现可以和C语言媲美，C语言经常被用来作为衡量运算速度的标准。 强大的基础库。Julia有一个强大的基础库，它不需要其他平台，就可以进行所有的线性代数运算，这些运算是数据分析模块的必备组件。 支持多分派。Julia实现了多分派机制，这使它可以使用同一种函数实现不同的过程，使函数更容易扩展，并可以对不同类型的输入重复使用。 容易上手。特别是对于那些从Python、R、Matlab或Octave迁移过来的使用者，学习Julia特别容易。 用户友好的界面。不论是在本地还是云上，Julia的用户界面都非常友好，在所有的流程中，用户与Julia的交流都非常顺畅。Julia还对所有的功能和数据类型提供了方便易用的帮助文件。 与其他语言无缝对接。这些语言包括（但不限于）R、Python和C。这使你不需要进行完整的迁移，就可以使用现有的代码库。 开源。Julia以及它的所有文档与教程都是开源的，非常易于获取，详尽而又全面。 开发者承诺。Julia的开发者承诺会一直加强这门语言的性能，并对使用者提供尽可能的帮助。他们提供了大量的讨论，组织年度会议，并提供咨询服务。 自定义函数。Julia的自定义函数可以和内置在基础代码中的函数一样快速而简洁。 并行能力。Julia具有强大的并行能力，这使得在多核计算机和集群上的部署非常容易。 极大的灵活性。Julia在开发新程序方面极其灵活，不论是编程新手，还是专家级用户，Julia适合各种编程水平的使用者，这个特性在其他语言中是很难得的。 变量 变量名必须以字母（a-z 或 A-Z），下划线，或一个 Unicode 编码指针中指向比 00A0 更大的指针子集开始；特别是 Unicode 字符 Lu/Ll/Lt/Lm/Lo/Nl（字母），Sc/So （货币和其他符号），和其他一些可以看做字符的一些输入（例如 Sm 数学符号的子集）是允许的。首位之后的字符也包括 ！和数字（0-9 和其他字符 Nd/No ），以及其他 Unicode 编码指针：变音符号和其他修改标记（字母 Mn/Mc/Me/Sk），一些标点连接器（字母 PC），素数，和其他的一些字符。 运算符类似 + 也是有效的标识符，但需要特别解析。在某些情况下，运算符可以像变量一样使用；例如 (+) 是指增加功能，和 (+) = f 将重新定义这个运算。大多数的 Unicode 中缀操作符（在 Sm 中），如 ⊕ ，会被解析为中缀操作符，同时可以自定义方法（例如，你可以使用 ⊗ = kron 定义 ⊕ 成为一个中缀 Kronecker 积）。 尽管 Julia 对命名本身只有很少的限制, 但尽量遵循一定的命名规范吧： 变量名使用小写字母 单词间使用下划线 (‘_’) 分隔，但不鼓励 类型名首字母大写, 单词间使用驼峰式分隔. 函数名和宏名使用小写字母, 不使用下划线分隔单词. 修改参数的函数结尾使用 ! . 这样的函数被称为 mutating functions 或 in-place functions 字符串 关于 Julia 字符串，有一些值得注意的高级特性： String 是个抽象类型，不是具体类型 Julia 的 Char 类型代表单字符，是由 32 位整数表示的 Unicode 码位 与 Java 中一样，字符串不可更改：String 对象的值不能改变。要得到不同的字符串，需要构造新的字符串 概念上，字符串是从索引值映射到字符的部分函数，对某些索引值，如果不是字符，会抛出异常 Julia 支持全部 Unicode 字符: 文本字符通常都是 ASCII 或 UTF-8 的，但也支持其它编码 Julia 函数的参数遵循 “pass-by-sharing” 的惯例，即不传递值，而是传递引用。函数参数本身，有点儿像新变量绑定（引用值的新位置），但它们引用的值与传递的值完全相同。对可变值（如数组）的修改，会影响其它函数。 Julia 提供一系列控制流： 复合表达式 ： begin 和 (;) 条件求值 ： if-elseif-else 和 ?: (ternary operator) 短路求值 ： &amp;&amp;, || 和 chained comparisons 重复求值: 循环 ： while 和 for 异常处理 ： try-catch ， error 和 throw 任务（也称为协程） ： yieldto 任务（也称为协程）任务是一种允许计算灵活地挂起和恢复的控制流，有时也被称为对称协程、轻量级线程、协同多任务等。 如果一个计算（比如运行一个函数）被设计为 Task，有可能因为切换到其它 Task 而被中断。原先的 Task 在以后恢复时，会从原先中断的地方继续工作。切换任务不需要任何空间，同时可以有任意数量的任务切换，而不需要考虑堆栈问题。任务切换与函数调用不同，可以按照任何顺序来进行。 任务比较适合生产者-消费者模式，一个过程用来生产值，另一个用来消费值。消费者不能简单的调用生产者来得到值，因为两者的执行时间不一定协同。在任务中，两者则可以正常运行。 Julia 提供了 produce 和 consume 函数来解决这个问题。生产者调用 produce 函数来生产值：]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-toolkit]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F12%2Fpython-toolkit%2F</url>
    <content type="text"><![CDATA[整理部分代码 python常见代码的归纳总结判断文件或者文件夹是否存在 if(os.path.exists(rootdir) == False) 创建文件夹 os.mkdir(rootdir) 调用系统命令 os.system(cmd) 字典循环 for key,value in dict.items() 打开文件并读取内容进行处理 fd = open(&apos;xxxx.txt&apos;, encoding=&apos;utf-8&apos;) for line in fd: print line fd.close() 创建文件并写入内容 fd = open(&apos;xxxx.txt&apos;, &apos;a+&apos;, encoding=&apos;utf-8&apos;) fd.write(&apos;aaaaa&apos; + &apos;\n&apos;) fd.close() 使用xlrd读取EXCEL 导入 import xlrd 打开excel data = xlrd.open_workbook(&apos;demo.xls&apos;) # 注意这里的workbook首字母是小写 查看文件中包含sheet的名称 data.sheet_names() 得到第一个工作表，或者通过索引顺序 或 工作表名称 table = data.sheets()[0] table = data.sheet_by_index(0) table = data.sheet_by_name(u&apos;Sheet1&apos;) 获取行数和列数 nrows = table.nrows ncols = table.ncols 获取整行和整列的值（数组） table.row_values(i) table.col_values(i) 循环行,得到索引的列表 for rownum in range(table.nrows): print table.row_values(rownum) 单元格 cell_A1 = table.cell(0,0).value cell_C4 = table.cell(2,3).value 分别使用行列索引 cell_A1 = table.row(0)[0].value cell_A2 = table.col(1)[0].value 简单的写入 row = 0 col = 0 ctype = 1 # 类型 0 empty,1 string, 2 number, 3 date, 4 boolean, 5 error value = &apos;lixiaoluo&apos; xf = 0 # 扩展的格式化 (默认是0) table.put_cell(row, col, ctype, value, xf) table.cell(0,0) # 文本:u&apos;lixiaoluo&apos; table.cell(0,0).value # &apos;lixiaoluo&apos; 使用xlwt写入EXCEL 导入xlwt import xlwt 新建一个excel文件 file = xlwt.Workbook() #注意这里的Workbook首字母是大写，无语吧 新建一个sheet table = file.add_sheet(&apos;sheet name&apos;) 写入数据table.write(行,列,value) table.write(0,0,&apos;test&apos;) 如果对一个单元格重复操作，会引发 returns error: # Exception: Attempt to overwrite cell: # sheetname=u&apos;sheet 1&apos; rowx=0 colx=0 所以在打开时加cell_overwrite_ok=True解决 table = file.add_sheet(&apos;sheet name&apos;,cell_overwrite_ok=True) 保存文件 file.save(&apos;demo.xls&apos;) 另外，使用style style = xlwt.XFStyle() #初始化样式 font = xlwt.Font() #为样式创建字体 font.name = &apos;Times New Roman&apos; font.bold = True style.font = font #为样式设置字体 table.write(0, 0, &apos;some bold Times text&apos;, style) # 使用样式 命令行 getopt try: options,args = getopt.getopt(sys.argv[1:],&quot;hp:i:&quot;,[&quot;help&quot;,&quot;ip=&quot;,&quot;port=&quot;]) except getopt.GetoptError: sys.exit() for name,value in options: if name in (&quot;-h&quot;,&quot;--help&quot;): usage() if name in (&quot;-i&quot;,&quot;--ip&quot;): print(value) if name in (&quot;-p&quot;,&quot;--port&quot;): print(value) 简单爬虫 import requests AGENT = &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36&apos; HEADERS = { &apos;User-Agent&apos;: AGENT, &apos;Content-Type&apos;:&apos;application/x-www-form-urlencoded; charset=UTF-8&apos;, &apos;X-Requested-With&apos;:&apos;XMLHttpRequest&apos;, &apos;Accept&apos;:&apos;*/*&apos; session = requests.session() 模拟登录postdata = { &apos;defaults&apos;:&apos;xxx&apos;, &apos;fromLogin&apos;:&apos;xxx&apos;, &apos;userName&apos;:&apos;xxx&apos;, &apos;password&apos;:&apos;xxxx&apos; } url = &apos;xxxxxxxx&apos; login_info = session.post(url, headers = HEADERS, data = postdata,verify = False) if(login_info.status_code == requests.codes.ok): print(&apos;login success&apos;) return True else: print(&apos;login err&apos;) return False } 下载html页面def downloadUrl(rootdir, url, orgid, page): html = session.get(url, headers=global_config.HEADERS, verify=False) if(html.text[1:7] == &apos;script&apos;): print(html.text) return &quot;err&quot; if(len(html.text) &lt; 60): return &quot;err&quot; sample = open(rootdir + &quot;/&quot; + str(orgid) + &apos;_&apos; + str(page) + &quot;.html&quot;, &quot;w&quot;, encoding=&apos;utf-8&apos;) sample.write(html.text) sample.close() return &apos;ok&apos; 解析JOSN文件内容 def scrapy_by_file(json_file_name): #读取JSON文件的内容 text = open(json_file_name, encoding=&apos;utf-8&apos;).read() #特殊处理,去除从WINDOWS系统带过来的BOM特殊字符 if text.startswith(u&apos;\ufeff&apos;): text = text.encode(&apos;utf8&apos;)[3:].decode(&apos;utf8&apos;) #将文本内容的JSON数据转换成自定义的JSON对象 try: json_data = json.loads(text) except: print(json_file_name) return for row in json_data[&apos;rows&apos;]: def scrapy_by_row(row): try: orgid = row[&apos;organization&apos;][&apos;id&apos;] familyid = row[&apos;censusRegisterFamily&apos;][&apos;id&apos;] except: print(&apos;errrr&apos;) return scrapy_by_row(row) 遍历文件夹 遍历目录(rootdir) 遍历到的每个文件都执行dirFuncdef waklThroughDir(rootdir, dirFunc): for parent, dirnames, filenames in os.walk(rootdir): for filename in filenames: print(filename) #获取后缀为txt的文件 if(filename.split(&apos;.&apos;)[-1] == &apos;html&apos;): dirFunc(os.path.join(parent, filename)) ##采集温州房产网基本信息 # -*- coding: utf-8 -*- import re import requests import time #-----------------------------用于解析的正则表达式常量------------------------------------------------------------------ #解析页数 PAGE_NUM = '共找到 (.*?) 符合条件的记录' #解析小区名称 NAME = 'texttext_title"&gt;&lt;ahref(.*?)&lt;/a&gt;&lt;/div&gt;&lt;divclass="texttext_moreinfo"&gt;' #解析小区价格 PRICE = 'class="hot_price"&gt;(.*?)&lt;/span&gt;' #解析小区地址 ADDRESS = 'text_moreinfo"&gt;(.*?)&lt;/div&gt;&lt;divclass="texttext_moreinfo"&gt;&lt;span&gt;' #文件生成路径 ROOTDIR = 'F:\\test\\' #-----------------------------模拟请求的头部信息，否则将被识别出是程序抓包而被拦截-------------------------------------- HEADERS = { 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8', 'Accept-Encoding': 'gzip, deflate, sdch', 'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36', 'Host': 'www.0577home.net', 'Upgrade-Insecure-Requests': '1' } #-----------------------------抓取某一页的房产信息，pageNo为页号-------------------------------------------------------- def getHouseListByPageno(pageNo): #建立一个连接用于后续发起请求 session = requests.session() url = 'http://www.0577home.net/xiaoqu/list_0_0_0_0_0_0_0_' + str(pageNo) + '.html' houseList = session.get(url, headers = HEADERS, verify = False) #以写入模式打开文件 fh = open(ROOTDIR + "houseList_pageNo" + str(pageNo) + ".txt", 'w' ,encoding='utf-8') #将movieList写入文件 fh.write(houseList.text) #关闭文件 fh.close() #-------------------------------获取需要抓取的页面总数------------------------------------------------------------------ def getPageNum(): #打开已经下载好的第一页房产内容 f = open(ROOTDIR + 'houseList_pageNo1.txt', encoding='utf-8') #获取文件内容 rawContent = f.read() #用正则表达式解析页面内容 pageNum = re.findall(PAGE_NUM, rawContent) #返回页面号 return int(pageNum[0]) / 20 + 1 def parseHouseListToFile(srcFile, dstFile): #打开待解析的文件 f = open(srcFile, encoding='utf-8') #读取文件内容以备解析 rawContent = f.read() p = re.compile('\s+') content = re.sub(p, '', rawContent) dnames = re.findall(NAME, content) names = [] for dname in dnames: idx = dname.rfind('&gt;') names.append(dname[idx + 1:]) prices = re.findall(PRICE, content) daddress = re.findall(ADDRESS, content) address = [] for daddr in daddress: id = daddr.rfind('&gt;') address.append(daddr[id + 1:]) i = 0 for x in names: #写入时用'$'做分割，结尾加上回车符 dstFile.write(names[i] + '$' + prices[i] + '$' + address[i] + '\n') i = i + 1 # -------------------------------主函数，下载并解析房产信息-------------------------------------------------------------- if __name__ == '__main__': #---------------------抓取页面----------------------------- #抓取第一页房产信息 getHouseListByPageno(1) #通过第一页房产信息获取总共要抓取的页面数量 pageNum = getPageNum() #抓取剩余的页面 for i in range(2, int(pageNum) + 1): getHouseListByPageno(str(i)) #---------------------解析页面----------------------------- #获取当前年月日 localtime = time.strftime('%Y%m%d', time.localtime(time.time())) #创建一个文件，文件名前面带上年月日 f = open(ROOTDIR + localtime + '_houseList.txt', 'a+', encoding='utf-8') #解析所有的页面 #for k in range(1, int(pageNum) + 1): for k in range(1, 115): parseHouseListToFile(ROOTDIR + "houseList_pageNo" + str(k) + ".txt", f) #关闭文件 f.close() f = open(ROOTDIR + localtime + '_houseList.txt', encoding='utf-8') fd = open(ROOTDIR + localtime + '_houseInfo.txt', 'w', encoding='utf-8') k = 0 for line in f: data = line.strip('\n') data = data.split('$') idx = data[3] getHouseInfoByPageno(idx, k) houseInfo = parseHouseInfo(ROOTDIR + "houseInfo_pageNo" + str(idx) + ".html") print(str(k) + "$".join(data) + '$' + "$".join(houseInfo)) fd.write("$".join(data) + '$' + "$".join(houseInfo) + '\n') k += 1 f.close() fd.close() 调用java import sys import jpype name = sys.argv[1] jarpath = &apos;/home/dsadm/why/python&apos; jpype.startJVM(jpype.getDefaultJVMPath(), &quot;-Djava.ext.dirs=%s&quot; % jarpath) DECRYPT = jpype.JClass(&apos;why.fmrt.decrypt.DECRYPT&apos;) upperName =DECRYPT.decrypt(name) print(upperName) jpype.shutdownJVM() 构建 web 页面 import os import tornado.httpserver import tornado.ioloop import tornado.options import tornado.web from view import * from tornado.options import define, options define(&quot;port&quot;, default=8000, help=&quot;run on the given port&quot;, type=int) class Application(tornado.web.Application): def __init__(self): handlers = [ (r&quot;/&quot;, Indexhandler), ] settings = dict( template_path=os.path.join(os.path.dirname(__file__), &apos;templates&apos;), autoescape=None, debug=False, ) tornado.web.Application.__init__(self, handlers, **settings) if __name__ == &quot;__main__&quot;: tornado.options.parse_command_line() http_server = tornado.httpserver.HTTPServer(Application(), xheaders=True) http_server.listen(options.port) tornado.ioloop.IOLoop.instance().start() 多进程 import multiprocessing for process_id in range(PROCESS_NUM): p = multiprocessing.Process(target=worker, args=(process_id,)) jobs.append(p) p.start() 多线程 # -*- coding: utf-8 -*- import threading class Threadconfig(): def __init__(self, thread_size): self.thread_size = thread_size def topen(self): self.thread_tasks = [] def build(self, func, **kwargs): self.thread_task = threading.Thread(target=func, kwargs=(kwargs)) self.thread_tasks.append(self.thread_task) def run(self): for thread_task in self.thread_tasks: thread_task.setDaemon(True) thread_task.start() while 1: alive = False for thread_num in range(0, self.thread_size): alive = alive or self.thread_tasks[thread_num].isAlive() if not alive: break def __del__(self): self.thread_tasks = [] 移除中文分隔符号 cmd = &quot;sed &apos;:a;N;$ s/\\r\\n//g;ba&apos; &quot; + oldfile + &quot; &gt; &quot; + newfile os.system(cmd)]]></content>
  </entry>
  <entry>
    <title><![CDATA[数据科学起步01]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F10%2F%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E8%B5%B7%E6%AD%A501%2F</url>
    <content type="text"><![CDATA[线性回归是所有模型的基石手工玩偶店的小何童鞋，想分析下玩偶的数量和成本之间的关系，他得到了如下表格的数据。将这些数据放在了图像之上，似乎是一个线性的关系，但是感觉并不严格，像是在一条直线上下随机波动。其实数据是由“自然之力”按照下面的公式来产生的。 其中b是一个随机变量，服从期望为0，方差为1的正态分布。 123456789101112131415161718192021# 10,7.7# 10,9.87# 11,11.18# 12,10.43# 13,12.36# 14,14.15# 15,15.73# 16,16.4# 17,18.86# 18,16.13# 19,18.21# 20,18.37# 21,22.61# 22,19.83# 23,22.67# 24,22.7# 25,25.16# 26,25.55# 27,28.21# 28,28.12# ... $$y{i} = x{i} + b_{i}$$ 机器学习的解法步骤如下：1.确定场景的类型2.定义损失函数，使得模型预测的成本和实际的成本相近3.提取特征（可能需要除去记错或者是特别异常的数据）4.确定模型并估计参数（直接上线性模型）5.评估模型效果（均方差要达到最小） 1%matplotlib inline 12import syssys.version &apos;3.6.4 (default, Jan 21 2018, 16:48:17) \n[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.39.2)]&apos; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135# _*_ coding=utf8 _*_"""机器学习方法实现"""import osimport sysimport matplotlib.pyplot as pltimport pandas as pd import numpy as npfrom sklearn import linear_modeldef data_load(path): # data = pd.read_csv(path) # data = pd.read_csv(path, delimiter='', header=0) # # 选择列 # data['x'] # data[['x', 'y']] # data.x # # # # 选择行 # data[:10] # data[10:] # data[2:3] passdef read_data(path):# data = pd.read_csv(path, delimiter=',', header=0) data = pd.read_csv(path) return datadef linearModel(data): features = ["x"] labels = ["y"] train_data = data[:15] test_data = data[15:] # 产生并且训练模型 model = train_model(train_data, features, labels) # 评价模型效果 error, score = evaluate_model(model, test_data, features, labels) # 图形化模型结果 visual_model(model, data, features, labels, error, score)def train_model(train_data, features, labels): model = linear_model.LinearRegression() model.fit(train_data[features], train_data[labels]) return modeldef evaluate_model(model, test_data, features, labels): error = np.mean( (model.predict(test_data[features]) - test_data[labels])**2) score = model.score(test_data[features], test_data[labels]) return error, scoredef visual_model(model, data, features, labels, error, score): """ 模型可视化 """ # 为在Matplotlib中显示中文，设置特殊字体 plt.rcParams['font.family'] = ['Heiti'] # 创建一个图形框 fig = plt.figure(figsize=(6, 6), dpi=80) # 在图形框里只画一幅图 ax = fig.add_subplot(111) # 在Matplotlib中显示中文，需要使用unicode # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.set_title(u'%s' % "线性回归示例") else: ax.set_title(u'%s' % "线性回归示例".decode("utf-8")) ax.set_xlabel('$x$') ax.set_ylabel('$y$') # 画点图，用蓝色圆点表示原始数据 # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.scatter(data[features], data[labels], color='b', label=u'%s: $y = x + \epsilon$' % "真实值") else: ax.scatter(data[features], data[labels], color='b', label=u'%s: $y = x + \epsilon$' % "真实值".decode("utf-8")) # 根据截距的正负，打印不同的标签 if model.intercept_ &gt; 0: # 画线图，用红色线条表示模型结果 # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.plot(data[features], model.predict(data[features]), color='r', label=u'%s: $y = %.3fx$ + %.3f'\ % ("预测值", model.coef_, model.intercept_)) else: ax.plot(data[features], model.predict(data[features]), color='r', label=u'%s: $y = %.3fx$ + %.3f'\ % ("预测值".decode("utf-8"), model.coef_, model.intercept_)) else: # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.plot(data[features], model.predict(data[features]), color='r', label=u'%s: $y = %.3fx$ - %.3f'\ % ("预测值", model.coef_, abs(model.intercept_))) else: ax.plot(data[features], model.predict(data[features]), color='r', label=u'%s: $y = %.3fx$ - %.3f'\ % ("预测值".decode("utf-8"), model.coef_, abs(model.intercept_))) legend = plt.legend(shadow=True) legend.get_frame().set_facecolor('#6F93AE') # 显示均方差和决定系数 # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.text(0.99, 0.01, u'%s%.3f\n%s%.3f'\ % ("均方差：", error, "决定系数：", score), style='italic', verticalalignment='bottom', horizontalalignment='right', transform=ax.transAxes, color='m', fontsize=13) else: ax.text(0.99, 0.01, u'%s%.3f\n%s%.3f'\ % ("均方差：".decode("utf-8"), error, "决定系数：".decode("utf-8"), score), style='italic', verticalalignment='bottom', horizontalalignment='right', transform=ax.transAxes, color='m', fontsize=13) # 展示上面所画的图片。图片将阻断程序的运行，直至所有的图片被关闭 # 在Python shell里面，可以设置参数"block=False"，使阻断失效。 plt.show()# 为什么搭建模型 有两个目的 使用模型对未知数据做预测；或者利用模型分析数据，找出数据的内在规律，为决策提供支持。# 在利用模型做预测时，我们希望模型的准确度越高越好，但是在利用模型做分析时， 我们则更关心模型是否是可靠的 12345678if __name__ == '__main__':# home_path = os.path.dirname(os.path.abspath(__file__)) if os.name == "posix": data_path = "./data/simple_example.csv" data = read_data(data_path) print(data.shape)# linearModel(data) (20, 2) 1linearModel(data) /usr/local/Cellar/python3/3.6.4_2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to &apos;gelss&apos; driver. warnings.warn(mesg, RuntimeWarning) 统计学1.假设条件概率2.估计参数3.推导参数的分布4.假设检验和置信区间 使用第三方库 statsmodels 来训练线性回归模型 123456789101112131415161718192021222324import statsmodels.api as smdef linear_model2(data): features = ["x"] labels = ["y"] Y = data[labels] X = sm.add_constant(data[features]) result = train_model2(X, Y) model_summary(result) def train_model2(X, Y): model = sm.OLS(Y, X) result = model.fit() return resultdef model_summary(result): # 整体统计分析结果 print(result.summary()) print(result.f_test("x=0")) print(result.f_test("const=0")) print(result.f_test(["x=0", "const=0"])) 123datapath = "./data/simple_example.csv"data = read_data(datapath)linear_model2(data) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.962 Model: OLS Adj. R-squared: 0.960 Method: Least Squares F-statistic: 460.5 Date: Tue, 07 Aug 2018 Prob (F-statistic): 2.85e-14 Time: 11:40:29 Log-Likelihood: -31.374 No. Observations: 20 AIC: 66.75 Df Residuals: 18 BIC: 68.74 Df Model: 1 Covariance Type: nonrobust ============================================================================== coef std err t P&gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ const -0.9495 0.934 -1.017 0.323 -2.912 1.013 x 1.0330 0.048 21.458 0.000 0.932 1.134 ============================================================================== Omnibus: 0.745 Durbin-Watson: 2.345 Prob(Omnibus): 0.689 Jarque-Bera (JB): 0.673 Skew: 0.074 Prob(JB): 0.714 Kurtosis: 2.113 Cond. No. 66.3 ============================================================================== Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. &lt;F test: F=array([[ 460.4584822]]), p=2.848465414495684e-14, df_denom=18, df_num=1&gt; &lt;F test: F=array([[ 1.03355794]]), p=0.32279564008314576, df_denom=18, df_num=1&gt; &lt;F test: F=array([[ 2442.62159921]]), p=1.2108814742372977e-22, df_denom=18, df_num=2&gt; 得到参数b的估计值为-0.9495, 但是这个值在b=0这个假设下的P-value高达32.3%，统计学上认为这种参数是不显著的，应该舍弃此参数。同理a的估计值是1.033，P-value小于0.01，因此a是显著的，应该被纳入模型。因此，需要调整模型。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import osimport sysimport numpy as npimport statsmodels.api as smfrom statsmodels.sandbox.regression.predstd import wls_prediction_stdimport matplotlib.pyplot as pltimport pandas as pddef modelSummary(re): """ 分析线性回归模型的统计性质 """ # 整体统计分析结果 print(re.summary()) # 在Windows下运行此脚本需确保Windows下的命令提示符(cmd)能显示中文 # 用f test检测x对应的系数a是否显著 print("检验假设x的系数等于0：") print(re.f_test("x=0")) # 用f test检测常量b是否显著 print("检测假设const的系数等于0：") print(re.f_test("const=0")) # 用f test检测a=1, b=0同时成立的显著性 print("检测假设x的系数等于1和const的系数等于0同时成立：") print(re.f_test(["x=1", "const=0"]))def visualizeModel(re, data, features, labels): """ 模型可视化 """ # 计算预测结果的标准差，预测下界，预测上界 prstd, preLow, preUp = wls_prediction_std(re, alpha=0.05) # 为在Matplotlib中显示中文，设置特殊字体 plt.rcParams['font.family'] = ['Heiti'] # 创建一个图形框 fig = plt.figure(figsize=(6, 6), dpi=80) # 在图形框里只画一幅图 ax = fig.add_subplot(111) # 在Matplotlib中显示中文，需要使用unicode # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.set_title(u'%s' % "线性回归统计分析示例") else: ax.set_title(u'%s' % "线性回归统计分析示例".decode("utf-8")) ax.set_xlabel('$x$') ax.set_ylabel('$y$') # 画点图，用蓝色圆点表示原始数据 # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.scatter(data[features], data[labels], color='b', label=u'%s: $y = x + \epsilon$' % "真实值") else: ax.scatter(data[features], data[labels], color='b', label=u'%s: $y = x + \epsilon$' % "真实值".decode("utf-8")) # 画线图，用红色虚线表示95%置信区间 # 在Python3中，str不需要decode if sys.version_info[0] == 3: ax.plot(data[features], preUp, "r--", label=u'%s' % "95%置信区间") ax.plot(data[features], re.predict(data[features]), color='r', label=u'%s: $y = %.3fx$'\ % ("预测值", re.params[features])) else: ax.plot(data[features], preUp, "r--", label=u'%s' % "95%置信区间".decode("utf-8")) ax.plot(data[features], re.predict(data[features]), color='r', label=u'%s: $y = %.3fx$'\ % ("预测值".decode("utf-8"), re.params[features])) ax.plot(data[features], preLow, "r--") legend = plt.legend(shadow=True) legend.get_frame().set_facecolor('#6F93AE') plt.show()def trainModel(X, Y): """ 训练模型 """ model = sm.OLS(Y, X) re = model.fit() return redef linearModel2(data): """ 线性回归统计性质分析步骤展示 参数 ---- data : DataFrame，建模数据 """ features = ["x"] labels = ["y"] Y = data[labels] # 加入常量变量 X = sm.add_constant(data[features]) # 构建模型 re = trainModel(X, Y) # 分析模型效果 modelSummary(re) # const并不显著，去掉这个常量变量 resNew = trainModel(data[features], Y) # 输出新模型的分析结果 print(resNew.summary()) # 将模型结果可视化 visualizeModel(resNew, data, features, labels) 12linearModel2(data) OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.962 Model: OLS Adj. R-squared: 0.960 Method: Least Squares F-statistic: 460.5 Date: Tue, 07 Aug 2018 Prob (F-statistic): 2.85e-14 Time: 11:42:08 Log-Likelihood: -31.374 No. Observations: 20 AIC: 66.75 Df Residuals: 18 BIC: 68.74 Df Model: 1 Covariance Type: nonrobust ============================================================================== coef std err t P&gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ const -0.9495 0.934 -1.017 0.323 -2.912 1.013 x 1.0330 0.048 21.458 0.000 0.932 1.134 ============================================================================== Omnibus: 0.745 Durbin-Watson: 2.345 Prob(Omnibus): 0.689 Jarque-Bera (JB): 0.673 Skew: 0.074 Prob(JB): 0.714 Kurtosis: 2.113 Cond. No. 66.3 ============================================================================== Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. 检验假设x的系数等于0： &lt;F test: F=array([[ 460.4584822]]), p=2.848465414495684e-14, df_denom=18, df_num=1&gt; 检测假设const的系数等于0： &lt;F test: F=array([[ 1.03355794]]), p=0.32279564008314576, df_denom=18, df_num=1&gt; 检测假设x的系数等于1和const的系数等于0同时成立： &lt;F test: F=array([[ 0.99654631]]), p=0.3886267976063851, df_denom=18, df_num=2&gt; OLS Regression Results ============================================================================== Dep. Variable: y R-squared: 0.996 Model: OLS Adj. R-squared: 0.996 Method: Least Squares F-statistic: 4876. Date: Tue, 07 Aug 2018 Prob (F-statistic): 2.26e-24 Time: 11:42:08 Log-Likelihood: -31.933 No. Observations: 20 AIC: 65.87 Df Residuals: 19 BIC: 66.86 Df Model: 1 Covariance Type: nonrobust ============================================================================== coef std err t P&gt;|t| [0.025 0.975] ------------------------------------------------------------------------------ x 0.9862 0.014 69.825 0.000 0.957 1.016 ============================================================================== Omnibus: 0.489 Durbin-Watson: 2.218 Prob(Omnibus): 0.783 Jarque-Bera (JB): 0.561 Skew: 0.033 Prob(JB): 0.755 Kurtosis: 2.182 Cond. No. 1.00 ============================================================================== Warnings: [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. 来对比下两种解法，数据科学家在搭建模型时，通常会定义一些技术指标来衡量模型预测的准确度。需要模型参数的估计值是可靠的，但是事实并非如此，机器学习的模型结果显示，玩偶生产的固定成本是负数，这违背了事实。模型没有抓住数据真正的内在关系。为了提高预测的准确度，常常提取更多的特征，并以此搭建复杂的模型。大家都热衷于复杂度更高的模型。一旦发生过拟合，模型越复杂，错得越多。]]></content>
      <categories>
        <category>data</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据分析]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F08%2F01%2F%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[1.数据整合困难 半导体制造涉及的工序和设备非常多，各种英文名字的系统很多到现在都还没有完全搞清楚，数据也分散在各个系统中，有结构化的，也有非结构化的（各种wafer map），很多数据存在于设备的日志中，基本没有被使用过。即使要使用这些数据，也面临一些困难，比如有些设备数据我们没有权限访问，需要跟Vendor申请，有些数据Vendor做过加密，需要解密（如PDF的FDC raw trace数据，与厂商沟通很久，才能得到你想要的），有些设备数据服务器挂掉了，都没人知道，甚至找不到服务器维护人员（如Tel公司的WIS数据，应该很有价值，但是数据服务器直接挂掉好久了）。另外，这些数据一般缺少元数据，没有数据字典这种东西，你拿到这些数据，也要花费很长时间去理解数据，更不用说将所有这些系统的数据整合打通了。还好目前已经整清楚一部分数据了，包括传统的YMS数据（WAT,CP,Metrology,WIP）和tool数据（iEMS，FDC），后续有机会把半导体行业数据一点一点理清楚，设计一套公共数据模型（类似互联网数据中台），可以满足各种数据应用 2.组织架构不够完善 随着大数据兴起，公司高层还是非常重视大数据的，但在组织架构上并没有提升到很高的位置，毕竟对于半导体制造，大数据仍然属于边缘的Support部门。在IT部门下面有传统的EA（Engineering Analysis）部门，很多资源在做数据接口、数据解析、报表等工作，在YE，YAE等偏业务部门也有数据分析团队，他们更接近Fab的用户，有实际的use case，能积累一定的行业经验。现在公司又冒出了大数据团队，既有IT的EA下面一个小团队（主要是搞个大数据平台hadoop，在上面做一些数据分析和应用），也有YE下面的一个小团队（面向业务需求，提供大数据应用），这几波人经常没有形成合力，事情推动起来比较困难，IT里面搞大数据的，接触用户的机会比较少，经常会搞一些研究型的项目（如做各种correlation），并没有跟实际业务问题对接起来。业务部门的大数据团队面临数据整合的困难，面临巧妇难为无米之炊的困境，在数据没有整合好之前，很难做出大的成果，IT在数据方面是有优势的，它负责各种数据库系统，对数据更清楚一些。这几个团队如果能够整合成一个大数据部门，并在组织架构上上升一层，价值会体现的更加明显。另外，团队内部角色定位和分工也不是很清晰，按照EA1,EA2这种划分有意义吗？团队内部也没有形成很好的工作流程，各个小组工作互不相干，在一个部门内部甚至很少会有接触到。智能制造不仅体现在IT自动化和信息化水平上，未来更多要体现在数据应用上，要让数据提供智能决策和生产。 3、依赖外部大数据供应商 IT部门比较忙的事情，就是跟各种大数据分析厂商搞POC，采购各种分析工具，大数据分析技能没有提升多少，各种厂商的工具倒接触了不少（PDF的extensio，bistel eDatalyzer，nanometrics，spotfire），主要是部门没有资源做自主分析，很多大数据人才不会选择制造业，还有部门领导也不相信自己的团队能做出来，借着POC名义让大家学习人家是怎么做的。目前大数据分析厂商大多数是国外的，主要是国外半导体行业发展好，有大量的应用机会，这其实是国内大数据的一个机会，制造业的问题相对比较通用一些，是比较容易做出解决方案和软件工具的，随着国内半导体行业的发展，是有制造业大数据创业机会的。 4、传统方法使用大数据 半导体制造分析使用传统统计分析方法较多（DOE，ANOVA，boxplot，假设检验），这跟行业特点是有关系的，不像互联网更关注相关关系，制造业更关注因果关系，发现了问题，要找到问题的根本原因，才能解决问题，所以DOE的思想是比较好理解的。但是这些方法的缺陷也比较明显，半导体制程太复杂，影响因素太多，每个因素都做DOE，是非常低效的，这时候机器学习、深度学习的方法是可以大大提高解决问题效率的，用户对这块的接受度还是比较低的，他们对可解释性要求较高，其实机器学习有些基于规则的模型还是比较有价值的，要让用户接受这些将会是一个漫长的过程，要逐渐改变用户的观念。另外，在与用户沟通时，要主动引导用户，不要问用户需要什么（用户想要的就是各种correlation，boxplot，regression），要搞清楚用户面临的痛点，我们提供更好的解决方案帮他们解决就好了，而不是为用户提供他们所要的那些功能。]]></content>
      <categories>
        <category>data</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[drl does not work yet]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F05%2F21%2Fdrl-does-not-work-yet%2F</url>
    <content type="text"><![CDATA[劝退文先看一下作者的背景。作者叫 Alex Irpan，现为谷歌大脑机器人团队的软件工程师。他从伯克利拿到的计算机科学本科学位，本科的时候曾经在伯克利人工智能实验室（Berkeley AI Research (BAIR) Lab）进行本科科研，导师是 DRL 大牛 Pieter Abbeel，他还和 John Schulman 工作过。 这篇文章一上来就指出深度强化学习是个大坑。它的成功案例其实很少，但每个都太有名了，例如用 Deep Q Network（DQN）在 Atari games 上用原始像素图片作为状态达到甚至超越人类专家的表现、通过左右互搏（self-play）等方式在围棋上碾压人类、大大降低了谷歌能源中心的能耗等等。造成的结果就是没有从事过深度强化学习的研究人员对它产生了很大的错觉，高估了它的能力，低估了它的难度。 强化学习本身是一个非常通用的人工智能范式，在直觉上让人觉得非常适合用来模拟各种时序决策任务，如语音、文本类任务。当它和深度神经网络这种只要给我足够层和足够多的神经元，可以逼近任何函数的非线性函数近似模型结合在一起感觉要上天啊，无怪乎 DeepMind 经常号称人工智能=深度学习+强化学习。 然而 Alex 告诉我们别急，让我们先来审视一些问题： 1.它的样本利用率非常低。换言之为了让模型的表现达到一定高度需要极为大量的训练样本。 2.最终表现很多时候不够好。在很多任务上用非强化学习甚至非学习的其它方法，如基于模型的控制（model based control），线性二次型调节器（Linear Quadratic Regulator）等等可以获得好得多的表现。最气人的是这些模型很多时候样本利用率还高。当然这些模型有的时候会有一些假设比如有训练好的模型可以模仿，比如可以进行蒙特卡洛树搜索等等。 3.DRL 成功的关键离不开一个好的奖励函数（reward function），然而这种奖励函数往往很难设计。在 Deep Reinforcement Learning That Matters 作者提到有时候把奖励乘以一个常数模型表现就会有天和地的区别。但奖励函数的坑爹之处还不止如此。奖励函数的设计需要保证： 加入了合适的先验，良好的定义了问题和在一切可能状态下的对应动作。坑爹的是模型很多时候会找到作弊的手段。Alex 举的一个例子是有一个任务需要把红色的乐高积木放到蓝色的乐高积木上面，奖励函数的值基于红色乐高积木底部的高度而定。结果一个模型直接把红色乐高积木翻了一个底朝天。仔啊，你咋学坏了，阿爸对你很失望啊。 奖励函数的值太过稀疏。换言之大部分情况下奖励函数在一个状态返回的值都是 0。这就和我们人学习也需要鼓励，学太久都没什么回报就容易气馁。都说 21 世纪是生物的世纪，怎么我还没感觉到呢？21 世纪才刚开始呢。我等不到了啊啊啊啊啊。 有的时候在奖励函数上下太多功夫会引入新的偏见（bias）。 要找到一个大家都使用而又具有好的性质的奖励函数。这里Alex没很深入地讨论，但链接了一篇陶神（Terence Tao）的博客，大家有兴趣可以去看下。 4.局部最优/探索和剥削（exploration vs. exploitation）的不当应用。Alex举的一个例子是有一个连续控制的环境里，一个类似马的四足机器人在跑步，结果模型不小心多看到了马四脚朝天一顿乱踹后结果较好的情况，于是你只能看到四脚朝天的马了。 5.对环境的过拟合。DRL 少有在多个环境上玩得转的。你训练好的 DQN 在一个 Atari game上work 了，换一个可能就完全不 work。即便你想要做迁移学习，也没有任何保障你能成功。 6.不稳定性。 读 DRL 论文的时候会发现有时候作者们会给出一个模型表现随着尝试 random seed 数量下降的图，几乎所有图里模型表现最终都会降到 0。相比之下在监督学习里不同的超参数或多或少都会表现出训练带来的变化，而 DRL 里运气不好可能很长时间你模型表现的曲线都没有任何变化，因为完全不 work。 即便知道了超参数和随机种子，你的实现只要稍有差别，模型的表现就可以千差万别。这可能就是 Deep Reinforcement Learning That Matters 一文里 John Schulman 两篇不同文章里同一个算法在同一个任务上表现截然不同的原因。 即便一切都很顺利，从我个人的经验和之前同某 DRL 研究人员的交流来看只要时间一长你的模型表现就可能突然从很好变成完全不 work。原因我不是完全确定，可能和过拟合和 variance 过大有关。 特别是上述第六点，几乎是灾难性的。作者提到自己实习的时候一开始实现 Normalized Advantage Function (NAF)，为了找出 Theano 本身的 bugs 花了六周，这还是在 NAF 作者就在他旁边可以供他骚扰的情况下的结果。原因就是DRL的算法很多时候在没找好超参数的情况下就是不 work 的，所以你很难判断自己的代码到底有没有 bug 还是运气不好。 作者也回顾了 DRL 成功的案例，他认为 DRL 成功的案例其实非常少，大体包括： 各类游戏：Atari Games, Alpha Go/Alpha Zero/Dota2 1v1/超级马里奥/日本将棋，其实还应该有 DRL 最早的成功案例，93年的西洋双陆棋（backgammon）。 DeepMind 的跑酷机器人。 为 Google 的能源中心节能。 Google 的 AutoML。 作者认为从这些案例里获得的经验教训是 DRL 可能在有以下条件的情况下更可能有好的表现，条件越多越好： 数据获取非常容易，非常 cheap。 不要急着一上来就攻坚克难，可以从简化的问题入手。 可以进行左右互搏。 奖励函数容易定义。 奖励信号非常多，反馈及时。 他也指出了一些未来潜在的发展方向和可能性： 局部最优或许已经足够好。未来某些研究可能会指出我们不必过于担心大部分情况下的局部最优。因为他们比起全局最优并没有差很多。 硬件为王。在硬件足够强的情况下我们或许就不用那么在乎样本利用率了，凡事硬刚就可以有足够好的表现。各种遗传算法玩起来。 人为添加一些监督信号。在环境奖励出现频次太低的情况下可以引入自我激励（intrinsic reward）或者添加一些辅助任务，比如DeepMind就很喜欢这套，之前还写了一篇 Reinforcement Learning with Unsupervised Auxiliary Tasks（https://arxiv.org/abs/1611.05397） 。LeCun 不是嫌蛋糕上的樱桃太少吗，让我们多给他点樱桃吧！ 更多融合基于模型的学习从而提高样本使用率。这方面的尝试其实已经有很多了，具体可以去看 Alex 提到的那些工作。但还远不够成熟。 仅仅把 DRL 用于 fine-tuning。比如最初 Alpha Go 就是以监督学习为主，以强化学习为辅。 自动学习奖励函数。这涉及到 inverse reinforcement learning 和 imitation learning。 迁移学习和强化学习的进一步结合。 好的先验。 有的时候复杂的任务反而更容易学习。Alex 提到的例子是 DeepMind 经常喜欢让模型学习很多同一环境的变种来减小对环境的过拟合。我觉得这也涉及 curriculum learning，即从简单的任务开始逐步加深难度。可以说是层层递进的迁移学习。另外一个可能的解释是很多时候人觉得困难的任务和机器觉得困难的任务是相反的。比如人觉得倒水很简单，你让机器人用学习的路子去学倒水就可以很难。但反过来人觉得下围棋很简单而机器学习模型却在下围棋上把人击败了。 最后 Alex 总体还是非常乐观的。他说尽管现在有很多困难，使得 DRL 或许还不是一个强壮（robust）到所有人都可以轻易加入的研究领域并且很多时候一些问题用DRL远没有监督学习简单和表现好，但或许过几年你再回来 DRL 就 work 了也未知啊。这还是很振奋人心的。田渊栋老师也表达过类似的想法，觉得正因为这个领域还不够成熟所以还有很多机会。他们都是了不起的研究人员。]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux高级命令]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F05%2F20%2Flinux%E9%AB%98%E7%BA%A7%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[1.找出以 .conf结尾的文件 并且分类 1234567891011121314 find / -name *.conf -type f -print | xargs file``` 2.找出系统内存使用量较高的进程```bash ps -aux | sort -rnk 4 | head 20``` 3.cpu(上条sort 处改为3)4.持续ping将结果记录到日志 ping api.jpush.cn | awk```]]></content>
  </entry>
  <entry>
    <title><![CDATA[hadoop-intro]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F05%2F15%2Fhadoop-intro%2F</url>
    <content type="text"></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how-dl]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F05%2F15%2Fhow-dl%2F</url>
    <content type="text"></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how-identify-tech-man]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F05%2F12%2Fhow-identify-tech-man%2F</url>
    <content type="text"><![CDATA[技术招聘除了考察人的协作精神和工作态度，一大目标便是判断人的技术能力和实际水平。在这件事情上多做观察、思考是很有意义的。 对于考察人的技术等级，学界是有认真的研究的。参见：德雷福斯模型解说。德雷福斯模型把人的技能水平，分成5级：新手、高级新手、胜任者、精通者、专家。对不同技能等级的认定是这样的： 新手：依靠指令清单，必须按部就班。就是必须给出详细而具体的操作规则，才能工作。比如你做一道从未做过的菜，需要看菜谱的说明，第一步做什么，第二步做什么等等，直到最后烹饪结束。 高级新手：有限的情景洞察力，同等对待工作的各个方面。对全局性、体系性的东西没兴趣。这是小工的水平。比如他能跟着师傅干点活，打打下手。可以靠着反复检索搜索引擎、StackOverflow解决具体的小问题。 胜任者：能够独立解决各种各样的领域内问题。这是一般的企业招聘，比较希望招到的等级，招进来稍作适应就能干活了，省心省力。 精通者：经验丰富，可以自我纠正、自我改进。这类等级的人，思考可以指向内在，通过反省、反馈改善技能。这种在企业可以算上高手、大拿了，培养不易。 专家：依靠直觉工作，不需要解释和理由。实际你让他解释，他可能也说不出个所以然，就是直觉给出答案，然后还是对的。专家人数稀少，需要很长时间训练、实践。通常的说法是10年出专家，10000小时定律。 这个是理论上的研究，实践中比较缺乏操作性，难以迅速的判定应聘者的实际情况。不信你打开收进来的大把简历，刚毕业的学生，每个技能名词上面都是一堆堆的“精通” – 你相信么？但它可以当成一个职业技能等级判定的参照标准。 于是乎，各家企业开启了各种“笔试”、“机试”，多轮面试，并且严格要求学历以及出身院校，试图以此过滤掉不合意的应征者，留下合格的人选。它当然是可行的，但是效果一般，而且容易出错，错失有思想有水平的人。不然也不会催生出各类“推荐式”的招聘。看重学历、学校当然也有其优点：它是快速过滤的手段，毕竟能考上好学校的人智商不会太差吧。但在大数字公司的一朋友说，公司里面还有初中毕业，一直精研安全领域的人，技术能力也是十分出色。如果严苛对待背景，这些人就会错过了。因为人的生活多种多样，有各种历史的背景因素影响经历。而部分人的经历，就是跟一些人不同的，可是不妨碍他们同样可以变得优秀。招聘，实际上是建立信任关系。如果有充足的信息证明，应聘者足够优秀，这就够了。条条框框只是辅助手段，并不是目的。 推荐式的招聘实际要靠谱的多，因为人很容易了解熟悉的人的水平。这是靠推荐者的信用背书。人平时沟通时说什么话，日常看什么书，关注哪些领域，琢磨过啥问题，哪些东西很熟，这个经常聊的熟人往往都知道。可是，这类招聘局限性也很大：面窄、靠机缘。靠推荐能招几个好手啊？好手往往是各家争抢的对象，窗口期有限，基本不会缺工作的。 说了一圈，还是要在技能水准判定上有更高效率的办法，招进合适的人来。 回到开头的德雷福斯模型，既然人的技能是分级的，那么对待不同的职位要求，也应该侧重不同的考察角度。如果千篇一律的走招聘流程，就容易出问题了。比如你明明要找的是“精通者”，可上来就让人一堆笔试、机试，这是不合适的。对方会十分的厌烦。体现高水平技术能力的并不在默写什么“字符串算法”那里。这反倒是刚毕业的人占便宜，因为才学过不久，印象深。不信你让工作10年的人跟计算机专业应届生比比写排序算法，真未必能赢。但是这并不重要 – 你干活不看手册不查文档吗？聪明人从不死记硬背。重要的地方在于对问题域的准确、深刻的理解，对各类技术优劣点、各种条件平衡的评判和把握。 对待初阶新人，应着重考察的是基本功是否扎实，专业成绩是否优秀。更重要的，是他对职业的热情，学习能力和研究精神。某类人要说起技术来，滔滔不绝，两眼放光，充满热情，对未知的、新生的各类概念、技术非常好奇，这种人想差都难。因为他会自我驱动，不用督促，自己就钻研前进。反之，觉得这个职业待遇高，只是想混饭吃的人，很少走得长远。这类初阶新人以毕业生、工作年限少者为多。测试考核，可以笔试查看其对基础概念的理解是否准确，知识领域的大致范围。甚至，布置一个有点挑战性的小任务，让他尝试解决，说明思路。 考察胜任、精通者的策略不一样。笔试做题没啥用，原因前面说了。这类招聘是重头戏，企业都喜欢找这样的，能干活。所以考核评估的地方也较多。我觉得可以分成几个方面去看。意识是否先进，是否会反省思考；是否善于解决问题，富有创造性；是否有比较深的积累和广阔的知识面。 业界的开发思想也是在不断变化，工具链一直在革新。聪明的人不用蛮力，而爱用工具提升效率，喜欢自动化操作解放人力。要查看人用什么开发工具链，用什么开发环境，解释下为什么？好的开发者会及时注意新出现的工具，挖掘它能解决什么问题，并尝试吸收，解决自己的需求。如果没有这个思想意识，工作效率就会打折扣了。因为你会落后行业发展水平。人善于自我反省，则会催动自我纠正，这正是精通者的特征。参考：优秀的开发者为什么要学习研究新的编程语言？ 解决问题的能力是重头戏，也是企业招聘人的主因。人要善于解决实际问题，而且，要学会聪明的解决问题。解决问题要看思路，看手段，看是否有创造性，这是真正考验人能力的地方。好的开发者，会考虑很多可能选项，预估各种优劣，给出一个较优的方案。 遇到难题，会用各种方法尝试。经验丰富的人，常常会使用技术的组合手段来处理难题，而不是一个语言一个工具到处用。所以，要查看下过往的项目经历遇到的问题、困难，是如何解决的，思路如何。一些公司据说不招聘不会用谷歌的工程师。谷歌打不开？嘿嘿，这就是你要克服的困难啊。这你都解决不了，还做什么研发。谷歌是人类最全、最新知识的总索引，充分利用事半功倍。 考察知识的深度、广度，对重要领域的概念是否有深刻的理解和掌握，以及从各类工作经验中得到的认知。问问他看过什么书，研究过什么东西。说白了，知道的东西是否多。一些公司很喜欢用CheckList模式来考核，列一堆领域的知识点、概念，问人懂不懂，知道就是水平好，不懂就是水平差。实际情况并非如此。人的工作过程是独立的，一些事情如果没有工作机会去接触并解决，那么一些冷僻的问题就永远都碰不上。当然也就不知道。但你能说没做过就一定做不好么？ 另外，人的技能树，其实也是“犬牙交错、参差不齐”的。什么意思？技术领域非常的广阔，你真的没办法每个领域都很精通，实际上是这个做的多，懂的多，那个用的少，知道的少。这个时候，应看具体知识领域，是哪一类。它是否需要复杂的、难度较高的背景。门槛高的技术，需要的配套技能多得多，比如AI、机器学习。而一般产品应用领域则不然，了解核心概念、设计意图，看着手册、最佳实践，也就能上手了。这个暂时不会，实际无关紧要的，工作一段学的认真点就会了。但是门槛高的领域，就需要很长时间的学习了。这是本质的差别。 学习了。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[what-can-python-do]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F04%2F18%2Fwhat-can-python-do%2F</url>
    <content type="text"><![CDATA[1.看看目前深圳python的职位情况 云计算相关 openstack 相关 运维平台（运维开发） web开发 大数据 高并发 深度学习的相关应用 …… 2.来看看一个招聘的需求 良好的python基础 oop]]></content>
  </entry>
  <entry>
    <title><![CDATA[my-vim-note]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F04%2F16%2Fmy-vim-note%2F</url>
    <content type="text"><![CDATA[安装 vim yum install ncurses-devel -y wget https://github.com/vim/vim/archive/master.zip unzip master.zip cd vim-master cd src/ ./configure make sudo make install vim --version 安装 python vimrc 配置文件]]></content>
  </entry>
  <entry>
    <title><![CDATA[js-learn-note-2018]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F04%2F15%2Fjs-learn-note-2018%2F</url>
    <content type="text"><![CDATA[Yarn是由Facebook开发的，可以认为它是NPM工具的改良版，因为它支持并行操作，这是npm所没有的功能，且可以更有效地利用了网络。Yarn受欢迎的原因包括：更快地的执行速度、强大的工作系统、许可检查功能、以及与NPM和和Bower软件包管理工具的完美兼容。 函数式编程 将运算过程定义成不同的函数 React 基于 Virtual DOM 实现了一个 SyntheticEvent （合成事件）层，我们所定义的事件处理器会接收到一个 SyntheticEvent 对象的实例，它完全符合 W3C 标准，不会存在任何 IE 标准的兼容性问题。并且与原生的浏览器事件一样拥有同样的接口，同样支持事件的冒泡机制，我们可以使用 stopPropagation() 和 preventDefault() 来中断它。所有事件都自动绑定到最外层上。如果需要访问原生事件对象，可以使用 nativeEvent 属性。 高阶组件 组件优化： 多使用纯函数：无依赖；相同输入相同输出；重复使用。 PureComponent：本质上讲，PureComponent就是重写了shouldComponentUpdate，对nextProps和nextState与当前state和props做浅比较，性能上优化。 Immutable：使用Immutable共享数据节点，节省渲染。 key：列表渲染指定key，相同key不渲染；尽量不要使用index当key，最好是id。 react-addons-pref：插件量化性能优化效果。 6.react 源码结构 addons：工具方法插件：PureRenderMixin、CSSTransitionGrouo、Fragment、LinkedStateMixin。 isomorphic：包含一系列同构方法。 shared：公用方法和常用方法。 test：测试方法。 core/tests：边界错误的测试用例。 renderers：React的核心代码，包含大部分功能实现，因此进行单独分析。]]></content>
  </entry>
  <entry>
    <title><![CDATA[github-big-things]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F04%2F13%2Fgithub-big-things%2F</url>
    <content type="text"><![CDATA[2008 ruby on rails 09 比特币 node.js 10 rails girls 11 travis ci 12 JavaScript 崛起 13 1000万repos 14 docker 15 unreal engine 16 apollo 17 python团队入驻 tensorflow 1.0开源 18 十周年]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python面试常考十二道题目]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F04%2F01%2Fpython%E9%9D%A2%E8%AF%9512%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.简述函数式编程在函数式编程中，函数是基本单位，变量只是一个名称，而不是一个存储单元。除了匿名函数外，Python还使用fliter(),map(),reduce(),apply()函数来支持函数式编程。 2.什么是匿名函数，匿名函数有什么局限性匿名函数，也就是lambda函数，通常用在函数体比较简单的函数上。匿名函数顾名思义就是函数没有名字，因此不用担心函数名冲突。不过Python对匿名函数的支持有限，只有一些简单的情况下可以使用匿名函数。 3.如何捕获异常，常用的异常机制有哪些？如果我们没有对异常进行任何预防，那么在程序执行的过程中发生异常，就会中断程序，调用python默认的异常处理器，并在终端输出异常信息。 try…except…finally语句:当try语句执行时发生异常，回到try语句层，寻找后面是否有except语句。找到except语句后，会调用这个自定义的异常处理器。except将异常处理完毕后，程序继续往下执行。finally语句表示，无论异常发生与否，finally中的语句都要执行。 assert语句：判断assert后面紧跟的语句是True还是False，如果是True则继续执行print，如果是False则中断程序，调用默认的异常处理器，同时输出assert语句逗号后面的提示信息。 with语句：如果with语句或语句块中发生异常，会调用默认的异常处理器处理，但文件还是会正常关闭。 4.copy()与deepcopy()的区别copy是浅拷贝，只拷贝可变对象的父级元素。 deepcopy是深拷贝，递归拷贝可变对象的所有元素。 5.函数装饰器有什么作用（常考）装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。有了装饰器，就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。 6.简述Python的作用域以及Python搜索变量的顺序Python作用域简单说就是一个变量的命名空间。代码中变量被赋值的位置，就决定了哪些范围的对象可以访问这个变量，这个范围就是变量的作用域。在Python中，只有模块（module），类（class）以及函数（def、lambda）才会引入新的作用域。Python的变量名解析机制也称为 LEGB 法则：本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in） 7.新式类和旧式类的区别,如何确保使用的类是新式类为了统一类(class)和类型(type)，python在2.2版本引进来新式类。在2.1版本中，类和类型是不同的。 为了确保使用的是新式类，有以下方法： 放在类模块代码的最前面 metaclass = type从内建类object直接或者间接地继承在python3版本中，默认所有的类都是新式类。 8.简述new和init的区别创建一个新实例时调用new,初始化一个实例时用init,这是它们最本质的区别。 new方法会返回所构造的对象，init则不会. new函数必须以cls作为第一个参数，而init则以self作为其第一个参数. 9.Python垃圾回收机制(常考)Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。 1 引用计数 PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.引用计数为0时，该对象生命就结束了。 优点: 简单 实时性 缺点: 维护引用计数消耗资源 循环引用 2 标记-清除机制 基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。 3 分代技术 分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长。 10.Python中的@property有什么作用?如何实现成员变量的只读属性？@property装饰器就是负责把一个方法变成属性调用，通常用在属性的get方法和set方法，通过设置@property可以实现实例成员变量的直接访问，又保留了参数的检查。另外通过设置get方法而不定义set方法可以实现成员变量的只读属性。 11.*args and **kwargs*args代表位置参数，它会接收任意多个参数并把这些参数作为元组传递给函数。 **kwargs代表的关键字参数，允许你使用没有事先定义的参数名，另外，位置参数一定要放在关键字参数的前面。 12.有用过with statement吗？它的好处是什么？具体如何实现？with语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。]]></content>
  </entry>
  <entry>
    <title><![CDATA[以太坊区块链简介]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F31%2F%E4%BB%A5%E5%A4%AA%E5%9D%8A%E5%8C%BA%E5%9D%97%E9%93%BE%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[以太坊区块链到底是什么？区块链有 2 个主要组件： 数据库：网络中每笔交易都存储在区块链上。当你部署合约时，就是一笔交易。当你为候选者投票时，又是另一笔交易。所有的这些交易都是公开的，每个人都可以看到并进行验证。这个数据永远也无法篡改。为了确保网络中的所有节点都有着同一份数据拷贝，并且没有向数据库中写入任何的无效数据，以太坊使用一个叫做工作量证明的算法来保证网络安全。(http://ethereum.stackexchange.com/questions/14/what-proof-of-work-function-does-ethereum-use) 代码：就数据库的层面而言，区块链就是存储交易。那么给候选者投票，检索所有投票的逻辑放在哪儿呢？在以太坊的世界里，你可以通过一个叫 Solidity 的语言编写逻辑/应用代码（也就是合约）。然后用 solidity 编译器将代码编译为以太坊字节码，并将字节码部署到区块链上（也有一些其他的语言可以写合约，不过 solidity 是到目前为止用得最多也是相对更容易的选择）。所以，以太坊不仅仅会存储交易，它还会存储和执行合约代码。 基本上，区块链就是存储数据和代码，并在 EVM（Ethereum Virtual Machine，以太坊虚拟机）中执行代码。为了构建基于 web 的 Dapp，以太坊也有一个非常方便的 JavaScript 库，叫做 web3.js，它可以连接到区块链节点。所以，你可以在一些有名的 js 框架，比如 reactjs，angularjs 等等中直接引入该库构建应用。 在异步的网络模型中，所有的节点由于没有时钟仅仅能根据接收到的消息作出判断，这时完全不能同时保证一致性、可用性和分区容错性，每一个系统只能在这三种特性中选择两种。不过这里讨论的一致性其实都是强一致性，也就是所有节点接收到同样的操作时会按照完全相同的顺序执行，被一个节点提交的更新操作会立刻反映在其他通过异步或部分同步网络连接的节点上，如果想要同时满足一致性和分区容错性，在异步的网络中，我们只能中心化存储所有数据，通过其他节点将请求路由给中心节点达到这两个目的。 最终一致性允许多个节点的状态出现冲突，但是所有能够沟通的节点都能够在有限的时间内解决冲突，从不一致的状态恢复到一致，这里列出的两个条件比较重要，一是节点直接可以正常通信，二是冲突需要在有限的时间内解决，只有在这两个条件成立时才能达到最终一致性。 拜占庭将军问题FLP 不可能定理是分布式系统领域最重要的定理之一，它给出了一个非常重要的结论：在网络可靠并且存在节点失效的异步模型系统中，不存在一个可以解决一致性问题的确定性算法。 这个定理其实也就是告诉我们不要浪费时间去为异步分布式系统设计在任意场景上都能够实现共识的算法，异步系统完全没有办法保证能在有限时间内达成一致。 在整个共识算法运行的过程中，Proposer 负责提出提案并向 Acceptor 分别发出两次 RPC 请求，Prepare 和 Accept；Acceptor 会根据其持有的信息 minProposal、acceptedProposal 和 acceptedValue 选择接受或者拒绝当前的提案，当某一个提案被过半数的 Acceptor 接受之后，我们就认为当前提案被整个集群接受了。]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pep8规范]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F28%2Fpep8%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[缩进每层缩进使用 4 个空格 断行风格断行首字母与括号开启符垂直对齐 # 这是正确的例子： foo = long_function_name(var_one, var_two, var_three, var_four) 悬挂缩进，首行不能有参数; 后面还有其它代码部分时，断行要添加一层缩进，使其与其它代码部分能区别开来 # 这是正确的例子，额外添加了一层缩进： def long_function_name( var_one, var_two, var_three, var_four): print(var_one) # 这是错误的例子，悬挂缩进，后面还有其它代码时，需要添加一层额外的缩进加以区别： def long_function_name( var_one, var_two, var_three, var_four): print(var_one) # 这是正确的例子，悬挂缩进方式应该有一层缩进 foo = long_function_name( var_one, var_two, var_three, var_four) # 这是错误的例子，悬挂方式首行不能有参数： foo = long_function_name(var_one, var_two, var_three, var_four) if 条件断行if ( 刚好有 4 个字条，相当于一层缩进。对于 if 条件断行，以下几种风格都可以： 没有额外的缩进 if (this_is_one_thing and that_is_another_thing): do_something() 添加注释加以区分 # Add a comment, which will provide some distinction in editors # supporting syntax highlighting. if (this_is_one_thing and that_is_another_thing): # Since both conditions are true, we can frobnicate. do_something() 添加额外的缩进加以区分 # Add some extra indentation on the conditional continuation line. if (this_is_one_thing and that_is_another_thing): do_something() 多行的括号括号结束符与最后行的首字符对齐，如： my_list = [ 1, 2, 3, 4, 5, 6, ] result = some_function_that_takes_arguments( &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, ) 括号结束符与首行的首字符对齐, 如： my_list = [ 1, 2, 3, 4, 5, 6, ] result = some_function_that_takes_arguments( &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, ) Tab 符还是空格用空格 每行最长长度所有行都不超过 80 个字符：限制编辑器窗口的宽度，使能并排同时打开多个文件。设置编辑器宽度（ set width to 80），来避免 wrapping对于较少结构限制的长文本（如 docstring 或注释），行长应限制为 72 个字符。如果团队成员都同意使用长行，则可以将行长增加到不超过 100 个字符，但是 docstring 和注释还必须为 72 个字符。有括号的长行可以用 implicit continuation 来断行，其它的可以用 \ 来断行，如： with open(&apos;/path/to/some/file/you/want/to/read&apos;) as file_1, \ open(&apos;/path/to/some/file/being/written&apos;, &apos;w&apos;) as file_2: file_2.write(file_1.read()) 操作符要和操作数在一起# 推荐的正确的风格，这样很容易将操作符与操作数匹配： income = (gross_wages + taxable_interest + (dividends - qualified_dividends) - ira_deduction - student_loan_interest) # 这种风格现成已不推荐使用了： income = (gross_wages + taxable_interest + (dividends - qualified_dividends) - ira_deduction - student_loan_interest) 空行分隔模块中最顶层的函数和类定义都要用两行空行分隔类中的方法定义用单行分隔要把一组相关的函数分组，可以用一些额外的空行函数中的逻辑区块可以加空行来分隔 源文件的编码Python 核心库文件的编码都必须用 UTF-8（Python 2 是 ASCII)。使用默认的编码时（Python 3: UTF-8，Python 2: ASCII)，不能使用编码声明标准库中，只有测试、作者名才能使用非默认的编码，其它情况下的非 ASCII 字符用 \x, \u, \u, \N 表示法表示。 Import每行 import 只导入一个包： # 正确: import os import sys # 错误： import sys, os # 正确：同一包中的内容可以在同一行导入 from subprocess import Popen, PIPE import 语句要在文件的前面，在模块注释及 docstring 之后，在模块全局变量和常数定义之前。 import 分组及导入顺序，每个分组之间用一行空行分隔 1). 标准库 2). 相关第三方库 3). 本地应用/库的特殊导入 推荐使用绝对导入，如： import mypkg.sibling from mypkg import sibling from mypkg.sibling import example 在复杂的包布局中，也可以用显式的相对导入，如： from . import sibling from .sibling import example 从一个模块中导入一个类时，要显示拼写出类名，如： from myclass import MyClass from foo.bar.yourclass import YourClass 如果与本地名称冲突，可以先导入模块： import myclass import foo.bar.yourclass 然后使用：&quot;myclass.MyClass&quot; 和 &quot;foo.bar.yourclass.YourClass&quot;。 应该避免使用 from &lt;module&gt; import * 模块级的特殊名称（如all)的位置：必须在模块的 docstring 或注释之后，但在任何的 import 语句之前。from future 比较特殊，Python 强制该语句必须在 docstring 或注释之后，因此风格如下： &quot;&quot;&quot;This is the example module. This module does stuff. &quot;&quot;&quot; from __future__ import barry_as_FLUFL __all__ = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] __version__ = &apos;0.1&apos; __author__ = &apos;Cardinal Biggles&apos; import os import sys 字符引号单引号和双引号的功能是等同的。对于多行字符串，应该用双引号字符形式的三引号””“，以便与 PEP257 中的 docstring 规范兼容 表达式和语句中的空格()、[]、{} 等括号内不要有多余的空格，如： # 正确： spam(ham[1], {eggs: 2}) # 错误： spam( ham[ 1 ], { eggs: 2 } ) ,、;、: 之前不要有空格，如： # 正确： if x == 4: print x, y; x, y = y, x # 错误： if x == 4 : print x , y ; x , y = y , x 在 slice 语句中的 :实际上是一个二元操作符，因此其两侧的空格数必须相同; 但当无 slice 参数时，两侧的空格可以都省略，如： # 以下是正确的风格： ham[1:9], ham[1:9:3], ham[:9:3], ham[1::3], ham[1:9:] ham[lower:upper], ham[lower:upper:], ham[lower::step] ham[lower+offset : upper+offset] ham[: upper_fn(x) : step_fn(x)], ham[:: step_fn(x)] ham[lower + offset : upper + offset] # 以下是错误的风格： ham[lower + offset:upper + offset] ham[1: 9], ham[1 :9], ham[1:9 :3] ham[lower : : upper] ham[ : upper] 函数调用的 () 及索引的 [] 前不要加空格，如： # 正确风格： spam(1) dct[&apos;key&apos;] = lst[index] # 错误风格： spam (1) dct [&apos;key&apos;] = lst [index] 不要在赋值语句中加入额外的空格来对齐，如： # 正确的风格： x = 1 y = 2 long_variable = 3 # 错误的风格: x = 1 y = 2 long_variable = 3 其它推荐风格任何行的行尾都不要有空白符。在二元操作符两侧一般都要加一个空格，一般的二元操作符如：赋值: =, +=, -=比较：==, &lt;, &gt;, !=, &lt;&gt;, &lt;=, &gt;=, in, not in, is, is not布尔操作： and, or, not在分优先级的表达式中，在最低优先级的操作符两侧加一个空格，但至多只能加一个空格，如： # 正确的风格： x = x*2 - 1 hypot2 = x*x + y*y c = (a+b) * (a-b) # 错误的风格： x = x * 2 - 1 hypot2 = x * x + y * y c = (a + b) * (a - b) 在关键字参数和默认参数值中的 = 两侧不要加空格，如： # 正确的风格： def complex(real, imag=0.0): return magic(r=real, i=imag) 错误的风格： def complex(real, imag = 0.0): return magic(r = real, i = imag) 函数注解中的 : 前不要加空格，这符合 : 的常规风格，但是 -&gt; 两侧要加空格，如： # 正确的风格： def munge(input: AnyStr): ... def munge() -&gt; AnyStr: ... # 错误的风格： def munge(input:AnyStr): ... def munge()-&gt;PosInt: ... 参数注解中，如果注解的参数有默认值，指定默认值的 = 两侧要加空格，如： # 正确的风格： def munge(sep: AnyStr = None): ... def munge(input: AnyStr, sep: AnyStr = None, limit=1000): ... # 错误的风格： def munge(input: AnyStr=None): ... def munge(input: AnyStr, limit = 1000): ... 不要将多条语句组合在一行中，如： # 正确的风格： if foo == &apos;blah&apos;: do_blah_thing() do_one() do_two() do_three() # 错误风格： if foo == &apos;blah&apos;: do_blah_thing() do_one(); do_two(); do_three() # 如果 if/for/while 体很小，组合在一行有时还是可以接受的， # 但是不推荐，如： if foo == &apos;blah&apos;: do_blah_thing() for x in lst: total += x while t &lt; 10: t = delay() # 但是在有多段语句时，绝对不能这样，如： if foo == &apos;blah&apos;: do_blah_thing() else: do_non_blah_thing() try: something() finally: cleanup() do_one(); do_two(); do_three(long, argument, list, like, this) if foo == &apos;blah&apos;: one(); two(); three() 注释注释内容必须要和代码同步！ 注释应该是完整的语句，首字母一般大写，一般要有句号。 注释很短时句号可以省略。 块注释一般由多个段落组成。 You should use two spaces after a sentence-ending period?? 用英文写注释 块注释每行用 # 及一个空格开始，如 # 段落用一个只有 # 的行分隔 行内注释注释与语句内容至少用两个空格分开，注释用 # 加一个空格开始 # 不要像下面这样，注释内容没有必要 x = x + 1 # Increment x # 但是有时，如下面的注释会很有用 x = x + 1 # Compensate for border 文档字符串公开的模块、函数、类及方法都应该有文档字符串，而非公开的方法可以用注释来代替，且注释放置在 def 行之后。多行的文档字符串，结束符要自成一行，如：“””Return a foobang Optional plotz says to frobnicate the bizbaz first.“””单行的文档字符串，结束符和内容放在同一行 命名没有推荐的风格，但是别人要能从你的代码中看出你用的是什么风格，常用的风格如下：b 单个小写字母B 单个大写字母 lowercase lower_case_with_underscores UPPERCASE UPPER_CASE_WITH_UNDERSCORES CapitalizedWords, 这种风格中，对于缩写词应全部用大写，如 HTTTPServerError 比 HttpServerError 好 mixedCase Capitalized_Words_With_Underscores，这个太丑，不要用这种！ st_mode、st_mtime 等前缀，一般是系统接口返回，如果自己写的代码不推荐用这种 _single_leading_underscore : 弱 “内部使用” 指示器，这种对象用 from M import * 不会被导入 single_trailing_underscore_ : 可以用来和 Python 关键词进行区分，如 Tkinter.Toplevel(master, class_=&apos;ClassName&apos;) __double_leading_underscore : 命名一个类属性时，可以进行命名矫正，例如 class FooBar 内的 __boo 会变成 _FooBar__boo double_leading_and_trailing_underscore : “magic” 对象，不要自己发明这种对象 命名传统不用单个 l, O, I 等这样的单个字符来命名，它们与数字不好区分包名和模块名：全部用小写，必要时可用 ，但不推荐，C/C++ 的扩展模块，如果其对应有 Python 版本，那么 C/C++ 扩展模块名前加 类名：用 CapWords 风格异常名：用 CapWords 风格，一般应该有 Error 后缀全局变量名：能用 from M import * 导入的变量全部放在 all 中，或者全局变量用 做前缀函数名：应该用全部用小写，单词间可以用 分隔，如 myfunc，不推荐用 mixedCase 风格函数和方法的参数：实例方法的第一个参数用 self, 类方法的第一个参数用 cls，如果参数与关键字冲突，在参数名后加 后缀，如 class实例变量和方法： 用小写字符和 , 非公开的实例变量和方法用一个 做前缀; 避免与子类中的名字冲突，类的变量可用两个 作前缀，例如 class FooBar 内的 boo 会变成只能通过 FooBar._FooBarboo 访问常数：全部大写，可用 _ 分隔，如 MAX_OVERFLOW、TOTAL 推荐的编程方式字符串连接不要用 a += b 或者 a = a + b, 用 &apos;&apos;.join(), 后者性能更好。 和单子如 None 的比较用 is 和 is not，不要用 ==，如果你想判断 if x is not None, 不要缩写成 if x 使用 if foo is not None，而不是 if not foo is None，前者更加易读 如果要实现序列比较操作的话，应将 6 个操作（__eq__ , __ne__ , __lt__ , __le__ , __gt__ , __ge__）全部实现，可以借助 functools.total_ordering() 修饰器来减少工作量 将函数保存在一个变量中应该用 def f(x): return 2*x， 而非 f = lambda x: 2*x，后者不利于调试 自定义的异常类应该继承至 Exception 类，而非 BaseException 类。 Python 2 中抛出异常用 raise ValueError(&apos;message&apos;)，而非 raise ValueRoor, &apos;message&apos; 尽可以的指明异常名，如： try: import platform_specific_module except ImportError: platform_specific_module = None 避免使用无异常名的 except: 语句，它会捕获全部的异常（如 Ctrl C）。 将异常绑定到名字的方法： try: process_data() except Exception as exc: raise DataProcessingFailedError(str(exc)) try: 中的语句要尽量减少，如： # 正确的写法： try: value = collection[key] except KeyError: return key_not_found(key) else: return handle_value(value) # 错误的写法 try: # Too broad! return handle_value(collection[key]) except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key) 如果资源只适用于某个代码段内，使用 with 或 try/finally 来确保能进行清理工作 上下文管理器应用通过一个单独的函数或方法来激活，如： # 正确的做法： with conn.begin_transaction(): do_stuff_in_transaction(conn) # 错误的做法： with conn: do_stuff_in_transaction(conn) return 语句应该一致，如： # 正确的做法： def foo(x): if x &gt;= 0: return math.sqrt(x) else: return None def bar(x): if x &lt; 0: return None return math.sqrt(x) # 错误的做法： def foo(x): if x &gt;= 0: return math.sqrt(x) def bar(x): if x &lt; 0: return return math.sqrt(x) 使用字符串的方法，而不是用 string 模块中的方法 使用 &apos;&apos;.startswith() 和 &apos;&apos;.endswidth() 而不用 slicing 来检查前缀和后缀： # 正确： if foo.startswith(&apos;bar&apos;): # 错误： if foo[:3] == &apos;bar&apos;: 判断对象的类型用 isinstance 而不直接 type 比较，如： # 正确： if isinstance(obj, int): # 错误: if type(obj) is type(1): 对序列是否空的判断不用 len，如： # 正确： if not seq: if seq: # 错误： if len(seq): if not len(seq): 布尔值的比较： # 正确： if greeting: # 不要这样: if greeting == True: # 这样更不行： if greeting is True: 检测工具使用 Flake8 来检查代码质量。]]></content>
  </entry>
  <entry>
    <title><![CDATA[multiprocessing源码分析]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F28%2Fmultiprocessing%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[threading源码分析]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F28%2Fthreading%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[inspect源码分析]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F28%2Finspect%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[gevent-note]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F28%2Fgevent-note%2F</url>
    <content type="text"><![CDATA[Coroutine 也就是 corporate routine，直译为「协同的例程」，中文一般叫做「协程」, 实际上这个概念和进程与线程有相似之处, 因为linux线程就是所谓的「轻量级进程」。 在gevent源码分析中找到一段表述的比较好的描述进程和协程异同的内容: 相同点: 二者都是可以看做是一种执行流, 该执行流可以挂起,并且在将来又可以在 你挂起的地方恢复执行, 这实际上都可以看做是continuation, 我们来看看当我们挂 起一个执行流时我们要保存的东西：栈, 因为如果你不保存栈,那么局部变量你就无法恢复,同时函数的调用链你也无 法恢复,寄存器的状态: 这好理解, 比如说EIP,如果你不保存,那么你恢复执行流就不知道 到底执行哪一条指令, 在比如说ESP,EBP, 如果你不保存,那么你即便有完整的栈 你也不知道怎么用.这二者实际就是所谓的上下文,也可以说是continuation. 在执行流切换时必须保存 这两个东西, 内核调度进程时也是一回事. 不同点: 执行流的调度者不同, 进程是内核调度, 而协程是在用户态调度, 也就是说进程 的上下文是在内核态保存恢复的,而协程是在用户态保存恢复的. 很显然用户态的 代价更低进程会被抢占,而协程不会,也就是说协程如果不主动让出CPU,那么其他的协程是不 可能得到执行机会,这实际和早期的操作系统类似,比如DOS, 它有一个yield原语, 一个进程调用yield,那么它就会让出CPU, 其他的进程也就有机会执行了, 如果一 个进程进入了死循环,那么整个系统也就挂起了,永远无法运行其他的进程了, 但 对协程而言,这不是问题对内存的占用不同,实际上协程可以只需要4K的栈就够了, 而进程占用的内存要大 的多.从操作系统的角度讲, 多协程的程序是单线程,单进程的那用一句话描述协程的优势就是由开发者决定协程的切换，操作系统无法干预切换，且占用内存小的多。 Gevent是一种基于协程的Python网络库，它用到Greenlet提供的，封装了libevent事件循环的高层同步API。它让开发者在不改变编程习惯的同时，用同步的方式写异步I/O的代码。 Gvanrossum从来不喜欢Gevent，而是更愿意另辟蹊径的实现asyncio(基于生成器的协程)。 1.Monkey-patching。中文「猴子补丁」，常用于对测试环境做一些hack。我个人不太喜欢这种「黑魔法」，因为如果其他人不了解细节，极为容易产生困惑。Gvanrossum说用它就是”patch-and-pray”，太形象了。由于Gevent直接修改标准库里面大部分的阻塞式系统调用，包括socket、ssl、threading和 select等模块，而变为协作式运行。但是我们无法保证你在复杂的生产环境中有哪些地方使用这些标准库会由于打了补丁而出现奇怪的问题，那么你只能祈祷（pray）了。其次，在Python之禅中明确说过：「Explicit is better than implicit.」，猴子补丁明显的背离了这个原则。最后，Gvanrossum说Stackless之父Christian Tismer也赞同他。 我喜欢显式的「yield from」 2.第三方库支持。得确保项目中用到其他用到的网络库也必须使用纯Python或者明确说明支持Gevent，而且就算有这样的第三方库，我还会担心这个第三方库的代码质量和功能性。Greenlet不支持Jython和IronPython，这样就无法把gevent设计成一个标准库了。之前是没有选择，很多人选择了Gevent，而现在明确的有了更正统的、正确的选择：asyncio（下一篇会详细介绍）。所以建议大家放弃Gevent，拥抱asyncio。 在Python 2的时代，高性能的网络编程主要是使用Twisted、Tornado和Gevent这三个库，但是它们的异步代码相互之间既不兼容也不能移植。如上一节说的，Gvanrossum希望在Python 3 实现一个原生的基于生成器的协程库，其中直接内置了对异步IO的支持，这就是asyncio，它在Python 3.4被引入到标准库。 Python 3.5添加了async和await这两个关键字，分别用来替换asyncio.coroutine和yield from。自此，协程成为新的语法，而不再是一种生成器类型了。事件循环与协程的引入，可以极大提高高负载下程序的I/O性能。除此之外还增加了async with(异步上下文管理)、async for(异步迭代器)语法。特别说的是，在新发布的Python 3.6里面终于可以用异步生成器了！ 现存的一些库其实并不能原生的支持asyncio（因为会发生阻塞或者功能不可用），比如requests，如果要写爬虫，配合asyncio的应该用aiohttp，其他的如数据库驱动等各种Python对应的库也都得使用对应的aioXXX版本了。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[one-blockchain-src-anal]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F27%2Fone-blockchain-src-anal%2F</url>
    <content type="text"><![CDATA[看看代码的实现： import hashlib import json from time import time from urllib.parse import urlparse from uuid import uuid4 import requests from flask import Flask, jsonify, request class Blockchain: def __init__(self): self.current_transactions = [] self.chain = [] self.nodes = set() # Create the genesis block self.new_block(previous_hash=&apos;1&apos;, proof=100) def register_node(self, address): &quot;&quot;&quot; Add a new node to the list of nodes :param address: Address of node. Eg. &apos;http://192.168.0.5:5000&apos; &quot;&quot;&quot; parsed_url = urlparse(address) if parsed_url.netloc: self.nodes.add(parsed_url.netloc) elif parsed_url.path: # Accepts an URL without scheme like &apos;192.168.0.5:5000&apos;. self.nodes.add(parsed_url.path) else: raise ValueError(&apos;Invalid URL&apos;) def valid_chain(self, chain): &quot;&quot;&quot; Determine if a given blockchain is valid :param chain: A blockchain :return: True if valid, False if not &quot;&quot;&quot; last_block = chain[0] current_index = 1 while current_index &lt; len(chain): block = chain[current_index] print(f&apos;{last_block}&apos;) print(f&apos;{block}&apos;) print(&quot;\n-----------\n&quot;) # Check that the hash of the block is correct if block[&apos;previous_hash&apos;] != self.hash(last_block): return False # Check that the Proof of Work is correct if not self.valid_proof(last_block[&apos;proof&apos;], block[&apos;proof&apos;], last_block[&apos;previous_hash&apos;]): return False last_block = block current_index += 1 return True def resolve_conflicts(self): &quot;&quot;&quot; This is our consensus algorithm, it resolves conflicts by replacing our chain with the longest one in the network. :return: True if our chain was replaced, False if not &quot;&quot;&quot; neighbours = self.nodes new_chain = None # We&apos;re only looking for chains longer than ours max_length = len(self.chain) # Grab and verify the chains from all the nodes in our network for node in neighbours: response = requests.get(f&apos;http://{node}/chain&apos;) if response.status_code == 200: length = response.json()[&apos;length&apos;] chain = response.json()[&apos;chain&apos;] # Check if the length is longer and the chain is valid if length &gt; max_length and self.valid_chain(chain): max_length = length new_chain = chain # Replace our chain if we discovered a new, valid chain longer than ours if new_chain: self.chain = new_chain return True return False def new_block(self, proof, previous_hash): &quot;&quot;&quot; Create a new Block in the Blockchain :param proof: The proof given by the Proof of Work algorithm :param previous_hash: Hash of previous Block :return: New Block &quot;&quot;&quot; block = { &apos;index&apos;: len(self.chain) + 1, &apos;timestamp&apos;: time(), &apos;transactions&apos;: self.current_transactions, &apos;proof&apos;: proof, &apos;previous_hash&apos;: previous_hash or self.hash(self.chain[-1]), } # Reset the current list of transactions self.current_transactions = [] self.chain.append(block) return block def new_transaction(self, sender, recipient, amount): &quot;&quot;&quot; Creates a new transaction to go into the next mined Block :param sender: Address of the Sender :param recipient: Address of the Recipient :param amount: Amount :return: The index of the Block that will hold this transaction &quot;&quot;&quot; self.current_transactions.append({ &apos;sender&apos;: sender, &apos;recipient&apos;: recipient, &apos;amount&apos;: amount, }) return self.last_block[&apos;index&apos;] + 1 @property def last_block(self): return self.chain[-1] @staticmethod def hash(block): &quot;&quot;&quot; Creates a SHA-256 hash of a Block :param block: Block &quot;&quot;&quot; # We must make sure that the Dictionary is Ordered, or we&apos;ll have inconsistent hashes block_string = json.dumps(block, sort_keys=True).encode() return hashlib.sha256(block_string).hexdigest() def proof_of_work(self, last_block): &quot;&quot;&quot; Simple Proof of Work Algorithm: - Find a number p&apos; such that hash(pp&apos;) contains leading 4 zeroes - Where p is the previous proof, and p&apos; is the new proof :param last_block: &lt;dict&gt; last Block :return: &lt;int&gt; &quot;&quot;&quot; last_proof = last_block[&apos;proof&apos;] last_hash = self.hash(last_block) proof = 0 while self.valid_proof(last_proof, proof, last_hash) is False: proof += 1 return proof @staticmethod def valid_proof(last_proof, proof, last_hash): &quot;&quot;&quot; Validates the Proof :param last_proof: &lt;int&gt; Previous Proof :param proof: &lt;int&gt; Current Proof :param last_hash: &lt;str&gt; The hash of the Previous Block :return: &lt;bool&gt; True if correct, False if not. &quot;&quot;&quot; guess = f&apos;{last_proof}{proof}{last_hash}&apos;.encode() guess_hash = hashlib.sha256(guess).hexdigest() return guess_hash[:4] == &quot;0000&quot; # Instantiate the Node app = Flask(__name__) # Generate a globally unique address for this node node_identifier = str(uuid4()).replace(&apos;-&apos;, &apos;&apos;) # Instantiate the Blockchain blockchain = Blockchain() @app.route(&apos;/mine&apos;, methods=[&apos;GET&apos;]) def mine(): # We run the proof of work algorithm to get the next proof... last_block = blockchain.last_block proof = blockchain.proof_of_work(last_block) # We must receive a reward for finding the proof. # The sender is &quot;0&quot; to signify that this node has mined a new coin. blockchain.new_transaction( sender=&quot;0&quot;, recipient=node_identifier, amount=1, ) # Forge the new Block by adding it to the chain previous_hash = blockchain.hash(last_block) block = blockchain.new_block(proof, previous_hash) response = { &apos;message&apos;: &quot;New Block Forged&quot;, &apos;index&apos;: block[&apos;index&apos;], &apos;transactions&apos;: block[&apos;transactions&apos;], &apos;proof&apos;: block[&apos;proof&apos;], &apos;previous_hash&apos;: block[&apos;previous_hash&apos;], } return jsonify(response), 200 @app.route(&apos;/transactions/new&apos;, methods=[&apos;POST&apos;]) def new_transaction(): values = request.get_json() # Check that the required fields are in the POST&apos;ed data required = [&apos;sender&apos;, &apos;recipient&apos;, &apos;amount&apos;] if not all(k in values for k in required): return &apos;Missing values&apos;, 400 # Create a new Transaction index = blockchain.new_transaction(values[&apos;sender&apos;], values[&apos;recipient&apos;], values[&apos;amount&apos;]) response = {&apos;message&apos;: f&apos;Transaction will be added to Block {index}&apos;} return jsonify(response), 201 @app.route(&apos;/chain&apos;, methods=[&apos;GET&apos;]) def full_chain(): response = { &apos;chain&apos;: blockchain.chain, &apos;length&apos;: len(blockchain.chain), } return jsonify(response), 200 @app.route(&apos;/nodes/register&apos;, methods=[&apos;POST&apos;]) def register_nodes(): values = request.get_json() nodes = values.get(&apos;nodes&apos;) if nodes is None: return &quot;Error: Please supply a valid list of nodes&quot;, 400 for node in nodes: blockchain.register_node(node) response = { &apos;message&apos;: &apos;New nodes have been added&apos;, &apos;total_nodes&apos;: list(blockchain.nodes), } return jsonify(response), 201 @app.route(&apos;/nodes/resolve&apos;, methods=[&apos;GET&apos;]) def consensus(): replaced = blockchain.resolve_conflicts() if replaced: response = { &apos;message&apos;: &apos;Our chain was replaced&apos;, &apos;new_chain&apos;: blockchain.chain } else: response = { &apos;message&apos;: &apos;Our chain is authoritative&apos;, &apos;chain&apos;: blockchain.chain } return jsonify(response), 200 if __name__ == &apos;__main__&apos;: from argparse import ArgumentParser parser = ArgumentParser() parser.add_argument(&apos;-p&apos;, &apos;--port&apos;, default=5000, type=int, help=&apos;port to listen on&apos;) args = parser.parse_args() port = args.port app.run(host=&apos;0.0.0.0&apos;, port=port) 提供了几个url: mine GET transactions/new POST chain GET nodes/register POST nodes/resolve GET /transactions/new to create a new transaction to a block /mine to tell our server to mine a new block. /chain to return the full Blockchain. /nodes/register to accept a list of new nodes in the form of URLs. /nodes/resolve to implement our Consensus Algorithm, which resolves any conflicts—to ensure a node has the correct chain. 单个区块： block = { &apos;index&apos;: 1, &apos;timestamp&apos;: 1506057125.900785, &apos;transactions&apos;: [ { &apos;sender&apos;: &quot;8527147fe1f5426f9dd545de4b27ee00&quot;, &apos;recipient&apos;: &quot;a77f5cdfa2934df3954a5c7c7da5df1f&quot;, &apos;amount&apos;: 5, } ], &apos;proof&apos;: 324984774000, &apos;previous_hash&apos;: &quot;2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824&quot; }]]></content>
  </entry>
  <entry>
    <title><![CDATA[blockchain-note]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F27%2Fblockchain-note%2F</url>
    <content type="text"><![CDATA[区块链中本聪2008年发表了《比特币：一种点对点式的电子现金系统》的论文。以太坊是2013年开创的项目。 区块 账户 共识 智能合约 本质上是一种健壮和安全的分布式状态机，五项核心能力： 存储数据共有数据分布式防篡改与隐私保护数字化合约三个方面可信： 数据可信 合约履行 历史可证明 目前典型的区块链账本设计为区块的单链表结构，只有增加没有减少，全局来说只有顺序处理，无法实现并行度。 目前涉及到的知识：分布式 存储 密码学 网络通讯 芯片技术 经济学 法律等。 应用场景 供应链领域 金融领域 政务及公共服务领域 其他领域： 保险防欺诈、大数据安全 原则 面向业务、标准化、松耦合与模块化、安全可审计、简洁与效率。 对 python的认识1.上下文管理器 with open(&apos;data.txt&apos;) as source, open(&apos;target.txt&apos;) as target: target.write(source.read()) 上下文管理器协议 需要实现 __enter__(), __exit__() 2.装饰器 装饰器本质上就是一个函数，这个函数接收其他函数作为参数，并将其以一个新的修改后的函数进行替换。 import functools import inspect def check_is_admin(f): @functools.wraps(f) def wrapper(*args, **kwargs): func_args = inspect.getcallargs(f, *args, **kwargs) print func_args if func_args.get(&apos;username&apos;) != &apos;admin&apos;: raise Exception(&quot;This user is not allowed to get food&quot;) return f(*args, **kwargs) return wrapper @check_is_admin def get_food(username, food=&apos;chocolate&apos;): return &quot;{0} get food: {1}&quot;.format(username, food) def main(): print get_food(&apos;admin&apos;) if __name__ == &apos;__main__&apos;: main() 装饰器不必检查参数username是基于位置的参数还是基于关键字的参数，而只需在字典中查找即可。 def makebold(fn): def wrapped(): return &quot;&lt;b&gt;&quot; + fn() + &quot;&lt;/b&gt;&quot; return wrapped def makeitalic(fn): def wrapped(): return &quot;&lt;i&gt;&quot; + fn() + &quot;&lt;/i&gt;&quot; return wrapped @makebold @makeitalic def hello(): return &quot;hello world&quot; print hello() ## returns &lt;b&gt;&lt;i&gt;hello world&lt;/i&gt;&lt;/b&gt; 3.全局变量 4.时间复杂度 list实质上是一个数组 使用链表的时候，应该用collection.deque 双向链表 set的实现是hash标，判断元素是否在某个集合中使用set，时间复杂度低。 5.python中的else 循环使用else 不建议try…except 中else 建议加else]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>blockchain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算综述]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F23%2F%E4%BA%91%E8%AE%A1%E7%AE%97%E7%BB%BC%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[neutron nova keystone 各种组件 网络技术领域知识 平安科技（深圳）有限公司 1.image 创建命令： glance image-create --name cirros --file /tmp/cirros-0.3.4-x86_64-disk.img -- disk-format qcow2 --container-format bare --progress 2.详细命令： keystone user-list # 被取代 openstack user list glance image-create glance image-delete glance image-update glance image-list glance image-show neutron net-create neutron net -delete neutron net -update neutron net -list neutron net –show neutron subnet-create neutron subnet -delete neutron subnet -update neutron subnet -list neutron subnet–show nova boot nova delete nova list nova show # 每个对象都有id tcp/ip协议不是一个协议，而是一个协议族的统称。里面包括了IP协议，IMCP协议，TCP协议，以及我们更加熟悉的http、ftp、pop3协议等等 1．为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？ 这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。 2．为什么TIME_WAIT状态还需要等2MSL后才能返回到CLOSED状态？ 这是因为虽然双方都同意关闭连接了，而且握手的4个报文也都协调和发送完毕，按理可以直接回到CLOSED状态（就好比从SYN_SEND状态到ESTABLISH状态那样）；但是因为我们必须要假想网络是不可靠的，你无法保证你最后发送的ACK报文会一定被对方收到，因此对方处于LAST_ACK状态下的SOCKET可能会因为超时未收到ACK报文，而重发FIN报文，所以这个TIME_WAIT状态的作用就是用来重发可能丢失的ACK报文。 sdn SDN采用与传统网络截然不同的控制架构，将网络控制平面分离和转发平面分离，采用集中控制替代原有分布式控制，并通过开放和可编程接口实现“软件定义”。与传统的网络架构相比，SDN通过软硬件分离，实现了网络虚拟化、IT化及软件化，并降低了设备的复杂度、简化网络运维、提高网络利用率、加速网络创新。 evpn EVPN是一种虚拟私有网络，那么在一套物理设备上必然可以有多个同时存在的EVPN实例，每个实例独立存在。每个EVI连接了一组或者多组用户网络，构成一个或者多个跨地域的二层网络。 vxlan 虚拟可拓展局域网 from multiprocessing import Poolfrom multiprocessing.dummy import Pool哪个速度快就用那个。尽量在写兼容的方式，这样在多线程/多进程之间切换非常方便。 现在，如果一个任务拿不准是CPU密集还是I/O密集型，且没有其它不能选择多进程方式的因素，都统一直接上多进程模式。 使用多线程(threading)和多进程(multiprocessing)完成常规的需求，在启动的时候start、jon等步骤不能省，复杂的需要还要用1-2个队列。随着需求越来越复杂，如果没有良好的设计和抽象这部分的功能层次，代码量越多调试的难度就越大。有没有什么好的方法把这些步骤抽象一下呢，让我们不关注这些细节，轻装上阵呢？ 答案是：有的。 从Python3.2开始一个叫做concurrent.futures被纳入了标准库，而在Python2它属于第三方的futures库，需要手动安装： 这个模块中有2个类：ThreadPoolExecutor和ProcessPoolExecutor，也就是对threading和multiprocessing的进行了高级别的抽象，暴露出统一的接口，帮助开发者非常方便的实现异步调用 lsvirtualenv: 列出全部的虚拟环境 showvirtualenv: 列出单个虚拟环境的信息 rmvirtualenv: 删除一个虚拟环境 cpvirtualenv: 拷贝虚拟环境 allvirtualenv: 对当前虚拟环境执行统一的命令。 比如， 要给 venv1 和 venv2 都安装flask, 就可以用allvirtualenv pip install flask cdvirtualenv: 可以直接切换到虚拟环境的子目录里面]]></content>
      <categories>
        <category>compute</category>
      </categories>
      <tags>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac-use-tips]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F19%2Fmac-use-tips%2F</url>
    <content type="text"><![CDATA[快捷键与触摸板 cmd 为 command 按键，通常情况下为所有桌面程序通用性的快捷键。 ctrl ，通常情况下是针对程序的功能进行加强，并且此功能往往是非 cmd 类（窗口操作，选择，复制粘贴等等）操作。 shift 按键通常用于加强操作。一般会让操作更进一步 or 相反操作。 cmd+tab =~ alt+tab 程序之间的切换 cmd+` 应用内窗口切换 cmd+h 窗口 hide cmd+m 窗口 minimize cmd+n 新建窗口 cmd+o 打开 cmd+s 保存 cmd+shift+s 另存为 cmd+p 打印 print cmd+w 关闭 cmd+q quit cmd+a select all cmd+i show info cmd+n create a new folder cmd+f search cmd+c copy cmd+v paste cmd+delete 删除选中文件 cmd+shift+delete 清空回收站 cmd+= 放大 cmd+- 缩小 cmd+t 新建选项卡 cmd+r 刷新 cmd+shift+3 截取整个屏幕 cmd+shift+4 截取选择区域 cmd+shift+4+SPACE 截取选择窗口 cmd+ 鼠标点击 -&gt; 选中不连续文件 control+ 鼠标点击 -&gt; 相当于 win 中右键点击 fn+left home fn+right end fn+up pageup fn+down pagedown 触摸板手势： 点击 单指点击 - 单击 单指滑动 - 滑动鼠标光标 双指点击 - 相当于 Windows 的鼠标右键 三指点击 - 划词查找 滑动与缩放 双指上下滑动 - 滚动 双指缩放 - 与 Android 上图片缩放一致 双指双击 - 只能缩放 双指旋转 - 旋转 双指左右滑动 - 应用内切换网页 双指头从右往左 三指头左右滑动 - 全屏幕 App 切换 三指拖动 - 扔掉鼠标必备 （谢评论区提醒） 大拇指和食中无名缩放 - launchpad openopen 命令用于打开文件、目录或执行程序。就等同于在命令行模式下，重复图形界面“双击”的动作。例如这个命令与在 Finder 中双击 Safari 是一样的： open /Applications/Safari.app/ 如果 open 一个文件，则会使用关联的程序打开之。例如 open screenshot.png 会在 Preview 中查看图片。 可以使用 -a 选项要求自行选择打开的程序，或使用 -e 强制在 TextEdit 中编辑此文件。 open 一个目录会在 Finder 窗口中打开此目录。一个很有用的技巧是 open . 打开当前目录。 Finder 和终端的交互是双向的——把文件从 Finder 中拖入终端，就等同于把文件的完整路径粘贴到命令行中。 pbcopy 和 pbpaste这两个工具可以打通命令行和剪贴板。当然用鼠标操作复制粘贴也可以——但这两个工具的真正威力，发挥在将其用作Unix工具的时候。意思就是说：可以将这两个工具用作管道、IO重定向以及和其他命令的整合。例如： ls ~ | pbcopy可以将主目录的文件列表复制到剪贴板。 也可以把任意文件的内容读入剪贴板： pbcopy &lt; blogpost.txt做点更疯狂的尝试：获取最新 Google 纪念徽标（doodle）的 URL 并复制到剪贴板： curl http://www.google.com/doodles#oodles/archive | grep -A5 &apos;latest-doodle on&apos; | grep &apos;img src&apos; | sed s/.*&apos;&lt;img src=&quot;\/\/&apos;/&apos;&apos;/ | sed s/&apos;&quot; alt=&quot;.*&apos;/&apos;&apos;/ | pbcopy 使用管道语法配合 pbcopy 工具可以简单的抓取命令的输出，而不必向上滚动翻阅终端窗口。可以用于和他人分享命令行的标准和错误输出。 pbcopy 和 pbpaste 也可以用于自动化或加速执行一些事情。例如把一些邮件的主题存为任务列表，就可以先从 Mail.app 中复制主题，再运行： pbpaste &gt;&gt; tasklist.txt mdfind许多 Linux 用户都发现 Linux 下查找文件的方法在 OS X 上不好用。当然经典的 Unix find 命令总是可以，但既然 OS X 有杀手级搜索工具 Spotlight ，为什么不在命令行上也使用一下呢？ 这就是mdfind命令了。 Spotlight 能做的查找， mdfind 也能做。包括搜索文件的内容和元数据（metadata）。 mdfind还提供更多的搜索选项。例如-onlyin选项可以约束搜索范围为一个目录： mdfind -onlyin ~/Documents essaymdfind 的索引数据库在后台自动更新，不过你也可以使用 mdutil 工具诊断数据库的问题，诊断 mdfind 的问题也等同于诊断 Spotlight 。如果 Spotlight 的工作不正确，mdutil -E命令可以强制重建索引数据库。也可以用 mdutil -i 彻底关闭文件索引。 screencapturescreencapture 命令可以截图。和 Grab.app 与 cmd + shift + 3 或 cmd + shift + 4 热键相似，但更加的灵活。 抓取包含鼠标光标的全屏幕，并以 image.png 插入到新邮件的附件中： screencapture -C -M image.png用鼠标选择抓取窗口（及阴影）并复制到剪贴板： screencapture -c -W延时10秒后抓屏，并在Preview中打开之： screencapture -T 10 -P image.png用鼠标截取一个矩形区域，抓取后存为pdf文件： screencapture -s -t pdf image.pdf更多用法请参阅 screencapture –help 。 launchctllaunchctl 管理 OS X 的启动脚本，控制启动计算机时需要开启的服务。也可以设置定时执行特定任务的脚本，就像 Linux cron 一样。 例如，开机时自动启动 Apache 服务器： sudo launchctl load -w /System/Library/LaunchDaemons/org.apache.httpd.plist 运行 launchctl list 显示当前的启动脚本。 sudo launchctl unload [path/to/script] 停止正在运行的启动脚本，再加上 -w 选项即可去除开机启动。用这个方法可以一次去除 Adobe 或 Microsoft Office 所附带的所有“自动更新”后台程序。 Launchd 脚本存储在以下位置： ~/Library/LaunchAgents /Library/LaunchAgents /Library/LaunchDaemons /System/Library/LaunchAgents /System/Library/LaunchDaemons saysay 是一个文本转语音（TTS）的有趣的工具，引擎和 OS X 使用的一样也是 VoiceOver 。如果不加其他选项，则会简单的语音朗读你给定的字符串： say “Never trust a computer you can’t lift.”用-f选项朗读特定文本文件，-o选项将朗读结果存为音频文件而不是播放：say -f mynovel.txt -o myaudiobook.aiffsay 命令可以用于在脚本中播放警告或提示。例如你可以设置 Automator 或 Hazel 脚本处理文件，并在任务完成时用 say 命令语音提示。 最好玩（不过也负罪感十足）的用法是：通过 SSH 连接到朋友或同事的计算机，然后用 say 命令给他们一个大大大惊喜…… 可以在系统设置 （System Preferences） 的字典和语音 （Dictation &amp; Speech） 选项中调整系统的语音选项甚至是语音的语言。 diskutildiskutil 是 OS X 磁盘工具应用的命令行版。既可以完成图形界面应用的所有任务，也可以做一些全盘填0、全盘填随机数等额外的任务。先使用 diskutil list 查看所有磁盘的列表和所在路径，然后对特定的磁盘执行命令。 警告：不正确使用 diskutil 可能意外的破坏磁盘数据。请小心。 brewHomebrew 程序提供的 brew ，严格来讲不是一个 OS X 的原生命令，但任何一个 OS X 的专业用户都不会错过它。“ OS X 缺少的包管理器”这个评价是恰如其分的。如果你曾经在 Linux 上使用过 apt-get （或其他包管理器——译者注），你就会发现 Homebrew 基本上是一样的。 使用 brew 可以简单的获取数千种开源工具和函数库。例如 brew install imagemagick 就可以安装 ImageMagick （几乎可以处理任何图像问题，转换任何格式的图像工具）， brew install node 可以安装 Node.js （当前大热的服务器端 JavaScript 编程工具）。 也可以通过 Homebrew 做有趣的事情： brew install archey 会安装 Archey （在启动命令行时显示苹果 LOGO 和计算机硬件参数的小工具）。 Homebrew 能安装的工具数量庞大，并且一直保持更新。Homebrew 最棒的一点是：所有的文件都被约束在 /usr/local/ 一个位置之下。也就是说可以通过 Homebrew 安装新版软件的同时，保持系统内置的依赖库或其他软件不变。同时如果想彻底删除 Homebrew ，也变得非常简单。 （注：删除 Homebrew 最好还是不要直接删除 /usr/local/ 。应当用这个卸载脚本点击预览。） #!/bin/sh # Just copy and paste the lines below (all at once, it won&apos;t work line by line!) # MAKE SURE YOU ARE HAPPY WITH WHAT IT DOES FIRST! THERE IS NO WARRANTY! function abort { echo &quot;$1&quot; exit 1 } set -e /usr/bin/which -s git || abort &quot;brew install git first!&quot; test -d /usr/local/.git || abort &quot;brew update first!&quot; cd `brew --prefix` git checkout master git ls-files -z | pbcopy rm -rf Cellar bin/brew prune pbpaste | xargs -0 rm rm -r Library/Homebrew Library/Aliases Library/Formula Library/Contributions test -d Library/LinkedKegs &amp;&amp; rm -r Library/LinkedKegs rmdir -p bin Library share/man/man1 2&gt; /dev/null rm -rf .git rm -rf ~/Library/Caches/Homebrew rm -rf ~/Library/Logs/Homebrew rm -rf /Library/Caches/Homebrew]]></content>
  </entry>
  <entry>
    <title><![CDATA[elk+redis]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F18%2Felk-redis%2F</url>
    <content type="text"><![CDATA[对常见的elk工具进行总结 cat /etc/issue # 检查系统版本 java -version # wget -qO - https://packages.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - echo &quot;deb https://packages.elastic.co/elasticsearch/2.x/debian stable main&quot; | sudo tee -a /etc/apt/sources.list.d/elasticsearch-2.x.list sudo apt-get update sudo apt-get install elasticsearch -y sudo service elasticsearch start echo &quot;deb https://packages.elastic.co/logstash/2.3/debian stable main&quot; | sudo tee -a /etc/apt/sources.list sudo apt-get install logstash -y sudo service logstash start echo &quot;deb http://packages.elastic.co/kibana/4.5/debian stable main&quot; | sudo tee -a /etc/apt/sources.list sudo apt-get install kibana -y sudo service kibana start sudo service nginx start # nginx 的配置文件位于 /etc/nginx/sites-available/default # 添加 access_log /home/shiyanlou/Code/elk/access.log; 接下来是具体的配置文件 # /etc/logstash/conf.d/logstash-shipper.conf input { stdin {} file { path =&gt; &quot;~/access.log&quot; start_position =&gt; beginning codec =&gt; multiline { &apos;negate&apos; =&gt; true &apos;pattern&apos; =&gt; &apos;^\d&apos; &apos;what&apos; =&gt; &apos;previous&apos; } } } output { stdout { codec =&gt; rubydebug } elasticsearch { hosts=&gt;[&quot;localhost:9200&quot;] index=&gt;&quot;logstash-%{+YYYY.MM.dd}&quot; } }]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[top-questions-python]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F17%2Ftop-questions-python%2F</url>
    <content type="text"><![CDATA[1.python2 编码问题 python代码内部请全部使用unicode编码，在获取外部内容时，先decode为unicode，向外输出时再encode为Str 在定义变量或者正则时，也定义unicode字符，如a=u”中文”；res=r””+u”正则”。 a=&quot;\\u8fdd\\u6cd5\\u8fdd\u89c4&quot; #变量a的内容为unicode编码，变量a为string编码（&quot;&quot;前不要加u） b=a.decode(&apos;unicode-escape&apos;) print b a=&quot;\\xe5\\x85\\xb3\\xe4\\xba\\x8e\\xe4&quot; #变量a的内容为string编码，变量a为string编码（&quot;&quot;前不要加u） b=a.decode(&apos;string-escape&apos;) print b 2.多线程问题 python带有GIL解释器锁的概念，同一时刻只能有一个线程在运行，遇到IO操作才会释放切换。 协程不同于线程的地方在于协程不是操作系统进行切换，而是由程序员编码进行切换的，也就是说切换是由程序员控制的，这样就没有了线程所谓的安全问题。 这也就是常选的gevent 方案 cpu 密集 多进程io密集 多线程 或者协程 3.协程 4.闭包 全局变量降低了函数或模块之间的通用性，不同的函数或模块都要依赖于全局变量。同样，全局变量降低了代码的可读性，阅读者可能并不知道调用的某个变量是全局变量。 # 原始情况 time = 0 def insert_time(min): time = time + min return time print(insert_time(2)) print(insert_time(10)) # 闭包 time = 0 def study_time(time): def insert_time(min): nonlocal time time = time + min return time return insert_time f = study_time(time) print(f(2)) print(time) print(f(10)) print(time) 这里最直接的表现就是全局变量 time 至此至终都没有修改过,这里还是用了 nonlocal 关键字,表示在函数或其他作用域中使用外层(非全局)变量。 这种内部函数的局部作用域中可以访问外部函数局部作用域中变量的行为，我们称为： 闭包。更加直接的表达方式就是，当某个函数被当成对象返回时，夹带了外部变量，就形成了一个闭包。k 闭包避免了使用全局变量，此外，闭包允许将函数与其所操作的某些数据（环境）关连起来。而且使用闭包，可以使代码变得更加的优雅。装饰器，是基于闭包实现的。 所有函数都有一个 __closure__ 属性，如果函数是闭包的话，那么它返回的是一个由 cell 组成的元组对象。cell 对象的 cell_contents 属性就是存储在闭包中的变量。 5.装饰器问题 6.爬虫问题 7.魔法方法 一个类创建的过程是怎样的，先是调用了 __new方法来创建一个对象，把参数传给 \init__ 方法进行实例化。 其实在实际开发中，很少会用到 __new 方法，除非你希望能够控制类的创建。通常讲到 \new__ ，都是牵扯到 metaclass(元类)的。 当然当一个对象的生命周期结束的时候，析构函数 __del__ 方法会被调用。但是这个方法是 Python 自己对对象进行垃圾回收的。 Python 没有真正意义上的私有属性。然后这就导致了对 Python 类的封装性比较差。我们有时候会希望 Python 能够定义私有属性，然后提供公共可访问的 get 方法和 set 方法。Python 其实可以通过魔术方法来实现封装。 方法说明 __getattr__(self, name)该方法定义了你试图访问一个不存在的属性时的行为。因此，重载该方法可以实现捕获错误拼写然后进行重定向, 或者对一些废弃的属性进行警告。 __setattr(self, name, value)定义了对属性进行赋值和修改操作时的行为。不管对象的某个属性是否存在,都允许为该属性进行赋值.有一点需要注意，实现 \setattr__ 时要避免”无限递归”的错误， __delattr(self, name) \delattr 与 \setattr 很像，只是它定义的是你删除属性时的行为， 实现 \delattr__ 是同时要避免”无限递归”的错误 __getattribute(self, name) \getattribute 定义了你的属性被访问时的行为，相比较，\getattr__ 只有该属性不存在时才会起作用。 因此，在支持 __getattribute的 Python 版本,调用\getattr 前必定会调用 \getattribute__ __getattribute__ 同样要避免”无限递归”的错误。 8.差异 Python3.x 中 input() 函数接受一个标准输入数据，返回为 string 类型。 Python2.x 中 input() 相等于 eval(raw_input(prompt)) ，用来获取控制台的输入。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-big-web-project]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F17%2Fpython-big-web-project%2F</url>
    <content type="text"><![CDATA[严格来说，MVC是一个古老的概念，从早期的Smalltalk开始已经不再适合于web应用开发。Django的开发人员已经正确意识到在Python中我们实际使用的是MTV（model，template，view）： 模板包含了HTML的内容以及页面显示逻辑。它是使用模板语言如Kajiki来编写，从视图（view）中获取数据，然后展示在页面中。 视图（有时也称为“控制器”），仅仅是使用Python语言编写的中间代码。它借助于web框架将所有的内容放在一起。它可以看到其他的所有层，并且定义了URLs，将它们映射到web框架中用于接收数据的函数，然后利用其他层以最终发送响应给web框架。它应该尽可能得小，因为它的代码是不能重复利用的，即使你尽量地缩减它，web表单也会促使其逐渐地变得复杂。 模型层本质上是一个持久层：它最重要的依赖就是SQLAlchemy。模型知道如何去保存数据，构成整个项目中最可重用的代码。当然它并不清楚HTTP相关的内容和你所使用的框架。它代表了排除用户界面细节的系统本质内容。 但是稍等下，哪里？在视图还是模型中？你应该在哪里放置程序的灵魂：业务规则？模板层已经自动被排除掉，因为它并不是Python编写的。所以剩下3个可能的答案： 视图层，这是最糟糕的选择。视图层应该仅仅包含中间代码，将代码数量保持尽可能得小，并且同系统中的其他部分隔离开，所以系统应该能在web框架中、使用中以及单元测试中独立访问。另外，业务逻辑应该存在于更加可重用的地方。视图层被视为展示逻辑的一部分，所以业务逻辑被排除在外。实际上，除了Web UI之外，在创建desktop UI时，开发者应该忽略视图和HTTP相关的内容，需要业务逻辑尽可能地被重用，因此，我们应该排除掉视图层。 模型层，这个是可能的选择，因为模型层至少是可重用的。但是模型层主要关注于持久化，它应该更少地依赖于SQLAlchemy（它已经是一个非常复杂的东西）。 新的层，这才是正确的答案。下面将举例来更好地理解这部分内容。 如果你要创建一个博客，那么MTV正好满足你的需求。但是对于更加复杂的项目来说，其实还是至少缺了一层。你应该将业务逻辑旋转到一个新的、可重用的层次中，大多数人称之为“Service”层，但是我更喜欢称之为”Action“层。 为什么你需要这层？ 在大型应用中，单个用户的操作引起多项活动是非常常见的。比如，用户成功地注册了你的服务，那么你的业务逻辑中可能会触发非常多的后台处理： 在关系数据库多张表中新增数据，使用了模型层。 将发送邮件给用户的任务放置到队列中。 将发送短信给用户的任务放置到队列中。 将创建实际使用服务时必需的空间和其他准备性资源的任务放置到队列中。 将更新用户数据的任务放置到队列中。 …. 这是一个理解“业务逻辑“的好例子：给定一个用户操作（比如注册），系统就要做一些必需的操作。这种业务逻辑被单个函数捕获会更好；这个函数应该在哪一层呢？ 如果所有的这些都实现在模型层，你能想象到它将变得多复杂吗？模型层在只面对持久化时已经很艰难了。现在想象一下模型层处理所有这些事务，它要使用多少外部服务？文件头部应该包括多少imports？反过来看，有多少模块愿意引入这个模型，可能在系统启动前就因为创建的循环依赖而导致系统崩溃。 循环依赖其实就是你没有正确认清系统架构的明显的标识。 对于依赖于Celery的模型来说，了解如何去发送邮件、短信以及使用外部服务等是不应该的做法。持久化对于模型层来说已经是非常复杂的主题了。你应该在模型层之外去处理这些业务逻辑——在模型层和视图层之间的一层。所以称之为”Action“层。 另外，模型层在关系型数据库中经常被映射到一张单独的表。如果你在用户表和订阅表中插入一条记录，哪一个模型应该包含上述逻辑呢？这几乎是不能确定的。因为实际执行的操作远超过了用户表和订阅表的范围。因此，业务逻辑应该被定义在任何模型之外。 当开发人员执行维护时，有时她想按步骤地执行每一步，而有时她想一次性执行完所有操作。分别地实现这些操作并在单个Action层函数中调用是有帮助的。 你可能会怀疑我提出的方法难道不是反面模式域模型的一种吗？没有动作的模型恰恰与面向对象设计相反！我并没有说“将所有的方法从模型中移除”。我的意思是指“将需要外部调用的方法移除”。模型中的方法仅仅用来使用它所需要的数据，并且属于模型中的那些数据。一个面向世界的，调用外部服务的并且很少使用自身数据的方法不应该被放置在模型中。 另一个使得这种架构成功的原因就是测试。TDD教会了程序员去让程序变得解耦，这样做通常会使得软件更加健壮。如果你想要创建一个Celery的应用，并且在你测试之前已经知道了其他的外部服务，那么你将经常陷入头痛中。 还有将业务逻辑放置在视图层之外的最后一个原因。在未来，当你最终决定从Flask过渡到Pyramid时，你很乐意将视图层保持简洁。如果所有的视图都是在与web框架间交互，并且动作层会执行所有的函数，那么你的代码就做到了非常好的隔离。Web框架通常都很贪婪，不要让你的系统跟随他们的脚步。 所以下面就是我所提议的在Python中构建大型应用的层次结构： 模型层是最底层的，最可重用并且可见的层。它仅专注于持久化，模型层是可以包含动作的，只不过这个动作仅仅属于这个模型。模型可以被其他层所返回，以各种方式在请求的结尾返回给模板。 外部服务。对每个服务都创建一个比如说发送邮件。 动作层。这是系统中的核心层，它包含了业务逻辑以及工作流。它使用外部服务去实现特定的目标并且借助模型层来持久化数据。通过以上这些层，它支撑起了整个系统，包括配置，除了用户界面。 模板层仅包括了页面展示逻辑比如说从列表中循环输出构成一个HTML表格。 视图层，这是最高层的，最不可重用的层。它依赖于（与系统中其他层隔离）web框架。并且依赖于表单验证库。它可以看到模板层以及动作层，但是不能直接调用模型层——它必须通过动作层。但是当一个动作层返回了模型数据，那么它可以被传递给模板中（一个Celery任务可以类比于一个web视图）。 这种体系结构有助于避免了在会话层中进行调试因为它清楚地定义了各自的职责。同时它也是明显经得起检测的，因为它做到了很好的解耦，因此可以减少测试的并且减少了模拟的次数。 好的架构总是解耦性非常好的。如果你曾经陷入到一个循环依赖中，你可以想一下是否真的定义好了每一层的职责。当你放弃了并且从一个函数中引入内容，那么你的架构已经失败了。 这并不是说你的web应用必须与Celery应用隔离开。在他们之间可以重用代码——特别是模型——但是对于Celery应用来说，不应该引入web框架！获取配置也不例外，因为在Python中读取配置是非常简单的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-top-30]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F17%2Fpython-top-30%2F</url>
    <content type="text"><![CDATA[1.家庭助理 2.PyTorch 3.Grumpy 4.sanic 5.Python-fire 6.spaCy 7.pipenv 8.micropython 9.prophet 10.SerpentAI 11.dash 12.instaPy 13.apistar 14.faiss 15.MechanicalSoup：一个与网站自动化交互的Python库 16.Better-exceptions：用Python编写的自动地漂亮的和有用的异常处理 17.Flashtext：从句子中提取关键词或替换句子中的关键词 18.Maya：用Python实现人类的日期时间 19.Mimesis (v1.0)：Python库，有助于为不同的目的以不同的语言生成模拟数据。这些数据在软件开发和测试的不同阶段特别有用 20.开放式无纸化：扫描、索引和归档所有的纸质文档。一个文档管理系统 21.Fsociety：黑客工具包。渗透测试框架 22.LivePython：实时可视化跟踪Python代码 23.Hatch：用于Python的现代项目、包和虚拟环境管理器 24.Tangent:用纯Python实现源到源的可调试导数 25.Clairvoyant：识别和监控短期股票走势的历史线索的Python程序 26.MonkeyType：Python通过收集运行时类型生成静态类型注释的系统 27.Eel：一个小的Python库，用于制作简单的电子类HTML / js GUI应用程序 28.Surprise v1.0：建立和分析推荐系统的Python scikit** 29.Gain：获取每个人的Web爬行框架 30.PDFTabExtract: 一组从PDF文件中提取表的工具，有助于对扫描文档进行数据挖掘]]></content>
  </entry>
  <entry>
    <title><![CDATA[简单看看汤不热的网站]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F15%2F%E7%AE%80%E5%8D%95%E7%9C%8B%E7%9C%8B%E6%B1%A4%E4%B8%8D%E7%83%AD%E7%9A%84%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[这里就不截图进行介绍了 每个tumblr的个人空间都是一个二级域名，你甚至可以绑定你自己的域名。 在个人主页上， 是一个微博式的消息列表，有文字，图片，视频等形式。消息的展现，是页面上的JavaScript脚本 通过请求Tumblr的Api来获取返回信息，然后添加到页面上的。通过API，可以省掉很多麻烦，至少不必分析整个页面的html来提取需要的信息了。 基础的url 是这样的： http://{0}.tumblr.com/api/read?type{1}&amp;num={2}&amp;start={3} 第一个参数是要访问的用户空间的用户名； 第二个参数是媒体类型， 图片为“photo”，视频为“video”； 第三个参数为请求的资源数； 第四个参数为从第几个资源开始 返回的数据是XML格式的数据，基本的层级为Tumblr&gt;posts&gt;post。图片的URL在post的photo-url字段中，视频与此类似，就不再演示了。 获取到媒体资源的url之后，就可以进行下载了。 video类型的资源的url，需要从player属性中进行进一步匹配才能得出最后的结果。 技术的分析： 发送http请求 使用requests模块 返回的数据是xml xmltodic模块，将xml文档处理成类似Json对象，方便我们对数据进行访问。 队列实现 python中自带Queue模块，可以满足我们目前的队列需求，由于python2.7和python3.0中 对queue模块的命名进行的变更，编程的时候需要注意。如果考虑兼容两个版本的话，可以 考虑引入 six模块（https://pypi.python.org/pypi/six）。 six模块是一个专门用于解决 从python2.x到python3.x的兼容性问题的模块， 它对python版本变更导致到部分模块不能应用的问题 进行了内部处理， 需要处理类似兼容问题的时候，可以考虑或者参考该模块的实现方式。 多线程进行下载 处理json 考虑到Tumblr需要FQ访问，如果本机不使用VPN的话，可能需要配置代理，代理采用json配置方式。 处理.使用python内置的json模块（https://docs.python.org/2/library/json.html）就可以了。 使用正则 为了精确匹配url信息，我们需要使用正则表达式对xml数据的中字段值进行进一步处理，使用 内置的re模块（https://docs.python.org/2/library/re.html）就可以了。]]></content>
      <categories>
        <category>pachong</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django项目配置小结]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F14%2Fdjango%E9%A1%B9%E7%9B%AE%E9%85%8D%E7%BD%AE%E5%B0%8F%E7%BB%93%2F</url>
    <content type="text"><![CDATA[dockerfile 的配置FROM python:3.5 COPY ./requirements.txt /src WORKDIR /src RUN pip install -r requirements.txt COPY . /src EXPOSE &lt;PORT&gt; CMD uwsgi --http :&lt;PORT&gt; --wsgi-file &lt;path/to/wsgi.py&gt; python 3.3开始 标准库已经支持创建虚拟环境 pyvenv ENV # 使用k神的pipenv 管理项目依赖 # 使用ensurepip 模块来引导启动pip python 3.4开始 python -m ensurepip 使用 gitignore.io这个网站提供的 .gitignore 文件管理代码库文件 日志管理的话（以下是直接写到标准输出） # settings.py # ... LOGGING = { &apos;version&apos;: 1, &apos;disable_existing_loggers&apos;: False, &apos;formatters&apos;: { &apos;verbose&apos;: { &apos;format&apos;: &apos;[application] %(levelname)s %(asctime)s %(module)s %(message)s&apos; } }, &apos;handlers&apos;: { &apos;console&apos;: { &apos;level&apos;: &apos;DEBUG&apos;, &apos;class&apos;: &apos;logging.StreamHandler&apos;, &apos;stream&apos;: sys.stdout, &apos;formatter&apos;: &apos;verbose&apos; }, }, &apos;loggers&apos;: { &apos;app&apos;: { &apos;handlers&apos;: [&apos;console&apos;], &apos;level&apos;: &apos;DEBUG&apos;, &apos;propagate&apos;: True, }, }, } 自动化测试既然是纯后端项目，工程师完全可以通过自动化测试来检测自己的代码。Django 本身对测试提供了很好的支持，可以通过 sqlite 来搭建测试数据库，还有基于内存的缓存，做测试不会增加对其他系统的依赖。开发起来事半功倍。 除了要写自动化测试代码，还要能统计测试覆盖率。目前我们用的是 coverage.py 这个工具，说实话没有 node.js 的 istanbul 好用，输出的报告没有 Istanbul 详细和易读。不过用来检查 “死代码” 还是够用的。 针对 http 代码的测试有些项目需要对接的第三方系统比较多，比如微信认证、支付、短信等常见的，可能还有其他一些垂直业务领域的系统。这部分接口对接的代码，也应该纳入到测试当中，毕竟 Python 作为脚本语言，代码很容易出现错误。 这块一般是用 responses 这个模块来 mock http 请求。 定时任务封装到command import schedule from django.core.management.base import BaseCommand class Command(BaseCommand): def handle(self, *args, **kwargs): schedule.every(45).minutes.do(do_this) schedule.every().day.at(&apos;04:00&apos;).do(do_that) while True: schedule.run_pending() time.sleep(1) Django如何处理并发 django本身提供了一个wsgi的接口，可以通过gevent，uwsgi，fastcgi等实现高并发，这里的高并发采用协程，线程，和进程都可能，或者同时采用几种。 对于操作数据库来说，线程安全其实不用太考虑，因为数据库的链接已经由数据库的连接池处理了，反而是数据库的竞争性的访问需要考虑多进程安全的问题，比如同时写某一个统计信息，那么就需要对这样的请求加锁，或这cas这样的机制来保证这种写操作不会冲突。 配置举例：# /usr/local/nginx/conf/nginx.conf server { listen 8088; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } ## 修改配置文件 server { listen 8088; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; #注释以下四行 #location / { #root html; #index index.html index.htm; #} #添加以下内容 location / { try_files @uri @pp; } location @pp { proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_pass http://127.0.0.1:5000; #反向代理的这个IP和端口 } ## gun 配置文件 config.py import gevent.monkey import multiprocessing gevent.monkey.patch_all() #监听本机的5000端口 bind=&apos;0.0.0.0:5000&apos; preload_app = True #开启进程 #workers=4 workers = multiprocessing.cpu_count() * 2 + 1 #每个进程的开启线程 threads = multiprocessing.cpu_count() * 2 backlog=2048 #工作模式为gevent worker_class=&quot;gevent&quot; # debug=True #如果不使用supervisord之类的进程管理工具可以是进程成为守护进程，否则会出问题 daemon = True #进程名称 proc_name=&apos;gunicorn.pid&apos; #进程pid记录文件 pidfile=&apos;app_pid.log&apos; loglevel=&apos;debug&apos; logfile = &apos;debug.log&apos; accesslog = &apos;access.log&apos; access_log_format = &apos;%(h)s %(t)s %(U)s %(q)s&apos; errorlog = &apos;error.log’ 启动： gunicorn -c config.py(gunicorn配置文件) flask_nginx(flask启动文件):app 启动nginx: sudo /usr/local/nginx/sbin/nginx Siege命令常用参数 -c 500 指定并发数500 -r 5 指定测试的次数5 -f urls.txt 制定url的文件 -i internet系统，随机发送url -b 请求无需等待 delay=0 -t 5 持续测试5分钟，默认是分，5s为5秒 # -t和-r不能同时使用 模拟1000个并发向URL发送5次测试： siege -c 1000 -r 5 http://127.0.0.1:8088(gunicorn+gevent+nginx+flask) 从 Tornado 说起刚开始，对 Tornado 的感觉最为新鲜，在官网介绍里其是一个无阻塞的Web服务器以及相关工具的集合，但 个人更为倾向其为一个颇为完备的微型 web 框架。Tornado 性能好的关键是其无阻塞异步的特性，但这魔术 似的效果是如何达成的呢？迷思与困惑。我那小脑袋里的思维还停留于多进程（多线程）那样的并发模型中， 实在有点难以理解 Tornado 的异步机制。 通过查阅各式文章以及源代码，整体的框架脉络开始逐渐在脑海中显现出来。其实，Tornado 的异步模型 是由事件驱动以及特定的回调函数（callback）所组成的！一直没有弄明白，Tornado 具体是如何实现 无阻塞异步，当清楚了事件驱动和回调函数的概念后，事情似乎又变得简单起来了。 对于一般的程序，在执行阶段若遇到 I/O 事件，整个进程将被阻塞住，直到 I/O 事件结束，程序又继续执行。 接设我们对一些 I/O 事件进行了定制，使其可以立即返回（即无阻塞），那么程序将能立即继续执行。但 问题又来了，那当 I/O 事件完成后又该怎么办呢？此时，回调函数的威力就出来了，我只需要将进行特定 处理的回调函数与该 I/O 事件绑定起来，当该 I/O 事件完成后就调用绑定的回调函数，就可以处理具体的 I/O 事件啦。啊，似乎还有一个问题，回调函数要如何与 I/O 事件绑定起来？最简单的想法是，直接通过 一个 while True 循环不断的轮询，当检测到 I/O 事件完成了即触发回调函数。但是，这样的效率当然不会 高，利用系统中高效的 I/O 事件轮询机制（epoll on Linux, kqueue on most BSD）就是最明智的 解决方案。于是，无阻塞 I/O +事件驱动+高效轮询方式便组成了 Tornado 的异步模型。 Tornado 的核心是 ioloop 和 iostream 这两个模块，前者提供了一个高效的 I/O 事件循环，后者则封装了 一个无阻塞的 socket 。通过向 ioloop 中添加网络 I/O 事件，利用无阻塞的 socket ，再搭配相应的回调 函数，便可达到梦寐以求的高效异步执行啦。多说无益，来看一下具体的示例： from tornado import ioloop from tornado.httpclient import AsyncHTTPClient urls = [&apos;http://www.google.com&apos;, &apos;http://www.yandex.ru&apos;, &apos;http://www.python.org&apos;] def print_head(response): print (&apos;%s: %s bytes: %r&apos; % (response.request.url, len(response.body), response.body[:50])) http_client = AsyncHTTPClient() for url in urls: print (&apos;Starting %s&apos; % url) http_client.fetch(url, print_head) ioloop.IOLoop.instance().start() 因为使用了 AsyncHTTPClient 来处理请求操作，整个示例是异步执行的，即三个url请求无等待的依次发出。 我们可以看到 fetch 方法使用了 print_head 函数来作为回调函数，这意味着，当 fetch 完成了请求操作， 相应的 print_head 函数便会被触发调用。恩，… 额，…，乍看起来，使用 Tornado 进行异步编程似乎 并不难，让人跃跃欲试。但实际上，在现实生活中，事件驱动的编程还是会很费脑力，需要一定的创造性思维。 不过，这也许是 Tornado 受欢迎的原因之一呢。 看下 GeventGevent 是基于协程（coroutine）实现的 Python 网络库，使用了轻量级的 greenlet 作为执行单元，并 基于 libevent 事件循环构建了直观的调用接口。 当时看到这样的描述，脑袋的第一反应是，协程？？稍稍了解后，发现协程其实也不是什么高深的概念，协程 也被称为微线程，一看这别名就知道跟线程应该很类似。作为类比倒也可以这么认为，两者关键的区别在于， 线程是由系统进行调度的，而协程是由用户自己进行调度的。当知道这一事实后，立刻想到，这自行调度灵活 肯定是会很灵活，但要调度的话可是很有难度的吧？调度的方法暂时不谈，除了更为灵活外，自行调度的直接 结果当然就是省去了系统调度（什么用户态转内核态，以及什么 context switch），因此协程间切换的资源 消耗很小，再配合协程生成成本很低的另一特点，这可真是相当的美妙。事实上，Python 语言本身就支持基础 的协程的概念，generator 是其中的产物（这里）。 对于 Gevent，其使用的协程实际上就是 greenlet 。当你使用 greenlet 生成了一些协程，就可以在这些 协程里不断跳转执行，两个 greenlet 之间的跳转被称为切换（switch）。通过切换，我们就可以实现对协程 的调度。还应该知道的是，每个 greenlet 都拥有一个父 greenlet ，这是在 greenlet 初始化时就确定的。 当一个 greenlet 执行完毕后，执行权会切换到其父 greenlet 中。实际上，所有的 greenlet 会被组织成 一颗树，树根便是最“老资格”的 greenlet ，这个老 greenlet 确定了各 greenlet 间的逻辑关系。 上面说到协程必须自行调度，不会是要自己构造一个调度器吧？这当然可以做到，但不是必须，因为 Gevent 已经基于 greenlet 和 libevent 封装了许多基础常用的库，例如 socket 、event 和 queue 等，只要使用 这些库进行开发，或者对使用的标准库或第三方库打一下补丁（monket patch），就能保证生成的各协程在 I/O 等待时正确地进行切换，从而实现无阻塞的异步执行。 刚接触 Gevent 时，感觉跟传统的并发编程很类似，但了解渐深后，才发现这货实际上跟 Tornado 更为类似。 因为， Gevent 本质上也是事件驱动。实现的策略可以是，在将要执行 I/O 阻塞事件时，先在事件循环中对该事件 进行注册，关联的回调函数便是对当前协程的切换操作（current_greenlet.switch()），注册成功后即 切换回当前协程的父协程中进行执行（current_greenlet.parent.switch()）。当注册的 I/O 事件被 触发后，事件循环在恰当时机便会执行该回调函数，也就是切换到原先的协程继续执行程序。从而，就实现 无阻塞的 I/O 事件处理。怎样，是否感觉相当的有趣？ :) Gevent 了不得的地方还在于，我们能像编写一般程序那样来编写异步程序，这可是弥足珍贵。为了更直观的 显示，让我们来看一下具体的运行示例: import gevent from gevent import monkey # patches stdlib (including socket and ssl modules) to cooperate with other greenlets monkey.patch_all() import urllib2 urls = [&apos;http://www.google.com&apos;, &apos;http://www.yandex.ru&apos;, &apos;http://www.python.org&apos;] def print_head(url): print (&apos;Starting %s&apos; % url) data = urllib2.urlopen(url).read() print (&apos;%s: %s bytes: %r&apos; % (url, len(data), data[:50])) jobs = [gevent.spawn(print_head, url) for url in urls] gevent.joinall(jobs) 上面示例做的事情实际上跟前面 Tornado 的示例是一样，同样是异步的对url进行请求。在我看来，使用 Gevent 进行编程，无论是可读性还是可操作性都能让人满意。但也要清楚，在实际操作中，为了达到较理想 效果，经常还是需要根据不同的情况对代码进行一些相应的“雕琢”。还有一点很常被人忽略， Gevent 是 基于协程实现的 Python 网络库，其适用面更多的是在于网络 I/O 频繁的需求里，很多情况下 Gevent 可能 并不是很好的选择。总的来说，Gevent 确实很讨人喜爱，性能好，开销小，代码易维护，是广大 pythoner 手中的一大利器。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[flask+gevent使用实例]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F14%2Fflask-gevent%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[&quot;&quot;&quot;Asynchronous requests in Flask with gevent&quot;&quot;&quot; from time import time from flask import Flask, Response from gevent.pywsgi import WSGIServer from gevent import monkey import requests # need to patch sockets to make requests async monkey.patch_all() CHUNK_SIZE = 1024*1024 # bytes app = Flask(__name__) # pylint: disable=invalid-name app.debug = True @app.route(&apos;/Seattle.jpg&apos;) def seattle(requests_counter=[0]): # pylint: disable=dangerous-default-value &quot;&quot;&quot;Asynchronous non-blocking streaming of relatively large (14.5MB) JPG of Seattle from wikimedia commons. &quot;&quot;&quot; requests_counter[0] += 1 request_num = requests_counter[0] url = &apos;http://upload.wikimedia.org/wikipedia/commons/3/39/Seattle_3.jpg&apos; app.logger.debug(&apos;started %d&apos;, request_num) rsp = requests.get(url, stream=True) def generator(): &quot;streaming generator logging the end of request processing&quot; yield &apos;&apos; # to make greenlet switch for data in rsp.iter_content(CHUNK_SIZE): yield data app.logger.debug(&apos;finished %d&apos;, request_num) return Response(generator(), mimetype=&apos;image/jpeg&apos;) def main(): &quot;Start gevent WSGI server&quot; # use gevent WSGI server instead of the Flask http = WSGIServer((&apos;&apos;, 5000), app.wsgi_app) # TODO gracefully handle shutdown http.serve_forever() if __name__ == &apos;__main__&apos;: main() 使用测试： pip install flask gevent requests python async_flask.py &amp; siege -c 1000 -t 5s http://127.0.0.1:5000/Seattle.jpg]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python当中的并发]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F13%2Fpython%E5%BD%93%E4%B8%AD%E7%9A%84%E5%B9%B6%E5%8F%91%2F</url>
    <content type="text"><![CDATA[并发的表现形式，并行处理是软件工程领域最广泛的话题之一。 两个事件互不影响，则两个事件是并发的。CPython的线程实现中带有一些麻烦的细节，使得实用性降低了。 GIL 只是强制在任何时候只有一个线程可以执行python代码 多线程可以使用的场景： 构建响应式界面 委派工作 构建多用户应用程序 如何让用户控制使用哪个处理后端（进程或者线程） from multiprocessing import Pool as ProcessPool from multiprocessing.dummpy import Pool as ThreadPool def main(use_threads=False): if use_threads: pool_cls = ThreadPool else: pool_cls = ProcessPool with pool_cls(4) as p: results = p.map(fetch_place, PLACES) for result in results: present_result(result) 异步编程异步编程的解决方案，如twisted tornado eventlet,真的值得了解 协同多任务是异步编程的核心。每个进程都在空闲时自动释放控制以允许同时执行多个程序。 gevent 的工作方式，gevent 的作用一条线程跑多个协程，适合多 IO 操作。 需要强调的是引入 gevent 不会加快获取数据的速度，例如，原来是 30ms，引入之后不会变少，只会变多，那么引入的好处是什么？原来你能在1秒之内接待33个客户端请求，引入之后可能可以接待100个/s，也可能接待 300个/s，这才是 gevent 的好处。]]></content>
  </entry>
  <entry>
    <title><![CDATA[flask and gevent]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F13%2Fflask-and-gevent%2F</url>
    <content type="text"><![CDATA[异步 WEB 架构的特点：gevent 为 Python 提供了比较完善的协程支持，其基于 greenlet 实现协程。 当 greenlet 遇到如网络访问、磁盘 IO 等操作时，就将自动切换至其他的 greenlet，待操作完成后，在适合的时间点回切 greenlet 继续执行。由于网络访问、磁盘 IO 等操作耗时较长，且实际 CPU 使用率较低（大部分工作由 DMA 等设备完成）。所以倘若非异步，涉及以上操作并发将以顺序执行， CPU 长期处于空闲状态。而异步模式将能实现并发程序间的切换，从而保证 CPU 有较高的利用率，而不是等待如网络访问、磁盘 IO 等操作。 注意：gevent 的使用并不能减少实际 CPU 的使用量，所以若程序的执行过程消耗的全为 CPU 资源，则其异步也是毫无意义的。 Flask+gevent 的最小程序实例：最小程序实例如下。 from gevent import monkey monkey.patch_all() from flask import Flask from gevent import pywsgi app = Flask(__name__) @app.route(&apos;/&apos;) def index(): return &apos;Hello World&apos; server = pywsgi.WSGIServer((&apos;127.0.0.1&apos;, 5000), app) server.serve_forever() 注意：为实现 Flask 与 gevent 的结合，需在程序开头引入 monkey patch。monkey patch 将以闭包的形式修改可以实现异步的标准库，从而实现异步。 注意：需使用支持 gevent 的 WSGI，例如：gevent.pywsgi、gunicorn 等。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python基础20题]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F10%2Fpython%E5%9F%BA%E7%A1%8020%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.简述函数式编程 在函数式编程中，函数是基本单位，变量只是一个名称，而不是一个存储单元。除了匿名函数外，Python还使用fliter(),map(),reduce(),apply()函数来支持函数式编程。 2.什么是匿名函数，匿名函数有什么局限性 匿名函数，也就是lambda函数，通常用在函数体比较简单的函数上。匿名函数顾名思义就是函数没有名字，因此不用担心函数名冲突。不过Python对匿名函数的支持有限，只有一些简单的情况下可以使用匿名函数。 3.如何捕获异常，常用的异常机制有哪些？ 如果我们没有对异常进行任何预防，那么在程序执行的过程中发生异常，就会中断程序，调用python默认的异常处理器，并在终端输出异常信息。 try…except…finally语句:当try语句执行时发生异常，回到try语句层，寻找后面是否有except语句。找到except语句后，会调用这个自定义的异常处理器。except将异常处理完毕后，程序继续往下执行。finally语句表示，无论异常发生与否，finally中的语句都要执行。 assert语句：判断assert后面紧跟的语句是True还是False，如果是True则继续执行print，如果是False则中断程序，调用默认的异常处理器，同时输出assert语句逗号后面的提示信息。 with语句：如果with语句或语句块中发生异常，会调用默认的异常处理器处理，但文件还是会正常关闭。 4.copy()与deepcopy()的区别 copy是浅拷贝，只拷贝可变对象的父级元素。 deepcopy是深拷贝，递归拷贝可变对象的所有元素。 5.函数装饰器有什么作用（常考） 装饰器本质上是一个Python函数，它可以让其他函数在不需要做任何代码变动的前提下增加额外功能，装饰器的返回值也是一个函数对象。它经常用于有切面需求的场景，比如：插入日志、性能测试、事务处理、缓存、权限校验等场景。有了装饰器，就可以抽离出大量与函数功能本身无关的雷同代码并继续重用。 6.简述Python的作用域以及Python搜索变量的顺序 Python作用域简单说就是一个变量的命名空间。代码中变量被赋值的位置，就决定了哪些范围的对象可以访问这个变量，这个范围就是变量的作用域。在Python中，只有模块（module），类（class）以及函数（def、lambda）才会引入新的作用域。Python的变量名解析机制也称为 LEGB 法则：本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in） 7.新式类和旧式类的区别,如何确保使用的类是新式类 为了统一类(class)和类型(type)，python在2.2版本引进来新式类。在2.1版本中，类和类型是不同的。 为了确保使用的是新式类，有以下方法： 放在类模块代码的最前面 metaclass = type从内建类object直接或者间接地继承在python3版本中，默认所有的类都是新式类。 8.简述new和init的区别 创建一个新实例时调用new,初始化一个实例时用init,这是它们最本质的区别。 new方法会返回所构造的对象，init则不会. new函数必须以cls作为第一个参数，而init则以self作为其第一个参数. 9.Python垃圾回收机制(常考) Python GC主要使用引用计数（reference counting）来跟踪和回收垃圾。在引用计数的基础上，通过“标记-清除”（mark and sweep）解决容器对象可能产生的循环引用问题，通过“分代回收”（generation collection）以空间换时间的方法提高垃圾回收效率。 1 引用计数 PyObject是每个对象必有的内容，其中ob_refcnt就是做为引用计数。当一个对象有新的引用时，它的ob_refcnt就会增加，当引用它的对象被删除，它的ob_refcnt就会减少.引用计数为0时，该对象生命就结束了。 优点: 简单 实时性 缺点: 维护引用计数消耗资源 循环引用 2 标记-清除机制 基本思路是先按需分配，等到没有空闲内存的时候从寄存器和程序栈上的引用出发，遍历以对象为节点、以引用为边构成的图，把所有可以访问到的对象打上标记，然后清扫一遍内存空间，把所有没标记的对象释放。 3 分代技术 分代回收的整体思想是：将系统中的所有内存块根据其存活时间划分为不同的集合，每个集合就成为一个“代”，垃圾收集频率随着“代”的存活时间的增大而减小，存活时间通常利用经过几次垃圾回收来度量。 Python默认定义了三代对象集合，索引数越大，对象存活时间越长。 10.Python中的@property有什么作用?如何实现成员变量的只读属性？ @property装饰器就是负责把一个方法变成属性调用，通常用在属性的get方法和set方法，通过设置@property可以实现实例成员变量的直接访问，又保留了参数的检查。另外通过设置get方法而不定义set方法可以实现成员变量的只读属性。 11.*args and **kwargs *args代表位置参数，它会接收任意多个参数并把这些参数作为元组传递给函数。**kwargs代表的关 键字参数，允许你使用没有事先定义的参数名，另外，位置参数一定要放在关键字参数的前面。 12.有用过with statement吗？它的好处是什么？具体如何实现？ with语句适用于对资源进行访问的场合，确保不管使用过程中是否发生异常都会执行必要的“清理”操作，释放资源，比如文件使用后自动关闭、线程中锁的自动获取和释放等。 13.写出代码输出 并解释 def extend_list(val, list=[]): list.append(val) return list list1 = extend_list(10) list2 = extend_list(123, []) list3 = extend_list(&apos;a&apos;) print(list1) # list1 = [10, &apos;a&apos;] print(list2) # list2 = [123, []] print(list3) # list3 = [10, &apos;a&apos;] class Parent(object): x = 1 class Child1(Parent): pass class Child2(Parent): pass print(Parent.x, Child1.x, Child2.x) # [1,1,1] Child1.x = 2 print(Parent.x, Child1.x, Child2.x) # [1,2,1] Partent.x = 3 print(Parent.x, Child1.x, Child2.x) # [3,2,3] 14.在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 arr = [[1,4,7,10,15], [2,5,8,12,19], [3,6,9,16,22], [10,13,14,17,24], [18,21,23,26,30]] def getNum(num, data=None): while data: if num &gt; data[0][-1]: del data[0] print(data) getNum(num, data=None) elif num &lt; data[0][-1]: data = list(zip(*data)) del data[-1] data = list(zip(*data)) print(data) getNum(num, data=None) else: return True data.clear() return False if __name__ == &apos;__main__&apos;: print(getNum(18, arr)) 15.获取最大公约数、最小公倍数 a = 36 b = 21 def maxCommon(a, b): while b: a,b = b, a%b return a def minCommon(a, b): c = a*b while b: a,b = b, a%b return c//a if __name__ == &apos;__main__&apos;: print(maxCommon(a,b)) print(minCommon(a,b)) 16.获取中位数 def median(data): data.sort() half = len(data) // 2 return (data[half] + data[~half])/2 l = [1,3,4,53,2,46,8,42,82] if __name__ == &apos;__main__&apos;: print(median(l)) 17.输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。 def getOneCount(num): if num &gt; 0: count = b_num.count(&apos;1&apos;) print(b_num) return count elif num &lt; 0: b_num = bin(~num) count = 8 - b_num.count(&apos;1&apos;) return count else: return 8 if __name__ == &apos;__main__&apos;: print(getOneCount(5)) print(getOneCount(-5)) print(getOneCount(0))]]></content>
  </entry>
  <entry>
    <title><![CDATA[python基础小结25]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F10%2Fpython%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%9325%2F</url>
    <content type="text"><![CDATA[1.什么是Python？使用Python有什么好处？ Python是一种编程语言，它有对象、模块、线程、异常处理和自动内存管理。 它简洁、简单、方便、容易扩展，有许多自带的数据结构，而且它开源。 2.什么是PEP8？ PEP8是一个编程规范，内容是一些关于如何让你的程序更具可读性的建议。 3.什么是pickling和unpickling？ Pickle模块读入任何Python对象，将它们转换成字符串，然后使用dump函数将其转储到一个文件中—— 这个过程叫做pickling。反之从存储的字符串文件中提取原始Python对象的过程，叫做 unpickling。 4.Python是如何被解释的？ Python是一种解释性语言，它的源代码可以直接运行。Python解释器会将源代码转换成中间语言， 之后再翻译成机器码再执行。 5.Python是怎样管理内存的？ Python的内存管理是由私有heap空间管理的。所有的Python对象和数据结构都在一个私有heap中。 程序员没有访问该heap的权限，只有解释器才能对它进行操作。为Python的heap空间分配内存是由 Python的内存管理模块进行的，其核心API会提供一些访问该模块的方法供程序员使用。Python有自 带的垃圾回收系统，它回收并释放没有被使用的内存，让它们能够被其他程序使用。 6.有哪些工具可以帮助debug或做静态分析？ PyChecker是一个静态分析工具，它不仅能报告源代码中的错误，并且会报告错误类型和复杂度。 Pylint是检验模块是否达到代码标准的另一个工具。 7.什么是Python装饰器？ Python装饰器是Python中的特有变动，可以使修改函数变得更容易。 8.数组和元组之间的区别是什么？ 数组和元组之间的区别：数组内容是可以被修改的，而元组内容是只读的。另外，元组可以被哈希，比 如作为字典的关键字。 9.参数按值传递和引用传递是怎样实现的？ Python中的一切都是类，所有的变量都是一个对象的引用。引用的值是由函数确定的，因此无法被改 变。但是如果一个对象是可以被修改的，你可以改动对象。 10.字典推导式和列表推导式是什么？ 它们是可以轻松创建字典和列表的语法结构。 11.Python都有哪些自带的数据结构？ Python自带的数据结构分为可变的和不可变的。 可变的有：数组、集合、字典； 不可变的有：字符串、元组、数。 12.什么是Python的命名空间？ 在Python中，所有的名字都存在于一个空间中，它们在该空间中存在和被操作——这就是命名空间。它 就好像一个盒子，每一个变量名字都对应装着一个对象。当查询变量的时候，会从该盒子里面寻找相应 的对象。 13.Python中的lambda是什么？ 这是一个常被用于代码中的单个表达式的匿名函数。 14.为什么lambda没有语句？ 匿名函数lambda没有语句的原因，是它被用于在代码被执行的时候构建新的函数对象并且返回。 15.Python中的pass是什么？ Pass是一个在Python中不会被执行的语句。在复杂语句中，如果一个地方需要暂时被留白，它常常被 用于占位符。 16.Python中什么是遍历器？ 遍历器用于遍历一组元素，比如列表这样的容器。 17.Python中的unittest是什么？ 在Python中，unittest是Python中的单元测试框架。它拥有支持共享搭建、自动测试、在测试中暂 停代码、将不同测试迭代成一组，等等的功能。 18.在Python中什么是slicing（分片）？ Slicing是一种在有序的对象类型中（数组，元组，字符串）节选某一段的语法。 19.在Python中什么是构造器？ 生成器是实现迭代器的一种机制。它功能的实现依赖于yield表达式， 除此之外它跟普通的函数没有两样。 20.Python中的docstring是什么？ Python中文档字符串被称为docstring， 它在Python中的作用是为函数、模块和类注释生成文档。 21.如何在Python中拷贝一个对象？ 如果要在Python中拷贝一个对象，大多时候你可以用copy.copy()或者copy.deepcopy()。但并 不是所有的对象都可以被拷贝。 22.Python中的负索引是什么？ Python中的序列索引可以是正也可以是负。如果是正索引，0是序列中的第一个索引，1是第二个索 引。如果是负索引，（-1）是最后一个索引而（-2）是倒数第二个索引。 23.如何将一个数字转换成一个字符串？ 你可以使用自带函数str()将一个数字转换为字符串。 如果你想要八进制或者十六进制数，可以用oct()或hex()。 24.Xrange和range的区别是什么？ Xrange用于返回一个xrange对象，而range用于返回一个数组。不管那个范围多大，Xrange都使用 同样的内存。 25.Python中的模块和包是什么？ 在Python中，模块是搭建程序的一种方式。每一个Python代码文件都是一个模块，并可以引用其他 的模块，比如对象和属性。 一个包含许多Python代码的文件夹是一个包。一个包可以包含模块和子文件夹。]]></content>
  </entry>
  <entry>
    <title><![CDATA[分享python面试题2]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F05%2F%E5%88%86%E4%BA%ABpython%E9%9D%A2%E8%AF%95%E9%A2%982%2F</url>
    <content type="text"><![CDATA[1.Python是如何进行内存管理的？ 答:从三个方面来说,一对象的引用计数机制,二垃圾回收机制,三内存池机制一、对象的引用计数机制Python内部使用引用计数，来保持追踪内存中的对象，所有对象都有引用计数。引用计数增加的情况：1，一个对象分配一个新名称2，将其放入一个容器中（如列表、元组或字典）引用计数减少的情况：1，使用del语句对对象别名显示的销毁2，引用超出作用域或被重新赋值sys.getrefcount( )函数可以获得对象的当前引用计数多数情况下，引用计数比你猜测得要大得多。对于不可变数据（如数字和字符串），解释器会在程序的不同部分共享内存，以便节约内存。二、垃圾回收1，当一个对象的引用计数归零时，它将被垃圾收集机制处理掉。2，当两个对象a和b相互引用时，del语句可以减少a和b的引用计数，并销毁用于引用底层对象的名称。然而由于每个对象都包含一个对其他对象的应用，因此引用计数不会归零，对象也不会销毁。（从而导致内存泄露）。为解决这一问题，解释器会定期执行一个循环检测器，搜索不可访问对象的循环并删除它们。三、内存池机制Python提供了对内存的垃圾收集机制，但是它将不用的内存放到内存池而不是返回给操作系统。1，Pymalloc机制。为了加速Python的执行效率，Python引入了一个内存池机制，用于管理对小块内存的申请和释放。2，Python中所有小于256个字节的对象都使用pymalloc实现的分配器，而大的对象则使用系统的malloc。3，对于Python对象，如整数，浮点数和List，都有其独立的私有内存池，对象间不共享他们的内存池。也就是说如果你分配又释放了大量的整数，用于缓存这些整数的内存就不能再分配给浮点数。 2.什么是lambda函数？它有什么好处? 答：lambda 表达式，通常是在需要一个函数，但是又不想费神去命名一个函数的场合下使用，也就是指匿名函数lambda函数：首要用途是指点短小的回调函数lambda [arguments]:expression &gt;&gt;&gt; a=lambdax,y:x+y &gt;&gt;&gt; a(3,11) 3.Python里面如何实现tuple和list的转换？ 答：直接使用tuple和list函数就行了，type()可以判断对象的类型 4.请写出一段Python代码实现删除一个list里面的重复元素 答：1,使用set函数，set(list) 2，使用字典函数， &gt;&gt;&gt;a=[1,2,4,2,4,5,6,5,7,8,9,0] &gt;&gt;&gt; b={} &gt;&gt;&gt;b=b.fromkeys(a) &gt;&gt;&gt;c=list(b.keys()) &gt;&gt;&gt; c 5.编程用sort进行排序，然后从最后一个元素开始判断 a=[1,2,4,2,4,5,7,10,5,5,7,8,9,0,3] a.sort() last=a[-1] for i inrange(len(a)-2,-1,-1): if last==a[i]: del a[i] else:last=a[i] print(a) 6.Python里面如何拷贝一个对象？（赋值，浅拷贝，深拷贝的区别） 答：赋值（=），就是创建了对象的一个新的引用，修改其中任意一个变量都会影响到另一个。 浅拷贝：创建一个新的对象，但它包含的是对原始对象中包含项的引用（如果用引用的方式修改其中一个对象，另外一个也会修改改变）{1,完全切片方法；2，工厂函数，如list()；3，copy模块的copy()函数} 深拷贝：创建一个新的对象，并且递归的复制它所包含的对象（修改其中一个，另外一个不会改变）{copy模块的deep.deepcopy()函数} 7.介绍一下except的用法和作用？ 答：try…except…except…[else…][finally…]执行try下的语句，如果引发异常，则执行过程会跳到except语句。对每个except分支顺序尝试执行，如果引发的异常与except中的异常组匹配，执行相应的语句。如果所有的except都不匹配，则异常会传递到下一个调用本代码的最高层try代码中。try下的语句正常执行，则执行else块代码。如果发生异常，就不会执行如果存在finally语句，最后总是会执行。8.Python中pass语句的作用是什么？ 答：pass语句不会执行任何操作，一般作为占位符或者创建占位程序，whileFalse:pass9.介绍一下Python下range()函数的用法？ 答：列出一组数据，经常用在for in range()循环中10.如何用Python来进行查询和替换一个文本字符串？ 答：可以使用re模块中的sub()函数或者subn()函数来进行查询和替换，格式：sub(replacement, string[,count=0])（replacement是被替换成的文本，string是需要被替换的文本，count是一个可选参数，指最大被替换的数量） &gt;&gt;&gt;import re &gt;&gt;&gt;p=re.compile(‘blue|white|red’) &gt;&gt;&gt;print(p.sub(‘colour’,&apos;blue socks and red shoes’)) colour socks and colourshoes &gt;&gt;&gt;print(p.sub(‘colour’,&apos;blue socks and red shoes’,count=1)) colour socks and redshoes subn()方法执行的效果跟sub()一样，不过它会返回一个二维数组，包括替换后的新的字符串和总共替换的数量 11.Python里面match()和search()的区别？ 答：re模块中match(pattern,string[,flags]),检查string的开头是否与pattern匹配。re模块中research(pattern,string[,flags]),在string搜索pattern的第一个匹配值。 &gt;&gt;&gt;print(re.match(‘super’, ‘superstition’).span()) (0, 5) &gt;&gt;&gt;print(re.match(‘super’, ‘insuperable’)) None &gt;&gt;&gt;print(re.search(‘super’, ‘superstition’).span()) (0, 5) &gt;&gt;&gt;print(re.search(‘super’, ‘insuperable’).span()) (2, 7) 12.用Python匹配HTML tag的时候，&lt;.&gt;和&lt;.?&gt;有什么区别？ 答：术语叫贪婪匹配( &lt;.&gt; )和非贪婪匹配(&lt;.?&gt; )例如:test&lt;.&gt; :test&lt;.?&gt; : 13.Python里面如何生成随机数？ 答：random模块随机整数：random.randint(a,b)：返回随机整数x,a&lt;=x&lt;=brandom.randrange(start,stop,[,step])：返回一个范围在(start,stop,step)之间的随机整数，不包括结束值。随机实数：random.random( ):返回0到1之间的浮点数random.uniform(a,b):返回指定范围内的浮点数。14.有没有一个工具可以帮助查找python的bug和进行静态的代码分析？ 答：PyChecker是一个python代码的静态分析工具，它可以帮助查找python代码的bug, 会对代码的复杂度和格式提出警告Pylint是另外一个工具可以进行codingstandard检查15.如何在一个function里面设置一个全局的变量？ 答：解决方法是在function的开始插入一个global声明：def f()global x16.单引号，双引号，三引号的区别 答：单引号和双引号是等效的，如果要换行，需要符号(),三引号则可以直接换行，并且可以包含注释如果要表示Let’s go 这个字符串单引号：s4 = ‘Let\’s go’双引号：s5 = “Let’s go”s6 = ‘I realy like“python”!’这就是单引号和双引号都可以表示字符串的原因了]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python装饰器全解]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F03%2Fpython%E8%A3%85%E9%A5%B0%E5%99%A8%E5%85%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[python装饰器的作用 使得函数包装和方法包装变得更容易阅读和理解 1.一般语法和可能的实现 作为一个函数 作为一个类 参数化装饰器 保存内省的装饰器 2.用法和有用的例子 参数检查 缓存 代理 上下文提供者 Python 函数不同于其他编程语言，它可以作为第一类对象使用，这是关键。因为装饰器本质上还是函数 很多人对装饰器难以理解，原因是由于以下三点内容没有搞清楚： 关于函数“变量”（或“变量”函数）的理解 关于高阶函数的理解 关于嵌套函数的理解 那么如果能对以上的问题一一攻破，同时遵循装饰器的基本原则，相信会对装饰器有个很好的理解的。那么我们先来看以下装饰器的目的及其原则。 1、装饰器 装饰器实际上就是为了给某程序增添功能，但该程序已经上线或已经被使用，那么就不能大批量的修改源代码，这样是不科学的也是不现实的，因为就产生了装饰器，使得其满足： 不能修改被装饰的函数的源代码 不能修改被装饰的函数的调用方式 满足1、2的情况下给程序增添功能那么根据需求，同时满足了这三点原则，这才是我们的目的。因为，下面我们从解决这三点原则入手来理解装饰器。 等等，我要在需求之前先说装饰器的原则组成： &lt; 函数+实参高阶函数+返回值高阶函数+嵌套函数+语法糖 = 装饰器 &gt; 这个式子是贯穿装饰器的灵魂所在！ 2、需求实现 improt time def test(): time.sleep(2) print(&quot;test is running!&quot;) test() 给程序添加统计运行时间（2 second）功能 如何进行呢？ 很显然，函数和变量是一样的，都是“一个名字对应内存地址中的一些内容”那么根据这样的原则，我们就可以理解两个事情： test1表示的是函数的内存地址 test1()就是调用对在test1这个地址的内容，即函数 如果这两个问题可以理解，那么我们就可以进入到下一个原因(关于高阶函数的理解) 那么对于高阶函数的形式可以有两种： 把一个函数名当作实参传给另外一个函数（“实参高阶函数”） 返回值中包含函数名（“返回值高阶函数”） 那么这里面所说的函数名，实际上就是函数的地址，也可以认为是函数的一个标签而已，并不是调用，是个名词。如果可以把函数名当做实参，那么也就是说可以把函数传递到另一个函数，然后在另一个函数里面做一些操作，根据这些分析来看，这岂不是满足了装饰器三原则中的第一条，即不修改源代码而增加功能。那我们看来一下具体的做法： 还是针对上面那段代码： improt time def test(): time.sleep(2) print(&quot;test is running!&quot;) def deco(func): start = time.time() func() #2 stop = time.time() print(stop-start) deco(test) #1 装饰有参数的函数 improt time def timer(func) def deco(*args, **kwargs): start = time.time() res = func(*args, **kwargs) stop = time.time() print(stop-start) return res return deco @timer def test(parameter): #8 time.sleep(2) print(&quot;test is running!&quot;) return &quot;Returned value&quot; test() 带参数的装饰器 import time def timer(parameter): def outer_wrapper(func): def wrapper(*args, **kwargs): if parameter == &apos;task1&apos;: start = time.time() func(*args, **kwargs) stop = time.time() print(&quot;the task1 run time is :&quot;, stop - start) elif parameter == &apos;task2&apos;: start = time.time() func(*args, **kwargs) stop = time.time() print(&quot;the task2 run time is :&quot;, stop - start) return wrapper return outer_wrapper @timer(parameter=&apos;task1&apos;) def task1(): time.sleep(2) print(&quot;in the task1&quot;) @timer(parameter=&apos;task2&apos;) def task2(): time.sleep(2) print(&quot;in the task2&quot;) task1() task2()]]></content>
  </entry>
  <entry>
    <title><![CDATA[分享python面试题]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F03%2F%E5%88%86%E4%BA%ABpython%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1.is和==有什么区别？ python当中对象包含三要素，分别是id（身份标识）、type（数据类型）、value（值） ==是python的比较运算符，用于比较value值是否相等 is是同一性运算符，比较的是id是否相同 a、b值相同 只有数值型和字符串型时， a is b 为true是tuple list dict 或者 set时，a is b 为false 2.解释装饰器 写代码要遵循开发封闭原则，虽然在这个原则是用的面向对象开发，但是也适用于函数式编程，简单来说，它规定已经实现的功能代码不允许被修改，但可以被扩展， def w1(func): def inner(): # 验证1 # 验证2 # 验证3 return func() return inner @w1 def f1(): print &apos;f1&apos; @w1 def f2(): print &apos;f2&apos; @w1 def f3(): print &apos;f3&apos; @w1 def f4(): print &apos;f4&apos; 如上例@w1内部会执行以下操作： 执行w1函数，并将 @w1 下面的 函数 作为w1函数的参数，即：@w1 等价于 w1(f1) 所以，内部就会去执行： def inner: #验证 return f1() # func是参数，此时 func 等于 f1 return inner # 返回的 inner，inner代表的是函数，非执行函数 其实就是将原来的 f1 函数塞进另外一个函数中 将执行完的 w1 函数返回值赋值给@w1下面的函数的函数名 w1函数的返回值是： def inner: #验证 return 原来f1() # 此处的 f1 表示原来的f1函数 然后，将此返回值再重新赋值给 f1，即： 新f1 = def inner: #验证 return 原来f1() 所以，以后业务部门想要执行 f1 函数时，就会执行 新f1 函数，在 新f1 函数内部先执行验证，再执行原来的f1函数，然后将 原来f1 函数的返回值 返回给了业务调用者。 如此一来， 即执行了验证的功能，又执行了原来f1函数的内容，并将原f1函数返回值 返回给业务调用者]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[normal-library]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F03%2Fnormal-library%2F</url>
    <content type="text"><![CDATA[我做运维的时候，使用Python完成了一些打包和备份的脚本，也就是把某个目录压缩成各种格式（tar.gz、tar.bz2、zip）。 这个脚本其实打包压缩的部分还是比较复杂的。直到我看到了这个： In : from shutil import make_archive In : make_archive(‘archive_xxx’, ‘bztar’) Out: ‘archive_xxx.tar.bz2’ 有兴趣的可以翻一下源码。你想要的说不定标准库里面已经实现。当然，有标准库不满足的额外需求，也可以参照它实现。 你可能接触过定时任务（crontab），它管理的任务很规矩，到点执行（当然精确度不那么高）。现在设想你有更复杂的任务需求：这个任务是动态的，也就是不一定啥时候就来排上队约定一个事件等着执行。这时候你可以想，这可以使用队列（Queue模块）啊，嗯也不错。难度再提高：加上优先级策略并能取消某个指定的已经放入队列的任务。现在思考下，这个怎么实现？其实很多工程实践的最好范例都在标准库中。sched模块中的scheduler类就是一个这样的通用的事件调度类。你可以学习它的实现。你问我它的实现多复杂？整个模块加上大幅的注释才134行。 学习Python的过程中，一开始我对于装饰器contextmanager+yield怎么都不懂。直到我看了contextmanager的源代码, 其实非常简单就懂了。它的docstring清楚地不能再清楚了： Typical usage: @contextmanager def some_generator(&lt;arguments&gt;): &lt;setup&gt; try: yield &lt;value&gt; finally: &lt;cleanup&gt; This makes this: with some_generator(&lt;arguments&gt;) as &lt;variable&gt;: &lt;body&gt; equivalent to this: &lt;setup&gt; try: &lt;variable&gt; = &lt;value&gt; &lt;body&gt; finally: &lt;cleanup&gt; 我之前使用多线程编程都这样用，在好长一段时间里面对于多进程和多线程之前怎么选择都搞得不清楚。看多了开源项目代码，我发现了好多人在用multiprocessing.dummy这个子模块，「dummy」这个词本身好奇怪，我决定去看多进程（multiprocessing）库的代码。「咦！怎么和多线程的接口一样呢」。后知后觉的我看到文档中这样说： multiprocessing.dummy replicates the API of multiprocessing but is no more than a wrapper around the threading module.恍然大悟！！！如果分不清任务是CPU密集型还是IO密集型，我就用如下2个方法分别试： from multiprocessing import Poolfrom multiprocessing.dummy import Pool哪个速度快就用那个。从此以后我都尽量在写兼容的方式，这样在多线程/多进程之间切换非常方便。 13-14年间，Flask还没怎么火，那时候装饰器风格的Web框架还有一个Bottle。我当时就直接想去看Bottle代码，发现一上来import了一堆模块，你先感受下bottle/bottle.py at master · bottlepy/bottle · GitHub ，第一感觉就是懵啊，这都是干什么的啊，为什么要用啊？这就是促使我去看标准库实现最重要的原因：学会了我才能更好的看懂别人写的代码。 但是不是所有的标准库都要一视同仁的看呢？你可以设置优先级，先看那些不可不知道的模块。我在这里列一下，并对它的用途和其中重要的类、函数的作用加以说明等。要是每个都写例子实在太多太密集，怕大家看不下去，我都用外部链接了。 argparse。 用来替代optparse的命令行解析库。如果你考虑用更直观的，推荐docopt，它使用docstring所见即所得实现命令行解析。 collections。 包含了一些额外的数据类型。其中的OrderedDict（有序列的字典）、defaultdict（带有默认值的字典）、namedtuple（通过创建带有字段属性的元组子类）和deque（高效实现插入和删除操作的双向列表）非常常用。 functools。 这个模块有一些非常有用的工具，其中的partial（偏函数）、wraps（将被包装函数的信息拷贝过来）、total_ordering（只需要定义2个XX方法就可实现对象对比的类装饰器）、cmp_to_key（将老式的比较函数转化为关键字函数）非常常用。 glob。 文件名的shell模式匹配，你不用遍历整个目录判断每个文件是不是符合，使用glob一句话就解决。 multiprocessing。多进程模块，这重要性就不说了。 os。应该是日常工作最常用的模块了，你是否了解它里面所有的函数和实现呢？举个例子，获取环境变量，我之前这样用：In : os.environ.get(‘PYTHONPATH’)读完源码之后我学了一招：os.getenv(‘PYTHONPATH’)好吧，省了5个字符。 Queue。这个模块用于多线程编程，它是一个线程安全的FIFO（先进先出）的队列实现。如果是多进程编程，选用multiprocessing.queues中的Queue、SimpleQueue、JoinableQueue这三个队列实现。 SimpleHTTPServer。最简单地HTTP Server实现。不使用Web框架，一句： python -m SimpleHTTPServer PORT 就可以运行起来静态服务。平时用它预览和下载文件太方便了。 subprocess。 如果你还被某些书籍引导使用os.system或者os.popen等模块，现在是放弃它们的时候了，这个模块会满足你绝大多数的系统命令执行、执行结果获取和解析等需求。其中最有用的是call（执行系统命令）、check_call（执行结果不为0则抛出异常）、check_output（最方便的获取执行的输出的函数）、Popen+PIPE（支持管道的多命令执行）。 threading。多线程模块，重要性也不必说。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-fp]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F03%2Fpython-fp%2F</url>
    <content type="text"><![CDATA[函数式编程函数式编程源自于数学理论，它似乎也更适用于数学计算相关的场景，因此本文以一个简单的数据处理问题为例，逐步介绍 Python 函数式编程从入门到走火入魔的过程。 问题：计算 N 位同学在某份试卷的 M 道选择题上的得分（每道题目的分值不同）。 首先来生成一组用于计算的伪造数据： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657# @file: data.pyimport random from collections import namedtuple Student = namedtuple('Student', ['id', 'ans']) N_Questions = 25 N_Students = 20 def gen_random_list(opts, n): return [random.choice(opts) for i in range(n)] # 问题答案 'ABCD' 随机ANS = gen_random_list('ABCD', N_Questions) # 题目分值 1~5 分SCORE = gen_random_list(range(1,6), N_Questions) QUIZE = zip(ANS, SCORE) students = [ # 学生答案为 'ABCD*' 随机，'*' 代表未作答 Student(_id, gen_random_list('ABCD*', N_Questions)) for _id in range(1, N_Students+1)] print(QUIZE) # [('A', 3), ('B', 1), ('D', 1), ...print(students) # [Student(id=1, ans=['C', 'B', 'A', ...``` 常规的面向过程编程风格，我们需要遍历每个学生，然后遍历每个学生对每道题目的答案并与真实答案进行比较，然后将正确答案的分数累计：```pythonimport data def normal(students, quize): for student in students: sid = student.id score = 0 for i in range(len(quize)): if quize[i][0] == student.ans[i]: score += quize[i][1] print(sid, '\t', score) print('ID\tScore\n==================') normal(data.students, data.quize) """ID Score ==================1 5 2 12 ...""" 通过创建嵌套两个 for 循环来遍历所有题目答案的判断和评分，这完全是为计算机服务的思路，虽然说 Python 中的 for 循环已经比 C 语言更进了一步，通常不需要额外的状态变量来记录当前循环的次数，但有时候也不得不使用状态变量，如上例中第二个循环中比较两个列表的元素。函数式编程的一大特点就是尽量抛弃这种明显循环遍历的做法，而是把注意集中在解决问题本身，一如在现实中我们批改试卷时，只需要将两组答案并列进行比较即可： from data import students, QUIZE student = students[0] # 将学生答案与正确答案合并到一起 # 然后过滤出答案一致的题目 filtered = filter(lambda x: x[0] == x[1][0], zip(student.ans, QUIZE)) print(list(filtered)) # [(&apos;A&apos;, (&apos;A&apos;, 3)), (&apos;D&apos;, (&apos;D&apos;, 1)), ...] 正确题目的分数进行累加： from functools import reduce reduced = reduce(lambda x, y: x + y[1][1], filtered, 0) print(reduced) 接下来进行推广： def cal(quize): def inner(student): filtered = filter(lambda x: x[0] == x[1][0], zip(student.ans, quize)) reduced = reduce(lambda x, y: x + y[1][1], filtered, 0) print(student.id, &apos;\t&apos;, reduced) return inner map(cal(QUIZE), students)]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-interview-0]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F01%2Fpython-interview-0%2F</url>
    <content type="text"><![CDATA[我从来不问google可获得的答案的问题， 只是问问面试者「在过去的工作中，遇到的Ta认为最有成就感的一件事情是什么」和「如果出现了一个google不到的问题，你会怎么解决」这样的问题。 我从来不问操作系统等和Python无关的话题，首先是我不怎么问和工作太无关的话题，有些东西用不到很多就被会遗忘，挑起来这种问题其实挺无聊；其次我是非计算机专业毕业，问的东西说不定我自己都没有把握，那就不出来献丑了。我只关注面试者的学习能力和解决问题的方式，说白了，是不是就是看他是不是「聪明的人」。 不问面试者的短处。我在自己被面试的时候有过这种精力，面试者问他擅长的内容，我不一定搞的定，如果反过来面试Ta，我也会灭掉Ta。所以我会尽力寻找面试者的优势和优点，尤其是对方已经明确承认。其实很多经验和能力，只是需要一个机会和环境，所以我不想放过任何一个合适的人。 面试者不会Python也没有关系。面试者的主动性和学习能力觉得更重要，如果他在其他领域能证明做的不错或者能让我感觉到这个一个未来有潜质成为优秀工程师的人，不会Python没有关系。 嗯目前看来，我没有看错过。 我从来不问Python语法这种看书和google就能学会的问题，我只想了解Ta是否愿意去学。举个例子，我会让面试者「讲讲日常开发中都用到了那些Python内置的模块」，原因在我的专栏「Python之美 - 知乎专栏」的 Python不能不知的模块 - Python之美 - 知乎专栏中有写，基本上说完我就能评估出他的能力和风格，继而就是再问一些问题去验证我的评估是不是准确。 最后，我一般都会和面试者细聊一个Ta认为在过去的工作或者自己开源的项目中最熟悉的一个，从项目设计、踩过的坑儿、开发周期以及如何安排、如何确定需求、如何和其他人协作等方面，最后评估下Ta是否能很容易的融入到我们现在的团队，大家是否可以接受Ta，对工作不负责的、没有用心工作的、没有团队意识的、沟通能力有缺陷的就放弃掉，对性格上容易发生冲突的、不适合团队合作的我就得考虑下，未来也会如实反馈给HR。 推荐几本书 《python参考手册》，绝对让你更上一层楼 《图解密码技术》，密码入门不二之选 《mysql技术内幕》（第五版），有点厚当手册读读，要有耐心，《高性能mysql》也强烈建议读读 《effective tcp/ip programming》 如果是搞web的对操作系统这块和密码技术会偏弱，但如果是系统工程师或是游戏服务端这块会明显偏强。吃午饭的时候我就一直在想这个问题，我觉得重点不是Python而是后端工程师，因为Python只是系统的一部分，linux基础操作要熟吧，sql要懂吧，消息队列要知道吧，git要熟悉吧……木桶理论，每一环都不能落下，精通其中一两环就更好了。基础功扎实，新东西学得快，代码写得溜，命令敲得顺，bug解的好，妈妈再也不用担心我天天加班了~~~ 一.语言1.推荐一本看过最好的python书籍？ 拉开话题好扯淡 2.谈谈python的装饰器，迭代器，yield？ 3.标准库线程安全的队列是哪一个？不安全的是哪一个？logging是线程安全的吗？ 4.python适合的场景有哪些？当遇到计算密集型任务怎么办？ 5.python高并发解决方案？我希望听到twisted-&gt;tornado-&gt;gevent，能扯到golang,erlang更好 二.操作系统可以直接认为是linux，毕竟搞后端的多数是和linux打交道。 1.tcp/udp的区别？tcp粘包是怎么回事，如何处理？udp有粘包吗？ 2.time_wait是什么情况？出现过多的close_wait可能是什么原因？ 3.epoll,select的区别？边缘触发，水平触发区别？ 三.存储存储可能包含rdbms，nosql以及缓存等，我以mysql,redis举例 mysql相关 1.谈谈mysql字符集和排序规则？ 2.varchar与char的区别是什么？大小限制？utf8字符集下varchar最多能存多少个字符 3.primary key和unique的区别？ 4.外键有什么用，是否该用外键？外键一定需要索引吗？ 5.myisam与innodb的区别？innodb的两阶段锁定协议是什么情况？ 6.索引有什么用，大致原理是什么？设计索引有什么注意点？ redis相关 1.什么场景用redis，为什么mysql不适合？ 2.谈谈redis的事务？用事务模拟原子+1操作？原子操作还有其它解决方案吗？ 3.redis内存满了会怎么样？ 四.安全web安全相关 1.sql注入是怎么产生的，如何防止？ 2.xss如何预防？htmlescape后能否避免xss? 3.csrf是什么？django是如何防范的？ 密码技术 1.什么是分组加密？加密模式有哪些？ecb和cbc模式有什么区别？为什么需要iv向量？ 2.简单说说https的过程？ 3.对称加密与非对称加密区别？ 4.如何生成共享秘钥？ 如何防范中间人攻击？]]></content>
  </entry>
  <entry>
    <title><![CDATA[about-react]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F03%2F01%2Fabout-react%2F</url>
    <content type="text"><![CDATA[react 的概述React 的设计哲学：以“简单直观”、“符合习惯”的方式去编程，让代码更容易被理解，从而易于维护和不断演化。 React 的最大价值？1.高性能虚拟 DOM 【★★】2.声明式的、直观的编程方式（别样的组件化、JSX也不是核心）【★】3.封装过的事件机制4.服务器端 Reader（忽略，不是核心，锦上添花）5.完善的错误提示信息 React 的适用场景：适用于数据不断变化的大型应用程序，eg.聊天、评论等会面临问题：如何将服务器端 or 用户输入的数据高效地反应到复杂的用户界面上 React 原理新的前端 UI 的构建方式：两层编程模型：数据模型、UI界面。数据模型驱动UI界面（从概念角度上看是直观的，而实际开发中困难重重） React 的初衷之一就是：既然整体刷新一定能解决层叠更新的问题，那我们为什么不索性就每次都这么做呢？让框架自身去解决哪些局部 UI 需要更新的问题-React做到了，实现的途径就是通过虚拟 DOM。 UI界面是一颗 DOM 树。我们再在全局定义一个唯一的数据模型。每次数据模型有任何变化，都将整个数据模型应用到 UI DOM 树上（由 React 来负责更新需要更新的界面部分）。 虚拟 DOM将变化的数据实时反应到UI上，就要对 DOM 进行操作。复杂和频繁的 DOM 操作，通常是性能瓶颈产生的原因。 虚拟DOM，是在浏览器端用 JS 实现了一套 DOM API。基于 React 的所有 DOM 构造都是通过虚拟 DOM 进行的。每当数据变化时，React 会重 新构建整个 DOM 树，并将当前的树和上一次的 DOM 树进行对比，得到 DOM 结构的区别。然后仅仅将需要变化的部分进行实际的浏览器 DOM 更新。且，React 能够批处理虚拟 DOM 的刷新，在一个事件循环内的两次数据变化会被合并。 虽然，每次都要构造完整的虚拟 DOM 树，但因为它是内存数据，性能极高 【那会消耗多少内存呢？】对实际 DOM 的操作，仅仅是 Diff 部分，故能提高性能。（至于 React 如何做到将原来 O(n^3) 复杂度的 Diff 算法降低到 O（n），感兴趣的你可以再深入学习下） 你永远只需要关心数据整体，两次数据之间的 UI 如何变化，则完全交给框架去做。开发逻辑没那么复杂了，开发难度降低，产生的bug几率也就更少。 简化的组件模型所谓组件，就是状态机器。对组件的管理 就是对状态的管理。这么，React 很少要暴露组件方法和外部交互，只要设置状态即可，只需要考虑在某个状态下UI是怎样的。 React 将用户界面看做简单的状态机器。当组件处于某个状态时，那就输出这个状态对应的界面，以保证界面的一致性。在 React 中，你只需要简单的更新某个组件的状态即可，然后基于新状态输出整个页面。由 React 负责以最高效的方式去比较两个界面并更新 DOM 树。 组件是 React 中构建用户界面的基本单位。与外界的交互除了 state（状态）之外，还有 props（属性）。事实上，state 更多由组件内部自己维护，props 则由外部初始化该组件时传递进来（一般是组件需要管理的数据）。React 认为，props 应该是只读的（一旦赋值过去就不要变化了）。 虚拟化DOM，不仅简化了UI逻辑，也内含了组件化开发思想。组件，即封装起来的具有独立功能的UI部件。将UI上每一个功能相对独立的模块定义成组件，然后将小的组件通过组合 or 嵌套构成大的组件，最终完成整体UI的构建。 MVC：开发者将三者定义成不同的类，实现了表现、数据、控制的分离（从技术角度拆分UI实现松耦合）React：新的思路，开发者从功能的角度出发，将UI拆成不同的组件。每个组件都独立封装。即按照界面模块自然划分的方式来组织和编写你的代码。 每个组件的UI和逻辑都定义在它们内部，高度自治。和外部完全通过API来交互，通过组合来实现复杂功能。 React 认为，一个组件应该具备以下特征： 可组合 Composeable：接口 可重用 Reusable：独立 可维护 Maintainable：各个组件仅包含自身的逻辑，更容易被理解和维护 可测试 Testable]]></content>
      <categories>
        <category>frontend</category>
      </categories>
      <tags>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[about-flask]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F28%2Fabout-flask%2F</url>
    <content type="text"><![CDATA[谈一谈 flask 从http 请求开始到响应 前置技能 wsgi WSGI，全称 Web Server Gateway Interface，或者 Python Web Server Gateway Interface ，是为 Python 语言定义的 Web 服务器和 Web 应用程序或框架之间的一种简单而通用的接口。自从 WSGI 被开发出来以后，许多其它语言中也出现了类似接口。 WSGI 的官方定义是，the Python Web Server Gateway Interface。从名字就可以看出来，这东西是一个Gateway，也就是网关。网关的作用就是在协议之间进行转换。 WSGI 是作为 Web 服务器与 Web 应用程序或应用框架之间的一种低级别的接口，以提升可移植 Web 应用开发的共同点。WSGI 是基于现存的 CGI 标准而设计的。 很多框架都自带了 WSGI server ，比如 Flask，webpy，Django、CherryPy等等。当然性能都不好，自带的 web server 更多的是测试用途，发布时则使用生产环境的 WSGI server或者是联合 nginx 做 uwsgi 。 在网上搜过WSGI的人应该会看到一个图，左边是Server，右边是APP，中间有一个连接纽带是WSGI。 不过，我看了源码以后的理解和这个有些不同，我个人觉得，实际上不应该单独写一个APP，因为，这个WSGI的使用方法实际上也是包含在APP里面的，最右端的app实际上应该指的是逻辑功能，包括URL和view function的对应关系。 WSGI其实是作为一个接口，来接受Server传递过来的信息, 然后通过这个接口调用后台app里的view function进行响应。 起到一个接口的功能，前面对接服务器，后面对接app的具体功能 def application(environ, start_response): # 一个符合wsgi协议的应用程序写法应该接受2个参数 start_response(&apos;200 OK&apos;, [(&apos;Content-Type&apos;, &apos;text/html&apos;)]) # environ为http的相关信息，如请求头等 start_response则是响应信息 return [b&apos;&lt;h1&gt;Hello, web!&lt;/h1&gt;&apos;] # return出来是响应内容 但是，作为app本身，你就算启动了程序，你也没办法给application传递参数？ 所以，实际上，调用application和传递2个参数的动作，是服务器来进行的，比如Gunicorn. 而这个叫做application的东西，在Flask框架内部的名字，叫做wsgi_app，请看下面章节的源码。 from flask import Flask app = Flask(__name__) #生成app实例 @app.route(&apos;/&apos;) def index(): return &apos;Hello World&apos; 这样，一个flask app就生成了 但是这里有一个概念必须要搞清楚，就是当你的gunicorn收到http请求，去调用app的时候，他实际上是用了Flask 的 call方法，这点非常重要！！！ 因为call方法怎么写，决定了你整个流程从哪里开始。 flask类的call方法 class Flask(_PackageBoundObject): #Flask类 #中间省略一些代码 def __call__(self, environ, start_response): #Flask实例的__call__方法 &quot;&quot;&quot;Shortcut for :attr:`wsgi_app`.&quot;&quot;&quot; return self.wsgi_app(environ, start_response) #注意他的return，他返回的时候，实际上是调用了wsgi_app这个功能 如此一来，我们便知道，当http请求从server发送过来的时候，他会启动call功能，最终实际是调用了wsgi_app功能并传入environ和start_response class Flask(_PackageBoundObject): #中间省略一些代码 #请注意函数的说明，说得非常准确，这个wsgi_app是一个真正的WSGI应用 def wsgi_app(self, environ, start_response): #他扮演的是一个中间角色 """The actual WSGI application. This is not implemented in `__call__` so that middlewares can be applied without losing a reference to the class. So instead of doing this:: app = MyMiddleware(app) It's a better idea to do this instead:: app.wsgi_app = MyMiddleware(app.wsgi_app) Then you still have the original application object around and can continue to call methods on it. :param environ: a WSGI environment :param start_response: a callable accepting a status code, a list of headers and an optional exception context to start the response """ ctx = self.request_context(environ) ctx.push() error = None try: try: response = self.full_dispatch_request() #full_dispatch_request起到了预处理和错误处理以及分发请求的作用 except Exception as e: error = e response = self.make_response(self.handle_exception(e)) #如果有错误发生，则生成错误响应 return response(environ, start_response) #如果没有错误发生，则正常响应请求，返回响应内容 finally: if self.should_ignore_error(error): error = None ctx.auto_pop(error) WSGI_APP 的内部流程 生成request请求对象和请求上下文环境 请求进入预处理，错误处理及请求转发到响应的过程 class Flask(_PackageBoundObject): #此处省略一些代码 def full_dispatch_request(self): &quot;&quot;&quot;Dispatches the request and on top of that performs request pre and postprocessing as well as HTTP exception catching and error handling. .. versionadded:: 0.7 &quot;&quot;&quot; self.try_trigger_before_first_request_functions() #进行发生真实请求前的处理 try: request_started.send(self) #socket部分的操作 rv = self.preprocess_request() #进行请求的预处理 if rv is None: rv = self.dispatch_request() except Exception as e: rv = self.handle_user_exception(e) response = self.make_response(rv) response = self.process_response(response) request_finished.send(self, response=response) return response 请求分发 class Flask(_PackageBoundObject): #省略一些代码 def dispatch_request(self): #看函数定义，matches the URL and returns the value of the view or error. """Does the request dispatching. Matches the URL and returns the return value of the view or error handler. This does not have to be a response object. In order to convert the return value to a proper response object, call :func:`make_response`. .. versionchanged:: 0.7 This no longer does the exception handling, this code was moved to the new :meth:`full_dispatch_request`. """ req = _request_ctx_stack.top.request if req.routing_exception is not None: self.raise_routing_exception(req) rule = req.url_rule # if we provide automatic options for this URL and the # request came with the OPTIONS method, reply automatically if getattr(rule, 'provide_automatic_options', False) \ and req.method == 'OPTIONS': return self.make_default_options_response() # otherwise dispatch to the handler for that endpoint return self.view_functions[rule.endpoint](**req.view_args) #最终进入view_functions，取出url对应的视图函数的返回值 req = _request_ctx_stack.top.request 可以暂时理解为，将请求对象赋值给req 这里先简单讲下，每个url进来以后，他都会对应一个view_function 另外说下view_functions 是一个字典形式，他的key和value的关系是endpoint ——&gt; view function 所以每个有效的URL进来，都能找到他对应的视图函数view function，取得返回值并赋值给 rv 这时候，通过make_response函数，将刚才取得的 rv 生成响应，重新赋值response 再通过process_response功能主要是处理一个after_request的功能，比如你在请求后，要把数据库连接关闭等动作，和上面提到的before_request对应和类似。 之后再进行request_finished.send的处理，也是和socket处理有关，暂时不详细深入。 之后返回新的response对象 这里特别需要注意的是，make_response函数是一个非常重要的函数，他的作用是返回一个response_class的实例对象，也就是可以接受environ和start_reponse两个参数的对象 返回wsgi_app 内部 当response从刚刚的full_dispatch_request功能返回之后，函数会对这个response加上environ, start_response的参数并返回给Gunicorn 至此，一个HTTP从请求到响应的流程就完毕了.]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-text]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F26%2Fpython-text%2F</url>
    <content type="text"><![CDATA[六款比较不错的特殊文本格式处理库 1.tablib 2.openpyxl 算是xlwt xlrd的替代品 3.unoconv 4.pypdf2 5.mistune 6.csvkit 命令行工具]]></content>
  </entry>
  <entry>
    <title><![CDATA[运维题目搜集]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F23%2F%E8%BF%90%E7%BB%B4%E9%A2%98%E7%9B%AE%E6%90%9C%E9%9B%86%2F</url>
    <content type="text"><![CDATA[三百台服务器 如何进行管理 1.设定跳板机 使用统一的账户登陆 便于安全与登陆的考量 2.使用salt、ansible、puppet 进行系统的统一调度与配置统一的管理 3.建立简单的服务器的系统、配置、应用的cmdb信息管理。便于查阅每台服务器上的各种信息记录 rabbitMQ 也就是消息队列中间件，消息中间件是在消息的传息过程中保存消息的容器 使用像pyflakes 这样的静态代码分析工具 选定一个特定的代码风格 开发工具保存高响应速度 找到合适的编辑器 感到舒服和更有效率的工具值得花钱]]></content>
      <categories>
        <category>ops</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Japronto介绍]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F23%2FJapronto%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[实现 HTTP 1.x 并且支持分片上传 完整支持 HTTP 流水线 可配置是否让链接 Keep-alive 支持同步和异步视图 多任务处理 代码热加载 简单易用的路由规则]]></content>
  </entry>
  <entry>
    <title><![CDATA[it从业人员的核心竞争力]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F23%2Fit%E4%BB%8E%E4%B8%9A%E4%BA%BA%E5%91%98%E7%9A%84%E6%A0%B8%E5%BF%83%E7%AB%9E%E4%BA%89%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[以前的长辈会说， 你要小心，你会的东西千万不能交给别人。俗话说的好，教会了徒弟饿死了师傅。 BUT， 在 IT 行业 ，这个是一个讲究分享的行业，业内有一句话叫做， if you can’t be replaced,you won’t get promoted 多写几条query Google 一下，从理论论文到工业实现到best practice code 瞬间一网打尽 沟通能力 学习能力 全局眼光和行业洞察力 创新能力 体察对方，表达自己，将需求转化为design，将task拆解为AI 的能力 从实际工作中总结提炼的能力，即将现实问题转换为经验，并举一反三推而广之的能力 形成这种行业性的vision 需要时间积累。 主要是 顺利理解和跟进，以最快的速度将他人原创应用到自己所从事的领域和正在实践的具体业务上，这就是一种跟进式创新]]></content>
  </entry>
  <entry>
    <title><![CDATA[2月好书推荐201802]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F22%2F2%E6%9C%88%E5%A5%BD%E4%B9%A6%E6%8E%A8%E8%8D%90201802%2F</url>
    <content type="text"><![CDATA[精益数据分析 定位 视觉锤 毛主席语录 金字塔原理 学会提问 鬼谷子 零秒思考 SWOT分析法 竞争分析]]></content>
      <categories>
        <category>suibi</category>
      </categories>
      <tags>
        <tag>books</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[10-to-illustriousness]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F21%2F10-to-illustriousness%2F</url>
    <content type="text"><![CDATA[1.不沟通明白，就整代码！！ 有时有些怕直接领导没有空，或者他说一次以为自己听懂了，不好意思问。。 需要详细问清楚再动手 2.先想清楚 再动手 3.一定要写注释 一定要写注释 一定要写注释 因为出了bug 后 自己都不记得当时怎么想的 为毛这么写 4.写完一定要认真测试 5.不要心存侥幸 6.文档一定要写 7.习惯于需求的改变 8.遇到问题 及时提出来 9.充分预估任务完成时间 10.有效的与同事沟通会大大提高工作效率]]></content>
      <categories>
        <category>jottings</category>
      </categories>
      <tags>
        <tag>life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django api interfaces]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F21%2Fdjango-api-interfaces%2F</url>
    <content type="text"><![CDATA[现在是个项目就需要API接口的时代，往往大家写API都有着自己的风格，而django却早有了解决api开发和自测的一套黑科技，我相信很多人都知道： django-rest-framework（主打接口序列化) django-rest-swagger（主打接口ui） 注意此处的django 版本 选择 建议是 &lt; 1.9 django-rest-swagger==0.3.5 Django REST framework 是一个强大且灵活的工具包，用以构建Web APIs。 为什么要使用REST framework？ 在线可视的API，对于赢得你的开发者们十分有用 验证策略涵盖了OAuth1a和OAuth2 同时支持ORM和非ORM数据源的序列化 可以配置各个环节，若无需更多强大的特性，使用一般基于类（function-based）的视图（views）即可 大量的文档，强力的社区支持 大公司如同Mozilla和Eventbrite，也是忠实的使用者 djangorestframework 版本使用建议为3.6.3 实际项目中需要注意的事项 1.数据加载到内存中长久保存，这样每次用户请求数据，无须计算或者检索数据，以此来提升用户体验。 2.谈一谈django 的登陆？注册？]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js-inter]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F18%2Fjs-inter%2F</url>
    <content type="text"><![CDATA[1.使用 typeof bar === “object” 来确定 bar 是否是对象的潜在陷阱是什么？如何避免这个陷阱？ null 也是对象 console.log((bar !== null) &amp;&amp; (typeof bar === &quot;object&quot;) &amp;&amp; (toString.call(bar) !== &quot;[object Array]&quot;)); 2.use strict?? 对于这个问题，既简要又最重要的答案是，use strict 是一种在JavaScript代码运行时自动实行更严格解析和错误处理的方法。那些被忽略或默默失败了的代码错误，会产生错误或抛出异常。通常而言，这是一个很好的做法。 严格模式的一些主要优点包括： 使调试更加容易。那些被忽略或默默失败了的代码错误，会产生错误或抛出异常，因此尽早提醒你代码中的问题，你才能更快地指引到它们的源代码。防止意外的全局变量。如果没有严格模式，将值分配给一个未声明的变量会自动创建该名称的全局变量。这是JavaScript中最常见的错误之一。在严格模式下，这样做的话会抛出错误。消除 this 强制。如果没有严格模式，引用null或未定义的值到 this 值会自动强制到全局变量。这可能会导致许多令人头痛的问题和让人恨不得拔自己头发的bug。在严格模式下，引用 null或未定义的 this 值会抛出错误。不允许重复的属性名称或参数值。当检测到对象（例如，var object = {foo: “bar”, foo: “baz”};）中重复命名的属性，或检测到函数中（例如，function foo(val1, val2, val1){}）重复命名的参数时，严格模式会抛出错误，因此捕捉几乎可以肯定是代码中的bug可以避免浪费大量的跟踪时间。使eval() 更安全。在严格模式和非严格模式下，eval() 的行为方式有所不同。最显而易见的是，在严格模式下，变量和声明在 eval() 语句内部的函数不会在包含范围内创建（它们会在非严格模式下的包含范围中被创建，这也是一个常见的问题源）。在 delete使用无效时抛出错误。delete操作符（用于从对象中删除属性）不能用在对象不可配置的属性上。当试图删除一个不可配置的属性时，非严格代码将默默地失败，而严格模式将在这样的情况下抛出异常。 3.NaN 是什么？它的类型是什么？你如何可靠地测试一个值是否等于 NaN ？ NaN 属性代表一个“不是数字”的值。这个特殊的值是因为运算不能执行而导致的，不能执行的原因要么是因为其中的运算对象之一非数字（例如， “abc” / 4），要么是因为运算的结果非数字（例如，除数为零）。 虽然这看上去很简单，但 NaN 有一些令人惊讶的特点，如果你不知道它们的话，可能会导致令人头痛的bug。 首先，虽然 NaN 意味着“不是数字”，但是它的类型，不管你信不信，是 Number： console.log(typeof NaN === “number”); // logs “true”此外， NaN 和任何东西比较——甚至是它自己本身！——结果是false： console.log(NaN === NaN); // logs “false”一种半可靠的方法来测试一个数字是否等于 NaN，是使用内置函数 isNaN()，但即使使用 isNaN() 依然并非是一个完美的解决方案。 一个更好的解决办法是使用 value !== value，如果值等于NaN，只会产生true。另外，ES6提供了一个新的 Number.isNaN() 函数，这是一个不同的函数，并且比老的全局 isNaN() 函数更可靠。 4.下列代码将输出什么？并解释原因。 console.log(0.1 + 0.2);console.log(0.1 + 0.2 == 0.3);一个稍微有点编程基础的回答是：“你不能确定。可能会输出“0.3”和“true”，也可能不会。JavaScript中的数字和浮点精度的处理相同，因此，可能不会总是产生预期的结果。“ 以上所提供的例子就是一个演示了这个问题的典型例子。但出人意料的是，它会输出： 0.30000000000000004 false 浮点数并不准确！！！ 5.JavaScript中的“闭包”是什么？请举一个例子。 闭包是一个可以访问外部（封闭）函数作用域链中的变量的内部函数。闭包可以访问三种范围中的变量：这三个范围具体为：（1）自己范围内的变量，（2）封闭函数范围内的变量，以及（3）全局变量。 下面是一个简单的例子： var globalVar = &quot;xyz&quot;; (function outerFunc(outerArg) { var outerVar = &apos;a&apos;; (function innerFunc(innerArg) { var innerVar = &apos;b&apos;; console.log( &quot;outerArg = &quot; + outerArg + &quot;\n&quot; + &quot;innerArg = &quot; + innerArg + &quot;\n&quot; + &quot;outerVar = &quot; + outerVar + &quot;\n&quot; + &quot;innerVar = &quot; + innerVar + &quot;\n&quot; + &quot;globalVar = &quot; + globalVar); })(456); })(123); 在上面的例子中，来自于 innerFunc， outerFunc和全局命名空间的变量都在 innerFunc的范围内。因此，上面的代码将输出如下： outerArg = 123innerArg = 456outerVar = ainnerVar = bglobalVar = xyz]]></content>
  </entry>
  <entry>
    <title><![CDATA[python-hardest]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F18%2Fpython-hardest%2F</url>
    <content type="text"><![CDATA[Python社区会有如此多的人关注于这样的问题: “对于解释器全局锁能做什么?” 要理解GIL的含义，我们需要从Python的基础讲起。像C++这样的语言是编译型语言，所谓编译型语言，是指程序输入到编译器，编译器再根据语言的语法进行解析，然后翻译成语言独立的中间表示，最终链接成具有高度优化的机器码的可执行程序。编译器之所以可以深层次的对代码进行优化，是因为它可以看到整个程序（或者一大块独立的部分）。这使得它可以对不同的语言指令之间的交互进行推理，从而给出更有效的优化手段。 与此相反，Python是解释型语言。程序被输入到解释器来运行。解释器在程序执行之前对其并不了解；它所知道的只是Python的规则，以及在执行过程中怎样去动态的应用这些规则。它也有一些优化，但是这基本上只是另一个级别的优化。由于解释器没法很好的对程序进行推导，Python的大部分优化其实是解释器自身的优化。更快的解释器自然意味着程序的运行也能“免费”的更快。也就是说，解释器优化后，Python程序不用做修改就可以享受优化后的好处。 如果其他条件不变，Python程序的执行速度直接与解释器的“速度”相关。不管你怎样优化自己的程序，你的程序的执行速度还是依赖于解释器执行你的程序的效率。这就很明显的解释了为什么我们需要对优化Python解释器做这么多的工作了。对于Python程序员来说，这恐怕是与免费午餐最接近的了。 大部分开发者听到“并发”通常会立刻想到多线程的程序。目前来说，多线程执行还是利用多核系统最常用的方式。尽管多线程编程大大好于“顺序”编程，不过即便是仔细的程序员也没法在代码中将并发性做到最好。编程语言在这方面应该做的更好，大部分应用广泛的现代编程语言都会支持多线程编程。 要想利用多核系统，Python必须支持多线程运行。作为解释型语言，Python的解释器必须做到既安全又高效。我们都知道多线程编程会遇到的问题。解释器要留意的是避免在不同的线程操作内部共享的数据。同时它还要保证在管理用户线程时保证总是有最大化的计算资源。 那么，不同线程同时访问时，数据的保护机制是怎样的呢？答案是解释器全局锁。从名字上看能告诉我们很多东西，很显然，这是一个加在解释器上的全局（从解释器的角度看）锁（从互斥或者类似角度看）。这种方式当然很安全，但是它有一层隐含的意思（Python初学者需要了解这个）：对于任何Python程序，不管有多少的处理器，任何时候都总是只有一个线程在执行。 不要使用多线程，请使用多进程 基于线程的编程毫无疑问是困难的。每当某个人觉得他了解关于线程是如何工作的一切的时候，总是会悄无声息的出现一些新的问题。因为在这方面想要得到正确合理的一致性真的是太难了，因此有一些非常知名的语言设计者和研究者已经总结得出了一些线程模型。就像某个写过多线程应用的人可以告诉你的一样，不管是多线程应用的开发还是调试都会比单线程的应用难上数倍。程序员通常所具有的顺序执行的思维模恰恰就是与并行执行模式不相匹配。GIL的出现无意中帮助了开发者免于陷入困境。在使用多线程时仍然需要同步原语的情况下，GIL事实上帮助我们保持不同线程之间的数据一致性问题。 那么现在看起来讨论Python最难得问题是有点问错了问题。我们有非常好的理由来说明为什么Python专家推荐我们使用多进程代替多线程，而不是去试图隐藏Python线程实现的不足。更进一步，我们鼓励开发者使用更安全更直接的方式实现并发模型，同时保留使用多线程进行开发除非你觉的真的非常必要的话。对于大多数人来说什么是最好的并行编程模型可能并不是十分清楚。但是目前我们清楚的是多线程的方式可能并不是最好的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ai-keyword]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F16%2Fai-keyword%2F</url>
    <content type="text"><![CDATA[深度学习 进化策略 迁移学习 卷积神经网络 知识图谱 聚类 回归 PCA t-SNE 贝叶斯 决策树 随机森林 遗传算法 强化学习 马尔科夫 概率图 什么是深度学习？深度学习是表征学习的通用框架，它有以下特征： 给定一个目标（objective） 学习能够实现目标的特征 直接的原始输入 使用最少的领域知识深度 深度学习是一项实现机器学习的技术。它仅仅是一种机器学习的方法。 深度神经网络通常被人们用来理解深度表征。 循环神经网络 RNN 卷积神经网络 CNN 工作方式： 选择数据： 训练 验证 测试 模型数据 验证模型 测试模型 使用模型 调优模型 机器学习所处在的位置： 数据科学家使用训练数据集来教计算机应该怎么做， 然后系统执行该任务 首先存在大数据 机器会学习使用训练数据集来进行分类，调节特定的算法来实现目标分类 该计算机可学习识别数据中的关系、趋势和模式 如何使用？ 快速三维地图测绘和建模 增强分析以降低风险 预测表现最佳的目标 九大算法 决策树 在进行逐步应答过程中，典型的决策树分析会使用分层变量或决策节点，例如，可将一个给定用户分类成信用可靠或不可靠 支持向量机 回归 朴素贝叶斯分类 隐马尔可夫模型 随机森林 循环神经网络 长短期记忆与门控循环单元神经网络 卷积神经网络]]></content>
      <categories>
        <category>AI</category>
      </categories>
      <tags>
        <tag>deep learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[artificial intelligence]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F15%2Fartificial-intelligence%2F</url>
    <content type="text"><![CDATA[面向对象编程 函数式编程 了解CNN RCNN 主流人工智能平台 熟悉一个 比如 keras 会要求手写至少一个算法实现。。 数据库 mysql 优化设计 django 登陆 详细源码！！]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[inner-strength]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F12%2Finner-strength%2F</url>
    <content type="text"><![CDATA[从尊敬一事无成的自己开始尊敬自己 才能拥有改变的力量 别在疲惫不堪时反省自己 乐于付出才能得到最纯粹的喜悦 喜悦永远不嫌多]]></content>
  </entry>
  <entry>
    <title><![CDATA[diverting-python]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F10%2Fdiverting-python%2F</url>
    <content type="text"><![CDATA[有趣的python 廖雪峰老师的 app awesome-python-app 社区系统 Minos 北京公交 beijing_bus 螺壳网 luokr.com 种子搜索网站 ssbc 在线音乐网站 listen1 小代码合集 python-gems 算法课程 algorithm 分词器 python-goose 过滤敏感词 https://github.com/observerss/textfilter 社区项目 基于tornado mongodb https://github.com/shiyanhui/Young 模拟登陆 https://github.com/xchaoinfo/fuck-login flask 论坛 https://github.com/sh4nks/flaskbb 数据探索平台 https://github.com/apache/incubator-superset python-sdk https://github.com/qiniu/python-sdk flask-admin https://github.com/flask-admin/flask-admin python-guide https://github.com/kennethreitz/python-guide mincss https://github.com/peterbe/mincss pymysql 纯 Pyton 写的 MySQL 库，纯 Python 的好处就是可以运行在任何装有 Python 解释器（CPython、PyPy、IronPython）的平台上。 https://github.com/PyMySQL/PyMySQL 系统情况监测 https://github.com/nicolargo/glances]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github-markdown]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F10%2Fgithub-markdown%2F</url>
    <content type="text"><![CDATA[可能是不同编辑器的缘故，有时在macdown 下写的md 文件 再使用subl 编辑器之后 没法正常的显示格式。因此在此 总结一番 github md 语法。 标题 # 代表级别 加粗 加粗 斜体 斜体 删除线 删除线 （？？） 引用 下面是一个引用： 大家好！我是一个引用。 代码引用 我需要引用一段代码： int a = 1; int b = 2; int c = a+b; 链接 链接到百度 图片 列表 主列表1 主列表2 次列表1 次列表2 主列表3 忽略关键字 **取消Markdown关键字]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[about-python-0]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F08%2Fabout-python-0%2F</url>
    <content type="text"><![CDATA[python应用的方方面面-0-Djangomodel 的继承 抽象继承 12345678910111213141516171819class Animal(models.Model): name = models.CharField(max_length=50) age = models.PositiveIntegerField() # 下面这句决定了Animal是一个抽象类/Model class Meta: abstract = True class Human(Animal): kind_hearted = models.BooleanField() sex = models.CharField('sex', choices=(('m','male'), ('f', 'female')), max_length=1) #...``` ****+ 正常继承和抽象继承的主要区别是父类这时也可以拥有数据库表了，并且不在身为存储公共信息的抽象类了，父类也可以进行实例化，查询等操作了。 class Country(models.Model): name = models.CharField(max_length=10) #... class Province(Country): return = models.BooleanField() #... 123456****+ 代理在子类中只能增加方法，而不能增加属性，在不影响父类数据存储的前提下，使子类继承父类，此时子类称为父类的“代理”。 from django.contrib.auth.models import User class Person(User): # this makes a class proxy proxy = True def can_dance(self): return True both Yellow and Black can_dance :)class Yellow(Person): hometown = models.CharField(max_length=30) class Black(Person) tribe_name = models.CharField(max_length=100) 12345678910****## django Q 对象在进行相对复杂的查询时，使用django.db.models.Q对象```sqlSELECT * FROM order WHERE id BETWEEN 20 ADN 100 AND(num &lt;= &apos;20&apos; or num &gt;= &apos;30&apos;); 可以改写为 1234567from django.db.models import Qfrom login.models import Order#...Order.objects.get(Q(id &gt;= 20) &amp; (id &lt;= 100),Q(num &lt;= 20) | (num &gt;= 30)) 验证表单提交格式是否正确 使用哪个函数？is_valid() # 函数方法，用于检查表单提交是否正确 取消级连删除user = models.ForeignKey(User, blank=True, null=True, on_delete=models.SET_NULL) 并且SET_NULL只有在null为True的时候，才可以使用 django 在 model 保存前做一定的固定操作1234567891011121314151617import loggingfrom django.db import modelsfrom django.db.models.signals import pre_savefrom django.dispatch import receiver class Order(models.Model): # ... logger = logging.getLogger(__name__) @receiver(pre_save, sender=Order)def pre_save_handler(sender, **kwargs): # 我们可以在Order这个Model保存之前尽情调戏了：） logger.debug(&quot;&#123;&#125;,&#123;&#125;&quot;.format(sender, **kwargs)) print &apos;fuck universe&apos; django session说到session的运行机制，就一定要先说一下cookie这一段信息。一般情况下cookies都是我们的浏览器生成的（显然可以人为修改），用于服务器对户进行筛选和维护，但是这个听上去很好吃的东西，能存的东西有点少而且容易被别人利用。这时候基于cookies的session的意义就比较明显了，在客户端的cookies中我们只保存session id，而将完整信息以加密信息的形式保存到服务器端，这样服务器可以根据session id相对安全的在数据库中查询用户的更细致的信息和状态。在Django中session和cookies的操作方法一样，如下： 1234567# 保存sessionrequest.session[&apos;order_id&apos;] = order_id# 删除sessiondel request.session[&apos;order_id&apos;]# 读取sessionsession.get(&apos;order_id&apos;, False)]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[aes 256]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F02%2F06%2Faes-256%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819import base64from Crypto.Cipher import AESfrom Crypto import Randomclass AESCipher: def __init__( self, key ): self.key = key def encrypt( self, raw ): raw = pad(raw) iv = Random.new().read( AES.block_size ) cipher = AES.new( self.key, AES.MODE_CBC, iv ) return base64.b64encode( iv + cipher.encrypt( raw ) ) def decrypt( self, enc ): enc = base64.b64decode(enc) iv = enc[:16] cipher = AES.new(self.key, AES.MODE_CBC, iv ) return unpad(cipher.decrypt( enc[16:] ))]]></content>
      <categories>
        <category>jiami</category>
      </categories>
      <tags>
        <tag>aes256</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux test]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F01%2F20%2Flinux-test%2F</url>
    <content type="text"><![CDATA[cron 后台常驻程序 daemon 用于 管理系统日常任务的调度 块设备 硬盘 一次显示一页内容 more 当前目录下还有多大的空间 du . 更改文件的权限设置 chmod 需要找出/etc/my.conf 文件属于哪个包执行什么命令 假如当前系统是在 level 3 运行 怎么样不重启可以切换到 level 5 运行 用于改变ide 硬盘的设置 列出定义在以后特定时间运行一次的所有任务 命令的作用 作为一个管理员你希望在每一个新用户的目录下放一个文件 那么你应该在哪个目录下放这个文件 以便新用户创建主目录时自动将这个文件复制到自己的目录下 export 的作用是什么 在使用了 shadow 口令的系统中 /ect/passwd /etc/shadow 两个文件的权限正确的是 删除一个用户的同时删除用户的主目录 crontab 使用 卸载一个已装载的文件系统 umask 设置为022 缺省的创建文件的权限为 查找一个二进制命令 Xconfigurator 装载所有在 /etc/fstab 中定义的文件系统 运行一个脚本 用户不需要什么样的权限 选择题目 21．在Linux中，如何标识接在IDE0上的slave硬盘的第2个扩展分区？A. /dev/hdb2B. /dev/hd1b2C. /dev/hdb6D. /dev/hd1b6 22．在应用程序起动时，如何设置进程的优先级？A. priorityB. niceC. reniceD. setpri 23．在 bash 中, 在一条命令后加入”1&gt;&amp;2” 意味着：A. 标准错误输出重定向到标准输入B. 标准输入重定向到标准错误输出C. 标准输出重定向到标准错误输出D. 标准输出重定向到标准输入 24．下面哪条命令可以把f1.txt复制为f2.txt?A. cp f1.txt | f2.txtB. cat f1.txt | f2.txtC. cat f1.txt &gt; f2.txtD. copy f1.txt | f2.txt 25．显示一个文件最后几行的命令是：A. tacB. tailC. rearD. last 26.如何快速切换到用户John的主目录下？A. cd @JohnB. cd #JohnC. cd &amp;JohnD. cd ~John 27.把一个流中所有字符转换成大写字符，可以使用下面哪个命令？A. tr a-z A-ZB. tac a-z A-ZC.sed /a-z/A-ZD. sed –toupper 28.使用什么命令可以查看Linux的启动信息？A. mesg -dB. dmesgC. cat /etc/mesgD. cat /var/mesg 29.运行级定义在：A. in the kernelB. in /etc/inittabC. in /etc/runlevelsD. using the rl command 30.如何装载(mount)上在 /etc/fstab 文件中定义的所有文件系统？A. mount -aB. mount /mnt/*C. mountD. mount /etc/fstab 31.使用ln命令将生成了一个指向文件old的符号链接new，如果你将文件old删除，是否还能够访问文件中的数据？A. 不可能再访问B. 仍然可以访问C. 能否访问取决于文件的所有者D. 能否访问取决于文件的权限 32.xt2fs文件系统中，缺省的为root用户保留多大的空间？A. 3%B. 5%C. 10%D. 15% 33.哪个命令用来显示系统中各个分区中inode的使用情况？A. df -iB. df -HC. free -bD. du -a -c / 34.多数Linux发行版本中，图形方式的运行级定义为？A. 1B. 2C. 3D. 5 35.在系统文档中找到关于print这个单词的所有说明？A. man printB. which printC. locate printD. apropos print 36.man 5 passwd 含义是？A. 显示 passwd 命令的使用方法B. 显示 passwd 文件的结构C. 显示 passwd 命令的说明的前五行D. 显示关于passwd的前五处说明文档。 37.如何在文件中查找显示所有以”“打头的行？A. find \ fileB. wc -l &lt; fileC. grep -n fileD. grep ‘^*’ file 38.在ps命令中什么参数是用来显示所有用户的进程的？A. aB. bC. uD. x 39.显示二进制文件的命令是？A. odB. vilC. viewD. binview 40.如何显示Linux系统中注册的用户数（包含系统用户）？A. account -lB. nl /etc/passwd |headC. wc –users /etc/passwdD. wc –lines /etc/passwd 41.在一行结束位置加上什么符号，表示未结束，下一行继续？A. /B. \C. ;D. | 42.命令 kill 9 的含义是：A. kills the process whose PID is 9.B. kills all processes belonging to UID 9.C. sends SIGKILL to the process whose PID is 9.D. sends SIGTERM to the process whose PID IS 9. 43.如何删除一个非空子目录/tmp？A. del /tmp/B. rm -rf /tmpC. rm -Ra /tmp/D. rm -rf /tmp/* 44.使用什么命令可以在今天午夜运行命令 cmd1 ？A. at midnight cmd1B. cron -at “00:00” cmd1C. batch -t “00:00” &lt; cmd1D. echo “cmd1” | at midnight 45.你的系统使用增量备份策略，当需要恢复系统时，你需要按什么顺序恢复备份数据？A. 最后一次全备份，然后从最早到最近的增量备份B. 最后一次全备份，然后从最近到最早的增量备份C. 最早到最近的增量备份，然后最后一次全备份D. 最近到最早的增量备份，然后最后一次全备份 46.对所有用户的变量设置，应当放在哪个文件下？A. /etc/bashrcB. /etc/profileC. ~/.bash_profileD. /etc/skel/.bashrc 47.Linux系统中，一般把命令 ls 定义为 ls –color 的别名，以便以不同颜色来标识不同类型的文件。但是，如何能够使用原先的ls命令？A. \lsB. ;lsC. ls $$D. ls –noalias 48.在Linux系统中的脚本文件一般以什么开头？A. $/bin/shB. #!/bin/shC. use /bin/shD. set shell=/bin/sh 49.下面哪种写法表示如果cmd1成功执行，则执行cmd2命令？A. cmd1&amp;&amp;cmd2B. cmd1|cmd2C. cmd1;cmd2D. cmd1||cmd2 50.在哪个文件中定义网卡的I/O地址？A. cat /proc/modulesB. cat /proc/devicesC. cat /proc/ioportsD. cat /io/dma 51.Linux中，提供TCP/IP包过滤功能的软件叫什么？A. rarpB. routeC. iptablesD. filter 52.如何暂停一个打印队列？A. lprB. lpqC. lpcD. lpd 53.在vi中退出不保存的命令是？A. :qB. :wC. :wqD. :q! 54.在 XFree86 3.x 中, 缺省的字体服务器为：A. xfsB. xfservC. fontsD. xfstt 55.使用什么命令检测基本网络连接？A. pingB. routeC. netstatD. ifconfig 56.下面哪个协议使用了二个以上的端口？A. telnetB. FTPC. rshD. HTTP 57.在PPP协议中，哪个认证协议不以明文传递密码？A. PAMB. PAPC. PGPD. CHAP 58.下面哪个文件系统应该分配最大的空间？A. /usrB. /libC. /rootD. /bin 59.如何在Debian系统中安装rpm包？A. alien pkgname.rpmB. dpkg –rpm pkgname.rpmC. dpkg –alien pkgname.rpmD. alien pkganme.rpm ; dpkg -i pkganme.deb 60.在安装软件时下面哪一步需要root权限？A. makeB. make depsC. make configD. make install 61.什么命令用来只更新已经安装过的rpm软件包？A. rpm -U .rpmB. rpm -F .rpmC. rpm -e .rpmD. rpm -q .rpm 62.在 windows 与 Linux 双起动的系统中，如果要让LILO 管理引导，则 LILO 应该放在：A. MBRB. /C. root分区的首扇区D. /LILO 63.ldconfig的配置文件是A. /lib/ld.soB. /etc/ld.so.confC. /etc/ld.so.cacheD. /etc/modules.conf 64.下面哪个命令可以压缩部分文件：A. tar -dzvf filename.tgz B. tar -tzvf filename.tgz C. tar -czvf filename.tgz D. tar -xzvf filename.tgz 65.网络服务的daemon是：A. lpdB. netdC. httpdD. inetd 66.Linux与windows 的网上领居互联，需要提供什么daemon?A. bindB. smbdC. nmbdD. shard 67.对于Apache服务器，提供的子进程的缺省的用户是：A. rootB. apachedC. httpdD. nobody 68.sendmail中缺省的未发出信件的存放位置是：A. /var/mail/B. /var/spool/mail/C. /var/spool/mqueue/D. /var/mail/deliver/ 69.apache的主配置文件是：A. httpd.confB. httpd.cfgC. access.cfgD. apache.conf 70.关于可装载的模块，装载时的参数，如I/O地址等的存放位置是：A. /etc/conf.modulesB. /etc/lilo.confC. /boot/System.mapD. /etc/sysconfig 71.在 Linux 中，如何关闭邮件提示？A. biff nB. mesg nC. notify offD. set notify=off 72.在 bash shell 环境下，当一命令正在执行时，按下 control-Z 会：A. 中止前台任务B. 给当前文件加上 EOF.C. 将前台任务转入后台D. 注销当前用户 73.定义bash环境的用户文件是：A. bash &amp; .bashrcB. bashrc &amp; .bash_confC. bashrc &amp; bash_profileD. .bashrc &amp; .bash_profile 74.下面哪条命令用来显示一个程序所使用的库文件？A. lddB. ld soC. modprobeD. ldconfig 75.如何查看一个RPM软件的配置文件的存放位置？A. rpm -qc rpm1B. rpm -Vc rpm1C. rpm –config rpm1D. rpm -qa –config rpm1 76.如何查看一个RPM软件的修改记录？A. rpm -Vc postfixB. rpm -qpil postfixC. rpm –changelog postfixD. rpm -q –changelog postfix 77.通过Makefile来安装已编译过的代码的命令是：A. makeB. installC. make dependD. make install 78.什么命令解压缩tar文件？A. tar -czvf filename.tgzB. tar -xzvf filename.tgzC. tar -tzvf filename.tgzD. tar -dzvf filename.tgz 79.在 XF86Config 配置文件中，哪个段用来设置字体文件？A. The Fonts section.B. The Files section.C. The xfsCodes section.D. The Graphics section. 80.8 bit color 指的是：A. 64K colorsB. 16K colorsC. 256 colorsD. 16M colors 81.下面哪个文件用来设置 X window 的显示分辨率？A. xinitB. xinitrcC. XF86SetupD. XF86Config 82.哪个变量用来指定一个远程X应用程序将输出放到哪个X server上？A. DISPLAYB. TERMC. ECHOD. OUTPUT 83.在xdm的配置目录中，哪个文件用来设置在用户通过xdm登录后自动起动的应用程序？A. The Xsession fileB. The Xsetup_0 fileC. The Xstart_up fileD. The GiveConsole file 84.命令 netstat -a 停了很长时间没有响应，这可能是哪里的问题？A. NFS.B. DNS.C. NIS.D. routing. 85.ping使用的协议是：A. TCPB. UDPC. SMBD. ICMP 86.下面哪个命令不是用来查看网络故障的？A. pingB. initC. telnetD. netstat 87.拨号上网使用的协议通常是：A. PPPB. UUCPC. SLIPD. Ethernet 88.TCP/IP中，哪个协议是用来进行IP自动分配的？A. ARPB. NFSC. DHCPD. DNS 89.下面哪个文件定义了网络服务的端口？A. /etc/netportB. /etc/servicesC. /etc/serverD. /etc/netconf 90.下面哪个功能用来生成一个文件的校验码？A. md5B. tarC. cryptD. md5sum 91.缺省的，用户邮件放在：A. ~/mail/B. /var/mail/C. /var/mail/spool/D. /var/spool/mail/ 92.下面哪个文件包含了供 NFS daemon 使用的目录列表？A. /etc/nfsB. /etc/nfs.confC. /etc/exportsD. /etc/netdir 93.如何停止一台机器的telnet服务？A. Put NONE in /etc/telnet.allowB. Put a line ‘ALL:ALL’ in /etc/hosts.denyC. Comment the telnet entry in /etc/inittabD. Comment the telnet entry in /etc/xinetd.conf 94.在哪个文件中保存了sendmail的别名？A. /etc/aliasesB. /etc/mailaliasesC. /etc/sendmail.aliasesD. /etc/sendmail/aliases 95.smbd and nmbddaemons 的配置文件是：A. /etc/exportsB. /etc/smb.confC. /etc/samba/configD. /usr/local/samba.cfg 96.下面哪个命令用来卸载一个内核模块？A. rmmodB. unmodC. delmodD. modprobe 97.什么情况下必须运行liloA. once a day from cronB. once a week from cronC. after installing a new kernelD. after installing a new module 98.什么命令显示所有装载的模块？A. lsmodB. dirmodC. modulesD. modlist 99.下面哪个命令刷新打印机队列？A. lpflushB. lprm -C. lpclearD. lprm all 100.下面哪个命令可以查看网卡的中断？A. cat /proc/ioportsB. cat /proc/interruptsC. cat /proc/memoryinfoD. which interrupts]]></content>
  </entry>
  <entry>
    <title><![CDATA[about python]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F01%2F18%2Fabout-python%2F</url>
    <content type="text"><![CDATA[面试前的准备工作很多都会一条一条问原理。一提到底层就尴尬！！！ 重点需要刷数据结构和算法题目。 进程管理 同步异步阻塞非阻塞等 爬虫类采集数据工作xpath 基础语法： 双斜杠 // 定位根节点 单斜杠 / 寻找当前标签路径的下一层路径标签或者对当前路径标签内容进行操作 /text() 获取当前的文本内容 /@xxx 属性值 | 可选符 可获取若干个 点 用来选取当前节点 点点 选取当前节点的父节点 web 开发工作运维运营工具类数据分析类]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mnist-keras]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F01%2F06%2Fmnist-keras%2F</url>
    <content type="text"><![CDATA[keras 训练卷积神经网络： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import numpy as npfrom keras.datasets import mnist# 引入卷积模块from keras.models import Sequentialfrom keras.layers import Dense, Dropout, Flattenfrom keras.layers.convolutional import Conv2D, MaxPooling2D# 读入数据(X_train, y_train), (X_test, y_test) = mnist.load_data()print(X_train[0].shape)print(y_train[0])# 图像是 28 * 28 的格式 标签是0-9的数字# 手写黑白字体变成四维张量形式 样本数量 长 宽 1X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')X_train /= 255X_test /= 255def tran_y(y): y_ohe = np.zeros(10) y_ohe[y] = 1 return y_ohey_train_ohe = np.array([tran_y(y_train[i]) for i in range(len(y_train))])y_test_ohe = np.array([tran_y(y_test[i]) for i in range(len(y_test))])model = Sequential()# 第一层卷积 64个过滤器 每个覆盖范围3*3*1 图像四周补0， relu进行非线性变化model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=(28, 28, 1), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))# 设立 dropout 层model.add(Dropout(0.5))model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.5))model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.5))# 当前层节点展平model.add(Flatten())# 构造全连接神经网络层model.add(Dense(128, activation='relu'))model.add(Dense(64, activation='relu'))model.add(Dense(32, activation='relu'))model.add(Dense(10, activation='softmax'))# 损失函数选择交叉熵model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])model.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe), epochs=20, batch_size=128)scores = model.evaluate(X_test, y_test_ohe, verbose=0)]]></content>
  </entry>
  <entry>
    <title><![CDATA[sanic-01]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F01%2F01%2Fsanic-01%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[sanic-00]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F01%2F01%2Fsanic-00%2F</url>
    <content type="text"><![CDATA[how to installpython3 -m pip install sanic getting_started安装完成之后 写下一个 run.py 文件 直接使用py3 运行即可 代码如下： 12345678910111213141516# run.pyfrom sanic import Sanicfrom sanic.response import textapp = Sanic(__name__)@app.route("/")async def test(request): return text("Hello tiny world!")app.run(host="0.0.0.0", port=10080, debug=True)]]></content>
  </entry>
  <entry>
    <title><![CDATA[2018-python-new]]></title>
    <url>%2Fzhangdavids.github.io%2F2018%2F01%2F01%2F2018-python-new%2F</url>
    <content type="text"><![CDATA[值得关注的 python 库 [] sanic web 开发领域 类似flask 但是更快 [] pipenv 包管理 k神新作 [] requestium 爬虫 结合了chrome的headless 无头特性 [] caffe2 深度学习框架 [] flashtext 文本处理 [] upterm 最强终端 [] pypython 交互式解释器 [] anaconda 包管理必备 [] sublime 3 编辑器 [] codesandbox 前端在线编辑器]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ten-dl-algorithm]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F12%2F30%2Ften-dl-algorithm%2F</url>
    <content type="text"><![CDATA[决策树 随机森林算法 逻辑回归 SVM 朴素贝叶斯 K最近邻 K均值 Adaboost算法 神经网络 马尔科夫]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy note]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F12%2F05%2Fscrapy-note%2F</url>
    <content type="text"><![CDATA[scrapy 总结整理]]></content>
  </entry>
  <entry>
    <title><![CDATA[tensorflow note learn ways]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F12%2F03%2Ftensorflow-note-learn-ways%2F</url>
    <content type="text"><![CDATA[机器学习是什么？？ 使用算法从原始数据中提取信息，并以某种类型的模型表示出来，然后使用这个模型来推断我们尚未建模的其他数据。 深度学习可以被定义在以下四个基本网络框架中拥有大量参数和层的神经网络： 无监督预训练网络upn 卷积神经网络cnn 循环神经网络rnn 递归神经网络rnn 卷积 基本上就是用共享权重在空间中进行扩展的标准神经网络。为了内部卷积来识别图片，内部卷积可以看到待识别物体的边。 循环神经网络 在时间上进行扩展，因为边进入下一个时间步，而不是在同一时间步进入下一个层。识别序列，例如语音或者文本。里面的循环意味着网络中存在短暂的记忆。 递归 更类似于分层网络，其中输入序列没有真正的时间面，而是输入必须以树状方式分层处理。 十种方法： 反向传播 随机梯度下降 学习率衰减 dropout max pooling 批标准化 lstm skip-gram 连续词袋 迁移学习]]></content>
  </entry>
  <entry>
    <title><![CDATA[tensorflow note how to install]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F12%2F03%2Ftensorflow-note-how-to-install%2F</url>
    <content type="text"><![CDATA[考虑到软件依赖项，依赖冲突。 单机建议用Virturalenv，分布式用Docker。 解决依赖冲突有以下方式：代码库内部的软件包依赖，依赖库放到代码中，局部引用。重复占用空间，手工更改。用户无法修改。使用依赖环境，虚拟环境。Virturalenv、Anaconda。使用容器，软件、文件系统、运行时、依赖库打包轻量级方案。典型应用有Docker。 TensorFlow需要用到两个经典库：Jupyter(iPython) Notebook、matplotlib。Jupyter Notebook可以交互式编写可视化结果文档，代码展示，Markdown单元，设计原型，代码写入逻辑块，方便调试脚本特定部分。matplotlib是绘图库，可以实现数据可视化，典型应用Seaborn。 Virtualenv环境安装 12sudo easy_install pipsudo pip install --upgrade virtualenv 创建虚拟环境目录： 1sudo mkdir ~/env 创建虚拟环境： 1virtualenv --system-site-packages ~/env/tensorflow 激活虚拟环境： 1source ~/env/tensorflow/bin/activate 关闭虚拟环境： 1deactivate 安装TensorFlow: Python 3.6: pip3 install –upgrade tensorflow 最后是把需要的whl下载下来，直接通过pip install 装本地的文件。 安装Jupyter、matplotlib 12sudo pip install jupytersudo pip install matplotlib 其中widgetsnbextension没有办法下载下来装，因为下下来的是3.0.0的，需要的是2.0.0的。 装完之后，在Jupyter上跑一个。 Test Code 123456789101112import tensorflow as tfimport numpy as npimport matplotlib.pyplot as plt%matplotlib inlinea = tf.random_normal([2,20])sess = tf.Session()out = sess.run(a)x,y = outplt.scatter(x,y)plt.show()]]></content>
  </entry>
  <entry>
    <title><![CDATA[tensorflow note 2017.12.03]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F12%2F03%2Ftensorflow-note-2017-12-03%2F</url>
    <content type="text"><![CDATA[TensorflowTensorflow既是机器学习算法实现接口，又是机器学习算法执行框架。TensorFlow的前端支持Python、C++、Go、Java等，目前推荐优先使用Python。后端使用C++、CUDA等。TensorFlow算法在异构系统方便移植，Android、iOS、CPU服务器、GPU集群等。可以实现机器学习、线性回归、逻辑回归、随机森林等算法。在语音识别、自然语言处理、计算机视觉、机器人控制、信息抽取、药物研发、分子活动预测等方面应用广泛。 TensorFlow方便设计神经网络结构。 不必写C++、CUDA。自动求导。 C++核心方便线上部署。支持低配置嵌入式设备。通过SWIG添加其他脚本支持。 每个mini-batch要从Python feed到网络，延迟大。 内置TF.lean、TF.Slim快速设计网络。兼容scikit-lean estimator接口，实现evaluate、grid、search、cross、validation等功能。 自动将分支转为子图。灵活移值，轻易部署任意数量设备。编译快。 TensorBoard可视化网络结构、过程。支持常见网络结构（卷积神经网络CNN，循环神经网络RNN）、深度强化学习、计算密集科学计算等。 缺点，计算图必须为静态图。异构支持各种硬件和操作系统。框架分布式性能是关键。TensorFlow 单机reduction只能用CPU，分布式通信使用socket RPC,不是RDMA，待优化。TensorFlow Serving 组件可导出训练好的模型，部署成对外提供预测是服务RESTful接口。实现应用机器学习全流程，训练模型、调试参数、打包模型、部署服务。 TensorBoard，监控运行过程关键指标，支持标量、图片、直方图、计算图可视化。]]></content>
  </entry>
  <entry>
    <title><![CDATA[javascript foundation]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F29%2Fjavascript-foundation%2F</url>
    <content type="text"><![CDATA[js的分层 jquery tool组件 ui应用 appmvc backboneJS js的规划 避免全局变量和方法（命名空间 闭包 面向对象） 模块化 常用内部类:Data Array Math String HTML属性，CSS属性HTML：属性.HTML属性=”值”；CSS：对象.style.CSS属性=”值”; class和float 1.class:className2.float:cssFloat 获取对象 id:document.getElementById(“id 名”) 事件:用户的动作 鼠标事件：onclick：点击onmouseover: 鼠标放上onmouseout:鼠标离开ondbclick:双击事件onmousedown:鼠标按下onmouseup:鼠标抬起onmousemove鼠标移动 表单事件：onfocus:获取焦点onblur:失去焦点onsubmit:提交事件onchange:当发生改变的时候onreset:重置事件 键盘事件:onkeyup:键盘抬起onkeydown:键盘按下onkeypress:键盘按键一次窗口时间:onload事件]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy middleware]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F28%2Fscrapy-middleware%2F</url>
    <content type="text"><![CDATA[scrapy 常用的中间件 总结 名称 功能 retry 重试可能由于临时问题引起的超时问题 cookie 该中间件使得爬取需要cookie(例如使用session)的网站成为了可能。 其追踪了web server发送的cookie，并在之后的request中发送回去， 就如浏览器所做的那样。 DefaultHeadersMiddleware 头设置为默认模式 downloadtimeout 设置超时 httpauth 对来自特定spider的request授权 httpcache 給request&amp;response设置缓存策略 httpproxy 給所有request设置http代理 redirect 重定向 metarefresh 根据meta-refresh html tag处理重定向 robotsTxt robots封禁处理]]></content>
  </entry>
  <entry>
    <title><![CDATA[cookie and session]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F28%2Fcookie-and-session%2F</url>
    <content type="text"><![CDATA[Cookie和Session 由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车，当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的，使用一些缓存服务比如Memcached之类的来放 Session 思考一下服务端如何识别特定的客户？这个时候Cookie就登场了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用 Cookie 来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。有人问，如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户 Cookie其实还可以用在一些方便用户的场景下，设想你某次登陆过一个网站，下次登录的时候不想再次输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名给填了，能够方便一下用户。这也是Cookie名称的由来，给用户的一点甜头。 所以，总结一下： Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中； Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式 生产环境下，nginx将请求分发给多个后端uwsgi进程，而不是线程... 开发服务器runserver从1.4开始就是单进程多线程的了。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js-foundation]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F27%2Fjs-foundation%2F</url>
    <content type="text"><![CDATA[1.javascript 的数据类型都有哪些？ null 表示“没有对象”，即该处不应该有值。（1） 作为函数的参数，表示该函数的参数不是对象。（2） 作为对象原型链的终点。 Object.getPrototypeOf(Object.prototype)// null 获取元素时，如果当前文档中特定元素不存在则返回null. undefined表示”缺少值”，就是此处应该有一个值，但是还没有定义。典型用法是：（1）变量被声明了，但没有赋值时，就等于undefined。（2) 调用函数时，应该提供的参数没有提供，该参数等于undefined。（3）对象没有赋值的属性，该属性的值为undefined。（4）函数没有返回值时，默认返回undefined。 引用数据类型：Object(Array,Date,RegExp,Function) 数组数据类型： function isArrayFn(value){ if (typeof Array.isArray === &quot;function&quot;) { return Array.isArray(value); }else{ return Object.prototype.toString.call(value) === &quot;[object Array]&quot;; } } 2.已知ID的Input输入框，希望获取这个输入框的输入值，怎么做？(不使用第三方框架) document.getElementById(“ID”).value 3.希望获取到页面中所有的checkbox怎么做？(不使用第三方框架) var domList = document.getElementsByTagName(‘input’) var checkBoxList = []; var len = domList.length; //缓存到局部变量 while (len--) { //使用while的效率会比for循环更高 if (domList[len].type == ‘checkbox’) { checkBoxList.push(domList[len]); } } 4.设置一个已知ID的DIV的html内容为xxxx，字体颜色设置为黑色(不使用第三方框架) var dom = document.getElementById(“ID”); dom.innerHTML = “xxxx”; dom.style.color = “#000”;]]></content>
  </entry>
  <entry>
    <title><![CDATA[django-template-3]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F27%2Fdjango-template-3%2F</url>
    <content type="text"><![CDATA[标签 标签的形式是： 标签要比变量复杂 标签的作用 在输出时创建一些文本 通过执行循环和一些逻辑来实现控制流 装载一些外部信息进入模板 内建标签 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204autoescape 使用形式： &#123;% autoescape off %&#125; (内容) &#123;% endautoescape %&#125; 意义：当某块内容不需要自动转义的时候，这样写就可以了。当然如果块内某些地方需要转义的话，调用filter也可以。block 使用形式： &#123;% block %&#125; (定义块内容) &#123;% endblock %&#125; 意义：定义一个块，该块能够被继承他的子孙模板重写 comment 使用形式： &#123;% comment %&#125; (内容) &#123;% endcomment %&#125; 意义：模板系统会忽略该标签内部的所有内容。 cycle 使用形式： 例如: &lt;tr class=&quot;&#123;% cycle list%&#125;&quot;&gt; ... &lt;/tr&gt; 意义：在循环时轮流使用给定的字符串列表中的值。 extends 使用形式：&#123;% extends &quot;base.html&quot; %&#125;或者&#123;% extends variable %&#125;变量可以是一个字符串，也可以是一个模板对象。 意义：表示本模板要对指定的父模板进行扩展。 filter 使用形式： &#123;%filter force_escape|lower%&#125; (内容) &#123;%endfilter%&#125; 意义：将filter 标签圈定的内容执行过滤器操作。 firstof 使用形式：&#123;%firstof var1 var2 var3%&#125; 意义：输出第一个值不等于False的变量 等价于： &#123;% if var1 %&#125; &#123;&#123; var1 &#125;&#125; &#123;% else %&#125; &#123;% if var2 %&#125; &#123;&#123; var2 &#125;&#125; &#123;% else %&#125; &#123;% if var3 %&#125; &#123;&#123; var3 &#125;&#125; &#123;% endif %&#125; &#123;% endif %&#125; &#123;% endif %&#125; for 使用形式： &#123;% for variable in list/dict %&#125; (使用variable) &#123;% endfor%&#125; 意义：循环list中的每个值，进行相应的输出 注意： (a)也可以反向遍历&#123;% for variable in list/dict reversed %&#125; (b)也可以&#123;% for x, y in points %&#125; points中的每个元素为 (x,y) (c)也可以&#123;% for key,value in data.items %&#125; data是一个dictionary for loop中定义的一些内建变量 forloop.counter 当前的迭代器数目(从1开始) forloop.counter0 当前的迭代器数目(从0开始) forloop.revcounter 当前的反向迭代器数目(从1开始) forloop.revcounter0 当前的反向迭代器数目(从0开始) forloop.first 值为True，如果是第一次通过迭代器 forloop.last 值为True，如果是最后一次通过迭代器 forloop.parentloop 对于嵌套循环，这是当前循环的上一层循环 for ... empty 使用形式如下： &#123;% for varibale in list %&#125; (内容1) &#123;% empty %&#125; (内容2) &#123;% endfor %&#125; 意义：当list是空的时候，能够执行内容2，其形式等同于，先if判断list是否存在，然后在根据情况做什么操作。 if 使用形式如下 ： &#123;% if variable %&#125; (内容1) &#123;% else %&#125; (内容2) &#123;% endif %&#125; 注意：variable中可以使用and or 或者not，但是有一条必须记住，就是不允许and 和 or一起使用 ifchanged 使用形式： (a)如果直接检测循环变量是否变化，那么使用： &#123;% ifchanged %&#125; (内容) &#123;% endifchanged %&#125; (b)如果检测循环变量的某个dot变量，例如循环变量是date，那么检测date.hour，那么使用： &#123;% ifchanged date.hour %&#125; (内容) &#123;% endifchanged %&#125; (c)ifchanged也可以加上一个&#123;% else %&#125;语句 意义：检测本次循环的值和上一次循环的值一样不一样，只能用在循环里面。 ifequal 使用形式： &#123;% ifequal variable1 variable2 %&#125; ... &#123;% endifequal %&#125; 意义：判断两个变量是否相等。 ifnotequal使用与(12)相同 include 使用形式：&#123;% include &quot;foo/bar.html&quot; %&#125;或者&#123;% include template_name %&#125; 意义：将另外一个模板文件中的内容添加到该文件中。注意区别extend是继承。 now 使用形式：&#123;% now &quot;jS F Y H:i &quot;%&#125;，注意存在需要转义的情况例如&#123;% now &quot;jS o\f F&quot; %&#125;，因为f是格式化字符串 具体的格式化字符串如下所示 a &apos;a.m.&apos; or &apos;p.m.&apos; (Note that this is slightly different than PHP&apos;s output, because this includes periods to match Associated Press style.) &apos;a.m.&apos;A &apos;AM&apos; or &apos;PM&apos;. &apos;AM&apos;b Month, textual, 3 letters, lowercase. &apos;jan&apos;B Not implemented. d Day of the month, 2 digits with leading zeros. &apos;01&apos; to &apos;31&apos;D Day of the week, textual, 3 letters. &apos;Fri&apos;f Time, in 12-hour hours and minutes, with minutes left off if they&apos;re zero. Proprietary extension. &apos;1&apos;, &apos;1:30&apos;F Month, textual, long. &apos;January&apos;g Hour, 12-hour format without leading zeros. &apos;1&apos; to &apos;12&apos;G Hour, 24-hour format without leading zeros. &apos;0&apos; to &apos;23&apos;h Hour, 12-hour format. &apos;01&apos; to &apos;12&apos;H Hour, 24-hour format. &apos;00&apos; to &apos;23&apos;i Minutes. &apos;00&apos; to &apos;59&apos;I Not implemented. j Day of the month without leading zeros. &apos;1&apos; to &apos;31&apos;l Day of the week, textual, long. &apos;Friday&apos;L Boolean for whether it&apos;s a leap year. True or Falsem Month, 2 digits with leading zeros. &apos;01&apos; to &apos;12&apos;M Month, textual, 3 letters. &apos;Jan&apos;n Month without leading zeros. &apos;1&apos; to &apos;12&apos;N Month abbreviation in Associated Press style. Proprietary extension. &apos;Jan.&apos;, &apos;Feb.&apos;, &apos;March&apos;, &apos;May&apos;O Difference to Greenwich time in hours. &apos;+0200&apos;P Time, in 12-hour hours, minutes and &apos;a.m.&apos;/&apos;p.m.&apos;, with minutes left off if they&apos;re zero and the special-case strings &apos;midnight&apos; and &apos;noon&apos; if appropriate. Proprietary extension. &apos;1 a.m.&apos;, &apos;1:30 p.m.&apos;, &apos;midnight&apos;, &apos;noon&apos;, &apos;12:30 p.m.&apos;r RFC 2822 formatted date. &apos;Thu, 21 Dec 2000 16:01:07 +0200&apos;s Seconds, 2 digits with leading zeros. &apos;00&apos; to &apos;59&apos;S English ordinal suffix for day of the month, 2 characters. &apos;st&apos;, &apos;nd&apos;, &apos;rd&apos; or &apos;th&apos;t Number of days in the given month. 28 to 31T Time zone of this machine. &apos;EST&apos;, &apos;MDT&apos;U Not implemented. w Day of the week, digits without leading zeros. &apos;0&apos; (Sunday) to &apos;6&apos; (Saturday)W ISO-8601 week number of year, with weeks starting on Monday. 1, 53y Year, 2 digits. &apos;99&apos;Y Year, 4 digits. &apos;1999&apos;z Day of the year. 0 to 365Z Time zone offset in seconds. The offset for timezones west of UTC is always negative, and for those east of UTC is always positive. spaceless 使用形式：&#123;% spaceless %&#125; (内容) &#123;% endspaceless %&#125; 意义：删除包围内容中的所有tab或者回车字符。 template 使用形式：&#123;% templatetag %&#125; 意义：模板系统本身没有转义的概念，因此如果要输出一个像“&#123;%”这样的东东，就需要采用这种方式，否则就会语法错误 其参数有： openblock &#123;%closeblock %&#125; openvariable &#123;&#123;closevariable &#125;&#125; openbrace &#123;closebrace &#125; opencomment &#123;#closecomment #&#125;with 使用形式： &#123;% with &quot;expensive var1&quot; as var2 %&#125; &#123;% endwith %&#125; 意义：当一个变量的访问消耗很大的模板解析时，可以用另外一个变量替换它，这种替换只有在with内部有效。 url 使用形式：&#123;% url path.to.some_view arg1,arg2 %&#125; 意义：给定某个module中函数的名字，给定参数，那么模板引擎给你一个URL，从而避免硬编码URL到代码中 注意：前提是URLconf中存在相应的映射,如果URLconf中没有该映射，那么会抛出异常， 这是可以选择使用 &#123;% url path.to.view arg1 ,arg2 as the url %&#125; &lt;a href=&quot;&#123;&#123; the_url &#125;&#125;&quot;&gt;Link to optional stuff&lt;/a&gt; 其实这相当于 &#123;% url path.to.view as the\_url %&#125; &#123;% if the_url %&#125; &lt;a href=&quot;&#123;&#123; the_url &#125;&#125;&quot;&gt;Link to optional stuff&lt;/a&gt; &#123;% endif %&#125;]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-template-2]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F27%2Fdjango-template-2%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django template]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F26%2Fdjango-template%2F</url>
    <content type="text"><![CDATA[django_template 知识点总结模板有三个知识点 变量标签过滤器 变量 变量的形式是：， 当模板引擎碰到变量的时候，引擎使用变量的值代替变量。 使用dot(.)能够访问变量的属性 当模板引擎碰到dot的时候，查找的顺序是什么样子呢？ 字典查找，例如：foo[“var1”] 属性查找，例如：foo.bar 方法查找，例如：foo.bar() list-index查找，例如：foo[bar] 注意：方法查找比一般的查找要复杂一些(1)如果调用方法期间，方法抛出一个异常，那么异常将会产生，除非异常对象带有一个属性silent_variable_failure，如果这个值是True，那么将会返回一个空字串。(2)方法调用仅仅对那些没有参数的方法才会生效(3)一些方法会产生副作用，所以系统允许方法设置一个属性alters_data，如果值为True，那么将不能够调用其设置方法是： 12345def sensitive_function(self): *** sensitive_function.alters_data = True 如果模板中使用的某个变量不存在，那么模板系统将使用setting.py中 变量TEMPLATE_STRING_IF_INVALID的值进行替代，在默认情况下，该变量的值是’’。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[multiprocessing]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F23%2Fmultiprocessing%2F</url>
    <content type="text"><![CDATA[进程 线程 协程python网络编程的两大必学模块socket和socketserver，其中的socketserver是一个支持IO多路复用和多线程、多进程的模块。一般我们在socketserver服务端代码中都会写这么一句： server = socketserver.ThreadingTCPServer(settings.IP_PORT, MyServer) ThreadingTCPServer这个类是一个支持多线程和TCP协议的socketserver，它的继承关系是这样的： class ThreadingTCPServer(ThreadingMixIn, TCPServer): pass 右边的TCPServer实际上是它主要的功能父类，而左边的ThreadingMixIn则是实现了多线程的类，它自己本身则没有任何代码。MixIn在python的类命名中，很常见，一般被称为“混入”，戏称“乱入”，通常为了某种重要功能被子类继承。 123456789101112131415161718class ThreadingMixIn: daemon_threads = False def process_request_thread(self, request, client_address): try: self.finish_request(request, client_address) self.shutdown_request(request) except: self.handle_error(request, client_address) self.shutdown_request(request) def process_request(self, request, client_address): t = threading.Thread(target = self.process_request_thread, args = (request, client_address)) t.daemon = self.daemon_threads t.start() 在ThreadingMixIn类中，其实就定义了一个属性，两个方法。在process_request方法中实际调用的正是python内置的多线程模块threading。这个模块是python中所有多线程的基础，socketserver本质上也是利用了这个模块。 1. thread线程，有时被称为轻量级进程(Lightweight Process，LWP），是程序执行流的最小单元。一个标准的线程由线程ID，当前指令指针(PC），寄存器集合和堆栈组成。另外，线程是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不独立拥有系统资源，但它可与同属一个进程的其它线程共享该进程所拥有的全部资源。一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。线程也有就绪、阻塞和运行三种基本状态。就绪状态是指线程具备运行的所有条件，逻辑上可以运行，在等待处理机；运行状态是指线程占有处理机正在运行；阻塞状态是指线程在等待一个事件（如某个信号量），逻辑上不可执行。每一个应用程序都至少有一个进程和一个线程。线程是程序中一个单一的顺序控制流程。在单个程序中同时运行多个线程完成不同的被划分成一块一块的工作，称为多线程。 以上那一段，可以不用看！举个例子，厂家要生产某个产品，在它的生产基地建设了很多厂房，每个厂房内又有多条流水生产线。所有厂房配合将整个产品生产出来，某个厂房内的所有流水线将这个厂房负责的产品部分生产出来。每个厂房拥有自己的材料库，厂房内的生产线共享这些材料。而每一个厂家要实现生产必须拥有至少一个厂房一条生产线。那么这个厂家就是某个应用程序；每个厂房就是一个进程；每条生产线都是一个线程。 python 主要是 threading 库 普通的多线程 123456789101112import threadingimport time def show(arg): time.sleep(1) print(&apos;thread&apos;+str(arg)) for i in range(10): t = threading.Thread(target=show, args=(i,)) t.start() print(&apos;main thread stop&apos;) 上述代码创建了10个“前台”线程，然后控制器就交给了CPU，CPU根据指定算法进行调度，分片执行指令。下面是Thread类的主要方法： start 线程准备就绪，等待CPU调度 setName 为线程设置名称 getName 获取线程名称 setDaemon 设置为后台线程或前台线程（默认是False，前台线程）如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止。如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程也执行完成后，程序停止。 join 该方法非常重要。它的存在是告诉主线程，必须在这个位置等待子线程执行完毕后，才继续进行主线程的后面的代码。但是当setDaemon为True时，join方法是无效的。 run 线程被cpu调度后自动执行线程对象的run方法 python的GIL，也就是全局解释器锁。在编程语言的世界，python因为GIL的问题广受诟病，因为它在解释器的层面限制了程序在同一时间只有一个线程被CPU实际执行，而不管你的程序里实际开了多少条线程。所以我们经常能发现，python中的多线程编程有时候效率还不如单线程，就是因为这个原因。那么，对于这个GIL，一些普遍的问题如下： 为什么有 GIL 作为解释型语言，Python的解释器必须做到既安全又高效。我们都知道多线程编程会遇到的问题。解释器要留意的是避免在不同的线程操作内部共享的数据。同时它还要保证在管理用户线程时总是有最大化的计算资源。那么，不同线程同时访问时，数据的保护机制是怎样的呢？答案是解释器全局锁GIL。GIL对诸如当前线程状态和为垃圾回收而用的堆分配对象这样的东西的访问提供着保护。 为什么不能去掉 首先，在早期的python解释器依赖较多的全局状态，传承下来，使得想要移除当今的GIL变得更加困难。其次，对于程序员而言，仅仅是想要理解它的实现就需要对操作系统设计、多线程编程、C语言、解释器设计和CPython解释器的实现有着非常彻底的理解。在1999年，针对Python1.5，一个“freethreading”补丁已经尝试移除GIL，用细粒度的锁来代替。然而，GIL的移除给单线程程序的执行速度带来了一定的负面影响。当用单线程执行时，速度大约降低了40%。虽然使用两个线程时在速度上得到了提高，但这个提高并没有随着核数的增加而线性增长。因此这个补丁没有被采纳。另外，在python的不同解释器实现中，如PyPy就移除了GIL，其执行速度更快（不单单是去除GIL的原因）。然而，我们通常使用的CPython占有着统治地位的使用量，所以，你懂的。在Python 3.2中实现了一个新的GIL，并且带着一些积极的结果。这是自1992年以来，GIL的一次最主要改变。旧的GIL通过对Python指令进行计数来确定何时放弃GIL。在新的GIL实现中，用一个固定的超时时间来指示当前的线程以放弃这个锁。在当前线程保持这个锁，且当第二个线程请求这个锁的时候，当前线程就会在5ms后被强制释放掉这个锁（这就是说，当前线程每5ms就要检查其是否需要释放这个锁）。当任务是可行的时候，这会使得线程间的切换更加可预测。 实际建议 建议在IO密集型任务中使用多线程， 在CPU密集型任务中使用多进程。 深入研究python的协程机制，你会有惊喜的。 通常而言，队列是一种先进先出的数据结构，与之对应的是堆栈这种后进先出的结构。但是在python中，它内置了一个queue模块，它不但提供普通的队列，还提供一些特殊的队列。具体如下： queue.Queue ：先进先出队列 queue.LifoQueue ：后进先出队列 queue.PriorityQueue ：优先级队列 queue.deque ：双向队列 生产者 消费者生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。这个阻塞队列就是用来给生产者和消费者解耦的。纵观大多数设计模式，都会找一个第三者出来进行解耦，如工厂模式的第三者是工厂类，模板模式的第三者是模板类。在学习一些设计模式的过程中，如果先找到这个模式的第三者，能帮助我们快速熟悉一个设计模式。 12345678910111213141516171819202122232425#!/usr/bin/env python# -*- coding:utf-8 -*-# Author:Liu Jiangimport timeimport queueimport threading q = queue.Queue(10)def productor(i): while True: q.put("厨师 %s 做的包子！"%i) time.sleep(2) def consumer(k): while True: print("顾客 %s 吃了一个 %s"%(k,q.get())) time.sleep(1) for i in range(3): t = threading.Thread(target=productor,args=(i,)) t.start() for k in range(10): v = threading.Thread(target=consumer,args=(k,)) v.start() 线程池在使用多线程处理任务时也不是线程越多越好，由于在切换线程的时候，需要切换上下文环境，依然会造成cpu的大量开销。为解决这个问题，线程池的概念被提出来了。预先创建好一个较为优化的数量的线程，让过来的任务立刻能够使用，就形成了线程池。在python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。下面是一个简单的线程池： 12345678910111213141516171819202122232425262728293031#!/usr/bin/env python# -*- coding:utf-8 -*-# Author:Liu Jiang import queueimport timeimport threading class MyThreadPool: def __init__(self, maxsize=5): self.maxsize = maxsize self._q = queue.Queue(maxsize) for i in range(maxsize): self._q.put(threading.Thread) def get_thread(self): return self._q.get() def add_thread(self): self._q.put(threading.Thread) def task(i, pool): print(i) time.sleep(1) pool.add_thread() pool = MyThreadPool(5)for i in range(100): t = pool.get_thread() obj = t(target=task, args=(i,pool)) obj.start() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190#!/usr/bin/env python# -*- coding:utf-8 -*- """一个基于thread和queue的线程池，以任务为队列元素，动态创建线程，重复利用线程，通过close和terminate方法关闭线程池。"""import queueimport threadingimport contextlibimport time # 创建空对象,用于停止线程StopEvent = object() def callback(status, result): """ 根据需要进行的回调函数，默认不执行。 :param status: action函数的执行状态 :param result: action函数的返回值 :return: """ pass def action(thread_name,arg): """ 真实的任务定义在这个函数里 :param thread_name: 执行该方法的线程名 :param arg: 该函数需要的参数 :return: """ # 模拟该函数执行了0.1秒 time.sleep(0.1) print("第%s个任务调用了线程 %s，并打印了这条信息！" % (arg+1, thread_name)) class ThreadPool: def __init__(self, max_num, max_task_num=None): """ 初始化线程池 :param max_num: 线程池最大线程数量 :param max_task_num: 任务队列长度 """ # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。 if max_task_num: self.q = queue.Queue(max_task_num) # 默认队列可接受无限多个的任务 else: self.q = queue.Queue() # 设置线程池最多可实例化的线程数 self.max_num = max_num # 任务取消标识 self.cancel = False # 任务中断标识 self.terminal = False # 已实例化的线程列表 self.generate_list = [] # 处于空闲状态的线程列表 self.free_list = [] def put(self, func, args, callback=None): """ 往任务队列里放入一个任务 :param func: 任务函数 :param args: 任务函数所需参数 :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数 1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数） :return: 如果线程池已经终止，则返回True否则None """ # 先判断标识，看看任务是否取消了 if self.cancel: return # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。 if len(self.free_list) == 0 and len(self.generate_list) self.max_num: self.generate_thread() # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。 w = (func, args, callback,) # 将任务放入队列 self.q.put(w) def generate_thread(self): """ 创建一个线程 """ # 每个线程都执行call方法 t = threading.Thread(target=self.call) t.start() def call(self): """ 循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态， 直到获取线程终止的flag。 """ # 获取当前线程的名字 current_thread = threading.currentThread().getName() # 将当前线程的名字加入已实例化的线程列表中 self.generate_list.append(current_thread) # 从任务队列中获取一个任务 event = self.q.get() # 让获取的任务不是终止线程的标识对象时 while event != StopEvent: # 解析任务中封装的三个参数 func, arguments, callback = event # 抓取异常，防止线程因为异常退出 try: # 正常执行任务函数 result = func(current_thread, *arguments) success = True except Exception as e: # 当任务执行过程中弹出异常 result = None success = False # 如果有指定的回调函数 if callback is not None: # 执行回调函数，并抓取异常 try: callback(success, result) except Exception as e: pass # 当某个线程正常执行完一个任务时，先执行worker_state方法 with self.worker_state(self.free_list, current_thread): # 如果强制关闭线程的flag开启，则传入一个StopEvent元素 if self.terminal: event = StopEvent # 否则获取一个正常的任务，并回调worker_state方法的yield语句 else: # 从这里开始又是一个正常的任务循环 event = self.q.get() else: # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除 self.generate_list.remove(current_thread) def close(self): """ 执行完所有的任务后，让所有线程都停止的方法 """ # 设置flag self.cancel = True # 计算已创建线程列表中线程的个数，然后往任务队列里推送相同数量的终止线程的标识元素 full_size = len(self.generate_list) while full_size: self.q.put(StopEvent) full_size -= 1 def terminate(self): """ 在任务执行过程中，终止线程，提前退出。 """ self.terminal = True # 强制性的停止线程 while self.generate_list: self.q.put(StopEvent) # 该装饰器用于上下文管理 @contextlib.contextmanager def worker_state(self, state_list, worker_thread): """ 用于记录空闲的线程，或从空闲列表中取出线程处理任务 """ # 将当前线程，添加到空闲线程列表中 state_list.append(worker_thread) # 捕获异常 try: # 在此等待 yield finally: # 将线程从空闲列表中移除 state_list.remove(worker_thread) # 调用方式if __name__ == '__main__': # 创建一个最多包含5个线程的线程池 pool = ThreadPool(5) # 创建100个任务，让线程池进行处理 for i in range(100): pool.put(action, (i,), callback) # 等待一定时间，让线程执行任务 time.sleep(3) print("-" * 50) print("任务停止之前线程池中有%s个线程，空闲的线程有%s个 " % (len(pool.generate_list), len(pool.free_list))) # 正常关闭线程池 pool.close() print("任务执行完毕，正常退出！") # 强制关闭线程池 # pool.terminate() # print("强制停止任务！") 2. process在python中multiprocess模块提供了Process类，实现进程相关的功能。但是，由于它是基于fork机制的，因此不被windows平台支持。想要在windows中运行，必须使用if __name == ‘\main__:的方式，显然这只能用于调试和学习，不能用于实际环境。（PS：在这里我必须吐槽一下python的包、模块和类的组织结构。在multiprocess中你既可以import大写的Process，也可以import小写的process，这两者是完全不同的东西。这种情况在python中很多，新手容易傻傻分不清。） 想要进程之间进行资源共享可以使用queues/Array/Manager这三个multiprocess模块提供的类。 12345678910111213from multiprocessing import Processfrom multiprocessing import Array def Foo(i,temp): temp[0] += 100 for item in temp: print(i,'-----&gt;',item) if __name__ == '__main__': temp = Array('i', [11, 22, 33, 44]) for i in range(2): p = Process(target=Foo, args=(i,temp)) p.start() 12345678910111213from multiprocessing import Process,Manager def Foo(i,dic): dic[i] = 100+i print(dic.values()) if __name__ == &apos;__main__&apos;: manage = Manager() dic = manage.dict() for i in range(10): p = Process(target=Foo, args=(i,dic)) p.start() p.join() 12345678910111213import multiprocessingfrom multiprocessing import Processfrom multiprocessing import queues def foo(i,arg): arg.put(i) print(&apos;The Process is &apos;, i, &quot;and the queue&apos;s size is &quot;, arg.qsize()) if __name__ == &quot;__main__&quot;: li = queues.Queue(20, ctx=multiprocessing) for i in range(10): p = Process(target=foo, args=(i,li,)) p.start() 这里就有点类似上面的队列了。从运行结果里，你还能发现数据共享中存在的脏数据问题。另外，比较悲催的是multiprocessing里还有一个Queue，一样能实现这个功能。 3. coroutine线程和进程的操作是由程序触发系统接口，最后的执行者是系统，它本质上是操作系统提供的功能。而协程的操作则是程序员指定的，在python中通过yield，人为的实现并发处理。协程存在的意义：对于多线程应用，CPU通过切片的方式来切换线程间的执行，线程切换时需要耗时。协程，则只使用一个线程，分解一个线程成为多个“微线程”，在一个线程中规定某个代码块的执行顺序。协程的适用场景：当程序中存在大量不需要CPU的操作时（IO）。在不需要自己“造轮子”的年代，同样有第三方模块为我们提供了高效的协程，这里介绍一下greenlet和gevent。本质上，gevent是对greenlet的高级封装，因此一般用它就行，这是一个相当高效的模块。 123456789101112131415from gevent import monkey; monkey.patch_all()import geventimport requests def f(url): print(&apos;GET: %s&apos; % url) resp = requests.get(url) data = resp.text print(&apos;%d bytes received from %s.&apos; % (len(data), url)) gevent.joinall([ gevent.spawn(f, &apos;https://www.python.org/&apos;), gevent.spawn(f, &apos;https://www.yahoo.com/&apos;), gevent.spawn(f, &apos;https://github.com/&apos;),])]]></content>
  </entry>
  <entry>
    <title><![CDATA[how-to-deploy-django]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F16%2Fhow-to-deploy-django%2F</url>
    <content type="text"><![CDATA[django 部署的关键点 安全秘匙 secret key 从环境变量中加载或者是从文件中进行读取 生产环境不能启动debug模式 allow_hosts 缓存 数据库 email设置 伺服静态文件 媒体文件是用户上传的，是不能信任的 HTTPS csrf session 性能优化等 日志的配置]]></content>
  </entry>
  <entry>
    <title><![CDATA[how-to-understand-unittest]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F16%2Fhow-to-understand-unittest%2F</url>
    <content type="text"><![CDATA[关于测试有段时间被领导叫过去写单元测试。 这段时间决定对此段经历做一些总结。 单元测试是一种软件测试过程，测试的是软件应用程序的独立单元，确保能做预期中的事情。 分为不同的层级，可以测试单个方法，看它能否返回正确的值以及能否处理正确的数据， 也可以测试整个方法组件，确保一系列用户输入能得到所需的结果。 单元测试背后，有四个基本的概念： 测试固件 fixture 执行测试所需要的设置。包含数据库、示例数据集合服务器搭建。可能还包括测试完毕之后执行的清理操作。 用例 case 测试的基本单元。检查指定的输入能否得到预期的结果。 组件 suit 一系列测试用例或者其他测试组件，作为一个整体执行 运行程序 runner 负责执行测试并把结果反馈給用户的软件程序。 自动化测试优点 节省时间 避免出问题 看起来专业 增进团队协作 将测试代码封装到一个类中，并且增加断言。 django的单元测试 会在app应用中查找测试 找到 testcase 的一个子类 为测试创建一个特殊的数据库 查找以test开头的测试方法 报告失败的测试 Django 为 编写测试提供了一些便利的工具 测试客户端 伪装成一个web浏览器 模拟对URL 的 GET POST 请求 跟踪重定向 测试指定的请求由指定的django 模板渲染，而且模板上下文包含特定的值 客户端的目的不是取代 selenium 或者是其他操作浏览器的框架 用于确认是否渲染了正确的模板，而且为模板传入了正确的上下文数据 TestCase 有一些扩展 Simple的Transaction的等等…]]></content>
  </entry>
  <entry>
    <title><![CDATA[tf-note-2]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F06%2Ftf-note-2%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[tf-note-1]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F06%2Ftf-note-1%2F</url>
    <content type="text"><![CDATA[andrew ng 深度学习 是 什么？ 简单点来说 是训练神经网络。 神经网络有时候规模会很大。 非常传统的例子， 是房价的预测。 假设有一个六间房的数据集，已知房屋的面积 房屋价格 想要找到一个函数来预测房价。 很显然，懂线性回归的同学会知道直接拟合一条直线就好。 这就是最简单的神经网络。 输入x， 经过一个神经元，得到预测价格y 这个函数被称为 ReLU 函数，全称是修正线性单元，修正指的是取不小于0的值。 大点的神经网络是把这些单个神经元堆叠起来形成的，你可以想象成搭乐高积木。 预测房屋价格，现在可能还有一些其他的特征，如卧室的数量，邮编也可以作为一个特性，因为说明了步行化程度。还有其他等等特性。。。 对于神经网络，只有你喂给它足够多的x和y的数据，得到足够多的x y 训练样本，就非常擅于计算从x到y的精准映射函数。这就是一个基本的神经网络，自己的神经网络在监督学习的环境下是如此有效和强大。 常见的应用有预测房价在线广告还有图像 文本等的处理语言翻译自动驾驶 图像领域，经常使用卷积神经网络，也就是CNN 对于序列数据，例如音频中含有时间成分，则使用 RNN 英语翻译 也 属于序列数据， RNN 无人驾驶，基于图片， 另外 就是 GAN 无监督学习了。 待续 。。。]]></content>
  </entry>
  <entry>
    <title><![CDATA[lagou-spider]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F11%2F05%2Flagou-spider%2F</url>
    <content type="text"><![CDATA[很久没有写爬虫了今天试着爬了一下 拉勾网站 深圳 python 的前 150 个职位 12345678910111213141516171819202122232425262728293031323334353637import timeimport requestsfrom pprint import pprintfrom fake_useragent import UserAgentua = UserAgent()import pymongoclient = pymongo.MongoClient("localhost", 27017)db = client.jobuser_agent = ua.randomurl = 'https://www.lagou.com/jobs/positionAjax.json?px=default&amp;city=%E6%B7%B1%E5%9C%B3&amp;needAddtionalResult=false&amp;isSchoolJob=0'headers = &#123; "Cookie": "user_trace_token=20171105173814-0b824fa6-c20d-11e7-978b-5254005c3644; LGUID=20171105173814-0b825535-c20d-11e7-978b-5254005c3644; index_location_city=%E6%B7%B1%E5%9C%B3; TG-TRACK-CODE=index_search; SEARCH_ID=5bb5150d5d314f32a34bdb68f6e2dbbc; _gid=GA1.2.1886275699.1509874693; _ga=GA1.2.1197843841.1509874693; LGRID=20171105173909-2cac9846-c20d-11e7-978b-5254005c3644; Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1509874693; Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1509874749; JSESSIONID=ABAAABAAAFCAAEG674AE53B34CFB49996425F9659B657CF", "Referer": "https://www.lagou.com/jobs/list_python?px=default&amp;city=%E6%B7%B1%E5%9C%B3", "User-Agent": user_agent&#125;def get_job_data(num): for i in range(num): payload = &#123; "first": "false", "pn": str(i+1), "kd": "python" &#125; response = requests.post(url, data=payload, headers=headers) time.sleep(5) # pprint(response.json()['content']['positionResult']['result']) for item in response.json()['content']['positionResult']['result']: db.my_collection.insert_one(item)if __name__ == '__main__': get_job_data(10) 还想着做一些可视化的东西。。。]]></content>
  </entry>
  <entry>
    <title><![CDATA[how fabric works]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F09%2F17%2Fhow-fabric-works%2F</url>
    <content type="text"></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how ansible works]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F09%2F17%2Fhow-ansible-works%2F</url>
    <content type="text"><![CDATA[ansible 是什么？ ansible 是如何工作的： 使用者认证通过之后在管理节点通过 ansible 工具调用各应用模块将指令推送到被管理端。 并且在执行完毕后自动删除产生的临时文件。 主要由六个部分组成： playbooks 通常是 json 格式的 yml 文件 inventory 管理主机的清单 modules 执行命令的功能模块 plugins 模块功能的补充，如循环插件等，功能不常用 api 供第三方程序调用的应用程序编程接口 ansible ansible 命令工具 遵循预先编排的规则将 playbook 逐条拆解为 play，将 play 组织成 ansible 可识别的任务 task，随后调用任务涉及的所有模块和插件，根据 inventory 中定义的主机列表通过 ssh 将任务集以临时文件或命令的形式传输到远程客户端执行并返回执行结果，如果是临时文件则执行完毕后自动删除。 下面会详细介绍一个企业级的应用，elk 日志系统基于 ansible 的自动化实现。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tensorflow foundation]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F09%2F17%2Ftensorflow-foundation%2F</url>
    <content type="text"><![CDATA[1. 基础架构自底向上分为： 网络层和设备层 数据操作层 图计算层 API 层 应用层 1.1 网络通信层和设备管理层 网络通信层包括 gRPC 和 RDMA ，都是分布式计算时需要用到的。设备管理层包括 tf 分别在 CPU GPU FPGA 等设备上的实现，也就是对上层提供了一个统一的接口，使得上层只需要处理卷积等逻辑，而不需要关心在硬件上的卷积的实现过程。 1.2 数据操作层 包括卷积函数、激活函数等操作。 1.3 图计算层 本地计算图和分布式计算图的实现 1.4 API 层 python实现和其他语言的实现 1.5 应用层 主要是训练相关类库和预测相关类库 2. 设计理念2.1 图的定义和图的实现完全分开 符号式编程涉及很多的嵌入和优化，不容易理解和调试，但是运行速度有所提升。 2.2 涉及的运算全部放在图中，图的运行只是发生在会话 session 中。 下面是举例： 123456789101112131415import tensorflow as tfa = tf.constant([1.0, 2.0])b = tf.constant([3.0, 4.0])c = a * bsess = tf.Session()print sess.run(c)sess.close()# 当然 一般写法是这样with tf.Session() as sess: print sess.run(c) 编程模型 运行原理： 输入input 塑形reshape Relu层 Logit层 Softmax 交叉熵cross entropy 梯度gradient SGD 训练 从输入开始，经过塑形后，一层一层进行前向传播运算。Relu层里会有两个参数，在输出前使用Relu激活函数来做非线性处理。然后进入Logit层，学习两个参数。用softmax来计算输出结果中各个类别的概率分布。用交叉熵来度量两个概率分布之间的相似性。然后开始计算梯度，以及交叉墒后的结果。随后进入SGD训练，也就是反向传播的过程，从上往下计算每一层的参数，依次进行更新。 tensorflow 顾名思义就是指“张量的流动”，数据流图是由节点node和边edge组成的有向无环图。 3.1 边 张量具有数据属性 如tf.float32等。 3.2 节点 节点的运算操作有数学、数组等。详细代码在源码tensorflow/python/ops/目录下。 3.3 设备 设备device是指一块可以用来运算且拥有自己地址空间的硬件。 3.4 变量 变量variable是一种特殊的数据，在图中有固定的位置，不像张量那样可以流动。 3.5 内核 操作是对抽象操作的一个统称，而内核kernel则是能够运行在特定设备上的一种对操作的实现。]]></content>
  </entry>
  <entry>
    <title><![CDATA[texas poker]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F09%2F02%2Ftexas-poker%2F</url>
    <content type="text"><![CDATA[德州扑克比较大小的设计，设计全面还是有一些繁琐的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235#! /usr/bin/env python# _*_ coding:utf8 _*_import randomdef poker(hands): "Return a list of winning hands: poker([hand,...]) =&gt; [hand,...]" return allmax(hands, key=hand_rank)def allmax(iterable, key=None): "Return a list of all items equal to the max of the iterable." iterable.sort(key=key,reverse=True) result = [iterable[0]] maxValue = key(iterable[0]) if key else iterable[0] for value in iterable[1:]: v = key(value) if key else value if v == maxValue: result.append(value) else: break return resultdef card_ranks(hand): "Return a list of the ranks, sorted with higher first." ranks = ['--23456789TJQKA'.index(r) for r, s in hand] ranks.sort(reverse = True) return [5, 4, 3, 2, 1] if (ranks == [14, 5, 4, 3, 2]) else ranks# 同花色def flush(hand): "Return True if all the cards have the same suit." suits = [s for r,s in hand] return len(set(suits)) == 1# 顺子def straight(ranks): "Return True if the ordered ranks form a 5-card straight." return (max(ranks)-min(ranks) == 4) and len(set(ranks)) == 5# 条子def kind(n, ranks): """Return the first rank that this hand has exactly n-of-a-kind of. Return None if there is no n-of-a-kind in the hand.""" for r in ranks: if ranks.count(r) == n: return r return None# 两对def two_pair(ranks): "If there are two pair here, return the two ranks of the two pairs, else None." pair = kind(2, ranks) lowpair = kind(2, list(reversed(ranks))) if pair and lowpair != pair: return (pair, lowpair) else: return Nonedef hand_rank(hand): "Return a value indicating the ranking of a hand." ranks = card_ranks(hand) if straight(ranks) and flush(hand): return (8, max(ranks)) elif kind(4, ranks): return (7, kind(4, ranks), kind(1, ranks)) elif kind(3, ranks) and kind(2, ranks): return (6, kind(3, ranks), kind(2, ranks)) elif flush(hand): return (5, ranks) elif straight(ranks): return (4, max(ranks)) elif kind(3, ranks): return (3, kind(3, ranks), ranks) elif two_pair(ranks): return (2, two_pair(ranks), ranks) elif kind(2, ranks): return (1, kind(2, ranks), ranks) else: return (0, ranks)def hand_rank_alt(hand): "Return a value indicating how high the hand ranks." # count is the count of each rank; ranks lists corresponding ranks # E.g. '7 T 7 9 7' =&gt; counts = (3, 1, 1) ranks = (7, 10, 9) groups = group(['--23456789TJQKA'.index(r) for r,s in hand]) counts, ranks = unzip(groups) if ranks == (14, 5, 4, 3, 2): # Ace low straight ranks = (5, 4, 3, 2, 1) straight = len(ranks) == 5 and max(ranks) - min(ranks) == 4 flush = len(set([s for r,s in hand])) == 1 return (9 if (5,) == counts else 8 if straight and flush else 7 if (4, 1) == counts else 6 if (3, 2) == counts else 5 if flush else 4 if straight else 3 if (3, 1, 1) == counts else 2 if (2, 2, 1) == counts else 1 if (2, 1, 1, 1) == counts else 0), rankscount_rankings = &#123;(5,): 10, (4, 1): 7, (3, 2): 6, (3, 1, 1): 3, (2, 2, 1): 2, (2, 1, 1, 1): 1, (1, 1, 1, 1, 1): 0&#125;def hand_rank_table(hand): "Return a value indicating how high the hand ranks." # count is the count of each rank; ranks lists corresponding ranks # E.g. '7 T 7 9 7' =&gt; counts = (3, 1, 1) ranks = (7, 10, 9) groups = group(['--23456789TJQKA'.index(r) for r,s in hand]) counts, ranks = unzip(groups) if ranks == (14, 5, 4, 3, 2): # Ace low straight ranks = (5, 4, 3, 2, 1) straight = len(ranks) == 5 and max(ranks) - min(ranks) == 4 flush = len(set([s for r,s in hand])) == 1 return max(count_rankings[counts], 4*straight + 5*flush), ranksdef group(items): "Return a list of [(count, x), ...], highest count first, then highest x first" groups = [(items.count(x), x) for x in set(items)] return sorted(groups, reverse = True)def unzip(iterable): "Return a list of tuples from a list of tuples : e.g. [(2, 9), (2, 7)] =&gt; [(2, 2), (9, 7)]" return zip(*iterable)mydeck = [r+s for r in '23456789TJQKA' for s in 'SHDC']def deal(numhands, n=5, deck=mydeck): random.shuffle(mydeck) return [mydeck[n*i:n*(i+1)] for i in range(numhands)]hand_names = ["Straight flush", "Four of a kind", "Full house", "Flush", "Straight", "Three of a kind", "Two pair", "One pair", "High card"]def hand_percentages(n=700*1000): counts = [0] * 9 for i in range(n/10): for hand in deal(10): ranking = hand_rank(hand)[0] counts[ranking] += 1 for i in reversed(range(9)): print "%15s: %6.3f %%" % (hand_names[i], 100.*counts[i]/n)def test(): "Test cases for the functions in poker program." sf1 = "6C 7C 8C 9C TC".split() # Straight Flush sf2 = "6D 7D 8D 9D TD".split() # Straight Flush fk = "9D 9H 9S 9C 7D".split() # Four of a Kind fh = "TD TC TH 7C 7D".split() # Full House tp = "5D 2C 2H 9H 5C".split() # Two Pair # Testing allmax assert allmax([2,4,7,5,1]) == [7] assert allmax([2,4,7,5,7]) == [7,7] assert allmax([2]) == [2] assert allmax([0,0,0]) == [0,0,0] # Testing card_ranks assert card_ranks(sf1) == [10, 9, 8, 7, 6] assert card_ranks(fk) == [9, 9, 9, 9, 7] assert card_ranks(fh) == [10, 10, 10, 7, 7] # Testing flush assert flush([]) == False assert flush(sf1) == True assert flush(fh) == False # Testing straight assert straight(card_ranks(sf1)) == True assert straight(card_ranks(fk)) == False # Testing kind assert kind(3, card_ranks(sf1)) == None assert kind(4, card_ranks(fk)) == 9 # Tesing two pair assert two_pair(card_ranks(sf1)) == None assert two_pair(card_ranks(tp)) == (5,2) # Testing group assert group([2,3,4,6,2,1,9]) == [(2,2),(1,9),(1,6),(1,4),(1,3),(1,1)] assert group([8,8,8,8]) == [(4,8)] assert group([2,6,1]) == [(1,6),(1,2),(1,1)] # Testing unzip assert unzip([(2,2),(1,9),(1,6),(1,4),(1,3),(1,1)]) == [(2,1,1,1,1,1),(2,9,6,4,3,1)] assert unzip([(1,6),(1,2),(1,1)]) == [(1,1,1),(6,2,1)] assert unzip([(2, 9), (2, 7)]) == [(2, 2), (9, 7)] # Testing hand rank assert hand_rank(sf1) == (8,10) assert hand_rank(fk) == (7,9,7) assert hand_rank(fh) == (6,10,7) # Testing hand rank alt assert hand_rank_alt(sf1) == (8, (10,9,8,7,6)) assert hand_rank_alt(fk) == (7,(9,7)) assert hand_rank_alt(fh) == (6,(10,7)) # Testing hand rank table assert hand_rank_table(sf1) == (9, (10,9,8,7,6)) assert hand_rank_table(fk) == (7,(9,7)) assert hand_rank_table(fh) == (6,(10,7)) # Testing poker assert poker([sf1, fk, fh]) == [sf1] assert poker([fk, fh]) == [fk] assert poker([fh, fh]) == [fh, fh] assert poker([fh]) == [fh] assert poker([sf2] + 99*[fh]) == [sf2] assert poker([sf1, sf2, fk, fh]) == [sf1, sf2] return 'tests pass']]></content>
  </entry>
  <entry>
    <title><![CDATA[vim table cheatsheet]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F08%2F27%2Fvim-table-cheatsheet%2F</url>
    <content type="text"><![CDATA[命令 描述 进入 vim - vim filename 打开或者新建文件，光标置于第一行行首 vim +n filename n行行首 vim + filename 最后一行行首 vim +/pattern filename 第一个与pattern匹配的串处 vim -r filename 恢复 vim filename … filename 打开多个 vim 配置 - all 列出所有选项设置情况 term 设置终端类型 ignorance 忽略大小写 list 显示制表位和行尾标志 number 显示行号 report 显示由面向行的命令修改过的数目 terse 显示简短的警告信息 warn 显示no write信息 nomagic 搜索模式使用前面不带\的特殊字符 nowrapscan 禁止vi在搜索到达文件两端时，又从另一端开始 mesg 允许vi显示其他用户用write写到自己终端上的信息 :set number 显示行号 加no不显示 :set ruler 标尺 有no :set hisearch 高亮显示查找到的单词 :syntax on 语法高亮 :set tabstop=8 tab大小为8 :set softtabstop=8 4: 4个空格，8:正常制表符，16:两个制表符 :set autoindent 自动缩进 :set cindent c语言格式自动缩进 移动光标 - k nk 上 j nj 下 h nh 左 l nl 右 Space 光标右移一个字符 BackSpace 左移 Enter 下移动一行 w/W 右移动一个字至字首 b/B 左移 e/E 右移到字尾 ) 句尾 ( 句首 } 段落结尾 { 开头 n$ n行尾 H 屏幕顶行 M 中间行 L 最后行 0 当前行首 ^ 第一个非空字符上 $ 当前行尾 gg 第一行 G 最后一行 f 当前行的字符a上 F 相反 % 匹配的符号如（）、[]、{}、&lt;&gt;等 nG n行上 G 最后一行 屏幕滚动 - ctrl + u 向文件首翻半屏 ctrl + d 尾 ctrl + f 文件尾一屏 ctrl + b 首一屏 nz 将第n行滚动至屏幕顶部，不指定n行时将当前行滚动到屏幕顶部 插入文本 - i 光标前 I 行首 a 光标后 A 行尾 o 当前行之下新开一行 O 之上 r 替换当前字符 R 替换当前字符以及以后的字符，直到按esc键 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入的文本代替之 ncw/W 修改指定数目的字 nCC 修改指定数目的行 删除命令 - x/X 删除一个字符，一个后一个前 dw 删除一个单词 dnw n个 dne 删除到单词尾 do 删除到行首 d$ 行尾 dd 删除当前行 ndd 当前行和后面n-1行 dnl 向右删除n个字母 dnh 左 dnj 下n行（n不含当前行） dnk 上n行 cnw[word] 将n个word改变为word C$ 改变到行尾 cc 改变整行 shift+j 删除行尾的换行符，下一行接上来了 复制粘贴 - p 粘贴用x或者d删除的文本 ynw 复制n个单词 yy 复制一行 ynl n个字符 y$ 复制当前光标至行尾处 nyy 拷贝n行 撤销 - u 撤销前一次的操作 shift+u 撤销对该行的所有操作 搜索以及替换 - /pattern 光标开始处向文件尾搜索 ?pattern 文件首 n 在同一个方向重复上一次搜索命令 N 反方向 cw newword 替换为newword n 继续查找 . 执行替换 :s/p1/p2/g 将当前行中所有p1均用p2替代 :n1,n2 s/p1/p2/g n1到n2行 :g/p1/s/p2/g 文件中所有 :1,$ s/string1/string2/g 全文中替换 书签 - m[a-z] 标记 `a 移动到标记a处 visual模式 - v 进入模式 V 行的 ctrl+v 进入块操作 行方式命令 - :n1,n2 co n3 n1到n2行拷贝到第n3行下 :n1,n2 m n3 移动 :n1,n2 d 删除 :n1,n2 wlcommand 作为command的输入并执行之 宏 - q[a-z] q终止录宏 reg 显示当前所定义的所有宏 窗口操作 - :split 分割一个 :split file.c 为另一个file.c分隔窗口 :nsplit file.c 并且指定行数 ctrl+w 在窗口中切换 :close 关闭当前窗口 文件及其他 - :q 退出 :q! 强制 :e filename 打开文件并且进行编辑 :e! 放弃修改，并重载 :w 保存 :wq 存盘退出 :ZZ 保存退出 :!command 执行shell命令command :r!command 输出结果放到当前行 :n1,n2 write temp.c :read file.c 将文件file.c的内容放到当前光标所在的下面]]></content>
  </entry>
  <entry>
    <title><![CDATA[make a forum with django]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F08%2F24%2Fmake-a-forum-with-django%2F</url>
    <content type="text"><![CDATA[每次想写点东西的时候，总是自己骗自己说，哎呀，哪有时间去搞这些东西。 决定还是一点点尝试写一个论坛系统出来。 Django这个框架非常庞大，可能在实际的开发过程中，我们用到的只是一小部分，比如创建model，view，然后根据这些写一些html的文件等。 再在页面调试的过程当中发现一些问题，对代码进行不断地修正。]]></content>
  </entry>
  <entry>
    <title><![CDATA[wechat-delete-friends]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F08%2F03%2Fwechat-delete-friends%2F</url>
    <content type="text"><![CDATA[在终端中执行: 12345git clone https://github.com/0x5e/wechat-deleted-friends.gitcd wechat-deleted-friendspython wdf.py 然后按照提示操作就可以了. 完成之后手动删除生成的一个群聊, 不要在里面说话, 不说话好友们是不知情的.]]></content>
  </entry>
  <entry>
    <title><![CDATA[ftp-download]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F08%2F03%2Fftp-download%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205#!/usr/bin/env python# encoding: utf-8import osimport sysimport ftplibimport tracebackclass FtpDownloader(object): PATH_TYPE_UNKNOWN = -1 PATH_TYPE_FILE = 0 PATH_TYPE_DIR = 1 def __init__(self, host, user=None, passwd=None, port=21, timeout=10): self.conn = ftplib.FTP( host=host, user=user, passwd=passwd, timeout=timeout ) def dir(self, *args): &apos;&apos;&apos; by defualt, ftplib.FTP.dir() does not return any value. Instead, it prints the dir info to the stdout. So we re-implement it in FtpDownloader, which is able to return the dir info. &apos;&apos;&apos; info = [] cmd = &apos;LIST&apos; for arg in args: if arg: cmd = cmd + (&apos; &apos; + arg) self.conn.retrlines(cmd, lambda x: info.append(x.strip().split())) return info def tree(self, rdir=None, init=True): &apos;&apos;&apos; recursively get the tree structure of a directory on FTP Server. args: rdir - remote direcotry path of the FTP Server. init - flag showing whether in a recursion. &apos;&apos;&apos; if init and rdir in (&apos;.&apos;, None): rdir = self.conn.pwd() tree = [] tree.append((rdir, self.PATH_TYPE_DIR)) dir_info = self.dir(rdir) for info in dir_info: attr = info[0] # attribute name = info[-1] path = os.path.join(rdir, name) if attr.startswith(&apos;-&apos;): tree.append((path, self.PATH_TYPE_FILE)) elif attr.startswith(&apos;d&apos;): if (name == &apos;.&apos; or name == &apos;..&apos;): # skip . and .. continue tree.extend(self.tree(rdir=path,init=False)) # recurse else: tree.append(path, self.PATH_TYPE_UNKNOWN) return tree def downloadFile(self, rfile, lfile): &apos;&apos;&apos; download a file with path %rfile on a FTP Server and save it to locate path %lfile. &apos;&apos;&apos; ldir = os.path.dirname(lfile) if not os.path.exists(ldir): os.makedirs(ldir) f = open(lfile, &apos;wb&apos;) self.conn.retrbinary(&apos;RETR %s&apos; % rfile, f.write) f.close() return True def treeStat(self, tree): numDir = 0 numFile = 0 numUnknown = 0 for path, pathType in tree: if pathType == self.PATH_TYPE_DIR: numDir += 1 elif pathType == self.PATH_TYPE_FILE: numFile += 1 elif pathType == self.PATH_TYPE_UNKNOWN: numUnknown += 1 return numDir, numFile, numUnknown def downloadDir(self, rdir=&apos;.&apos;, ldir=&apos;.&apos;, tree=None, errHandleFunc=None, verbose=True): &apos;&apos;&apos; download a direcotry with path %rdir on a FTP Server and save it to locate path %ldir. args: tree - the tree structure return by function FtpDownloader.tree() errHandleFunc - error handling function when error happens in downloading one file, such as a function that writes a log. By default, the error is print to the stdout. &apos;&apos;&apos; if not tree: tree = self.tree(rdir=rdir, init=True) numDir, numFile, numUnknown = self.treeStat(tree) if verbose: print &apos;Host %s tree statistic:&apos; % self.conn.host print &apos;%d directories, %d files, %d unknown type&apos; % ( numDir, numFile, numUnknown ) if not os.path.exists(ldir): os.makedirs(ldir) ldir = os.path.abspath(ldir) numDownOk = 0 numDownErr = 0 for rpath, pathType in tree: lpath = os.path.join(ldir, rpath.strip(&apos;/&apos;).strip(&apos;\\&apos;)) if pathType == self.PATH_TYPE_DIR: if not os.path.exists(lpath): os.makedirs(lpath) elif pathType == self.PATH_TYPE_FILE: try: self.downloadFile(rpath, lpath) numDownOk += 1 except Exception as err: numDownErr += 1 if errHandleFunc: errHandleFunc(err, rpath, lpath) elif verbose: print &apos;An Error occurred when downloading &apos;\ &apos;remote file %s&apos; % rpath traceback.print_exc() print if verbose: print &apos;Host %s: %d/%d/%d(ok/err/total) files downloaded&apos; % ( self.conn.host, numDownOk, numDownErr, numFile ) elif pathType == self.PATH_TYPE_UNKNOWN: if verbose: print &apos;Unknown type romote path got: %s&apos; % rpath if verbose: print &apos;Host %s directory %s download finished:&apos; % ( self.conn.host, rdir ) print &apos;%d directories, %d(%d failed) files, %d unknown type.&apos; % ( numDir, numFile, numDownErr, numUnknown ) return numDir, numFile, numUnknown, numDownErrif __name__ == &apos;__main__&apos;: import sys import traceback from pprint import pprint as pr flog = open(&apos;err.log&apos;, &apos;wb&apos;) def run(host): try: fd = FtpDownloader( host=host, user=&apos;test&apos;, passwd=&apos;test&apos;, port=21, timeout=10 ) numDir, numFile, numUnknown, numDownErr = fd.downloadDir( rdir=&apos;.&apos;, ldir=&apos;download&apos;, tree=None, errHandleFunc=None, verbose=True ) flog.write( &apos;%s\nok\n&apos; &apos;%d directories, %d(%d failed) files, %d unknown type\n\n\n&apos; % ( host, numDir, numFile, numDownErr, numUnknown ) ) except Exception as err: traceback.print_exc() flog.write( &apos;%s\nerror\n%s\n\n\n&apos; % ( host, traceback.format_exc() ) ) pr(run(sys.argv[1])) flog.close()]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[adaptor]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F08%2F01%2Fadaptor%2F</url>
    <content type="text"><![CDATA[直接看代码吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778# -*- coding: utf-8 -*-class OldCourse(object): """ 老的课程类 """ def show(self): """ 显示关于本课程的所有信息 """ print("show description") print("show teacher of course") print("show labs")class Page(object): """ 使用课程对象的客户端 """ def __init__(self, course): self.course = course def render(self): self.course.show()class NewCourse(object): """ 新的课程类, 为了模块化显示课程信息，实现了新的课程类 """ def show_desc(self): """ 显示描述信息 """ print("show description") def show_teacher(self): """ 显示老师信息 """ print("show teacher of course") def show_labs(self): """ 显示实验 """ print("show labs")class Adapter(object): """ 适配器, 尽管实现了新的课程类，但是在很多代码中还是需要使用 OldCourse.show() 方法 """ def __init__(self, course): self.course = course def show(self): """ 适配方法，调用真正的操作 """ self.course.show_desc() self.course.show_teacher() self.course.show_labs()if __name__ == '__main__': old_course = OldCourse() page = Page(old_course) page.render() print("") new_course = NewCourse() # 新课程类没有 show 方法，我们需要使用适配器进行适配 adapter = Adapter(new_course) page = Page(adapter) page.render()]]></content>
      <categories>
        <category>pattern</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[merge-sort]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F07%2F16%2Fmerge-sort%2F</url>
    <content type="text"><![CDATA[理解不深入的缘故，每次写算法都要对着例子抄。。 12345678910111213141516def mergesort(seq): mid = len(seq) lft, rgt = seq[:mid], seq[mid:] if len(lft) &gt; 1: lft = mergesort(lft) if len(rgt) &gt; 1: rgt = mergesort(rgt) res = [] while lft and rgt: if lft[-1] &gt;= rgt[-1]: res.append(lft.pop()) else: res.append(rgt.pop()) res.reverse() return (lft or rgt) + res 这些都是吃饭的家伙。。]]></content>
      <tags>
        <tag>algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-rest-framework-5]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F07%2F15%2Fdjango-rest-framework-5%2F</url>
    <content type="text"></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django-rest-framework-tutorial-4]]></title>
    <url>%2Fzhangdavids.github.io%2F2017%2F07%2F14%2Fdjango-rest-framework-tutorial-4%2F</url>
    <content type="text"><![CDATA[drf框架教程4（djangorestframework）写在前面在外包的这段日子，不知如何描述滋味，虽然没有网络可以说限制了工作时间逛网页这种，但是自我感觉收获满足不了自己。是时候重新出发了。 工作当中有用到drf框架，在csdn中找到了还不错的中文翻译文档，受益匪浅。想着自己也做一部分翻译的工作。如有错误之处，请多多指教。 额外说明目前版本为 3.6.3 马太胖老师的前三篇翻译 框架github地址 文档地址 认证和权限目前为止，我们的API对谁能够编辑或者删除snippet（代码片段）还没有任何限制。我们将增加一些扩展功能来确保以下： snippets总关联一个创建者 只有认证后的用户才能创建一个snippets 只有创建者才能更新或者删除snippet 非认证的请求只拥有只读的权限 对model做一些修改，增加一个表示创建者，另外增加一个用来存储代码中的HTML高亮。 1234# snippets/models.pyowner = models.ForeignKey('auth.User', related_name='snippets', on_delete=models.CASCADE)highlighted = models.TextField() 另外 我们需要确保模型保存的时候，我们能够生成高亮的字段，这里使用pygments代码高亮库。 1234567891011121314151617from pygments.lexers import get_lexer_by_namefrom pygments.formatters.html import HtmlFormatterfrom pygments import highlightdef save(self, *args, **kwargs): &quot;&quot;&quot; Use the `pygments` library to create a highlighted HTML representation of the code snippet. &quot;&quot;&quot; lexer = get_lexer_by_name(self.language) linenos = self.linenos and &apos;table&apos; or False options = self.title and &#123;&apos;title&apos;: self.title&#125; or &#123;&#125; formatter = HtmlFormatter(style=self.style, linenos=linenos, full=True, **options) self.highlighted = highlight(self.code, lexer, formatter) super(Snippet, self).save(*args, **kwargs) 为用户模型增加endpoints现在我们有一些用户了，我们最好也把用户增加到API上，创建一个新的序列化脚本serializers.py 123456789# snippets/serializers.pyfrom django.contrib.auth.models import Userclass UserSerializer(serializers.ModelSerializer): snippets = serializers.PrimaryKeyRelatedField(many=True, queryset=Snippet.objects.all()) class Meta: model = User fields = (&apos;id&apos;, &apos;username&apos;, &apos;snippets&apos;) 因为snippets和user是反向关联，所以在使用ModelSerializers时不会缺省加入，因此需要显示加入。 我们还需要创建一些对用户呈现而言的views，最好使用只读的view，所以使用ListAPIView和RetrieveAPIView泛型类Views。 123456789101112# snippets/views.pyfrom django.contrib.auth.models import Userclass UserList(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializerclass UserDetail(generics.RetrieveAPIView): queryset = User.objects.all() serializer_class = UserSerializer 确保导入了UserSerializers类 1from snippets.serializers import UserSerializer 修改url 12url(r&apos;^users/$&apos;, views.UserList.as_view()),url(r&apos;^users/(?P&lt;pk&gt;[0-9]+)/$&apos;, views.UserDetail.as_view()), snippets与users关联现在，如果我们创建一个code snippet，还没有方法指定其创建者。User并没有作为序列化内容的一部分发送，而是作为request的一个属性。 这里的处理方法是重载snippet view中的.pre_save()方法，它可以让我们处理request中隐式的信息。 在SnippetList和SnippetDetail的view类中，都需要添加如下的方法： 12def perform_create(self, serializer): serializer.save(owner=self.request.user) 更新序列器现在snippets已经和创建者关联起来了，我们接下来还需要更新SnippetSerializer，在其定义中增加一个新的字段： 1owner = serializers.ReadOnlyField(source=&apos;owner.username&apos;) Note: 确定你在嵌入类Meta的字段列表中也加入了’owner’。 这个字段所做的十分有趣。source参数表明增加一个新字段，可以指定序列化实例任何属性。它可以采用如上的点式表示（dotted notation），这时他可以直接遍历到指定的属性。在Django’s template中使用时，也可以采用类似的方式。 我们增加字段是一个无类型Field类，而我们之前的字段都是有类型的，例如CharField,BooleanFieldetc… 无类型字段总是只读的，它们只用在序列化表示中，而在反序列化时（修改model）不被使用。 给views增加必需的权限现在代码片段 snippets 已经关联了用户，我们需要确保只有认证用户才能增、删、改snippets. REST framework 包括许多权限类可用于view的控制。这里我们使用IsAuthenticatedOrReadOnly, 它可确保认证的request获取read-write权限，而非认证的request只有read-only 权限. 现需要在views模块中增加 import。 from rest_framework import permissions 然后需要在SnippetList和SnippetDetailview类中都增加如下属性： permission_classes = (permissions.IsAuthenticatedOrReadOnly,) 可视化API增加登陆如果你打开浏览器，访问可浏览API，你会发现只有登录后才能创建新的snippet了。 我们可以编辑URLconf来增加一个登录view。首先增加新的import： from django.conf.urls import include 然后，在文件末尾增加一个pattern来为browsable API增加 login 和 logout views. urlpatterns += [ url(r&apos;^api-auth/&apos;, include(&apos;rest_framework.urls&apos;, namespace=&apos;rest_framework&apos;)), ] 具体的，r’^api-auth/‘部分可以用任何你想用的URL来替代。这里唯一的限制就是 urls 必须使用’rest_framework’命名空间。 现在如果你打开浏览器，刷新页面会看到页面右上方的 ‘Login’ 链接。如果你用之前的用户登录后，你就又可以创建 snippets了。 一旦你创建了一些snippets，当导航至’/users/‘时，你会看到在每个user的snippets字段都包含了一系列snippet的pk。 对象级权限我们希望任何人都可以浏览snippets，但只有创建snippet的用户才能编辑或删除它。 为了实现这个需求，我们需要创建定制的权限（custom permission）。 在 snippets 应用中，创建一个新文件：permissions.py 12345678910111213141516from rest_framework import permissionsclass IsOwnerOrReadOnly(permissions.BasePermission): &quot;&quot;&quot; Custom permission to only allow owners of an object to edit it. &quot;&quot;&quot; def has_object_permission(self, request, view, obj): # Read permissions are allowed to any request, # so we&apos;ll always allow GET, HEAD or OPTIONS requests. if request.method in permissions.SAFE_METHODS: return True # Write permissions are only allowed to the owner of the snippet. return obj.owner == request.user 现在我们可以为snippet实例增加定制权限了，需要编辑SnippetDetail 类的permission_classes属性： permission_classes = (permissions.IsAuthenticatedOrReadOnly, IsOwnerOrReadOnly,) 别忘了import 这个IsOwnerOrReadOnly类。 from snippets.permissions import IsOwnerOrReadOnly 现在打开浏览器，你可以看见 ‘DELETE’ 和 ‘PUT’ 动作只会出现在那些你的登录用户创建的snippet页面上了. 通过API验证我们已经有了一系列的权限，如果我们需要编辑任何snippet，我们需要认证我们的request。因为我们还没有建立任何authentication classes, 所以目前是默认的SessionAuthentication和BasicAuthentication在起作用。 当我们通过Web浏览器与API互动时，我们登录后、然后浏览器session可以为所有的request提供所需的验证。 如果我们使用程序访问这些API，我们则需要显式的为每个request提供认证凭证（authentication credentials）。 如果我们试图未认证就创建一个snippet，将得到错误如下： 12345http POST http://127.0.0.1:8000/snippets/ code="print 123"&#123; "detail": "Authentication credentials were not provided."&#125; 如果我们带着用户名和密码来请求时则可以成功创建： 1234567891011http -a tom:password123 POST http://127.0.0.1:8000/snippets/ code="print 789"&#123; "id": 1, "owner": "tom", "title": "foo", "code": "print 789", "linenos": false, "language": "python", "style": "friendly"&#125; 我们已经为我们的Web API创建了相当细粒度的权限控制和相应的系统用户。 在教程第5部分part 5，我们将把所有的内容串联起来，为我们的高亮代码片段创建HTML节点，并利用系统内的超链接关联来提升API的一致性表现。]]></content>
      <categories>
        <category>web</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[a-gem-named-faraday]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F11%2F24%2Fa-gem-named-faraday%2F</url>
    <content type="text"><![CDATA[每天有各种繁琐事情，让自己有借口不写东西。尝试每天写点小东西，比如推荐一个库之类的。今天推荐faraday，这是一个ruby的库。 12345678conn = Faraday.new(:url =&gt; 'https://github.com') do |faraday| faraday.request :url_encoded # form-encode POST params faraday.response :logger # log requests to STDOUT faraday.adapter Faraday.default_adapter # make requests with Net::HTTPendresponse = conn.getputs response.status # 200 例子应该好懂，get post都有，详细咨询github =^_^=]]></content>
      <categories>
        <category>ruby</category>
      </categories>
      <tags>
        <tag>ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how-to-use-awk]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F09%2F25%2Fhow-to-use-awk%2F</url>
    <content type="text"><![CDATA[说起linux下的几个用的人不多的上古神器，基本会想到sed awk，这里先总结下awk的用法。 直接上实例吧 1234567891011121314151617181920$ cat netstat.txtProto Recv-Q Send-Q Local-Address Foreign-Address Statetcp 0 0 0.0.0.0:3306 0.0.0.0:* LISTENtcp 0 0 0.0.0.0:80 0.0.0.0:* LISTENtcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTENtcp 0 0 coolshell.cn:80 124.205.5.146:18245 TIME_WAITtcp 0 0 coolshell.cn:80 61.140.101.185:37538 FIN_WAIT2tcp 0 0 coolshell.cn:80 110.194.134.189:1032 ESTABLISHEDtcp 0 0 coolshell.cn:80 123.169.124.111:49809 ESTABLISHEDtcp 0 0 coolshell.cn:80 116.234.127.77:11502 FIN_WAIT2tcp 0 0 coolshell.cn:80 123.169.124.111:49829 ESTABLISHEDtcp 0 0 coolshell.cn:80 183.60.215.36:36970 TIME_WAITtcp 0 4166 coolshell.cn:80 61.148.242.38:30901 ESTABLISHEDtcp 0 1 coolshell.cn:80 124.152.181.209:26825 FIN_WAIT1tcp 0 0 coolshell.cn:80 110.194.134.189:4796 ESTABLISHEDtcp 0 0 coolshell.cn:80 183.60.212.163:51082 TIME_WAITtcp 0 1 coolshell.cn:80 208.115.113.92:50601 LAST_ACKtcp 0 0 coolshell.cn:80 123.169.124.111:49840 ESTABLISHEDtcp 0 0 coolshell.cn:80 117.136.20.85:50025 FIN_WAIT2tcp 0 0 :::22 :::* LISTEN 从netstat命令中提取了如上信息作为用例 输出第1列和第4例 1awk '&#123;print $1, $4&#125;' netstat.txt 其中单引号中的被大括号括着的就是awk的语句，注意，其只能被单引号包含。 其中的$1..$n表示第几例。注：$0表示整个行。 再来看看awk的格式化输出，和C语言的printf没什么两样： 1awk '&#123;printf "%-8s %-8s %-8s %-18s %-22s %-15s\n",$1,$2,$3,$4,$5,$6&#125;' netstat.txt 再来看看如何过滤记录（下面过滤条件为：第三列的值为0 &amp;&amp; 第6列的值为LISTEN） 1awk '$3==0 &amp;&amp; $6=="LISTEN" ' netstat.txt 其中的“==”为比较运算符。其他比较运算符：!=, &gt;, &lt;, &gt;=, &lt;= 我们来看看各种过滤记录的方式： 1awk ' $3&gt;0 &#123;print $0&#125;' netstat.txt 需要表头的话，我们可以引入内建变量NR： 1awk '$3==0 &amp;&amp; $6=="LISTEN" || NR==1 ' netstat.txt 加上格式化输出： 1awk '$3==0 &amp;&amp; $6=="LISTEN" || NR==1 &#123;printf "%-20s %-20s %s\n",$4,$5,$6&#125;' netstat.txt 说到了内建变量，我们可以来看看awk的一些内建变量： 变量 含义 $0 当前记录（这个变量中存放着整个行的内容） $1~$n 当前记录的第n个字段，字段间由FS分隔 FS 输入字段分隔符 默认是空格或Tab NF 当前记录中的字段个数，就是有多少列 NR 已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 FNR 当前记录数，与NR不同的是，这个值会是各个文件自己的行号 RS 输入的记录分隔符， 默认为换行符 OFS 输出字段分隔符， 默认也是空格 ORS 输出的记录分隔符，默认为换行符 FILENAME 当前输入文件的名字 如果要输出行号： 1awk '$3==0 &amp;&amp; $6=="ESTABLISHED" || NR==1 &#123;printf "%02s %s %-20s %-20s %s\n",NR, FNR, $4,$5,$6&#125;' netstat.txt 未完待续]]></content>
  </entry>
  <entry>
    <title><![CDATA[how-to-use-sed-in-linux]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F08%2F08%2Fhow-to-use-sed-in-linux%2F</url>
    <content type="text"><![CDATA[sed是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作，下面先了解一下sed的用法sed命令行格式为： sed [-nefri] ‘command’ 输入文本 常用选项： -n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。 -e∶直接在指令列模式上进行 sed 的动作编辑； -f∶直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作； -r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法) -i∶直接修改读取的档案内容，而不是由萤幕输出。 常用命令： a ∶新增， a 的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)～ c ∶取代， c 的后面可以接字串，这些字串可以取代 n1,n2 之间的行！ d ∶删除，因为是删除啊，所以 d 后面通常不接任何咚咚； i ∶插入， i 的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)； p ∶列印，亦即将某个选择的资料印出。通常 p 会与参数 sed -n 一起运作～ s ∶取代，可以直接进行取代的工作哩！通常这个 s 的动作可以搭配正规表示法！例如 1,20s/old/new/g 就是啦！ 举例：（假设我们有一文件名为ab） 删除某行 [root@localhost ruby] # sed &apos;1d&apos; ab #删除第一行 [root@localhost ruby] # sed &apos;$d&apos; ab #删除最后一行 [root@localhost ruby] # sed &apos;1,2d&apos; ab #删除第一行到第二行 [root@localhost ruby] # sed &apos;2,$d&apos; ab #删除第二行到最后一行 显示某行 [root@localhost ruby] # sed -n &apos;1p&apos; ab #显示第一行 [root@localhost ruby] # sed -n &apos;$p&apos; ab #显示最后一行 [root@localhost ruby] # sed -n &apos;1,2p&apos; ab #显示第一行到第二行 [root@localhost ruby] # sed -n &apos;2,$p&apos; ab #显示第二行到最后一行 使用模式进行查询 [root@localhost ruby] # sed -n &apos;/ruby/p&apos; ab #查询包括关键字ruby所在所有行 [root@localhost ruby] # sed -n &apos;/\$/p&apos; ab #查询包括关键字$所在所有行，使用反斜线\屏蔽特殊含义 增加一行或多行字符串 [root@localhost ruby]# cat ab Hello! ruby is me,welcome to my blog. end [root@localhost ruby] # sed ‘1a drink tea’ ab #第一行后增加字符串”drink tea” Hello! drink tea ruby is me,welcome to my blog. end [root@localhost ruby] # sed ‘1,3a drink tea’ ab #第一行到第三行后增加字符串”drink tea” Hello! drink tea ruby is me,welcome to my blog. drink tea end drink tea [root@localhost ruby] # sed ‘1a drink tea\nor coffee’ ab #第一行后增加多行，使用换行符\n Hello! drink tea or coffee ruby is me,welcome to my blog. end 代替一行或多行 [root@localhost ruby] # sed ‘1c Hi’ ab #第一行代替为Hi Hi ruby is me,welcome to my blog. end [root@localhost ruby] # sed ‘1,2c Hi’ ab #第一行到第二行代替为Hi Hi end 替换一行中的某部分 格式：sed ‘s/要替换的字符串/新的字符串/g’ （要替换的字符串可以用正则表达式） [root@localhost ruby] # sed -n ‘/ruby/p’ ab | sed ‘s/ruby/bird/g’ #替换ruby为bird [root@localhost ruby] # sed -n ‘/ruby/p’ ab | sed ‘s/ruby//g’ #删除ruby 插入 [root@localhost ruby] # sed -i &apos;$a bye&apos; ab #在文件ab中最后一行直接输入&quot;bye&quot; [root@localhost ruby]# cat ab Hello! ruby is me,welcome to my blog. end bye 删除匹配行 sed -i &apos;/匹配字符串/d&apos; filename （注：若匹配字符串是变量，则需要“”，而不是‘’。记得好像是） 替换匹配行中的某个字符串 sed -i &apos;/匹配字符串/s/替换源字符串/替换目标字符串/g&apos; filename]]></content>
  </entry>
  <entry>
    <title><![CDATA[为何你学不好高等数学]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F24%2F%E4%B8%BA%E4%BD%95%E4%BD%A0%E5%AD%A6%E4%B8%8D%E5%A5%BD%E9%AB%98%E7%AD%89%E6%95%B0%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[今天看到一篇文章，很有感悟，顺笔就写点东西。 Google的I/O大会之后，“AI将无处不在，智能将无处不在”。 数据分析， 人工智能， 图像识别等趋势， 不彻底学习线性代数 信号处理 算法导论（特别重要，以前看的时候感觉有些算法就是没事找事），是无法应付的。 为什么学得不好，我前段时间看《射雕英雄传》的时候， 刚好看到郭靖在江南七怪的教导下，武功没长进，全真道长说了十个字“教而不得法，学而不得道”。这里并不是指责说大学的老师没有良好的教授方法，主要还是自己学不知其所以然。。 这里的高等数学当然是包括 微积分 线性代数 概率统计。 《程序员的数学－－线性代数》这本书，综述里有一句话。 m＊n的矩阵A， 表示了从n维空间到m维空间的“映射”。具体来说就是，把n维空间中的点x（n维列向量）变换到m维空间的点（m维列向量）Ax的映射。 为什么要引入矩阵，矩阵是用来做空间变换的，矩阵是一种映射，所以要学习好矩阵的乘积。 行列式＝对角线元素的乘积，但是行列式有什么意义呢？为什么对角矩阵如何特殊，要拿出来单独讲呢？ 书中以“空间变换”的角度进行了解释。一个n维向量乘以一个n＊n的对角矩阵，实际上就是把对角矩阵中的各个值直接乘到了n维向量的对应的值上，也就是对n维空间的各个维度进行了系度拉伸。那么这些对角元素的乘积，实际上是这个矩阵变换給n维空间带来的体积变化的倍数。（n维空间体积＝第一维长度＊第二维长度……＊第n维长度）行列式的值是空间体积变化的倍数！！ 接着有网友表示，他的线性代数，是看了mit的公开课才明白的，:),你感觉学的那些貌似没啥意义，自然也没有足够的兴趣，自然也学不好，线性代数教給我们的是一种方法，我们需要从更高级的学科中重新思考过它，才能看明白数学现象的本质。]]></content>
      <categories>
        <category>data</category>
      </categories>
      <tags>
        <tag>data</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R实战0-数据处理难题的一套解决方案]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F24%2FR%E5%AE%9E%E6%88%980-%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%9A%BE%E9%A2%98%E7%9A%84%E4%B8%80%E5%A5%97%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[对数据的处理现在普遍就是两种方案，python 或者 R。 一组学生参加了数学 科学和英语的考试。考试完成之后，需要給学生确定一个成绩衡量指标。会把综合成绩的前20%评定为A，接着是B C D F。可以看到数据处理的一个障碍，三科成绩无法比较，或者说比较没有意义。。:) 当然有人认为可以这么处理，比如知道数学的总分是700，将成绩全部换为以100分为计量单位的。。当然英语也是，，计总分为50分，换成对应100的来处理。。。 也许吧，可以试试 :) 在这我们使用R来进行处理。 根据原始的学生花名册将数据采集进去，自然是选择数据框的格式。 12345678options(digits = 2)stduent &lt;- c("John Davis", "Angela Willams", "Bully Moose", "David Jones", "Janice Markhammer", "Cherry Cushing", "Reuven Ytzrhak", "Greg Knox", "Joel England", "Mary Rayburn")Math &lt;- c(502, 600, 412, 358, 495, 512, 410, 625, 573, 522)Science &lt;- c(95, 99, 80, 82, 75, 85, 80, 95, 89, 86)English &lt;- c(25, 22, 18, 15, 20, 28, 15, 30, 27, 18)roster &lt;- data.frame(stduent, Math, Science, English, stringsAsFactors = FALSE)roster we get 12345678910111213&gt; roster stduent Math Science English1 John Davis 502 95 252 Angela Willams 600 99 223 Bully Moose 412 80 184 David Jones 358 82 155 Janice Markhammer 495 75 206 Cherry Cushing 512 85 287 Reuven Ytzrhak 410 80 158 Greg Knox 625 95 309 Joel England 573 89 2710 Mary Rayburn 522 86 18 这里有两个细节没有注意。。一个是刚好十个学生；另外一个是貌似student单词貌似拼写错了。。 由于三科考试的分值不同，如何让它们变得可以进行比较。一种方式是将数据进行标准化，使用单位标准差来表示，这个过程使用scale（）函数来实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960z &lt;- scale(roster[,2:4]) ``` we get ```Rz Math Science English [1,] 0.013 1.078 0.587 [2,] 1.143 1.591 0.037 [3,] -1.026 -0.847 -0.697 [4,] -1.649 -0.590 -1.247 [5,] -0.068 -1.489 -0.330 [6,] 0.128 -0.205 1.137 [7,] -1.049 -0.847 -1.247 [8,] 1.432 1.078 1.504 [9,] 0.832 0.308 0.954[10,] 0.243 -0.077 -0.697attr(,"scaled:center") Math Science English 501 87 22 attr(,"scaled:scale") Math Science English 86.7 7.8 5.5 ``` - 使用mean（）函数计算各行的均值来获得综合得分，并且使用函数cbind（）函数将其添加到花名册当中。```Rscore &lt;- apply(z, 1, mean)roster &lt;- cbind(roster, score)``` 计算均值之后，并把score分数加进去。 - 函数quantile（）给出学生综合得分的百分位数。 这个函数可以综合得分的百分位数 ```Ry &lt;- quantile(score, c(.8, .6, .4, .2))``` - 使用逻辑运算符，重编码为A B C D F。 ```Rroster$grade[score &gt;= y[1]] &lt;- "A"roster$grade[score &lt;= y[1] &amp; score &gt;=y[2]] &lt;- "B"roster$grade[score &lt;= y[2] &amp; score &gt;=y[3]] &lt;- "C"roster$grade[score &lt;= y[3] &amp; score &gt;=y[4]] &lt;- "D"roster$grade[score &lt;= y[4]] &lt;- "F"``` - 使用函数strsplit（）以空格为界，将学生姓名拆分为姓和名。 name &lt;- strsplit((roster$stduent), “ “) 12345注意返回的是什么值，这里是列表！！ - 使用函数sapply（）提取列表元素。 lastname &lt;- sapply(name, “[“, 2)firstname &lt;- sapply(name, “[“, 1)roster &lt;- cbind(firstname, lastname, roster[, -1]) 123将原来的student化成两列，一列是姓，一列是名，同时也将student列舍弃掉。 - 使用order（）函数依据姓氏和名字对数据集进行排序 roster &lt;- roster[order(lastname, firstname),]roster 12finally we get roster firstname lastname Math Science English score grade6 Cherry Cushing 512 85 28 0.35 C1 John Davis 502 95 25 0.56 B9 Joel England 573 89 27 0.70 B4 David Jones 358 82 15 -1.16 F8 Greg Knox 625 95 30 1.34 A5 Janice Markhammer 495 75 20 -0.63 D3 Bully Moose 412 80 18 -0.86 D10 Mary Rayburn 522 86 18 -0.18 C2 Angela Willams 600 99 22 0.92 A7 Reuven Ytzrhak 410 80 15 -1.05 F ``` Done!!!!!!]]></content>
  </entry>
  <entry>
    <title><![CDATA[scrapy爬虫实践详解]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F19%2Fscrapy%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[爬虫框架里最出色的的的确确还是Scrapy。 Scrapy是Python开发的一个快速,高层次的屏幕抓取和Web抓取框架，用于抓取Web站点并从页面中提取结构化的数据。 下图展示了Scrapy的大致架构，其中包含了主要组件和系统的数据处理流程（绿色箭头表示）。下面会对组件和流程进行了一个简单的解释。 ##来看看图中的组件 1.Scrapy Engine（Scrapy引擎） Scrapy引擎是用来控制整个系统的数据处理流程，并进行事务处理的触发。更多的详细内容可以看下面的数据处理流程。 2.Scheduler（调度程序） 调度程序从Scrapy引擎接受请求并排序列入队列，并在Scrapy引擎发出请求后返还给它们。 3.Downloader（下载器） 下载器的主要职责是抓取网页并将网页内容返还给蜘蛛（Spiders）。 4.Spiders（蜘蛛） 蜘蛛是有Scrapy用户自己定义用来解析网页并抓取制定URL返回的内容的类，每个蜘蛛都能处理一个域名或一组域名。换句话说就是用来定义特定网站的抓取和解析规则。 5.Item Pipeline（项目管道） 项目管道的主要责任是负责处理有蜘蛛从网页中抽取的项目，它的主要任务是清晰、验证和存储数据。当页面被蜘蛛解析后，将被发送到项目管道，并经过几个特定的次序处理数据。每个项目管道的组件都是有一个简单的方法组成的Python类。它们获取了项目并执行它们的方法，同时还需要确定的是是否需要在项目管道中继续执行下一步或是直接丢弃掉不处理。 项目管道通常执行的过程有： 清洗HTML数据 验证解析到的数据（检查项目是否包含必要的字段） 检查是否是重复数据（如果重复就删除） 将解析到的数据存储到数据库中 6.Middlewares（中间件） 中间件是介于Scrapy引擎和其他组件之间的一个钩子框架，主要是为了提供一个自定义的代码来拓展Scrapy的功能。 ##数据的处理流程 Scrapy的整个数据处理流程有Scrapy引擎进行控制，其主要的运行方式为： 引擎打开一个域名，时蜘蛛处理这个域名，并让蜘蛛获取第一个爬取的URL。 引擎从蜘蛛那获取第一个需要爬取的URL，然后作为请求在调度中进行调度。 引擎从调度那获取接下来进行爬取的页面。 调度将下一个爬取的URL返回给引擎，引擎将它们通过下载中间件发送到下载器。 当网页被下载器下载完成以后，响应内容通过下载中间件被发送到引擎。 引擎收到下载器的响应并将它通过蜘蛛中间件发送到蜘蛛进行处理。 蜘蛛处理响应并返回爬取到的项目，然后给引擎发送新的请求。 引擎将抓取到的项目项目管道，并向调度发送请求。 系统重复第二步后面的操作，直到调度中没有请求，然后断开引擎与域之间的联系。 ##新建工程 scrapy startproject doubanmovie 目录就不详细再说了。 ##定义项目（Item） 1234567891011# _*_ coding=utf-8 _*_ from scrapy.item import Item, Fieldclass DoubanmovieItem(Item): name = Field()#电影名 year = Field()#上映年份 score = Field()#豆瓣分数 director = Field()#导演 classification = Field()#分类 actor = Field()#演员 这个地方只是需要相应添加需要的字段。 ##编写爬虫 （spiders） Spider是整个项目中最核心的类，在这个类中我们需要定义抓取对象（url 域名）以及抓取规则。 scrapy官方文档中的教程是基于BaseSpider的，但是这个只能爬取给定的url，无法根据一个初始的url向外扩展。还有scrapy.contrib.spiders.CrawlSpider可以使用。 在doubanmovie/spiders目录下新建movie_spider.py文件，并填写代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122# -*- coding: utf-8 -*-from scrapy.selector import Selectorfrom scrapy.contrib.spiders import CrawlSpider,Rulefrom scrapy.contrib.linkextractors.sgml import SgmlLinkExtractorfrom doubanmovie.items import DoubanmovieItemclass movieSpider(CrawlSpider): name="doubanmovie" allowed_domains=["movie.douban.com"] start_urls=["https://movie.douban.com/top250"] rules=[ Rule(SgmlLinkExtractor(allow=(r'https://movie.douban.com/top250\?start=\d+.*'))), Rule(SgmlLinkExtractor(allow=(r'https://movie.douban.com/subject/\d+')),callback="parse_item"), ] def parse_item(self,response): sel=Selector(response) item=DoubanmovieItem() item['name']=sel.xpath('//*[@id="content"]/h1/span[1]/text()').extract() item['year']=sel.xpath('//*[@id="content"]/h1/span[2]/text()').re(r'\((\d+)\)') item['score']=sel.xpath('//*[@id="interest_sectl"]/div[1]/div[2]/strong/text()').extract() item['director']=sel.xpath('//*[@id="info"]/span[1]/span[2]/a/text()').extract() item['classification']= sel.xpath('//span[@property="v:genre"]/text()').extract() item['actor']= sel.xpath('//*[@id="info"]/span[3]/a[1]/text()').extract() return item``` 首先是`name` 这个是定义spider名字的字符串，必须的。 接着是`allowed_domains` 包含了spider允许爬取的域名（domain）列表（list），可选。 `start_urls` URL列表。当没有制定特定的URL时，spider将从该列表中开始进行爬取。 因此，第一个被获取到的页面的URL将是该列表之一。 后续的URL将会从获取到的数据中提取。 `rules` 一个包含一个(或多个) Rule 对象的集合(list)。 每个 Rule 对爬取网站的动作定义了特定表现。 Rule对象在下边会介绍。 如果多个rule匹配了相同的链接，则根据他们在本属性中被定义的顺序，第一个会被使用。 然后就是使用xpath从网页从抽取出来item，这里是较为重要的部分，一定要搞清楚抓取的item是什么类型的，要做哪些处理放入字典当中去。 这个需要不断尝试，耐心调试下 ![shell 调试](http://o7b8j5zne.bkt.clouddn.com/shell%E8%B0%83%E8%AF%95.png) scrapy shell （domains） Scrapy 使用一种叫做 XPath selectors的机制，它基于 XPath表达式。如果你想了解更多selectors和其他机制可以查阅资料[官网](http://doc.scrapy.org/topics/selectors.html#topics-selectors ) 这是一些XPath表达式的例子和他们的含义 为了方便使用XPaths，Scrapy提供XPathSelector 类， 有两种口味可以选择， HtmlXPathSelector (HTML数据解析) 和XmlXPathSelector (XML数据解析)。 为了使用他们你必须通过一个 Response 对象对他们进行实例化操作。你会发现Selector对象展示了文档的节点结构。因此，第一个实例化的selector必与根节点或者是整个目录有关 。 Selectors 有三种方法path()：返回selectors列表, 每一个select表示一个xpath参数表达式选择的节点. extract()：返回一个unicode字符串，该字符串为XPath选择器返回的数据 re()： 返回unicode字符串列表，字符串作为参数由正则表达式提取出来 ##管道文件 （pipeline） ```python # -*- coding: utf-8 -*-import pymongofrom scrapy.exceptions import DropItemfrom scrapy.conf import settingsfrom scrapy import log#Connect to the MongoDB databaseclient = pymongo.MongoClient()db = client['pythontest']item_info = db['mydouban']class MongoDBPipeline(object): def process_item(self, item, spider): #Remove invalid data valid = True for data in item: if not data: valid = False raise DropItem("Missing %s of blogpost from %s" %(data, item['url'])) if valid: #Insert data into database new_movie = &#123; "name":item['name'][0], "year":item['year'][0], "score":item['score'][0], "director":item['director'], "classification":item['classification'], "actor":item['actor'] &#125; item_info.insert_one(new_movie) log.msg("Item wrote to MongoDB database %s/%s" % ('pythontest', 'mydouban'), level=log.DEBUG, spider=spider) return item ``` 爬虫获取到数据以后我们需要将其存储到数据库中，之前我们提到该操作需要靠项目管道（pipeline）来处理，其通常执行的操作为：清洗HTML数据 验证解析到的数据（检查项目是否包含必要的字段） 检查是否是重复数据（如果重复就删除） 将解析到的数据存储到数据库中 这里考虑数据的复杂性，使用mongodb数据库来存储。##配置文件（settings） ```pythonBOT_NAME = 'doubanmovie'SPIDER_MODULES = ['doubanmovie.spiders']NEWSPIDER_MODULE = 'doubanmovie.spiders'ITEM_PIPELINES=&#123; 'doubanmovie.pipelines.MongoDBPipeline':300,&#125;LOG_LEVEL='DEBUG'DOWNLOAD_DELAY = 2RANDOMIZE_DOWNLOAD_DELAY = TrueUSER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/536.5 (KHTML, like Gecko) Chrome/19.0.1084.54 Safari/536.5'COOKIES_ENABLED = True 在settings.py里设置一些信息。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python实战之django小试]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8Bdjango%E5%B0%8F%E8%AF%95%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python实战之使用webpy构建小型电影网站]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8B%E4%BD%BF%E7%94%A8webpy%E6%9E%84%E5%BB%BA%E5%B0%8F%E5%9E%8B%E7%94%B5%E5%BD%B1%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python实战之六抓取58同城数据]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8B%E5%85%AD%E6%8A%93%E5%8F%9658%E5%90%8C%E5%9F%8E%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[python实战之五推特数据流分析]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8B%E4%BA%94%E6%8E%A8%E7%89%B9%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[一直想着能够从twitter获取一些数据来做些分析。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python实战之四使用tushare包]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8B%E5%9B%9B%E4%BD%BF%E7%94%A8tushare%E5%8C%85%2F</url>
    <content type="text"><![CDATA[tushare是比较著名的金融财经的包。通过pip安装tushare包之后，直接就可以调用 import tushare as ts df = ts.get_sina_dd(&apos;600848&apos;, date=&apos;2015-12-24&apos;, vol=500) #指定大于等于500手的数据 数据是直接dataframe，比较方便存储。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python实战之三读取大文件]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8B%E4%B8%89%E8%AF%BB%E5%8F%96%E5%A4%A7%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[这篇呢，就是如何来读取一个大型的excel表格，考虑文件大小在500M以上的这种如何进行读取和分析。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python实战之二发送微博]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8B%E4%BA%8C%E5%8F%91%E9%80%81%E5%BE%AE%E5%8D%9A%2F</url>
    <content type="text"><![CDATA[python能不能发微博呢？ 我们知道很多应用都有开发者平台，只要成为开发者，就可以调用其中的数据。当然初级的开发者调用的次数等都有限制。 廖雪峰老师开发了weibo的python sdk直接安装一下就好 ##代码预览 #!/usr/bin/env python # _*_ coding: utf-8 _*_ from weibo import APIClient APP_KEY = '2234125265' # app key APP_SECRET = '******' # app secret CALLBACK_URL = 'https://api.weibo.com/oauth2/default.html' # callback url 授权回调页,与OAuth2.0 授权设置的一致 def press_sina_weibo(): client = APIClient(app_key=APP_KEY, app_secret=APP_SECRET, redirect_uri=CALLBACK_URL) print client.get_authorize_url() r = client.request_access_token(raw_input("input code:").strip()) client.set_access_token(r.access_token, r.expires_in) print client.post.statuses__update(status=u'这是来自ipad pro客户端的微博信息') #print client.statuses.user_timeline.get() if __name__ == '__main__': press_sina_weibo() 这里不太方便的是需要手动输入下参数进去。看过一些sina的官方开发者文档，感觉限制很多的，也试过尝试一些开发者开源项目爬取微博，导致微博被盗。。 文档很重要，还可能思维方面与国外人差异有点大 ，跟不上，看全英文的又吃力。。。]]></content>
  </entry>
  <entry>
    <title><![CDATA[实战项目之爬取ganji网]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2F%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E4%B9%8B%E7%88%AC%E5%8F%96ganji%E7%BD%91%2F</url>
    <content type="text"><![CDATA[爬取分类信息网站龙头 ganji网。 首先呢，来看看结构 我们需要来看看首页那里的所有类目，里面包含20项基本上所有的帖子都会被分类在这20个下方，根据时间被分配不同的id，像这样http://bj.ganji.com/ershoubijibendiannao/2111373477x.htm当然后面加了个x。。。 第一步先把这20个类目的地址爬取出来。 from bs4 import BeautifulSoup import requests start_url = 'http://bj.ganji.com/wu/' url_host = 'http://bj.ganji.com' def get_index_url(url): # url = start_url wb_data = requests.get(url) soup = BeautifulSoup(wb_data.text, 'lxml') links = soup.select('.fenlei &gt; dt &gt; a') for link in links: page_url = url_host + link.get('href') print(page_url) get_index_url(start_url) 程序的运行结果是20个链接， http://bj.ganji.com/jiaju/ http://bj.ganji.com/rirongbaihuo/ http://bj.ganji.com/shouji/ http://bj.ganji.com/shoujihaoma/ http://bj.ganji.com/bangong/ http://bj.ganji.com/nongyongpin/ http://bj.ganji.com/jiadian/ http://bj.ganji.com/ershoubijibendiannao/ http://bj.ganji.com/ruanjiantushu/ http://bj.ganji.com/yingyouyunfu/ http://bj.ganji.com/diannao/ http://bj.ganji.com/xianzhilipin/ http://bj.ganji.com/fushixiaobaxuemao/ http://bj.ganji.com/meironghuazhuang/ http://bj.ganji.com/shuma/ http://bj.ganji.com/laonianyongpin/ http://bj.ganji.com/xuniwupin/ http://bj.ganji.com/qitawupin/ http://bj.ganji.com/ershoufree/ http://bj.ganji.com/wupinjiaohuan/ 把这20个链接放入程序中，成为channel_list。这也就是我们的第一个小程序 channel_extracing.py。 第二步从大的分类下获取单个帖子的链接，先来分析下页面结构， 以二手笔记本电脑为例，可以看到后面结构为o＋page，这里o代表的是个人发布的，后面是page。那么首先考虑的是构造一个爬虫来抓取links # spider 1 def get_links_from(channel, pages, who_sells='o'): # http://bj.ganji.com/ershoubijibendiannao/o3/ # o for personal a for merchant list_view = '{}{}{}/'.format(channel, str(who_sells), str(pages)) wb_data = requests.get(list_view,headers=headers,proxies=proxies) soup = BeautifulSoup(wb_data.text, 'lxml') if soup.find('ul', 'pageLink'): for link in soup.select('dd.feature div ul li a'): item_link = link.get('href') if item_link != "javascript:": url_list.insert_one({'url': item_link}) print(item_link) # return urls else: # It's the last page ! pass 这里注意一下加了一个判断，判断这一页不是最后一页，就是看下方有无pageLink，俗称也就是翻页器类似的，还有就是直接加上了headers部分和proxy部分反爬取。 函数的结果是urls，并考虑使用mongo数据库来存储这个url_list。 接下来就是访问单个的url来抓取里面的数据信息了。 # spider 2 def get_item_info_from(url,data=None): wb_data = requests.get(url,headers=headers) if wb_data.status_code == 404: pass else: soup = BeautifulSoup(wb_data.text, 'lxml') data = { 'title':soup.title.text.strip(), 'price':soup.select('.f22.fc-orange.f-type')[0].text.strip(), 'pub_date':soup.select('.pr-5')[0].text.strip().split(' ')[0], 'area':list(map(lambda x:x.text,soup.select('ul.det-infor &gt; li:nth-of-type(3) &gt; a'))), 'cates':list(soup.select('ul.det-infor &gt; li:nth-of-type(1) &gt; span')[0].stripped_strings), 'url':url } print(data) item_info.insert_one(data) 看图，单个页面我们考虑抓取，标题title 价格price 发布时间pub_data 交易地点area 类型cates 另外再考虑把url也加入里面。大概先这样咯。 把程序组织一下 组成第二个py程序 page_parsing.py当然详情页抓取的数据我们也放到mongo的数据库中。 到这里初步小结一下，实现了哪些呢？先是从ganji的首页获取分类，20个分类然后在这20个分类下，获取单个帖子的详情页，然后通过详情页去抓取想要的数据。爬取的初步流程完成了，接下来就是包装，写个主函数，定义下我们抓取多少页的大分类，先url_list然后item_info都存入到mongo的数据库中。ps 考虑写一个计数的函数观察我们抓取的信息数目。 第三步主函数的分析 from multiprocessing import Pool from page_parsing import get_item_info_from,url_list,item_info,get_links_from from channel_extracing import channel_list 也就是前面的两个函数，我们实现了几个功能： channel_list两个方法 get_item_info_from get_links_from两个mongo数据库的collections url_list item_info 另外这里使用多进程来加快抓取的速度 def get_all_links_from(channel): for i in range(1,100): get_links_from(channel,i) 注意前面定义的函数我们定义了页面，这里抓取1-99页，当然也许部分分类商品多，99不足，部分分类商品不是很多，我们也已经有判断会pass掉。。 if __name__ == '__main__': pool = Pool(processes=6) # pool = Pool() pool.map(get_all_links_from,channel_list.split()) pool.close() pool.join() 开6个进程进行爬爬爬，先存url，再根据url访问抓取。 第四步写上一个计数的函数，这样可以在运行main函数存入数据库时并打印链接的同时，统计已经写了多少数据进去。 import time from page_parsing import url_list while True: print(url_list.find().count()) time.sleep(5) 最后附上项目github地址 项目地址]]></content>
      <categories>
        <category>pachong</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python实战之一发送电子邮件]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F17%2Fpython%E5%AE%9E%E6%88%98%E4%B9%8B%E4%B8%80%E5%8F%91%E9%80%81%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[把曾经做过的东西做下小结吧。如何来使用python发送电子邮件呢？ 一般而言，官方提供的思路就是使用smtplib包，但是实现起来个人感觉还是稍显复杂，需要按照要求书写好多比如smtp mime 手动添加邮件头，还需要一些email标准的某些知识。like this： 123456789101112131415161718192021222324252627282930313233343536373839#!/usr/bin/python#-*- coding: utf-8 -*-import smtplibfrom email.mime.text import MIMETextfrom email.mime.multipart import MIMEMultipartfrom email.header import Headersender = &apos;z.j19910903@163.com&apos;# 发件人to = [&quot;815012839@qq.com&quot;, &quot;a@qq.com&quot;] # 多个收件人的写法subject = &apos;From Python Email test&apos;# 邮件主题smtpserver = &apos;smtp.163.com&apos;# smtp服务器username = &apos;z.j19910903&apos;# 发件人邮箱用户名password = &apos;******&apos;# 发件人邮箱密码mail_postfix = &apos;163.com&apos;contents = &apos;这是一个Python的邮件，收到请勿回复，谢谢！！&apos;def send_mail(to_list, sub, content): me = sender msg = MIMEText(content, _subtype=&apos;plain&apos;, _charset=&apos;utf-8&apos;) msg[&apos;Subject&apos;] = subject msg[&apos;From&apos;] = me msg[&apos;To&apos;] = &quot;;&quot;.join(to_list) try: server = smtplib.SMTP() server.connect(smtpserver) server.login(username, password) server.sendmail(me, to_list, msg.as_string()) server.close() return True except Exception, e: print str(e) return Falseif __name__ == &apos;__main__&apos;: if send_mail(to, subject, contents): print &quot;邮件发送成功! &quot; else: print &quot;失败!!!&quot; 可能看起来也不是很多，但是还是感觉稍稍有点麻烦。python让人着迷的地方，就是有大量的优秀开发人员开发的各种第三方库，现在我们需要的只是yagmail。 ##yagmail安装不多说，直接pip pip install yagmail 它支持python2.7＋ 使用的话也相对简单 import yagmail yag = yagmail(zhangjohn202@gmail.com,&apos;your2-steppassword&apos;) contents=&apos;i love you more!&apos; yag.send(to=&apos;815012839@qq.com&apos;,subject=&apos;fall love at first sight&apos;,contents=contents) 这里说下，一般的邮箱都是用户名和登录密码，别的邮箱我不知道现在有多少改进，感觉gmail不愧是属于全人类的邮箱，这里采用更为安全的方式来进行登录，两步验证密码。 自然只是最简单的举例，yagmail实现的功能还有富文本邮件 邮件附件以及使用邮件模板这较为常见的三项，详细可以参考yagmail的github主页。]]></content>
  </entry>
  <entry>
    <title><![CDATA[python之数据结构]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F16%2Fpython%E4%B9%8B%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[对于一门语言来说，数据结构是其所有精华的所在，是python开发的基础。对于很多新人来说，就是觉得挺简单的，实际上手还是较困难。 python这里介绍四种数据结构：1.元组2.列表3.字典4.序列 元组tuple是由一系列元素组成的ds，所有元素被包含在一对圆括号中。创建元组时，可以不指定元素个数，但是一旦创建之后，就不能进行任何修改。这里需要注意一下，如果创建的元组只包含一个元素，通常会忽略单元素后的逗号。正确写法如下： tuple = (apple,) print (tuple[0]) print (type(tuple)) 这段代码定义了一个单元素的tuple“apple”，并且类型为。 元组，列表，字典等都是从0开始的，［0］获取的就是第一个元素。 元组创建之后，不能进行修改，也不能进行赋值操作。 元组可以进行负数索引，分片索引，另外元组还可以由其他元组组成，就成了二元元组。 元组的遍历 这里介绍下二元元组的遍历。 for i in tuple: for j in i: print(j) ##列表 列表是方括号。 列表可以实现添加 删除 查找等操作，元素的值可以被修改。 添加使用append（） 还可以考虑insert（），不过insert要指明位置。 删除直接用remove（） pop（）是取出最后一个元素。 列表的使用和元组十分相似，支持负数索引 分片还有多元列表等特性，但是列表中的元素可以进行修改。 列表还可以进行连接操作。一种是extend（）连接两个不同的列表，另外一种是使用运算符“＋”或“＋＝”。 list = [&quot;apple&quot;,&quot;banana&quot;,&quot;orange&quot;,&quot;grape&quot;] print(list.index(&quot;grape&quot;)) print(&quot;orange&quot; in list) 打印索引， 判断orange是否在列表中。 列表排序和反转 list.sort() list.reverse() sort()这个函数，需要仔细说明下，sort（cmp,key=None,reverse=False） 在这和大家分享一下机器学习里的一个案例，看看列表的操作。 统计 Python 中的字数问题在 Python 中实施函数“count_words()”，该函数将字符串“s”和数字“n”用作输入，并返回“s”中“n”个出现频率最高的单词。返回值应该是一个元组列表 - 出现频率最高的“n”个单词及其相应的出现次数“[(, ), (, ), …]”，按出现次数的降序排列。您可以假设所有输入都是小写形式，并且不含标点符号或其他字符（只包含字母和单个分隔空格）。如果出现次数相同，则按字母顺序排列出现次数相同的单词。例如： print count_words(&quot;betty bought a bit of butter but the butter was bitter&quot;,3) Output: [(&apos;butter&apos;, 2), (&apos;a&apos;, 1), (&apos;betty&apos;, 1)] &quot;&quot;&quot;Count words.&quot;&quot;&quot; from collections import Counter from operator import itemgetter def count_words(s, n): &quot;&quot;&quot;Return the n most frequently occuring words in s.&quot;&quot;&quot; cnt = Counter() for word in s.split(&quot; &quot;): cnt[word] += 1 a = cnt.items() b = sorted(a,key=lambda a:a[0],reverse=False) c = sorted(b,key=itemgetter(1),reverse=True) top_n = c[0:n] # TODO: Count the number of occurences of each word in s # TODO: Sort the occurences in descending order (alphabetically in case of ties) # TODO: Return the top n words as a list of tuples (&lt;word&gt;, &lt;count&gt;) return top_n def test_run(): &quot;&quot;&quot;Test count_words() with some inputs.&quot;&quot;&quot; print count_words(&quot;cat bat mat cat bat cat&quot;, 3) print count_words(&quot;betty bought a bit of butter but the butter was bitter&quot;, 3) if __name__ == &apos;__main__&apos;: test_run() 如何来分析这个案例呢？ 首先是定义一个字符串 s＝“betty bought a bit of butter but the butter was bitter” 接着使用文档中提到的collections来处理这个统计 from collections import Counter cnt = Counter() for word in s.split(&quot; &quot;): cnt[word] += 1 这里处理完之后，需要停下来检查一下cnt是啥类型class ‘collections.Counter’ Counter({&apos;butter&apos;: 2, &apos;a&apos;: 1, &apos;bitter&apos;: 1, &apos;of&apos;: 1, &apos;but&apos;: 1, &apos;betty&apos;: 1, &apos;bit&apos;: 1, &apos;was&apos;: 1, &apos;the&apos;: 1, &apos;bought&apos;: 1}) 这个形式应该就是我们后续要介绍的dict字典类型，我们需要把它转换为列表 cnt.items() 转换了之后，我们还需要做哪些处理呢？ [(&apos;a&apos;, 1), (&apos;butter&apos;, 2), (&apos;bitter&apos;, 1), (&apos;of&apos;, 1), (&apos;but&apos;, 1), (&apos;betty&apos;, 1), (&apos;bit&apos;, 1), (&apos;was&apos;, 1), (&apos;the&apos;, 1), (&apos;bought&apos;, 1)] 看看题目的要求，统计次数多的在前，一是数值大的要靠前站；另外就是数值一样，按照字典顺序，a-z这种排列一下。 这里我就考虑使用这种顺序尝试一下咯。 先根据字典顺序，排列一下 sorted(a,key=lambda a:a[0],reverse=False) 这个是正常的升序排列，得到结果： [(&apos;a&apos;, 1), (&apos;betty&apos;, 1), (&apos;bit&apos;, 1), (&apos;bitter&apos;, 1), (&apos;bought&apos;, 1), (&apos;but&apos;, 1), (&apos;butter&apos;, 2), (&apos;of&apos;, 1), (&apos;the&apos;, 1), (&apos;was&apos;, 1)] 接下来就是把数值大的调到前面去，也就是比较一下第二个值，按照降序排列处理一下 from operator import itemgetter sorted(b,key=itemgetter(1),reverse=True) 这样就基本实现了对列表里的排序，接着分片处理下就达到了题目要求。 这个方案是我的初步方案，可能不是最简便的，供大家参考下，嘻嘻。 列表还有一个操作就是实现堆栈和队列，这个在大学的数据结构课程有简单接触的，问题就是很多只知道大概了啊。。 堆栈就是后进先出 队列则是先进先出使用列表的append（）和pop（）操作可以模拟这两个数据结构append（）可以把一个元素添加到堆栈的顶部，pop（）把堆栈的最后一个元素弹出来。 队列的不同之处在于弹出时参数设置不一样，pop（－1）弹出第一个元素 ##字典 字典也是较为常见的，也是比较的重要的数据结构。key-value这种键值对，也是数据库的一种基本模式。 字典是花括号｛｝ 这里需要注意一下，键是区分大小写的。一般而言，创建字典时，可以使用数字作为索引。键值对这种结构， value=dict[key] 说下字典的遍历： for (k,v) in dict.items(): print (&quot;dict[%s] =&quot;% k,v) 值也可以是字典 元组 或者是字典，这种称为混合型字典。字典有这么些方法： keys（） 返回keys列表value（）返回value列表get（）get（）访问字典中的value值减少了代码的长度，而且表达方式容易理解，避免了使用if语句带来的维护代价。update（）update（）函数相当于一个合并函数，把一个字典的key和value值全部复制到另外一个字典中。D.update(E) -&gt; None 把字典E的内容合并到字典D中，有相同的键值，e的值会覆盖d的。setdefault（）可以创建新的元素并设置默认值，声明如下： D.setdefault(k,[d]) -&gt; D.get(k,[d]) 还有一些常用方法：items（） 返回（key，value）元组组成的列表iteritems（） 返回指向字典的遍历器 字典还有排序和复制 排序的话和列表的差不多 print （sorted(dict.items(), key=lambda d:d[0])） 这是按照key排序 前面提到的update函数，比如把a字典的内容复制到b字典，并且b字典原有的顺序保持不变，从而实现字典b的扩展。但是，如果需要把a的内容复制到b，并且清除b中的原有内容的话，则需要使用copy（）。 copy（）是浅拷贝还有deepcopy（）是深拷贝 深拷贝能够拷贝对象内部所有的数据和引用，很像c语言中的指针。字典b浅拷贝a的数据，如何b的数据发生添加 删除或者修改，a中的数据也将发生变化。如果是深拷贝，a的数据是不会受到b的变化而变化的。 深拷贝和浅拷贝适用于python的任何对象，不只是局限于字典。 另外，还有全局字典 sys.modules模块，这个字典是python启动时就加载在内存当中的，这个起到缓存的作用。 ##序列 序列是具有索引和切片能力的集合，元组 列表 字符串都属于序列。 这里主要是元组和列表的区别。 元组是只读的，而且元组没有提供排序和查找的方法。列表可读写，而且提供丰富的操作，支持排序 查找。元组的数据通常具有不同的含义，而列表的数据通常具有相同的含义。相同之处则是都支持负数索引和分片的操作。 每天能适当做一些自己的总结，对于知识的掌握还是很有好处的。希望自己能够好好坚持。有目标的人咋个说呢？今天看到一个前辈说，真正的牛人也许一辈子只投4次简历。你就错过了毕业就去好公司的机会，所以需要更加努力学习。对于初级的程序员来说，很想做出一点东西来，但是又不知道哪些重要哪些不重要，到底该学到什么程度，不知道导致不确定，不确定导致决策瘫痪，干脆就啥也不动，整年整年苦闷的像没头苍蝇一样到处乱撞，荒废时间。 今年不论在哪里工作，决定給自己设定一个目标，在博客上写下52篇博客，虽然前期可能借鉴他人的经验较多，但是希望自己还是能保持到平均一周一篇的水平，不断写写写去积累。 周博客这里可能局限于一些技术见闻，所见所感这块，另外希望自己能写下10篇左右的读书笔记。 没有什么面试比持续两年的面试更具有信息量，书单加上github。]]></content>
  </entry>
  <entry>
    <title><![CDATA[macdown语法简介]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F15%2Fmacdown%E8%AF%AD%E6%B3%95%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[#markdown语法简介 1.标题1）使用＝和－标记一级和二级标题使用方法是文字下方加上＝＝＝＝＝＝这样 一级标题 2） 使用＃，可以表示1-6级标题 ##二级标题 2.段落段落的前后要有空行，所谓的空行是指没有文字内容。若想在段内强制换行的方式是使用两个以上空格加上回车（引用中换行省略回车）。 3.区块引用在段落的每行或者只在第一行使用符号&gt;,还可以使用多个嵌套引用，如： 区块引用 嵌套引用 4.代码区块代码区块的建立是在每行加上4个空格或者一个制表符（如同写代码一样）。如普通段落： void main() { printf(&quot;Hello, Markdown.&quot;); } 注意:需要和普通段落之间存在空行。 5.强调在强调内容两侧分别加上或者_，如： , 还是斜体 粗体， 还是粗体 6.列表使用*、+、或-标记无序列表，如： 为什么 怎么办 啥时候 有序列表的标记方式是将上述的符号换成数字,并且加上点 第一点 7.分割线 分割线最常使用就是三个或以上*，还可以使用_。 大道至简 道法三千 杏杏冥冥 8.链接链接可以由两种形式生成：行内式和参考式。 行内式：markdown库 参考式：younghz的Markdown库1younghz的Markdown库2 9.图片 添加图片的形式和链接相似，只需在链接的基础上前方加一个！。10.反斜杠\ 相当于反转义作用。使符号成为普通符号。 11.符号`` 起到表记作用。如： ctrl+a 12.表格 Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1]]></content>
  </entry>
  <entry>
    <title><![CDATA[爬虫实践教程3-多进程]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F15%2F%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5%E6%95%99%E7%A8%8B3-%E5%A4%9A%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[python爬虫多数都是运行在linux内核的服务器上的，多进程比多线程更合适，调度开销差不多，但是进程性能更好。爬虫不是服务器交互，一般情况下提升几倍效率即可。 直接来看看代码 12345678910111213141516171819202122232425262728293031323334353637383940#coding:utf-8import multiprocessingfrom bs4 import BeautifulSoupimport requests#url详情页def pageUrls(url): web_data = requests.get(url) soup = BeautifulSoup(web_data.text, 'lxml') sum = int(soup.select('span.total &gt; em:nth-of-type(1)')[0].get_text()) pageNum = sum/50 return [url+'/loupan/s?p=&#123;&#125;'.format(str(i)) for i in range(1, pageNum+2, 1)]def detailPage(myurl): urls = pageUrls(myurl) for url in urls: web_data = requests.get(url) soup = BeautifulSoup(web_data.text, 'lxml') titles = soup.select('div.list-results &gt; div.key-list &gt; div &gt; div.infos &gt; div &gt; h3 &gt; a') for title in titles: print url print title.get_text() print title.get('href') print "**********"def main(urls): pool = multiprocessing.Pool(multiprocessing.cpu_count()) for url in urls: pool.apply_async(detailPage, (url, )) # pool.map(detailPage, urls) pool.close() pool.join()if __name__ == "__main__": startUrl = 'http://gz.fang.anjuke.com/?from=navigation' web_data = requests.get(startUrl) soup = BeautifulSoup(web_data.text, 'lxml') urls = [url.get('href') for url in soup.select('.city-mod &gt; dl &gt; dd &gt; a')] main(urls) 这次我们准备爬取的是安居客的网站。先从主代码开始，startUrl，使用requests和beautifulsoup进行解析。获取地址之后，进入main函数。multiprocessing 创建一个进程池，进程个数为cpu内核数，一般写4或6个即可。apply_async函数从进程池中取出一个进程执行func，args为func的参数，我们这段代码不断地从进程池中取出进程去执行我们的detailPage方法。当然，也可以采用下面这种方式： pool.map(detailPage, urls) 接着就是关闭进程池还有wait进程池中的全部进程。]]></content>
      <categories>
        <category>pachong</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫实践教程2]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F15%2F%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5%E6%95%99%E7%A8%8B2%2F</url>
    <content type="text"><![CDATA[这里先介绍一下，我们使用工具selenium和Phantomjs来配合抓取。安装的话， 直接 pip install -U selenium 而Phantomjs则通过brew来安装，不细说。 brew install phantomjs 选择原因：Phantomjs是基于webkit的没有界面的浏览器，可以像浏览器一样解析网页，个人感觉的效果比firefox和chrome稍微快些。selenium是web的自动测试工具，可以模拟人的操作。几乎支持市面上所有的主流浏览器。 来看看代码 123456789101112131415161718192021222324252627282930#coding:utf-8import unittestfrom selenium import webdriverfrom bs4 import BeautifulSoupclass seleniumTest(unittest.TestCase): def setUp(self): self.driver = webdriver.PhantomJS() def testEle(self): driver = self.driver driver.get('http://www.douyu.com/directory/all') soup = BeautifulSoup(driver.page_source, 'xml') while True: titles = soup.find_all('h3', &#123;'class': 'ellipsis'&#125;) nums = soup.find_all('span', &#123;'class': 'dy-num fr'&#125;) for title, num in zip(titles, nums): print title.get_text(), num.get_text() if driver.page_source.find('shark-pager-disable-next') != -1: break elem = driver.find_element_by_class_name('shark-pager-next') elem.click() soup = BeautifulSoup(driver.page_source, 'xml') def tearDown(self): print 'down'if __name__ == "__main__": unittest.main() 这里一些概念说明：1.unittest 单元测试，简单的测试用例。以setup开头，中间测试的方法以test开头，测试完成之后会有一个teardown。2.斗鱼tv是看直播时较常去的，直接用浏览器打开 斗鱼网页源码中可以直接看到房间的信息，返回的不是json格式而是html，直接使用phantomjs模拟浏览器的访问过程，通过driver.get方法获取浏览器加载完成后的代码，无论是否是异步，取到的source都是和在浏览器中看到的完全一样！ 这里lxml方式有数据丢失，原因未知。。后来尝试了xml无误，暂时不知原因。。 还有对比之前的瓜子和果壳，我们只从中抓取了部分页面。这里抓取全部我们需要加上条件判断，最后一页时斗鱼下一页的标签会变灰，这个时候我们就加上这个跳出循环。 if driver.page_source.find(&apos;shark-pager-disable-next&apos;) != -1: break 还有这里 elem = driver.find_element_by_class_name(&apos;shark-pager-next&apos;) elem.click() soup = BeautifulSoup(driver.page_source, &apos;xml&apos;) 第一行代码是webdriver里面带有的定位标签的方法，直接使用class来定位，取到这个控件，然后执行element的click（）方法模拟鼠标的点击，页面会自动跳到下一页，接着解析网页的源码。 tips这里加上一点selenium的小操作编码学习的一个小突破感觉就是不断滴回顾学习吧，有些看完文档之后，觉得是这样没错，可是不久就好像啥也不剩了，在基础阶段模范性学习当中，要不断深化下已经学到的东西，适当做些归纳总结会很好。 填入表单数据 #coding:utf-8 from selenium import webdriver from selenium.webdriver.common.keys import Keys driver = webdriver.Firefox() driver.get(&apos;https://www.baidu.com/&apos;) elem = driver.find_element_by_id(&apos;kw&apos;) elem.send_keys(u&apos;爬虫&apos;) elem.send_keys(Keys.RETURN) print(driver.page_source) 滚动页面至最下方 #coding:utf-8 from selenium import webdriver import time driver = webdriver.Firefox() driver.get(&apos;http://www.jianshu.com/collections&apos;) time.sleep(1) for i in range(10): dirver.execute_script(&apos;window.scrollTo(0,document.body.scrollHeight)&apos;) time.sleep(1)]]></content>
      <categories>
        <category>pachong</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫实践教程1]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F15%2F%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5%E6%95%99%E7%A8%8B1%2F</url>
    <content type="text"><![CDATA[一般来说呢，很多网页都是直接分好页面直接下一页这样。不过还有很多网页是ajax异步请求数据的网页，以果壳网为例，我们尝试一下抓取。 # coding:utf-8 from bs4 import BeautifulSoup import requests import json import pymongo url = &apos;http://www.guokr.com/scientific/&apos; def dealData(url): client = pymongo.MongoClient(&apos;localhost&apos;, 27017) guoke = client[&apos;guoke&apos;] guokeData = guoke[&apos;guokeData&apos;] web_data = requests.get(url) datas = json.loads(web_data.text) print datas.keys() for data in datas[&apos;result&apos;]: guokeData.insert_one(data) def start(): urls = [&apos;http://www.guokr.com/apis/minisite/article.json?retrieve_type=by_subject&amp;limit=20&amp;offset={}&amp;_=1462252453410&apos;.format(str(i)) for i in range(20, 100, 20)] for url in urls: dealData(url) start() &apos;&apos;&apos; 异步加载的网站 这里比如果壳网的抓取 &apos;&apos;&apos; 网页的抓取大概流程就是这样：1.使用谷歌或者火狐浏览器，检查元素，分析下我们想抓取什么，有啥子障碍。2.异步加载的数据不在返回的网页源码中，在网络标签和xhr分页面，向下滑动鼠标可以发现新的get请求被列出来。偏移量是多少，需要好好总结规律，然后不断尝试。]]></content>
      <categories>
        <category>pachong</category>
      </categories>
      <tags>
        <tag>python, requests</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫实践教程0]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F15%2F%E7%88%AC%E8%99%AB%E5%AE%9E%E8%B7%B5%E6%95%99%E7%A8%8B0%2F</url>
    <content type="text"><![CDATA[爬虫的基本就是从网页上获取我们需要的信息。 # coding=utf-8 from bs4 import BeautifulSoup import requests from pymongo import MongoClient client = MongoClient(&apos;localhost&apos;,27017) db = client[&apos;guazigz&apos;] item_info = db[&apos;item_info&apos;] def detailOper(url): web_data = requests.get(url) web_data.encoding=&apos;utf-8&apos; soup = BeautifulSoup(web_data.text, &apos;lxml&apos;) titles = soup.select(&apos;div.list &gt; ul &gt; li &gt; div &gt; p.infoBox &gt; a&apos;) prices = soup.select(&apos;div.list &gt; ul &gt; li &gt; div &gt; p.priType-s &gt; span &gt; i.fc-org.priType&apos;) for title, price in zip(titles, prices): data = { &apos;title&apos;: title.get_text(), &apos;detailHerf&apos;: title.get(&apos;href&apos;), &apos;price&apos;:price.get_text().replace(u&apos;万&apos;, &apos;&apos;).replace(&apos; &apos;,&apos;&apos;).replace(&apos;\n&apos;,&apos;&apos;) } item_info.insert_one(data) print(data) def start(): urls = [&apos;http://www.guazi.com/gz/buy/o{}/&apos;.format(str(i)) for i in range(1, 30, 1)] for url in urls: detailOper(url) if __name__ == &apos;__main__&apos;: start() 如上的程序相对来说很好阅读， 从瓜子二手车网站抓取了29页数据，每页40条，共1160条数据存入到名为guazigz的mongo数据库中。集合名为item_info,注意一下，print（data）是为了能清晰显示数据，实际是可以删除注释掉的。]]></content>
      <categories>
        <category>pachong</category>
      </categories>
      <tags>
        <tag>requests, python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F15%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fzhangdavids.github.io%2F2016%2F05%2F12%2Fmongo%E5%B0%8F%E8%AF%95%2F</url>
    <content type="text"><![CDATA[#MongoDB的一些小结 ##强大 灵活 可扩展1.扩展了关系型数据库的辅助索引 范围查询（range query）和排序。内置的对MapReduce式聚合的支持，以及对地理空间索引的支持。 2.面向文档的数据库，思路首先就是将原来的“行”（row）的概念换成更加灵活的“文档”（documents）。面向文档的方式可以将文档或者数组内嵌进来，所以用一条记录就可以表示非常复杂的层次关系。这对于面向对象语言的开发者来说，是非常自然的事情。 我们先来看看一些常见的操作命令首先进入命令行之后默认的是test数据库，一般而言我们首先需要切换到我们需要的数据库，比如这里举例一下 guazigzuse guazigz再来详细学习 一.数据库常用命令 1.help查看命令提示 help db.help(); db.yourColl.help(); db.youColl.find().help(); rs.help(); 这里的youColl换成你数据库里对应的集合（Collection）即可 2.查询数据库 show dbs; 3.删除当前使用数据库 db.dropDatabase(); 4.从指定的主机上克隆数据库 db.cloneDatabase(&quot;127.0.0.1&quot;); 5.从指定的机器上复制指定数据库数据到某个数据库 db.copyDatabase(&quot;mydb&quot;,&quot;temp&quot;,&quot;127.0.0.1&quot;) 6.修复当前数据库 db.repairDatabase(); 7.查看当前使用的数据库 db.getName(); db; 8.显示当前db状态 db.stats(); 9.查看当前db的链接机器地址 db.getMongo(); 二.Collection聚集集合1.创建一个聚集集合（table） db.createCollection(“collName”, {size: 20, capped: 5, max: 100});//创建成功会显示{“ok”:1} //判断集合是否为定容量db.collName.isCapped(); 2.得到指定名称 db.getCollection(&quot;account&quot;); 3.得到当前db的所有集合 db.getCollectionNames(); 4.显示当前db所有聚集索引的状态 db.printCollectionStats(); 三.用户相关1.添加一个用户 db.addUser(&quot;name&quot;); db.addUser(&quot;userName&quot;, &quot;pwd123&quot;, true); //添加用户、设置密码、是否只读 2.数据库认证 安全模式 db.auth(&quot;userName&quot;, &quot;123123&quot;); 3.显示当前所有用户 show users； 4.删除用户 db.removeUser(&quot;userName&quot;); 四.聚合集合查询 1.查询所有记录 db.userInfo.find(); //相当于： select* from userInfo; 默认每页显示20条记录，当显示不下的情况下，可以用it迭代命令查询下一页数据。注意：键入it命令不能带“；”但是你可以设置每页显示数据的大小，用DBQuery.shellBatchSize= 50;这样每页就显示50条记录了。 2.查询去掉后的当前聚集集合中的某列的重复数据 db.userInfo.distinct(&quot;name&quot;); //会过滤掉name中的相同数据 //相当于：select distict name from userInfo; 3.查询数值范围内数据 db.userInfo.find({age: {$gte: 23, $lte: 26}}); //大于等于23，小于等于26 4.查询name中包含mongo的数据 db.userInfo.find({name: /mongo/}); //相当于%% [code]select * from userInfo where name like ‘%mongo%&apos;; 5.查询name中以mongo开头的 db.userInfo.find({name: /^mongo/}); //select * from userInfo where name like ‘mongo%&apos;; 6.查询指定列name age数据 db.userInfo.find({}, {name: 1, age: 1}); //相当于：select name, age from userInfo; 7.查询前5条数据 db.userInfo.find().limit(5); //相当于：selecttop 5 * from userInfo; 8.查询10条以后的数据 db.userInfo.find().skip(10); //相当于：select * from userInfo where id not in ( selecttop 10 * from userInfo ); 9.查询某个结果集的记录条数 db.userInfo.find({age: {$gte: 20}}).count(); //相当于：select count(*) from userInfo where age &gt;= 20; 10.按照某列进行排序 db.userInfo.find({sex: {$exists: true}}).count(); //相当于：select count(sex) from userInfo; 这一段里是比较重要的索引部分五.索引 (index)1.创建 db.userInfo.ensureIndex({name: 1}); db.userInfo.ensureIndex({name: 1, ts: -1}); 2.查询当前聚集集合所有索引 db.userInfo.getIndexes(); 3.查看总索引记录大小 db.userInfo.totalIndexSize(); 4.读取当前集合的所有index信息 db.users.reIndex(); 5.删除指定索引 db.users.dropIndex(&quot;name_1&quot;); 6.删除所有索引 db.users.dropIndexes(); 索引这块可能详细说，有很所需要注意的地方，要不断翻阅琢磨！ 这一段里是比较重要的索引部分 六. 修改 添加 删除集合数据 1.添加（save） db.users.save({name: ‘zhangsan&apos;, age: 25, sex: true}); //添加的数据的数据列，没有固定，根据添加的数据为准 2.修改（update） db.users.update({age: 25}, {$set: {name: &apos;changeName&apos;}}, false, true); //相当于：update users set name = ‘changeName&apos; where age = 25; db.users.update({name: &apos;Lisi&apos;}, {$inc: {age: 50}}, false, true); //相当于：update users set age = age + 50 where name = ‘Lisi&apos;; db.users.update({name: &apos;Lisi&apos;}, {$inc: {age: 50}, $set: {name: &apos;hoho&apos;}}, false, true); //相当于：update users set age = age + 50, name = ‘hoho&apos; where name = ‘Lisi&apos;; 3.删除（remove） db.users.remove({age: 132}); 4.查询修改删除 db.users.findAndModify({ query: {age: {$gte: 25}}, sort: {age: -1}, update: {$set: {name: &apos;a2&apos;}, $inc: {age: 2}}, remove: true }); db.runCommand({ findandmodify : &quot;users&quot;, query: {age: {$gte: 25}}, sort: {age: -1}, update: {$set: {name: &apos;a2&apos;}, $inc: {age: 2}}, remove: true }); 七.查看基本信息 查看聚集集合基本信息1、查看帮助 db.yourColl.help();2、查询当前集合的数据条数 db.yourColl.count();3、查看数据空间大小 db.userInfo.dataSize();4、得到当前聚集集合所在的db db.userInfo.getDB();5、得到当前聚集的状态 db.userInfo.stats();6、得到聚集集合总大小 db.userInfo.totalSize();7、聚集集合储存空间大小 db.userInfo.storageSize();8、Shard版本信息 db.userInfo.getShardVersion();9、聚集集合重命名 db.userInfo.renameCollection(“users”); //将userInfo重命名为users10、删除当前聚集集合 db.userInfo.drop(); show dbs:显示数据库列表 show collections：显示当前数据库中的集合（类似关系数据库中的表） show users：显示用户 use &lt;db name&gt;：切换当前数据库，这和MS-SQL里面的意思一样 db.help()：显示数据库操作命令，里面有很多的命令 db.foo.help()：显示集合操作命令，同样有很多的命令，foo指的是当前数据库下，一个叫foo的集合，并非真正意义上的命令 db.foo.find()：对于当前数据库中的foo集合进行数据查找（由于没有条件，会列出所有数据） db.foo.find( { a : 1 } )：对于当前数据库中的foo集合进行查找，条件是数据中有一个属性叫a，且a的值为1]]></content>
  </entry>
</search>
